{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08cf9338",
   "metadata": {},
   "source": [
    "# Evaluate Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646d3e0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c3f67",
   "metadata": {},
   "source": [
    "#### Load the API key and libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5914d9f9",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from src.Language_Evaluation import llm_language_evaluation\n",
    "from src.data_analysis import run_analysis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6cc1c",
   "metadata": {
    "height": 30
   },
   "source": [
    "#### Load the Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee875ae",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "PATH = 'data/Portuguese.csv'\n",
    "MODEL = \"Llama-2-13b\"\n",
    "TEMPERATURE = 0.7\n",
    "N_REPETITIONS = 10\n",
    "REASONING = False\n",
    "LANGUAGES = ['english', 'portuguese']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded1020",
   "metadata": {},
   "source": [
    "#### Run The Experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa463d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The model file 'Models/Llama-2-13b.gguf' already exists. Do you want to overwrite it? (yes/no):  No\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model installation aborted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from Models/Llama-2-13b.gguf (version GGUF V2 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q8_0     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:             blk.15.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:             blk.15.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.2.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:            blk.2.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.2.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.2.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.2.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:              blk.2.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:         blk.2.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.2.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.2.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.3.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:            blk.3.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.3.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.3.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.3.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:              blk.3.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:         blk.3.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.3.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.3.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.4.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:            blk.4.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.4.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.4.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.4.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:              blk.4.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:         blk.4.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:              blk.4.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:              blk.4.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.5.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:            blk.5.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:            blk.5.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:              blk.5.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:            blk.5.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:              blk.5.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:         blk.5.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:              blk.5.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:              blk.5.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.6.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:            blk.6.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:            blk.6.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:              blk.6.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:            blk.6.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:              blk.6.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:         blk.6.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:              blk.6.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:              blk.6.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:           blk.7.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:            blk.7.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.7.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.7.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:            blk.7.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.7.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:         blk.7.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:              blk.7.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:              blk.7.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.8.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:            blk.8.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:            blk.8.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:              blk.8.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:            blk.8.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:              blk.8.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:         blk.8.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:              blk.8.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:              blk.8.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.9.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:            blk.9.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:            blk.9.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:              blk.9.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:            blk.9.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:              blk.9.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:         blk.9.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:              blk.9.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:              blk.9.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:          blk.15.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:           blk.15.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:        blk.15.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.15.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.16.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.16.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.16.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.16.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:          blk.17.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:           blk.17.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:           blk.17.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:        blk.17.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:             blk.17.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:             blk.17.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.18.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:        blk.18.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:             blk.18.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:             blk.18.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.19.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:        blk.19.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:             blk.19.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:             blk.19.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.20.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:        blk.20.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:             blk.20.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.20.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:          blk.21.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:           blk.21.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:           blk.21.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:             blk.21.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:        blk.21.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:             blk.21.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:             blk.21.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.22.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:        blk.22.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:             blk.22.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.23.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:        blk.23.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:             blk.23.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.24.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:        blk.24.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:             blk.24.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.25.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:        blk.25.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:             blk.25.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:          blk.26.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:           blk.26.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:             blk.26.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:        blk.26.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:             blk.26.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:           blk.27.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:             blk.27.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:        blk.27.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:             blk.27.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.28.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:             blk.28.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:        blk.28.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:             blk.28.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:           blk.29.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:             blk.29.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:        blk.29.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:             blk.29.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:                    output.weight q8_0     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:          blk.32.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  291:           blk.32.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  292:           blk.32.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  293:             blk.32.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  294:           blk.32.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  295:             blk.32.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  296:        blk.32.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  297:             blk.32.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  298:             blk.32.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  299:          blk.33.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  300:           blk.33.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  301:           blk.33.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  302:             blk.33.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  303:           blk.33.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  304:             blk.33.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  305:        blk.33.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  306:             blk.33.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  307:             blk.33.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  308:          blk.34.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  309:           blk.34.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  310:           blk.34.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  311:             blk.34.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  312:           blk.34.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  313:             blk.34.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  314:        blk.34.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  315:             blk.34.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  316:             blk.34.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  317:          blk.35.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  318:           blk.35.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  319:           blk.35.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  320:             blk.35.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  321:           blk.35.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  322:             blk.35.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  323:        blk.35.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  324:             blk.35.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  325:             blk.35.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  326:          blk.36.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  327:           blk.36.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  328:           blk.36.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  329:             blk.36.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  330:           blk.36.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  331:             blk.36.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  332:        blk.36.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  333:             blk.36.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  334:             blk.36.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  335:          blk.37.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  336:           blk.37.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  337:           blk.37.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  338:             blk.37.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  339:           blk.37.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  340:             blk.37.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  341:        blk.37.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  342:             blk.37.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  343:             blk.37.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  344:          blk.38.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  345:           blk.38.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  346:           blk.38.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  347:             blk.38.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  348:           blk.38.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  349:             blk.38.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  350:        blk.38.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  351:             blk.38.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  352:             blk.38.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  353:          blk.39.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  354:           blk.39.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  355:           blk.39.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  356:             blk.39.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  357:           blk.39.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  358:             blk.39.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  359:        blk.39.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  360:             blk.39.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  361:             blk.39.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  362:               output_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                          general.file_type u32     \n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  18:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q8_0:  282 tensors\n",
      "llm_load_print_meta: format           = GGUF V2 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = mostly Q8_0\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 12.88 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name   = LLaMA v2\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.12 MB\n",
      "llm_load_tensors: mem required  = 13189.98 MB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  =  400.00 MB\n",
      "llama_new_context_with_model: compute buffer total size = 80.88 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Question 1: \n",
      "Language: english\n",
      "Question: \n",
      "In which ocular region are caliciform cells physiologically found?\n",
      "a) Cornea.\n",
      "b) Corneoscleral limbus.\n",
      "c) Gray line.\n",
      "d) Semilunar fold.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    27 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3616.50 ms /   200 tokens (   18.08 ms per token,    55.30 tokens per second)\n",
      "llama_print_timings:        eval time =  3135.57 ms /    26 runs   (  120.60 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  6831.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.21 ms /    21 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2546.53 ms /    21 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2606.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.78 ms /    36 runs   (    0.58 ms per token,  1732.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4414.04 ms /    36 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4517.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3271.69 ms /    27 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3348.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.57 ms /     7 runs   (  120.37 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   861.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1727.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2914.70 ms /    24 runs   (  121.45 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2981.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.57 ms /    27 runs   (    0.58 ms per token,  1734.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3254.69 ms /    27 runs   (  120.54 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  3331.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   839.41 ms /     7 runs   (  119.92 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.36 ms /    25 runs   (    0.57 ms per token,  1740.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3032.74 ms /    25 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3103.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    27 runs   (    0.58 ms per token,  1730.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.00 ms /    27 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3375.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Em qual região ocular células caliciformes são fisiologicamente encontradas?\n",
      "a)Córnea.\n",
      "b)Limbo corneoescleral.\n",
      "c)Linha cinzenta.\n",
      "d)Prega semilunar.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.29 ms /    12 runs   (    0.61 ms per token,  1645.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1588.30 ms /    63 tokens (   25.21 ms per token,    39.66 tokens per second)\n",
      "llama_print_timings:        eval time =  1333.49 ms /    11 runs   (  121.23 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2956.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.29 ms /     7 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   873.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.59 ms /     7 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   871.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.61 ms /    36 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4383.94 ms /    36 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4485.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.93 ms /     7 runs   (  123.99 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   886.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.09 ms /     7 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   884.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.46 ms /     7 runs   (  120.49 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   862.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.72 ms /    40 runs   (    0.57 ms per token,  1760.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4887.22 ms /    40 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4999.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.41 ms /    32 runs   (    0.58 ms per token,  1737.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3932.01 ms /    32 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4022.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.93 ms /    12 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1469.63 ms /    12 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1503.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 2: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the alternative that best correlates the histological characteristics with the respective ocular tissues:\n",
      "\n",
      "I. Monolayer of cells tightly joined together by junctional complexes.\n",
      "II. Parallel and regular striations observed under optical microscopy, perpendicular to the epithelium.\n",
      "III. It contains bipolar cells, amacrine cells, horizontal cells and Muller cells.\n",
      "IV. It contains magnocellular, parvocellular and coniocellular cells.\n",
      "\n",
      "A. Photoreceptors.\n",
      "B. Retinal pigmented epithelium.\n",
      "C. Retinal ganglionic layer.\n",
      "D. Inner nuclear layer.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.25 ms /    39 runs   (    0.57 ms per token,  1752.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2497.29 ms /   158 tokens (   15.81 ms per token,    63.27 tokens per second)\n",
      "llama_print_timings:        eval time =  4650.78 ms /    38 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7259.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.13 ms /    39 runs   (    0.57 ms per token,  1762.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4758.35 ms /    39 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4869.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.12 ms /    39 runs   (    0.57 ms per token,  1762.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4763.55 ms /    39 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4875.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    90.25 ms /   157 runs   (    0.57 ms per token,  1739.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19474.11 ms /   157 runs   (  124.04 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 19938.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.40 ms /    39 runs   (    0.57 ms per token,  1741.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4822.94 ms /    39 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4934.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.70 ms /   145 runs   (    0.58 ms per token,  1732.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17839.76 ms /   145 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18267.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n",
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.12 ms /    96 runs   (    0.58 ms per token,  1710.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11788.21 ms /    96 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 12068.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.61 ms /   107 runs   (    0.58 ms per token,  1736.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13165.58 ms /   107 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 13523.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.20 ms /    39 runs   (    0.57 ms per token,  1756.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4757.38 ms /    39 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4869.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.91 ms /    58 runs   (    0.58 ms per token,  1710.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7219.95 ms /    58 runs   (  124.48 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  7388.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que melhor correlaciona as características histológicas com os respectivos tecidos oculares:\n",
      "\n",
      "I. Monocamada de células fortemente unidas por complexos juncionais.\n",
      "II. Estriações paralelas e regulares observadas à microscopia óptica, perpendiculares ao epitélio.\n",
      "III. Contém células bipolares, células amácrinas, células horizontais e células de Muller.\n",
      "IV. Contém células magnocelulares, parvocelulares e coniocelulares.\n",
      "\n",
      "A. Fotorreceptores.\n",
      "B. Epitélio pigmentado da pigmentado da retina.\n",
      "C. Camada ganglionar retiniana.\n",
      "D. Camada nuclear interna.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.37 ms /    64 runs   (    0.58 ms per token,  1712.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3810.76 ms /   196 tokens (   19.44 ms per token,    51.43 tokens per second)\n",
      "llama_print_timings:        eval time =  7840.10 ms /    63 runs   (  124.45 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 11838.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.53 ms /     7 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    99.05 ms /   171 runs   (    0.58 ms per token,  1726.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21104.02 ms /   171 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 21617.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.37 ms /    11 runs   (    0.58 ms per token,  1727.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1346.01 ms /    11 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1377.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.84 ms /    94 runs   (    0.58 ms per token,  1713.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11621.04 ms /    94 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 11900.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.91 ms /   125 runs   (    0.58 ms per token,  1714.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15410.08 ms /   125 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 15782.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1729.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.08 ms /     7 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.48 ms /    41 runs   (    0.57 ms per token,  1746.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5012.41 ms /    41 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5129.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3474.30 ms /    28 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3554.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.60 ms /     7 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   876.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 3: \n",
      "Language: english\n",
      "Question: \n",
      "Order the three cell names found in the corneal epithelium, starting with the most superficial, followed by the intermediate and the deep.\n",
      "a) Flat, wing, basal.\n",
      "b) wing, basal, flat.\n",
      "c) Basal, flat, wing.\n",
      "d) wing, flat, basal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    25 runs   (    0.56 ms per token,  1797.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1570.68 ms /    79 tokens (   19.88 ms per token,    50.30 tokens per second)\n",
      "llama_print_timings:        eval time =  2926.28 ms /    24 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4569.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.98 ms /    73 runs   (    0.58 ms per token,  1738.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8837.59 ms /    73 runs   (  121.06 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  9051.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.54 ms /    68 runs   (    0.57 ms per token,  1764.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8282.72 ms /    68 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  8480.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.48 ms /    33 runs   (    0.56 ms per token,  1785.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4087.59 ms /    33 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4181.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    25 runs   (    0.55 ms per token,  1819.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3035.80 ms /    25 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3105.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.67 ms /    25 runs   (    0.55 ms per token,  1829.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3034.73 ms /    25 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3105.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.80 ms /    36 runs   (    0.55 ms per token,  1818.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4339.93 ms /    36 runs   (  120.55 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  4442.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.48 ms /    35 runs   (    0.56 ms per token,  1796.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4255.24 ms /    35 runs   (  121.58 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4354.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.54 ms /    25 runs   (    0.54 ms per token,  1846.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3064.23 ms /    25 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3133.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.40 ms /    35 runs   (    0.55 ms per token,  1804.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4340.52 ms /    35 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  4442.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Ordene as três denominações celulares encontradas no epitélio da córnea, iniciando pelo mais superficial, seguido do intermediário e do profundo.\n",
      "a)Plana, alada, basal.\n",
      "b)Alada, basal, plana.\n",
      "c)Basal, plana, alada.\n",
      "d)Alada, plana, basal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.33 ms /    82 runs   (    0.58 ms per token,  1732.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1581.18 ms /    96 tokens (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:        eval time =  9911.43 ms /    81 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 11733.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.90 ms /    37 runs   (    0.56 ms per token,  1770.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4457.60 ms /    37 runs   (  120.48 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  4562.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.86 ms /    28 runs   (    0.57 ms per token,  1765.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3393.68 ms /    28 runs   (  121.20 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3473.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.21 ms /    20 runs   (    0.56 ms per token,  1783.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2453.50 ms /    20 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2509.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.01 ms /    30 runs   (    0.57 ms per token,  1763.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3660.43 ms /    30 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3744.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.42 ms /    36 runs   (    0.57 ms per token,  1762.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4434.41 ms /    36 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4537.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.77 ms /    94 runs   (    0.57 ms per token,  1748.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11485.01 ms /    94 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 11756.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.36 ms /    20 runs   (    0.57 ms per token,  1761.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2452.06 ms /    20 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2508.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.56 ms /    29 runs   (    0.57 ms per token,  1751.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3527.72 ms /    29 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3609.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   125.03 ms /   217 runs   (    0.58 ms per token,  1735.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26535.61 ms /   217 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 27188.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 4: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding Descemet's membrane of the cornea, it is correct to state:\n",
      "a) Endothelial cells do not participate in its formation.\n",
      "b) Its thickness in the adult is about 30 µm.\n",
      "c) Its most anterior portion is of embryonic origin.\n",
      "d) Its thickness reduces with age.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.43 ms /    24 runs   (    0.60 ms per token,  1663.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1910.71 ms /    83 tokens (   23.02 ms per token,    43.44 tokens per second)\n",
      "llama_print_timings:        eval time =  2801.20 ms /    23 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4782.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.02 ms /    40 runs   (    0.58 ms per token,  1737.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4846.27 ms /    40 runs   (  121.16 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4960.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.95 ms /    68 runs   (    0.57 ms per token,  1745.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8226.88 ms /    68 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  8423.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.35 ms /    25 runs   (    0.57 ms per token,  1742.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3064.12 ms /    25 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3135.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.49 ms /    48 runs   (    0.57 ms per token,  1745.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5834.93 ms /    48 runs   (  121.56 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5971.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.83 ms /    17 runs   (    0.58 ms per token,  1729.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2071.06 ms /    17 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2119.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.63 ms /    29 runs   (    0.57 ms per token,  1744.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3533.33 ms /    29 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3615.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.77 ms /    24 runs   (    0.57 ms per token,  1743.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2898.96 ms /    24 runs   (  120.79 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2967.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.43 ms /    48 runs   (    0.57 ms per token,  1749.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5887.82 ms /    48 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6024.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.02 ms /    40 runs   (    0.58 ms per token,  1737.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4855.83 ms /    40 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4970.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a membrana de Descemet da córnea, é correto afirmar:\n",
      "a)As células endoteliais não participam da sua formação.\n",
      "b)Sua espessura no adulto é de cerca de 30 µm.\n",
      "c)Sua porção mais anterior é de origem embrionária.\n",
      "d)Sua espessura reduz-se com a idade.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.46 ms /     6 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1845.33 ms /   103 tokens (   17.92 ms per token,    55.82 tokens per second)\n",
      "llama_print_timings:        eval time =   660.78 ms /     5 runs   (  132.16 ms per token,     7.57 tokens per second)\n",
      "llama_print_timings:       total time =  2523.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {:response:\"A\"}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.63 ms /    58 runs   (    0.58 ms per token,  1724.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7099.03 ms /    58 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7269.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.94 ms /     7 runs   (    0.56 ms per token,  1774.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.96 ms /     7 runs   (  120.28 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   861.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   122.16 ms /   211 runs   (    0.58 ms per token,  1727.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25872.20 ms /   211 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 26513.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.92 ms /     7 runs   (    0.56 ms per token,  1787.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.08 ms /     7 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   871.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1765.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.96 ms /     7 runs   (  119.85 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.90 ms /     7 runs   (    0.56 ms per token,  1794.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.55 ms /     7 runs   (  119.79 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =   857.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.91 ms /     7 runs   (    0.56 ms per token,  1791.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.36 ms /     7 runs   (  121.34 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.87 ms /     7 runs   (    0.55 ms per token,  1806.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.68 ms /     7 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   875.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.89 ms /     7 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.26 ms /     7 runs   (  120.75 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   864.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.04 ms /    59 runs   (    0.58 ms per token,  1733.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7162.53 ms /    59 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  7332.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 5: \n",
      "Language: english\n",
      "Question: \n",
      "About the lipidic layer of the lacrimal film, choose the right answer. a) its purpose is to stabilize the lacrimal film secreted by the meibomian and manz glans b) Cholesterol esters are within its components, and one of the functions is to delay the lacrimal film evaporation c) In meibomian gland dysfunction, the fusion point decrease, leading to stagnation d) can be evaluated by the lacrimal film break up time, keeping intact less than five seconds in healthy eyes.\n",
      "Test #0: \n",
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.05 ms /    64 runs   (    0.58 ms per token,  1727.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2549.81 ms /   129 tokens (   19.77 ms per token,    50.59 tokens per second)\n",
      "llama_print_timings:        eval time =  7778.50 ms /    63 runs   (  123.47 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10514.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.87 ms /    64 runs   (    0.58 ms per token,  1735.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7789.21 ms /    64 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7973.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.51 ms /    77 runs   (    0.64 ms per token,  1555.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9542.95 ms /    77 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  9776.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.22 ms /    60 runs   (    0.64 ms per token,  1569.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7390.86 ms /    60 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7573.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.80 ms /    61 runs   (    0.67 ms per token,  1495.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7435.95 ms /    61 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  7624.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.20 ms /    61 runs   (    0.68 ms per token,  1480.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7424.91 ms /    61 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7619.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.67 ms /   107 runs   (    0.60 ms per token,  1654.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13093.62 ms /   107 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 13417.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n",
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.33 ms /    61 runs   (    0.58 ms per token,  1726.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7512.68 ms /    61 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7688.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.84 ms /    17 runs   (    0.58 ms per token,  1727.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2082.93 ms /    17 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2132.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.22 ms /    61 runs   (    0.58 ms per token,  1731.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7493.10 ms /    61 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7671.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a camada lipídica do filme lacrimal, assinale a alternativa correta. a)Tem por propósito básico estabilizar o filme e é secretada pelas glândulas de Meibomius e de Manz.  b)Ésteres de colesterol estão entre seus componentes e uma de suas funções é retardar a evaporação do filme lacrimal. c)Na disfunção das glândulas de Meibomius, o ponto de fusão de sua secreção diminui, colaborando para a estagnação dessas substâncias. d)Pode ser avaliada pelo tempo de ruptura do filme lacrimal, permanecendo intacta por menos de cinco segundos em olhos saudáveis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.16 ms /     7 runs   (    0.59 ms per token,  1681.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3175.39 ms /   183 tokens (   17.35 ms per token,    57.63 tokens per second)\n",
      "llama_print_timings:        eval time =   733.49 ms /     6 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3929.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.94 ms /    31 runs   (    0.58 ms per token,  1728.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3815.52 ms /    31 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3905.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1699.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.29 ms /     7 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   876.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1701.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.69 ms /     7 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   878.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.06 ms /     7 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   885.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    99.79 ms /   165 runs   (    0.60 ms per token,  1653.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20399.58 ms /   165 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 21102.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.51 ms /     7 runs   (    0.64 ms per token,  1550.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.19 ms /     7 runs   (  120.60 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   891.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.40 ms /     7 runs   (    0.63 ms per token,  1590.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.49 ms /     7 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   901.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   119.55 ms /   184 runs   (    0.65 ms per token,  1539.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22588.27 ms /   184 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 23874.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 6: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the external ocular muscles, choose the correct answer. a) in the Hering's law, the innervation is equally distributed to the agosist and antagonist muscles, for a given ocular version. b) The persecutory movements will automatically occur, slowly, with the displacement of the fixation point c) In the sherrington's law, the contraction stimulus is distributed between the agonists of both eyes, so that it occur symmetrically. d) Saccadic movements are characterized by abrupq, uncoordinated, reflex movments.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.49 ms /     7 runs   (    0.64 ms per token,  1559.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.96 ms /     7 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   897.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   149.36 ms /   230 runs   (    0.65 ms per token,  1539.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2621.36 ms /   137 tokens (   19.13 ms per token,    52.26 tokens per second)\n",
      "llama_print_timings:        eval time = 28294.96 ms /   229 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 32550.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.74 ms /    80 runs   (    0.66 ms per token,  1516.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9755.98 ms /    80 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 10301.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.09 ms /   111 runs   (    0.66 ms per token,  1518.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13669.01 ms /   111 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 14430.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.80 ms /    78 runs   (    0.65 ms per token,  1535.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9609.65 ms /    78 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 10139.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.68 ms /    24 runs   (    0.65 ms per token,  1531.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2929.95 ms /    24 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3090.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    71.19 ms /   109 runs   (    0.65 ms per token,  1531.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13429.68 ms /   109 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 14176.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.26 ms /    70 runs   (    0.58 ms per token,  1738.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8634.25 ms /    70 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  8836.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.01 ms /    83 runs   (    0.58 ms per token,  1728.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10253.03 ms /    83 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10497.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.48 ms /    70 runs   (    0.58 ms per token,  1729.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8662.86 ms /    70 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  8870.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.11 ms /    66 runs   (    0.58 ms per token,  1731.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8137.51 ms /    66 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  8329.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre os músculos oculares externos, assinale a alternativa correta.\n",
      "a)Na lei de Hering, a inervação se distribui igualmente para os músculos agonista e antagonista, para determinada versão.\n",
      "b)Os movimentos persecutórios se dão automaticamente, de maneira lenta, ao deslocamento do ponto de fixação.\n",
      "c)Na lei de Sherrington, o estímulo de contração é distribuído entre os agonistas de ambos os olhos, para que ela ocorra simetricamente.\n",
      "d)Os movimentos sacádicos são caracterizados por movimentos bruscos, descoordenados, de natureza totalmente reflexa.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.18 ms /     7 runs   (    0.60 ms per token,  1673.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3749.31 ms /   178 tokens (   21.06 ms per token,    47.48 tokens per second)\n",
      "llama_print_timings:        eval time =   733.47 ms /     6 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4503.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.12 ms /    47 runs   (    0.58 ms per token,  1733.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5802.17 ms /    47 runs   (  123.45 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  5938.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.55 ms /    79 runs   (    0.58 ms per token,  1734.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9760.49 ms /    79 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  9990.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.69 ms /    75 runs   (    0.58 ms per token,  1716.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9216.05 ms /    75 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  9433.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.81 ms /    64 runs   (    0.58 ms per token,  1738.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7867.78 ms /    64 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8052.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Os movimentos sacádicos são caracterizados por movimentos bruscos, descoordenados, de natureza totalmente reflexa.'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.58 ms /    67 runs   (    0.58 ms per token,  1736.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8314.18 ms /    67 runs   (  124.09 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  8508.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.18 ms /    47 runs   (    0.58 ms per token,  1729.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5971.68 ms /    47 runs   (  127.06 ms per token,     7.87 tokens per second)\n",
      "llama_print_timings:       total time =  6109.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.33 ms /   134 runs   (    0.58 ms per token,  1732.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16516.48 ms /   134 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16917.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.93 ms /    60 runs   (    0.58 ms per token,  1717.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7458.84 ms /    60 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  7634.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.09 ms /    76 runs   (    0.58 ms per token,  1723.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9423.94 ms /    76 runs   (  124.00 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  9647.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 7: \n",
      "Language: english\n",
      "Question: \n",
      "About the cornea, it is correct to state. a) The arrangement of corneal collagen fibrils is unrelated to its transparency. b) Pleomorphism of endothelial cells is characterized by the variation in the size of these cells. c) anterior stroma have a large number of mitochondria, responsible for the production of energy that supplies the endothelial pump. d) The endothelium behaves as a permeable non-selective barrier between the aqueous humor and the substantia propria.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.36 ms /    64 runs   (    0.58 ms per token,  1713.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2195.79 ms /   127 tokens (   17.29 ms per token,    57.84 tokens per second)\n",
      "llama_print_timings:        eval time =  7805.51 ms /    63 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 10191.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    96.07 ms /   166 runs   (    0.58 ms per token,  1727.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20475.54 ms /   166 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 20977.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.14 ms /    71 runs   (    0.58 ms per token,  1725.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8649.83 ms /    71 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  8856.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.20 ms /    71 runs   (    0.58 ms per token,  1723.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8787.49 ms /    71 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  8994.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.73 ms /   114 runs   (    0.58 ms per token,  1734.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14059.90 ms /   114 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 14399.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.17 ms /    49 runs   (    0.57 ms per token,  1739.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5977.31 ms /    49 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  6116.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.77 ms /   114 runs   (    0.58 ms per token,  1733.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14132.52 ms /   114 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 14462.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.44 ms /    80 runs   (    0.58 ms per token,  1722.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9852.26 ms /    80 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 10083.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.74 ms /    67 runs   (    0.58 ms per token,  1729.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8181.00 ms /    67 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8373.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.52 ms /    48 runs   (    0.59 ms per token,  1682.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5894.02 ms /    48 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6032.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a córnea, é correto afirmar:\n",
      "a)A disposição das fibrilas de colágeno corneanas não tem relação com a sua transparência.\n",
      "b)Pleomorfismo das células endoteliais é caracterizado pela variação do tamanho dessas células.\n",
      "c)As células do estroma anterior possuem grande quantidade de mitocôndrias, responsáveis pela produção de energia que supre a bomba endotelial.\n",
      "d)O endotélio comporta-se como uma barreira permeável não-seletiva entre o humor aquoso e a substância própria.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.17 ms /     7 runs   (    0.60 ms per token,  1678.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3194.99 ms /   162 tokens (   19.72 ms per token,    50.70 tokens per second)\n",
      "llama_print_timings:        eval time =   724.85 ms /     6 runs   (  120.81 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3939.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.37 ms /    11 runs   (    0.58 ms per token,  1728.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1362.66 ms /    11 runs   (  123.88 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  1393.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.31 ms /    59 runs   (    0.58 ms per token,  1719.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7284.00 ms /    59 runs   (  123.46 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  7455.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.04 ms /    71 runs   (    0.61 ms per token,  1649.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8736.65 ms /    71 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8943.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.85 ms /   205 runs   (    0.58 ms per token,  1724.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25335.50 ms /   205 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 25947.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.67 ms /    27 runs   (    0.58 ms per token,  1722.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3308.67 ms /    27 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3385.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1722.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.38 ms /     7 runs   (  121.77 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1716.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.49 ms /     7 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.37 ms /     7 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.39 ms /    56 runs   (    0.60 ms per token,  1677.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6933.32 ms /    56 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  7096.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 8: \n",
      "Language: english\n",
      "Question: \n",
      "Choose the alternative that correctly fills in the gaps. Levocycloversion corresponds to ____________ of the right eye and ________ of the left eye and is triggered when the head is tilted towards the shoulder___________.\n",
      "a) Excicloduction / incicloduction / left.\n",
      "b) Incicloduction / excicloduction / left.\n",
      "c) Excicloduction / incicloduction / law.\n",
      "d) Incicloduction / excicloduction / right.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.32 ms /    24 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2296.37 ms /   126 tokens (   18.23 ms per token,    54.87 tokens per second)\n",
      "llama_print_timings:        eval time =  2796.27 ms /    23 runs   (  121.58 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5161.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.44 ms /   106 runs   (    0.57 ms per token,  1753.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13097.26 ms /   106 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 13406.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.17 ms /    24 runs   (    0.55 ms per token,  1822.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2935.57 ms /    24 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3003.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.27 ms /    24 runs   (    0.55 ms per token,  1808.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2947.81 ms /    24 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3015.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.62 ms /    81 runs   (    0.56 ms per token,  1775.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9945.26 ms /    81 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10178.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.85 ms /    29 runs   (    0.55 ms per token,  1829.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3622.06 ms /    29 runs   (  124.90 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3703.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.00 ms /    77 runs   (    0.57 ms per token,  1750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9527.89 ms /    77 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  9751.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.16 ms /    24 runs   (    0.55 ms per token,  1824.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2913.62 ms /    24 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2980.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.48 ms /    82 runs   (    0.57 ms per token,  1764.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10204.14 ms /    82 runs   (  124.44 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 10439.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.22 ms /    24 runs   (    0.55 ms per token,  1815.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2935.60 ms /    24 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3002.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que preenche corretamente as lacunas. A levocicloversão corresponde a ____________ do olho direito e ________ do olho esquerdo e é desencadeada quando se inclina a cabeça para o ombro___________.\n",
      "a)Exciclodução / inciclodução / esquerdo.\n",
      "b)Inciclodução / exciclodução / esquerdo.\n",
      "c)Exciclodução / inciclodução / direito.\n",
      "d)Inciclodução / exciclodução / direito.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.45 ms /    27 runs   (    0.57 ms per token,  1747.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3044.48 ms /   149 tokens (   20.43 ms per token,    48.94 tokens per second)\n",
      "llama_print_timings:        eval time =  3210.35 ms /    26 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6331.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.12 ms /    27 runs   (    0.56 ms per token,  1785.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3334.43 ms /    27 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3410.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.38 ms /   146 runs   (    0.57 ms per token,  1750.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18098.22 ms /   146 runs   (  123.96 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 18528.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.13 ms /    27 runs   (    0.56 ms per token,  1784.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3307.43 ms /    27 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3384.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.36 ms /    24 runs   (    0.56 ms per token,  1796.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2960.15 ms /    24 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3027.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.51 ms /    73 runs   (    0.57 ms per token,  1758.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9002.82 ms /    73 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9212.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.26 ms /    52 runs   (    0.56 ms per token,  1777.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6385.12 ms /    52 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6533.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.77 ms /    28 runs   (    0.56 ms per token,  1775.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3488.17 ms /    28 runs   (  124.58 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3567.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.28 ms /    24 runs   (    0.55 ms per token,  1806.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2967.98 ms /    24 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3034.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.17 ms /    27 runs   (    0.56 ms per token,  1779.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3329.31 ms /    27 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3405.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 9: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the vitreous body cells, mark the correct alternative.\n",
      "a) They are more numerous in the adult than in the embryonic vitreous.\n",
      "b) They are mainly represented by lymphocytes and mature neutrophils.\n",
      "c) They are abundant in the region of the vitreous base.\n",
      "d) They are absent in the newborn.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.53 ms /    25 runs   (    0.58 ms per token,  1720.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1685.17 ms /    87 tokens (   19.37 ms per token,    51.63 tokens per second)\n",
      "llama_print_timings:        eval time =  2929.94 ms /    24 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4686.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.88 ms /    17 runs   (    0.58 ms per token,  1720.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2089.15 ms /    17 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2136.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1742.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2936.98 ms /    24 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3004.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.98 ms /    24 runs   (    0.58 ms per token,  1716.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2970.94 ms /    24 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3039.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.91 ms /    68 runs   (    0.60 ms per token,  1662.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8363.16 ms /    68 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8563.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2926.64 ms /    24 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2994.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.21 ms /    25 runs   (    0.69 ms per token,  1452.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3072.85 ms /    25 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3149.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1733.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2940.45 ms /    24 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3007.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.26 ms /    70 runs   (    0.58 ms per token,  1738.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8608.95 ms /    70 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8809.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1740.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3029.39 ms /    25 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3099.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação às células do corpo vítreo, assinale a alternativa correta.\n",
      "a)São mais numerosos no adulto, comparativamente às do vítreo embrionário.\n",
      "b)São representadas principalmente por linfócitos e neutrófilos maduros.\n",
      "c)São abundantes na região da base vítrea.\n",
      "d)Estão ausentes no recém-nascido.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.30 ms /    39 runs   (    0.57 ms per token,  1749.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2273.65 ms /   108 tokens (   21.05 ms per token,    47.50 tokens per second)\n",
      "llama_print_timings:        eval time =  4643.97 ms /    38 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7029.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.43 ms /    46 runs   (    0.57 ms per token,  1740.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5672.74 ms /    46 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5803.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.71 ms /    71 runs   (    0.57 ms per token,  1743.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8766.15 ms /    71 runs   (  123.47 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8974.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.73 ms /    55 runs   (    0.58 ms per token,  1733.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6757.21 ms /    55 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6916.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.38 ms /    39 runs   (    0.57 ms per token,  1742.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4810.59 ms /    39 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4921.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.68 ms /     7 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.83 ms /    19 runs   (    0.57 ms per token,  1755.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2322.25 ms /    19 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2375.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.50 ms /     7 runs   (  124.36 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   889.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.95 ms /    40 runs   (    0.57 ms per token,  1742.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4900.92 ms /    40 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5014.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.55 ms /     7 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   873.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 10: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the physiology of the oculomotor muscles, mark the correct alternative.\n",
      "a) Muscle contraction is independent of calcium availability.\n",
      "b) The muscle fiber is a multinucleated cell.\n",
      "c) Each muscle contraction is the result of a unique cycle of formation and destruction of actin-myosin bridges.\n",
      "d) Muscle relaxation rely mainly on sodium availability.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.85 ms /   108 runs   (    0.58 ms per token,  1718.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2470.22 ms /   102 tokens (   24.22 ms per token,    41.29 tokens per second)\n",
      "llama_print_timings:        eval time = 13088.83 ms /   107 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 15879.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.96 ms /    24 runs   (    0.58 ms per token,  1719.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2935.44 ms /    24 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3003.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.08 ms /    28 runs   (    0.57 ms per token,  1741.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3416.99 ms /    28 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3496.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1724.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3508.98 ms /    28 runs   (  125.32 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  3590.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.46 ms /    24 runs   (    0.60 ms per token,  1659.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2963.82 ms /    24 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3034.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.62 ms /    27 runs   (    0.58 ms per token,  1728.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3307.06 ms /    27 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3385.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.76 ms /    95 runs   (    0.58 ms per token,  1734.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11606.88 ms /    95 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 11883.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   130.76 ms /   227 runs   (    0.58 ms per token,  1736.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27911.05 ms /   227 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 28606.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.62 ms /    27 runs   (    0.58 ms per token,  1728.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3322.58 ms /    27 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3399.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1733.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3262.30 ms /    27 runs   (  120.83 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3338.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação à fisiologia dos músculos oculomotores, assinale a alternativa correta.\n",
      "a)A contração muscular independe da disponibilidade de cálcio.\n",
      "b)A fibra muscular é uma célula multinucleada.\n",
      "c)Cada contração muscular é resultado de um ciclo único de formação e destruição de pontes de actina-miosina.\n",
      "d)O relaxamento muscular depende principalmente da disponibilidade de sódio.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.05 ms /   151 runs   (    0.60 ms per token,  1658.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2680.24 ms /   123 tokens (   21.79 ms per token,    45.89 tokens per second)\n",
      "llama_print_timings:        eval time = 18594.87 ms /   150 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 21742.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.19 ms /    28 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3426.08 ms /    28 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3506.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.62 ms /    51 runs   (    0.58 ms per token,  1721.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6211.57 ms /    51 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6360.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.46 ms /    20 runs   (    0.57 ms per token,  1745.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2463.20 ms /    20 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2521.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.27 ms /    68 runs   (    0.58 ms per token,  1731.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8428.59 ms /    68 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  8629.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.85 ms /    55 runs   (    0.58 ms per token,  1726.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6783.64 ms /    55 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  6946.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1735.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3444.84 ms /    28 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3525.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.35 ms /    58 runs   (    0.58 ms per token,  1739.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7254.94 ms /    58 runs   (  125.09 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  7423.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.73 ms /    27 runs   (    0.58 ms per token,  1716.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3336.78 ms /    27 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3415.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.45 ms /    58 runs   (    0.58 ms per token,  1733.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7150.27 ms /    58 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  7317.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 11: \n",
      "Language: english\n",
      "Question: \n",
      "With regard to the lens, mark the correct alternative.\n",
      "a) Although its volume increases with age, its weight remains constant.\n",
      "b) The proteolysis of its fibers is the main mechanism of its cellular growth.\n",
      "c) The synthesis of its proteins takes place during the differentiation of the cell into fiber.\n",
      "d) Its protein synthesis is continuous throughout life, maintaining stable plasticity and elasticity from childhood to aging.\n",
      " \n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.60 ms /    27 runs   (    0.61 ms per token,  1626.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2194.06 ms /   107 tokens (   20.51 ms per token,    48.77 tokens per second)\n",
      "llama_print_timings:        eval time =  3274.80 ms /    26 runs   (  125.95 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  5549.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.12 ms /    24 runs   (    0.59 ms per token,  1699.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2920.42 ms /    24 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2989.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.00 ms /    62 runs   (    0.58 ms per token,  1722.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7567.03 ms /    62 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7748.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.52 ms /    25 runs   (    0.58 ms per token,  1721.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3019.69 ms /    25 runs   (  120.79 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3091.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.96 ms /    51 runs   (    0.59 ms per token,  1702.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6322.56 ms /    51 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6473.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Its protein synthesis is continuous throughout life, maintaining stable plasticity and elasticity from childhood to aging.'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.44 ms /    49 runs   (    0.58 ms per token,  1722.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6064.98 ms /    49 runs   (  123.78 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6209.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1734.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3445.85 ms /    28 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3526.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.62 ms /    62 runs   (    0.57 ms per token,  1740.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7558.84 ms /    62 runs   (  121.92 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  7739.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3416.80 ms /    28 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3497.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.35 ms /    49 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6022.40 ms /    49 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6166.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação ao cristalino, assinale a alternativa correta.\n",
      "a)Embora seu volume aumente com a idade, seu peso mantém-se constante.\n",
      "b)A proteólise de suas fibras é o principal mecanismo de seu crescimento celular.\n",
      "c)A síntese de suas proteínas processa-se durante a diferenciação da célula em fibra.\n",
      "d)Sua síntese proteica é continua ao longo da vida, mantendo plasticidade e elasticidade estáveis da infância ao envelhecimento.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.33 ms /    27 runs   (    0.60 ms per token,  1653.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2402.68 ms /   141 tokens (   17.04 ms per token,    58.68 tokens per second)\n",
      "llama_print_timings:        eval time =  3232.61 ms /    26 runs   (  124.33 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  5718.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1664.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.56 ms /     7 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.78 ms /    27 runs   (    0.58 ms per token,  1711.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3309.92 ms /    27 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3388.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.96 ms /   145 runs   (    0.58 ms per token,  1727.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17837.79 ms /   145 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18275.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.67 ms /    53 runs   (    0.58 ms per token,  1727.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6508.33 ms /    53 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6661.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.06 ms /    33 runs   (    0.58 ms per token,  1731.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4029.23 ms /    33 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4123.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1741.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3389.38 ms /    27 runs   (  125.53 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  3466.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   130.55 ms /   226 runs   (    0.58 ms per token,  1731.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27929.94 ms /   226 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 28617.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.62 ms /    70 runs   (    0.58 ms per token,  1723.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8634.03 ms /    70 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  8835.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.94 ms /    55 runs   (    0.58 ms per token,  1721.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6724.74 ms /    55 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  6881.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 12: \n",
      "Language: english\n",
      "Question: \n",
      "A patient with arthrosis has been using high doses of chloroquine for years. It is believed that this drug can cause malfunction of the retinal pigment epithelium, since:\n",
      "a) It hinders the synthesis of melanin.\n",
      "b) It hinders phagocytosis of the disks of the photoreceptor outer segments.\n",
      "c) It hinders the transport of intracellular ions.\n",
      "d) It favors intense heat exchange between the photoreceptors and the choroid.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.62 ms /    25 runs   (    0.58 ms per token,  1710.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2732.51 ms /   130 tokens (   21.02 ms per token,    47.58 tokens per second)\n",
      "llama_print_timings:        eval time =  2976.83 ms /    24 runs   (  124.03 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  5781.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.61 ms /    25 runs   (    0.58 ms per token,  1711.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3043.66 ms /    25 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3115.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.28 ms /    28 runs   (    0.58 ms per token,  1719.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3419.61 ms /    28 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3499.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    76.27 ms /   132 runs   (    0.58 ms per token,  1730.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16284.15 ms /   132 runs   (  123.36 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16670.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.12 ms /    97 runs   (    0.58 ms per token,  1728.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11959.31 ms /    97 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 12240.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.94 ms /    24 runs   (    0.58 ms per token,  1721.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2946.55 ms /    24 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3014.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   102.19 ms /   170 runs   (    0.60 ms per token,  1663.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20860.53 ms /   170 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 21373.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.58 ms /    50 runs   (    0.57 ms per token,  1749.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6093.06 ms /    50 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6234.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.80 ms /    24 runs   (    0.58 ms per token,  1738.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2950.30 ms /    24 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3018.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.29 ms /    80 runs   (    0.58 ms per token,  1728.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9752.26 ms /    80 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  9982.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente com artrose faz uso de altas doses de cloroquina há anos. Acredita-se que essa droga pode causar mau funcionamento do epitélio pigmentar retiniano, uma vez que:\n",
      "a)Impede a síntese de melanina.\n",
      "b)Impede a fagocitose dos discos dos segmentos externos dos fotorreceptores.\n",
      "c)Impede o transporte de íons intracelulares.\n",
      "d)Favorece a intensa troca de calor entre os fotorreceptores e a coroide.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    70.21 ms /   120 runs   (    0.59 ms per token,  1709.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2651.00 ms /   143 tokens (   18.54 ms per token,    53.94 tokens per second)\n",
      "llama_print_timings:        eval time = 14661.60 ms /   119 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 17668.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.79 ms /   144 runs   (    0.58 ms per token,  1718.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17783.50 ms /   144 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 18213.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.31 ms /   116 runs   (    0.59 ms per token,  1698.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14396.72 ms /   116 runs   (  124.11 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 14741.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.05 ms /   113 runs   (    0.58 ms per token,  1737.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13906.52 ms /   113 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 14237.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.36 ms /     7 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.28 ms /     7 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   874.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.41 ms /   113 runs   (    0.58 ms per token,  1727.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14007.31 ms /   113 runs   (  123.96 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 14346.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.68 ms /    86 runs   (    0.58 ms per token,  1731.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10566.23 ms /    86 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10815.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   111.82 ms /   193 runs   (    0.58 ms per token,  1725.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23788.81 ms /   193 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 24371.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    70.19 ms /   121 runs   (    0.58 ms per token,  1723.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14833.27 ms /   121 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 15193.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 13: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the blood flow in the choroid, it is possible to state:\n",
      "a) It is responsible for all nutrition of the retina.\n",
      "b) It is responsible for 95% of the glucose consumed in the inner part of the retina.\n",
      "c)Participates in the thermal regulation of photoreceptors.\n",
      "d) The pre-capillary sphincters prevent the hyperflow of blood in noble areas such as the macula.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.24 ms /    24 runs   (    0.59 ms per token,  1685.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2294.83 ms /   110 tokens (   20.86 ms per token,    47.93 tokens per second)\n",
      "llama_print_timings:        eval time =  2815.82 ms /    23 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5180.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1725.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3525.06 ms /    28 runs   (  125.90 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  3605.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.49 ms /    32 runs   (    0.58 ms per token,  1730.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3927.81 ms /    32 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4019.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1727.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2948.10 ms /    24 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3016.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.46 ms /    25 runs   (    0.58 ms per token,  1728.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3079.36 ms /    25 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3151.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.99 ms /    24 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2941.59 ms /    24 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3010.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1723.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3030.35 ms /    25 runs   (  121.21 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3101.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    24 runs   (    0.58 ms per token,  1725.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2932.06 ms /    24 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3000.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.97 ms /    24 runs   (    0.58 ms per token,  1718.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2932.26 ms /    24 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3000.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação ao fluxo sanguíneo na coroide, podemos afirmar:\n",
      "a)É responsável por toda nutrição da retina.\n",
      "b)É responsável por 95% da glicose consumida na parte interna da retina.\n",
      "c)Participa da regulação térmica dos fotorreceptores.\n",
      "d)Os esfíncteres pré-capilares previnem o hiperfluxo de sangue em áreas nobres como a mácula.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1722.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3052.40 ms /    25 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3123.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1687.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2284.93 ms /   124 tokens (   18.43 ms per token,    54.27 tokens per second)\n",
      "llama_print_timings:        eval time =   748.43 ms /     6 runs   (  124.74 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3053.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.23 ms /     9 runs   (    0.58 ms per token,  1720.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1121.82 ms /     9 runs   (  124.65 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  1147.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.28 ms /    28 runs   (    0.58 ms per token,  1719.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3440.82 ms /    28 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3520.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.66 ms /    47 runs   (    0.61 ms per token,  1640.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5761.17 ms /    47 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5899.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    86.70 ms /   126 runs   (    0.69 ms per token,  1453.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15397.24 ms /   126 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 15810.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.64 ms /    28 runs   (    0.63 ms per token,  1587.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3431.34 ms /    28 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3515.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.50 ms /    24 runs   (    0.60 ms per token,  1655.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2977.50 ms /    24 runs   (  124.06 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3047.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.10 ms /    24 runs   (    0.59 ms per token,  1702.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.08 ms /    24 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2984.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.86 ms /    27 runs   (    0.59 ms per token,  1702.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3273.69 ms /    27 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3352.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.96 ms /    27 runs   (    0.59 ms per token,  1691.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3285.72 ms /    27 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3363.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 14: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the embryology of the choroid, it is correct to state:\n",
      "a) The choriocapillaris is the first to be formed, with subsequent formation of the great vessels.\n",
      "b) The basal lamina originate the Bruch's membrane, which lies between the choriocapillaris and Sattler's layer.\n",
      "c) The intermediate vascular layer is the last to form and develops from the ciliary body towards the equator.\n",
      "d) The choroidal stroma is essentially produced from mesoderm cells.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.33 ms /    54 runs   (    0.60 ms per token,  1670.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2417.78 ms /   133 tokens (   18.18 ms per token,    55.01 tokens per second)\n",
      "llama_print_timings:        eval time =  6539.78 ms /    53 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  9116.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1699.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.92 ms /     7 runs   (  120.42 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   862.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    27 runs   (    0.58 ms per token,  1731.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3259.45 ms /    27 runs   (  120.72 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3336.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.57 ms /    54 runs   (    0.58 ms per token,  1710.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6642.54 ms /    54 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6800.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.61 ms /    25 runs   (    0.58 ms per token,  1710.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3105.36 ms /    25 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3178.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.28 ms /    28 runs   (    0.58 ms per token,  1720.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3401.31 ms /    28 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3482.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.77 ms /    53 runs   (    0.58 ms per token,  1722.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6475.50 ms /    53 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  6628.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.19 ms /    28 runs   (    0.58 ms per token,  1729.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3448.92 ms /    28 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3530.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.66 ms /    28 runs   (    0.60 ms per token,  1680.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3534.16 ms /    28 runs   (  126.22 ms per token,     7.92 tokens per second)\n",
      "llama_print_timings:       total time =  3615.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.94 ms /    17 runs   (    0.58 ms per token,  1710.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2089.68 ms /    17 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2138.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a embriologia da coroide, é correto afirmar:\n",
      "a)A coriocapilar é a primeira a se formar, com posterior formação dos grandes vasos.\n",
      "b)A lâmina basal dá origem à membrana de Bruch que se situa entre o coriocapilar e a camada de Sattler.\n",
      "c)A camada vascular intermediária é a última a se formar e desenvolve-se do corpo ciliar em direção ao equador.\n",
      "d)O estroma da coroide é essencialmente produzido a partir de células do mesoderma.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.36 ms /    67 runs   (    0.60 ms per token,  1660.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2795.00 ms /   154 tokens (   18.15 ms per token,    55.10 tokens per second)\n",
      "llama_print_timings:        eval time =  8137.95 ms /    66 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 11131.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.17 ms /   106 runs   (    0.58 ms per token,  1732.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13089.72 ms /   106 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13401.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.98 ms /     7 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   882.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "Error converting respose to json: {:response:\"b\"}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.43 ms /     6 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   724.04 ms /     6 runs   (  120.67 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   740.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.49 ms /     7 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   877.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1752.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.42 ms /     7 runs   (  124.20 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   889.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.43 ms /     7 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   876.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.47 ms /    86 runs   (    0.58 ms per token,  1738.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10567.49 ms /    86 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10820.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.15 ms /    90 runs   (    0.58 ms per token,  1725.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11055.19 ms /    90 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11319.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.71 ms /    41 runs   (    0.58 ms per token,  1728.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5067.22 ms /    41 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5185.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.13 ms /    98 runs   (    0.58 ms per token,  1715.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12137.01 ms /    98 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 12424.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 15: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding ocular embryology, it is correct to state:\n",
      "a) Corneal epithelium arises from neural crest cells.\n",
      "b) At birth, the cornea and sclera have curvature radius.\n",
      "c) Bowman's layer appears between the first and second month of pregnancy.\n",
      "d) The cornea develops from the ectodermal surface and neural crest cells.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.08 ms /    24 runs   (    0.59 ms per token,  1705.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1971.08 ms /    97 tokens (   20.32 ms per token,    49.21 tokens per second)\n",
      "llama_print_timings:        eval time =  2812.16 ms /    23 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4852.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.94 ms /    45 runs   (    0.58 ms per token,  1735.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5512.66 ms /    45 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5642.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n",
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.87 ms /    19 runs   (    0.57 ms per token,  1748.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2320.63 ms /    19 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2375.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.28 ms /    37 runs   (    0.58 ms per token,  1738.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4546.38 ms /    37 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4652.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.01 ms /    47 runs   (    0.57 ms per token,  1740.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5784.16 ms /    47 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5920.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n",
      "{'response': 'd) The cornea develops from the ectodermal surface and neural crest cells.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.02 ms /    37 runs   (    0.60 ms per token,  1680.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4586.24 ms /    37 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4694.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.15 ms /    47 runs   (    0.58 ms per token,  1731.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5742.84 ms /    47 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5878.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} The cornea develops from the ectodermal surface and neural crest cells.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.25 ms /    37 runs   (    0.57 ms per token,  1740.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4513.94 ms /    37 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4621.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.86 ms /    47 runs   (    0.57 ms per token,  1750.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5757.38 ms /    47 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5893.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.53 ms /    36 runs   (    0.57 ms per token,  1753.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4452.15 ms /    36 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4555.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação à embriologia ocular, é correto afirmar:\n",
      "a)O epitélio da córnea origina-se a partir das células da crista neural.\n",
      "b)Ao nascimento, córnea e esclera apresentam o mesmo raio de curvatura.\n",
      "c)A camada de Bowman surge entre o primeiro e o segundo mês de gestação.\n",
      "d)A córnea desenvolve-se a partir da superfície ectodérmica e das células da crista neural.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.89 ms /    38 runs   (    0.63 ms per token,  1590.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2549.22 ms /   130 tokens (   19.61 ms per token,    51.00 tokens per second)\n",
      "llama_print_timings:        eval time =  4511.35 ms /    37 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  7181.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.46 ms /    63 runs   (    0.58 ms per token,  1727.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7867.66 ms /    63 runs   (  124.88 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  8051.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) A córnea desenvolve-se a partir da superfície ectodérmica e das células da crista neural.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.08 ms /    59 runs   (    0.58 ms per token,  1731.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7244.19 ms /    59 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7415.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) A córnea desenvolve-se a partir da superfície ectodérmica e das células da crista neural.'}\n",
      "Test #3: \n",
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.15 ms /    61 runs   (    0.58 ms per token,  1735.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7496.10 ms /    61 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7674.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.31 ms /    63 runs   (    0.58 ms per token,  1735.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7723.11 ms /    63 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  7906.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.52 ms /    38 runs   (    0.57 ms per token,  1765.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4661.83 ms /    38 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4771.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} A córnea desenvolve-se a partir da superfície ectodérmica e das células da crista neural.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.37 ms /    58 runs   (    0.58 ms per token,  1737.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7102.67 ms /    58 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7269.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.87 ms /     7 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   868.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.46 ms /    58 runs   (    0.58 ms per token,  1733.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7101.06 ms /    58 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7268.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.93 ms /    31 runs   (    0.58 ms per token,  1729.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3811.15 ms /    31 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3900.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 16: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the autosomal dominant inheritance diseases, it is correct to state:\n",
      "a) In general, they are observed in several gestations.\n",
      "b) Men tend to be more affected than women.\n",
      "c) The severity of the disease is always the same among affected people from the same family.\n",
      "d) Only females transmit the mutation.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.92 ms /    24 runs   (    0.58 ms per token,  1723.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1902.38 ms /    80 tokens (   23.78 ms per token,    42.05 tokens per second)\n",
      "llama_print_timings:        eval time =  2804.45 ms /    23 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4776.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1731.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3008.12 ms /    24 runs   (  125.34 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  3077.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.62 ms /   100 runs   (    0.58 ms per token,  1735.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12316.82 ms /   100 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 12615.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1736.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3041.37 ms /    25 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3113.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.81 ms /    17 runs   (    0.58 ms per token,  1732.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2060.65 ms /    17 runs   (  121.21 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2108.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.94 ms /    24 runs   (    0.58 ms per token,  1721.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.13 ms /    24 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2985.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.80 ms /    17 runs   (    0.58 ms per token,  1735.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2090.65 ms /    17 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2140.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.81 ms /    17 runs   (    0.58 ms per token,  1732.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2069.31 ms /    17 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2117.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.79 ms /    17 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2064.78 ms /    17 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2113.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.82 ms /    17 runs   (    0.58 ms per token,  1730.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2077.53 ms /    17 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2126.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre as doenças de herança autossômica dominante, é correto afirmar:\n",
      "a)Em geral, são observadas em várias gestações.\n",
      "b)Os homens costumam ser mais afetados do que as mulheres.\n",
      "c)A gravidade da doença é sempre a mesma entre as pessoas afetadas da mesma família.\n",
      "d)Apenas as mulheres transmitem a mutação.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.38 ms /    76 runs   (    0.58 ms per token,  1712.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1984.10 ms /   109 tokens (   18.20 ms per token,    54.94 tokens per second)\n",
      "llama_print_timings:        eval time =  9172.88 ms /    75 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 11384.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.66 ms /    34 runs   (    0.58 ms per token,  1729.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4128.87 ms /    34 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4228.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.52 ms /    48 runs   (    0.57 ms per token,  1744.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5934.59 ms /    48 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  6074.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.28 ms /    49 runs   (    0.58 ms per token,  1732.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6010.16 ms /    49 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6156.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   909.59 ms /     7 runs   (  129.94 ms per token,     7.70 tokens per second)\n",
      "llama_print_timings:       total time =   930.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   876.67 ms /     7 runs   (  125.24 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =   897.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {'response': 'c'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   145.06 ms /   252 runs   (    0.58 ms per token,  1737.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 31120.25 ms /   252 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 31898.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.49 ms /    52 runs   (    0.59 ms per token,  1705.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6389.61 ms /    52 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6542.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.06 ms /     7 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   879.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.62 ms /    48 runs   (    0.58 ms per token,  1737.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5854.89 ms /    48 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5994.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)} A gravidade da doença é sempre a mesma entre as pessoas afetadas da mesma família.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3310.26 ms /    27 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3388.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 17: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding mitochondrial inheritance diseases, it is correct to state:\n",
      "a) Daltonism is an example of a disease linked to mitochondrial DNA.\n",
      "b) Inheritance occurs only through maternal lineage.\n",
      "c) Male patients assisted by the disease will transmit the phenotype to all offspring.\n",
      "d) Leber's hereditary optic neuropathy is an example of a disease linked to mitochondrial DNA, it usually causes congenital blindness and affects patients of both sexes in the same proportion.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.92 ms /    17 runs   (    0.58 ms per token,  1714.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2786.39 ms /   127 tokens (   21.94 ms per token,    45.58 tokens per second)\n",
      "llama_print_timings:        eval time =  1963.84 ms /    16 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4799.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n",
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   139.22 ms /   240 runs   (    0.58 ms per token,  1723.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 29656.74 ms /   240 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 30400.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.98 ms /    70 runs   (    0.59 ms per token,  1708.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8740.96 ms /    70 runs   (  124.87 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  8946.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1738.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2084.73 ms /    17 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2133.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.60 ms /    20 runs   (    0.58 ms per token,  1723.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2445.96 ms /    20 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2503.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.35 ms /    17 runs   (    0.61 ms per token,  1642.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2131.63 ms /    17 runs   (  125.39 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  2181.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.37 ms /    73 runs   (    0.58 ms per token,  1723.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8950.89 ms /    73 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  9164.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.22 ms /    17 runs   (    0.60 ms per token,  1662.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2067.89 ms /    17 runs   (  121.64 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2116.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1727.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.29 ms /    24 runs   (  121.47 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2984.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2932.54 ms /    24 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3001.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre as doenças de padrão de herança mitocondrial, é correto afirmar:\n",
      "a)Daltonismo é um exemplo de doença ligada ao DNA mitocondrial.\n",
      "b)A herança ocorre apenas pela linhagem materna.\n",
      "c)Pacientes do sexo masculino afetados pela doença, transmitirão o fenótipo para toda a prole.\n",
      "d)A neuropatia óptica hereditária de Leber é um exemplo de doença ligada ao DNA mitocondrial, causa geralmente cegueira congênita e afeta na mesma proporção pacientes de ambos os sexos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1702.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3223.15 ms /   164 tokens (   19.65 ms per token,    50.88 tokens per second)\n",
      "llama_print_timings:        eval time =   745.21 ms /     6 runs   (  124.20 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3988.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1697.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.17 ms /     7 runs   (  121.02 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   867.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1708.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.89 ms /     7 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.44 ms /     7 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.18 ms /     7 runs   (    0.60 ms per token,  1675.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.04 ms /     7 runs   (  124.43 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1701.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.47 ms /     7 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.39 ms /     7 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   117.62 ms /   203 runs   (    0.58 ms per token,  1725.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25088.76 ms /   203 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 25709.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n",
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.01 ms /     7 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   871.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.07 ms /     7 runs   (  121.01 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   867.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 18: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the lenses below best corrects simple myopic astigmatism?\n",
      "a)-3.00 spherical diopter + 1.00 cylindrical diopter X 90°.\n",
      "b) +1.00 spherical diopter -1.00 cylindrical diopter X 90°.\n",
      "c)-3.00 spherical diopter + 3.00 cylindrical diopter X 180°.\n",
      "d) 0.00 spherical diopter +1.00 cylindrical diopter X 180°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.71 ms /    50 runs   (    0.55 ms per token,  1804.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2462.53 ms /   138 tokens (   17.84 ms per token,    56.04 tokens per second)\n",
      "llama_print_timings:        eval time =  6029.50 ms /    49 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8638.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.82 ms /    52 runs   (    0.55 ms per token,  1804.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6406.75 ms /    52 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6557.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.11 ms /    28 runs   (    0.54 ms per token,  1853.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3438.32 ms /    28 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3518.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.71 ms /    50 runs   (    0.55 ms per token,  1804.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6231.80 ms /    50 runs   (  124.64 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  6376.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.77 ms /    52 runs   (    0.55 ms per token,  1807.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6420.77 ms /    52 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6570.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    27 runs   (    0.53 ms per token,  1873.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3296.31 ms /    27 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3372.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.76 ms /    53 runs   (    0.58 ms per token,  1722.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6490.41 ms /    53 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6648.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.28 ms /    27 runs   (    0.60 ms per token,  1658.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3361.54 ms /    27 runs   (  124.50 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3444.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.89 ms /    52 runs   (    0.56 ms per token,  1800.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6408.29 ms /    52 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  6561.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.87 ms /    52 runs   (    0.56 ms per token,  1801.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6402.96 ms /    52 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6557.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das lentes abaixo melhor corrige um astigmatismo miópico simples?\n",
      "a)-3,00 dioptria esférica + 1,00 dioptria cilindrica X 90°.\n",
      "b)+1,00 dioptria esférica -1,00 dioptria cilindrica X 90°.\n",
      "c)-3,00 dioptria esférica + 3,00 dioptria cilindrica X 180°.\n",
      "d)0,00 dioptria esférica +1,00 dioptria cilindrica X 180°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.10 ms /    20 runs   (    0.60 ms per token,  1653.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2424.67 ms /   157 tokens (   15.44 ms per token,    64.75 tokens per second)\n",
      "llama_print_timings:        eval time =  2311.49 ms /    19 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4796.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.17 ms /     9 runs   (    0.57 ms per token,  1739.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1119.54 ms /     9 runs   (  124.39 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  1145.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.11 ms /    65 runs   (    0.57 ms per token,  1751.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7962.16 ms /    65 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8153.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.76 ms /    47 runs   (    0.57 ms per token,  1756.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5741.40 ms /    47 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5877.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)-3,00 dioptria esférica + 3,00 dioptria cilindrica X 180°'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1816.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.14 ms /     7 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.66 ms /    37 runs   (    0.56 ms per token,  1790.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4516.88 ms /    37 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4623.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)-3,00 dioptria esférica + 3,00 dioptria cilindrica X 180°'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.61 ms /    24 runs   (    0.57 ms per token,  1763.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2979.51 ms /    24 runs   (  124.15 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3049.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.03 ms /   126 runs   (    0.58 ms per token,  1725.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15539.46 ms /   126 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 15919.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.77 ms /    63 runs   (    0.57 ms per token,  1761.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7795.76 ms /    63 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  7981.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.76 ms /    29 runs   (    0.58 ms per token,  1730.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3553.21 ms /    29 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3638.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 19: \n",
      "Language: english\n",
      "Question: \n",
      "What is the focal length of the circle of least confusion on Sturm's conoid of a +1.00 OD +2.00 DC X 180° spherocylindrical lens?\n",
      "a) 0 m.\n",
      "b) 0.5 m.\n",
      "c) 1 m.\n",
      "d) 2 m.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.16 ms /    27 runs   (    0.56 ms per token,  1781.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1961.77 ms /    84 tokens (   23.35 ms per token,    42.82 tokens per second)\n",
      "llama_print_timings:        eval time =  3182.51 ms /    26 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5223.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.95 ms /    29 runs   (    0.55 ms per token,  1818.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3571.28 ms /    29 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3655.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.28 ms /    12 runs   (    0.52 ms per token,  1912.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1442.13 ms /    12 runs   (  120.18 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  1476.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.85 ms /    29 runs   (    0.55 ms per token,  1829.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3545.28 ms /    29 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3628.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.55 ms /    30 runs   (    0.55 ms per token,  1812.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3675.36 ms /    30 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3762.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.25 ms /    30 runs   (    0.54 ms per token,  1845.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3665.15 ms /    30 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3751.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.68 ms /     7 runs   (    0.53 ms per token,  1903.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.01 ms /     7 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.94 ms /    29 runs   (    0.55 ms per token,  1819.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3544.31 ms /    29 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3627.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.51 ms /    30 runs   (    0.55 ms per token,  1817.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3646.14 ms /    30 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3732.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.01 ms /    34 runs   (    0.56 ms per token,  1788.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4232.66 ms /    34 runs   (  124.49 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  4332.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual é a distância focal do círculo de menor confusão no conoide de Sturm de uma lente esferocilíndrica de +1,00 DE +2,00 DC X 180°?\n",
      "a)0 metros.\n",
      "b)0,5 metros.\n",
      "c)1 metros.\n",
      "d)2 metros.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.64 ms /    10 runs   (    0.56 ms per token,  1773.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2181.16 ms /    87 tokens (   25.07 ms per token,    39.89 tokens per second)\n",
      "llama_print_timings:        eval time =  1104.78 ms /     9 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3315.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {:response:\"c\")1 metros.\"}\n",
      "Generating new response...\n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.23 ms /    22 runs   (    0.56 ms per token,  1799.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2678.25 ms /    22 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2742.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.19 ms /    79 runs   (    0.57 ms per token,  1748.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9673.60 ms /    79 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  9907.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.22 ms /    33 runs   (    0.55 ms per token,  1811.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4038.91 ms /    33 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4134.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.54 ms /    12 runs   (    0.55 ms per token,  1834.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1485.67 ms /    12 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  1520.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.50 ms /    12 runs   (    0.54 ms per token,  1845.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1488.14 ms /    12 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  1522.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.87 ms /     7 runs   (    0.55 ms per token,  1806.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.05 ms /     7 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.37 ms /    29 runs   (    0.53 ms per token,  1886.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3552.27 ms /    29 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3636.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.50 ms /    12 runs   (    0.54 ms per token,  1846.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1463.83 ms /    12 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1497.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.88 ms /     7 runs   (    0.55 ms per token,  1804.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   877.93 ms /     7 runs   (  125.42 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =   897.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.55 ms /    12 runs   (    0.55 ms per token,  1830.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1458.99 ms /    12 runs   (  121.58 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  1493.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 20: \n",
      "Language: english\n",
      "Question: \n",
      "What is the focal length of the circle of least confusion on Sturm's conoid of a +1.00 OD +2.00 DC X 180° spherocylindrical lens?\n",
      "a) 0 meters.\n",
      "b) 0.5 meters.\n",
      "c) 1 meters.\n",
      "d) 2 meters.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.64 ms /     7 runs   (    0.52 ms per token,  1922.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2083.86 ms /    84 tokens (   24.81 ms per token,    40.31 tokens per second)\n",
      "llama_print_timings:        eval time =   739.57 ms /     6 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  2843.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.78 ms /    29 runs   (    0.54 ms per token,  1838.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3529.26 ms /    29 runs   (  121.70 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3613.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.31 ms /    33 runs   (    0.55 ms per token,  1802.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4037.85 ms /    33 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4133.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    29 runs   (    0.54 ms per token,  1858.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3628.25 ms /    29 runs   (  125.11 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  3711.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.80 ms /    27 runs   (    0.55 ms per token,  1824.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3321.00 ms /    27 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3398.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.55 ms /    32 runs   (    0.55 ms per token,  1823.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3891.39 ms /    32 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3983.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.03 ms /    24 runs   (    0.54 ms per token,  1842.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2946.69 ms /    24 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3015.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    30 runs   (    0.54 ms per token,  1851.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3702.65 ms /    30 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3788.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.42 ms /    12 runs   (    0.53 ms per token,  1869.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1468.02 ms /    12 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1501.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.28 ms /    12 runs   (    0.52 ms per token,  1910.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1469.46 ms /    12 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1502.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um ponto objetivo situado a dois metros de uma lente convexa de 2 DE forma um ponto imagem a que distância da lente?\n",
      "a)2,0 m.\n",
      "b)1,5 m.\n",
      "c)0,67 m.\n",
      "d)0,4 m.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.97 ms /    33 runs   (    0.57 ms per token,  1739.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1347.45 ms /    74 tokens (   18.21 ms per token,    54.92 tokens per second)\n",
      "llama_print_timings:        eval time =  3912.33 ms /    32 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5356.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.56 ms /    20 runs   (    0.58 ms per token,  1729.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2496.71 ms /    20 runs   (  124.84 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  2555.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.18 ms /    32 runs   (    0.57 ms per token,  1760.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3922.46 ms /    32 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4015.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.54 ms /    22 runs   (    0.57 ms per token,  1754.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2684.88 ms /    22 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2748.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.52 ms /    20 runs   (    0.58 ms per token,  1736.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2399.11 ms /    20 runs   (  119.96 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =  2456.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.71 ms /     7 runs   (  120.24 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.48 ms /    20 runs   (    0.57 ms per token,  1742.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2433.59 ms /    20 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2491.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.93 ms /    23 runs   (    0.56 ms per token,  1778.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2834.21 ms /    23 runs   (  123.23 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2900.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.50 ms /    13 runs   (    0.58 ms per token,  1733.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1639.67 ms /    13 runs   (  126.13 ms per token,     7.93 tokens per second)\n",
      "llama_print_timings:       total time =  1677.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.59 ms /    24 runs   (    0.57 ms per token,  1766.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2924.98 ms /    24 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2993.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 21: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following values ​​in decimal logarithm (logMAR) corresponds to normal visual acuity (1.0)?\n",
      "to 1.\n",
      "b)0.\n",
      "c)1.\n",
      "d)2.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.98 ms /    24 runs   (    0.58 ms per token,  1716.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1300.50 ms /    56 tokens (   23.22 ms per token,    43.06 tokens per second)\n",
      "llama_print_timings:        eval time =  2778.92 ms /    23 runs   (  120.82 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  4150.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.72 ms /    28 runs   (    0.56 ms per token,  1780.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3446.54 ms /    28 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3527.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.23 ms /    30 runs   (    0.57 ms per token,  1741.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3650.62 ms /    30 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3737.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.48 ms /    27 runs   (    0.57 ms per token,  1744.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3296.76 ms /    27 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3375.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.44 ms /    27 runs   (    0.57 ms per token,  1748.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3287.53 ms /    27 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3366.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1758.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   836.24 ms /     7 runs   (  119.46 ms per token,     8.37 tokens per second)\n",
      "llama_print_timings:       total time =   856.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.47 ms /    31 runs   (    0.56 ms per token,  1774.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3748.65 ms /    31 runs   (  120.92 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3837.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.33 ms /    27 runs   (    0.57 ms per token,  1760.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3316.84 ms /    27 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3394.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.74 ms /    28 runs   (    0.56 ms per token,  1779.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3418.46 ms /    28 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3499.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.62 ms /    28 runs   (    0.56 ms per token,  1792.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3462.21 ms /    28 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3542.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual dos valores abaixo em logaritmo decimal (logMAR) corresponde a acuidade visual normal (1,0)?\n",
      "a)-1.\n",
      "b)0.\n",
      "c)1.\n",
      "d)2.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.29 ms /    30 runs   (    0.58 ms per token,  1735.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1414.52 ms /    60 tokens (   23.58 ms per token,    42.42 tokens per second)\n",
      "llama_print_timings:        eval time =  3542.32 ms /    29 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5045.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    28 runs   (    0.57 ms per token,  1749.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3376.73 ms /    28 runs   (  120.60 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3458.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.28 ms /    23 runs   (    0.58 ms per token,  1731.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2838.37 ms /    23 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  2905.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1757.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.41 ms /     7 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   874.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3293.51 ms /    27 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3370.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.99 ms /    28 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3393.35 ms /    28 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3474.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.69 ms /    24 runs   (    0.57 ms per token,  1753.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2907.91 ms /    24 runs   (  121.16 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2978.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.25 ms /    27 runs   (    0.56 ms per token,  1770.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3320.72 ms /    27 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3398.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1767.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.53 ms /     7 runs   (  123.08 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   880.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.74 ms /    28 runs   (    0.56 ms per token,  1778.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3412.62 ms /    28 runs   (  121.88 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3493.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 22: \n",
      "Language: english\n",
      "Question: \n",
      "What is the optical effect resulting from the interpolation of two polaroid filters perpendicular to each other?\n",
      "a) Transmission is reduced by 50%.\n",
      "b) Transmission is increased by 50%.\n",
      "c) Absence of light transmission.\n",
      "d)No loss of light energy.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.65 ms /    53 runs   (    0.58 ms per token,  1729.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1679.52 ms /    69 tokens (   24.34 ms per token,    41.08 tokens per second)\n",
      "llama_print_timings:        eval time =  6321.90 ms /    52 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  8158.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.40 ms /    27 runs   (    0.57 ms per token,  1753.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3269.12 ms /    27 runs   (  121.08 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3347.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.48 ms /    34 runs   (    0.57 ms per token,  1745.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4124.45 ms /    34 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4224.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.86 ms /    34 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4130.85 ms /    34 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4230.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.03 ms /    28 runs   (    0.57 ms per token,  1746.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3460.33 ms /    28 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3542.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.04 ms /    31 runs   (    0.58 ms per token,  1718.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3759.76 ms /    31 runs   (  121.28 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3850.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.87 ms /    31 runs   (    0.58 ms per token,  1734.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3809.56 ms /    31 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3899.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c} Absence of light transmission.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.64 ms /    42 runs   (    0.56 ms per token,  1776.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5104.50 ms /    42 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5227.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.88 ms /    28 runs   (    0.57 ms per token,  1762.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3490.23 ms /    28 runs   (  124.65 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3571.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.61 ms /    31 runs   (    0.57 ms per token,  1759.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3830.26 ms /    31 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3919.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c} Absence of light transmission.'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual o efeito óptico decorrente da interpolação de dois filtros polaroides perpendiculares entre si?\n",
      "a)Transmissão reduzida em 50%.\n",
      "b)Transmissão ampliada em 50%.\n",
      "c)Ausência de transmissão luminosa.\n",
      "d)Nenhuma perda de energia luminosa.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.29 ms /    45 runs   (    0.58 ms per token,  1711.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2020.58 ms /    94 tokens (   21.50 ms per token,    46.52 tokens per second)\n",
      "llama_print_timings:        eval time =  5347.26 ms /    44 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  7500.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.17 ms /    46 runs   (    0.57 ms per token,  1757.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5652.79 ms /    46 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5786.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.15 ms /    32 runs   (    0.57 ms per token,  1762.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3864.37 ms /    32 runs   (  120.76 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3957.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.73 ms /    19 runs   (    0.56 ms per token,  1770.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2320.34 ms /    19 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2374.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.34 ms /    20 runs   (    0.57 ms per token,  1764.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2449.59 ms /    20 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2507.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n",
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.71 ms /    19 runs   (    0.56 ms per token,  1773.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2296.67 ms /    19 runs   (  120.88 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2351.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.94 ms /     7 runs   (    0.56 ms per token,  1776.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.27 ms /     7 runs   (  121.04 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   866.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'c} Ausência de transmissão luminosa.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.05 ms /    18 runs   (    0.56 ms per token,  1790.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2243.47 ms /    18 runs   (  124.64 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  2295.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.55 ms /    83 runs   (    0.57 ms per token,  1745.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10142.74 ms /    83 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 10388.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.12 ms /    18 runs   (    0.56 ms per token,  1778.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2244.83 ms /    18 runs   (  124.71 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  2296.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 23: \n",
      "Language: english\n",
      "Question: \n",
      "In which of the materials is the speed of light the lowest?\n",
      "a) Air.\n",
      "b) Diamond.\n",
      "c) Glass.\n",
      "d) The speed of light is constant regardless of the medium.\n",
      "Test #0: \n",
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    24 runs   (    0.60 ms per token,  1670.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1173.62 ms /    50 tokens (   23.47 ms per token,    42.60 tokens per second)\n",
      "llama_print_timings:        eval time =  2815.44 ms /    23 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4060.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.50 ms /    27 runs   (    0.57 ms per token,  1741.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3276.11 ms /    27 runs   (  121.34 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3354.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.47 ms /    27 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.25 ms /    27 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3379.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3321.24 ms /    27 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3399.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n",
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.74 ms /    17 runs   (    0.57 ms per token,  1745.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2044.72 ms /    17 runs   (  120.28 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2093.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.55 ms /    24 runs   (    0.56 ms per token,  1770.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2889.61 ms /    24 runs   (  120.40 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2959.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.39 ms /    27 runs   (    0.57 ms per token,  1754.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3293.19 ms /    27 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3371.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.20 ms /    24 runs   (    0.59 ms per token,  1689.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2911.85 ms /    24 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2981.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.29 ms /    28 runs   (    0.62 ms per token,  1619.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3438.92 ms /    28 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3524.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.44 ms /    27 runs   (    0.76 ms per token,  1321.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3264.05 ms /    27 runs   (  120.89 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3363.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Em qual dos materiais abaixo a velocidade da luz é a menor?\n",
      "a)Ar.\n",
      "b)Diamante.\n",
      "c)Vidro.\n",
      "d)A velocidade da luz é constante independente do meio.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.56 ms /    27 runs   (    0.69 ms per token,  1454.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1481.29 ms /    63 tokens (   23.51 ms per token,    42.53 tokens per second)\n",
      "llama_print_timings:        eval time =  3158.42 ms /    26 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4730.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.33 ms /    28 runs   (    0.73 ms per token,  1377.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3384.37 ms /    28 runs   (  120.87 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3475.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.17 ms /    28 runs   (    0.76 ms per token,  1322.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3393.56 ms /    28 runs   (  121.20 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3490.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.27 ms /    27 runs   (    0.57 ms per token,  1768.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3291.63 ms /    27 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3370.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.34 ms /    27 runs   (    0.57 ms per token,  1760.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.24 ms /    27 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3379.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.28 ms /    27 runs   (    0.57 ms per token,  1767.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3277.98 ms /    27 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3356.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.92 ms /    42 runs   (    0.57 ms per token,  1755.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5152.80 ms /    42 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5276.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.55 ms /    41 runs   (    0.57 ms per token,  1741.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5033.16 ms /    41 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5154.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.26 ms /    27 runs   (    0.57 ms per token,  1768.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3350.07 ms /    27 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3427.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n",
      "{'response': 'C'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 24: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the alternative that corresponds to a reflection from a convex mirror.\n",
      "a) Keratoscopy with Placido disc.\n",
      "b) Shaving mirror.\n",
      "c) Dentist's mirror.\n",
      "d) Reflector headlamp.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.95 ms /    42 runs   (    0.57 ms per token,  1753.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5094.01 ms /    42 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5214.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.62 ms /    72 runs   (    0.58 ms per token,  1729.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1396.44 ms /    58 tokens (   24.08 ms per token,    41.53 tokens per second)\n",
      "llama_print_timings:        eval time =  8654.61 ms /    71 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 10262.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.11 ms /    42 runs   (    0.57 ms per token,  1742.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5116.44 ms /    42 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5236.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1768.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   840.85 ms /     7 runs   (  120.12 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   861.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.47 ms /    20 runs   (    0.57 ms per token,  1744.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2412.73 ms /    20 runs   (  120.64 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2469.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.23 ms /    32 runs   (    0.57 ms per token,  1755.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3911.88 ms /    32 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4003.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.91 ms /    33 runs   (    0.57 ms per token,  1744.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3954.08 ms /    33 runs   (  119.82 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =  4049.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.54 ms /    29 runs   (    0.57 ms per token,  1753.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3593.09 ms /    29 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3675.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.65 ms /    22 runs   (    0.57 ms per token,  1739.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2694.92 ms /    22 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2758.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.15 ms /    33 runs   (    0.58 ms per token,  1722.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3991.33 ms /    33 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4086.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que corresponde a uma reflexão de um espelho convexo.\n",
      "a)Ceratoscopia com disco de Plácido.\n",
      "b)Espelho de barbear.\n",
      "c)Espelho do dentista.\n",
      "d)Farol refletor.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.23 ms /    30 runs   (    0.57 ms per token,  1741.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3607.61 ms /    30 runs   (  120.25 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  3693.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.43 ms /    60 runs   (    0.57 ms per token,  1742.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1824.20 ms /    75 tokens (   24.32 ms per token,    41.11 tokens per second)\n",
      "llama_print_timings:        eval time =  7259.25 ms /    59 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  9261.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.53 ms /    43 runs   (    0.57 ms per token,  1752.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5231.91 ms /    43 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5356.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.38 ms /    43 runs   (    0.57 ms per token,  1763.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5225.49 ms /    43 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5348.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.82 ms /     7 runs   (    0.55 ms per token,  1831.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.57 ms /     7 runs   (  120.37 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.90 ms /     7 runs   (    0.56 ms per token,  1793.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.75 ms /     7 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   884.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.83 ms /    42 runs   (    0.57 ms per token,  1762.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5159.92 ms /    42 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5282.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.84 ms /    42 runs   (    0.57 ms per token,  1761.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5089.88 ms /    42 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5211.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.84 ms /    42 runs   (    0.57 ms per token,  1761.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5168.46 ms /    42 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5291.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.01 ms /    25 runs   (    0.56 ms per token,  1784.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3067.21 ms /    25 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3139.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.90 ms /     7 runs   (    0.56 ms per token,  1793.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.21 ms /     7 runs   (  120.74 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   864.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 25: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "A converging lens focuses light from a source 1 m away at a distance of 50 cm. How powerful is this lens?\n",
      "a) + 1 diopter.\n",
      "b) + 2 diopter.\n",
      "c) + 3 diopter.\n",
      "d) + 4 diopter.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.70 ms /    32 runs   (    0.55 ms per token,  1807.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2022.58 ms /    75 tokens (   26.97 ms per token,    37.08 tokens per second)\n",
      "llama_print_timings:        eval time =  3784.85 ms /    31 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5900.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   125.64 ms /   221 runs   (    0.57 ms per token,  1758.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27247.50 ms /   221 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 27926.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.18 ms /    31 runs   (    0.55 ms per token,  1803.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3832.02 ms /    31 runs   (  123.61 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3920.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.48 ms /    33 runs   (    0.56 ms per token,  1785.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4087.98 ms /    33 runs   (  123.88 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4183.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) + 2 diopter'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.01 ms /   116 runs   (    0.57 ms per token,  1757.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14252.84 ms /   116 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 14596.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.05 ms /    34 runs   (    0.62 ms per token,  1615.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4159.20 ms /    34 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4263.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.86 ms /   131 runs   (    0.58 ms per token,  1726.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16114.37 ms /   131 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 16513.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.11 ms /   131 runs   (    0.57 ms per token,  1744.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16054.66 ms /   131 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 16447.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.56 ms /   186 runs   (    0.57 ms per token,  1745.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22856.15 ms /   186 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 23423.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.03 ms /    34 runs   (    0.56 ms per token,  1786.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4120.27 ms /    34 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4218.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Uma lente convergente foca a luz proveniente de uma fonte situada a 1 m a uma distância de 50 cm. Qual o poder desta lente?\n",
      "a)+ 1 dioptria.\n",
      "b)+ 2 dioptria.\n",
      "c)+ 3 dioptria.\n",
      "d)+ 4 dioptria.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.53 ms /    15 runs   (    0.57 ms per token,  1757.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2035.81 ms /    86 tokens (   23.67 ms per token,    42.24 tokens per second)\n",
      "llama_print_timings:        eval time =  1697.83 ms /    14 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3777.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.27 ms /    32 runs   (    0.57 ms per token,  1751.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3932.69 ms /    32 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4026.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.78 ms /    27 runs   (    0.55 ms per token,  1827.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3306.22 ms /    27 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3385.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.00 ms /    27 runs   (    0.56 ms per token,  1799.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.13 ms /    27 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3382.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)+ 2 dioptria'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.03 ms /    36 runs   (    0.56 ms per token,  1797.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4408.79 ms /    36 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4513.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a) + 1 dioptria.'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.80 ms /    34 runs   (    0.55 ms per token,  1808.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4174.06 ms /    34 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4273.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a)'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.38 ms /    35 runs   (    0.55 ms per token,  1806.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4288.30 ms /    35 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4389.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a)'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    30 runs   (    0.54 ms per token,  1840.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3732.37 ms /    30 runs   (  124.41 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3818.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.38 ms /    33 runs   (    0.56 ms per token,  1795.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4050.62 ms /    33 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4145.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a) 1 dioptria'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.63 ms /    31 runs   (    0.54 ms per token,  1864.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3785.51 ms /    31 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3873.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 26: \n",
      "Language: english\n",
      "Question: \n",
      "If we were to measure the focal power of the image of the posterior surface of the cornea after its removal from the eyeball, we would have a value around (consider the anterior curvature of the cornea 7.7 mm; the posterior curvature of the cornea 6.8 mm; the index of corneal stroma refraction 1.376 and the refractive index of air 1.00):\n",
      "a) + 5.00 Dioptres.\n",
      "b) 0.00 Dioptres.\n",
      "c)- 5.00 Dioptres.\n",
      "d)- 55.00 Dioptres.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.28 ms /    40 runs   (    0.56 ms per token,  1795.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3619.23 ms /   158 tokens (   22.91 ms per token,    43.66 tokens per second)\n",
      "llama_print_timings:        eval time =  4815.68 ms /    39 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8551.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.26 ms /    40 runs   (    0.56 ms per token,  1797.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4905.15 ms /    40 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5021.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.55 ms /    39 runs   (    0.55 ms per token,  1810.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4768.41 ms /    39 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4882.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.29 ms /    39 runs   (    0.57 ms per token,  1749.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4824.87 ms /    39 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4941.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.66 ms /    34 runs   (    0.55 ms per token,  1822.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4176.18 ms /    34 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4276.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   119.42 ms /   209 runs   (    0.57 ms per token,  1750.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26017.82 ms /   209 runs   (  124.49 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time = 26670.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.94 ms /   209 runs   (    0.57 ms per token,  1757.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25874.75 ms /   209 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 26523.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.67 ms /    43 runs   (    0.55 ms per token,  1816.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5315.45 ms /    43 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5441.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.96 ms /    40 runs   (    0.55 ms per token,  1821.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5020.14 ms /    40 runs   (  125.50 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  5137.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.76 ms /    36 runs   (    0.55 ms per token,  1821.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4400.24 ms /    36 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4504.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Se fossemos medir o poder focal imagem da face posterior da córnea após sua retirada do globo ocular, teríamos um valor ao redor de (considere a curvatura anterior da córnea 7,7 mm; a curvatura posterior da córnea 6,8 mm; o índice de refração do estroma corneano 1,376 e o índice de refração do ar 1,00):\n",
      "a)+ 5,00 Dioptrias.\n",
      "b)0,00 Dioptrias.\n",
      "c)- 5,00 Dioptrias.\n",
      "d)- 55,00 Dioptrias.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.45 ms /    34 runs   (    0.54 ms per token,  1842.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3035.76 ms /   165 tokens (   18.40 ms per token,    54.35 tokens per second)\n",
      "llama_print_timings:        eval time =  4063.92 ms /    33 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7199.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.86 ms /    36 runs   (    0.52 ms per token,  1908.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4411.43 ms /    36 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4516.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.44 ms /    41 runs   (    0.55 ms per token,  1826.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5045.32 ms /    41 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5165.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.04 ms /    18 runs   (    0.50 ms per token,  1991.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2200.27 ms /    18 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2252.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.20 ms /    18 runs   (    0.51 ms per token,  1956.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2187.25 ms /    18 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2239.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.32 ms /    38 runs   (    0.53 ms per token,  1870.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4697.02 ms /    38 runs   (  123.61 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4809.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a) 5,00 Dioptrias'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.26 ms /    18 runs   (    0.51 ms per token,  1943.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2204.49 ms /    18 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2256.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.15 ms /    39 runs   (    0.54 ms per token,  1844.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4795.32 ms /    39 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4909.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.88 ms /    37 runs   (    0.54 ms per token,  1861.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4550.02 ms /    37 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4658.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.37 ms /    38 runs   (    0.54 ms per token,  1865.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4645.96 ms /    38 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4757.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 27: \n",
      "Language: english\n",
      "Question: \n",
      "When reducing the cylinder prescription in a patient who did not adapt to his glasses with the following prescription -1.50 spherical diopter < > -3.50 cylindrical diopter X 180°, a possible prescription maintaining the spherical equivalent is:\n",
      "a)- 2.50 spherical diopter < > -2.50 cylindrical diopter X 180°.\n",
      "b) +1.50 spherical diopter < > -2.50 cylindrical diopter X 180°.\n",
      "c) -4.50 spherical diopter < > +2.50 cylindrical diopter X 90°.\n",
      "d) -2.50 spherical diopter < > +3.00 cylindrical diopter X 90°.a)- 2.50 spherical diopter < > -2.50 cylindrical diopter X 180°.\n",
      "b) +1.50 spherical diopter < > -2.50 cylindrical diopter X 180°.\n",
      "c) -4.50 spherical diopter < > +2.50 cylindrical diopter X 90°.\n",
      "d) -2.50 spherical diopter < > +3.00 cylindrical diopter X 90°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.51 ms /    55 runs   (    0.57 ms per token,  1745.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =  5475.88 ms /   312 tokens (   17.55 ms per token,    56.98 tokens per second)\n",
      "llama_print_timings:        eval time =  6673.86 ms /    54 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 12314.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.10 ms /    55 runs   (    0.57 ms per token,  1768.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6862.75 ms /    55 runs   (  124.78 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  7024.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.27 ms /    55 runs   (    0.57 ms per token,  1758.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6841.79 ms /    55 runs   (  124.40 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  7005.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a)- 2.50 spherical diopter < > -2.50 cylindrical diopter X 180°'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.94 ms /    55 runs   (    0.56 ms per token,  1777.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6851.32 ms /    55 runs   (  124.57 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  7014.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a)- 2.50 spherical diopter < > -2.50 cylindrical diopter X 180°'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.83 ms /    55 runs   (    0.56 ms per token,  1784.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6803.94 ms /    55 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6966.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'Answer option'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.88 ms /    32 runs   (    0.56 ms per token,  1789.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3975.47 ms /    32 runs   (  124.23 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  4068.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.70 ms /    49 runs   (    0.57 ms per token,  1769.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6024.73 ms /    49 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6168.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.07 ms /    55 runs   (    0.56 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6849.20 ms /    55 runs   (  124.53 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  7012.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "Error converting respose to json:  Sure, I'm ready to assist you! Here's my response in JSON format:\n",
      "\n",
      "{\"response\": \"b\") +1.50 spherical diopter < > -2.50 cylindrical diopter X 180°.\"\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.22 ms /    55 runs   (    0.57 ms per token,  1761.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6788.20 ms /    55 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6950.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.34 ms /    54 runs   (    0.56 ms per token,  1779.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6646.68 ms /    54 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6805.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.44 ms /    55 runs   (    0.57 ms per token,  1749.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6817.41 ms /    55 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6979.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to assist you! Please provide the medical query in English or Portuguese with the appropriate delimiters (i.e., ####). I will respond with the answer in JSON format as requested.\n",
      "\n",
      "Here is the correct answer to the sample question\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.15 ms /    55 runs   (    0.57 ms per token,  1765.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6808.78 ms /    55 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6970.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to assist you! Here's the answer to your medical query in JSON format:\n",
      "\n",
      "{\"response\": \"a\") -2.50 spherical diopter < > -2.50 cylindrical diopter X 1\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.99 ms /    55 runs   (    0.56 ms per token,  1774.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6811.73 ms /    55 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6971.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to assist you! Please provide the medical query in English or Portuguese, delimited with #### characters, and I will provide the answer in JSON format with the key \"response\".\n",
      "\n",
      "Here is the correct answer for your first question:\n",
      "\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.07 ms /    29 runs   (    0.59 ms per token,  1698.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3574.83 ms /    29 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3662.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to assist you! Please provide the medical query with the four possible answer options delimited with #### characters.\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.91 ms /    54 runs   (    0.65 ms per token,  1546.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6690.05 ms /    54 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6856.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Ao reduzirmos a prescrição do cilindro em um paciente que não se adaptou a seus óculos com a seguinte prescrição -1,50 Diotria esferica < > -3,50 dioptria cilindrica X 180°, uma possível prescrição mantendo o equivalente esférico é:\n",
      "a)- 2,50 dioptria esferica < > -2,50 dioptria cilindrica X 180°.\n",
      "b)+1,50 dioptria esferica < > -2,50 dioptria cilindrica X 180°.\n",
      "c)-4,50 dioptria esferica < > +2,50 dioptria cilindrica X 90°.\n",
      "d)-2,50 dioptria esferica < > +3,00 dioptria cilindrica X 90°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3762.66 ms /   225 tokens (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:        eval time =   725.83 ms /     6 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4508.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.31 ms /    27 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3379.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    81.54 ms /   142 runs   (    0.57 ms per token,  1741.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17624.71 ms /   142 runs   (  124.12 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 18049.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.04 ms /     9 runs   (    0.56 ms per token,  1785.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1106.18 ms /     9 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  1132.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.41 ms /     7 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.41 ms /    20 runs   (    0.57 ms per token,  1752.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2479.41 ms /    20 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2536.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.94 ms /     7 runs   (    0.56 ms per token,  1778.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.48 ms /     7 runs   (  124.07 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.43 ms /     7 runs   (  120.92 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.49 ms /     7 runs   (  123.78 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   886.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1761.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.15 ms /     7 runs   (  121.45 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   869.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 28: \n",
      "Language: english\n",
      "Question: \n",
      "A light ray is deviated by 20 mm from the visual axis at a distance of 50 cm from a prism. What is the power of the prism in diopters-prismatics?\n",
      "a) 0.4.\n",
      "b)2.5.\n",
      "c)4.\n",
      "d) 10.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.96 ms /    29 runs   (    0.58 ms per token,  1709.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1922.31 ms /    78 tokens (   24.64 ms per token,    40.58 tokens per second)\n",
      "llama_print_timings:        eval time =  3410.60 ms /    28 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5418.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.84 ms /    24 runs   (    0.58 ms per token,  1733.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2932.00 ms /    24 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3001.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2906.08 ms /    24 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2976.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.95 ms /    26 runs   (    0.58 ms per token,  1738.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3150.94 ms /    26 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3226.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.02 ms /    28 runs   (    0.57 ms per token,  1748.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3487.86 ms /    28 runs   (  124.57 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3571.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.77 ms /    24 runs   (    0.57 ms per token,  1742.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2883.59 ms /    24 runs   (  120.15 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  2952.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.94 ms /    28 runs   (    0.57 ms per token,  1757.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3408.85 ms /    28 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3489.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.34 ms /    29 runs   (    0.56 ms per token,  1774.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3558.81 ms /    29 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3642.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.72 ms /    24 runs   (    0.57 ms per token,  1748.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.45 ms /    24 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2985.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1738.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2925.80 ms /    24 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2996.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um raio de luz sofre desvio de 20 mm do eixo visual a uma distância de 50 cm de um prima. Qual é o poder do prisma em dioptrias-prismáticas?\n",
      "a)0,4.\n",
      "b)2,5.\n",
      "c)4.\n",
      "d)10.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.33 ms /    12 runs   (    0.61 ms per token,  1636.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2062.66 ms /    83 tokens (   24.85 ms per token,    40.24 tokens per second)\n",
      "llama_print_timings:        eval time =  1357.47 ms /    11 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3456.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.66 ms /    29 runs   (    0.57 ms per token,  1740.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3539.55 ms /    29 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3624.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.04 ms /    27 runs   (    0.56 ms per token,  1795.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3304.68 ms /    27 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3383.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.58 ms /    31 runs   (    0.57 ms per token,  1763.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3769.31 ms /    31 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3859.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1762.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   834.28 ms /     7 runs   (  119.18 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =   853.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    95.79 ms /   168 runs   (    0.57 ms per token,  1753.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20593.88 ms /   168 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 21112.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.26 ms /    25 runs   (    0.57 ms per token,  1753.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3024.44 ms /    25 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3097.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.58 ms /    31 runs   (    0.57 ms per token,  1763.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3782.19 ms /    31 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3873.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.55 ms /    31 runs   (    0.57 ms per token,  1765.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3786.29 ms /    31 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3876.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.68 ms /    26 runs   (    0.56 ms per token,  1771.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3197.62 ms /    26 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3272.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 29: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Considering Gullstrand's schematic eye, what is the characteristic of the image formed on the retina?\n",
      "a) Real, inverted.\n",
      "b) Virtual, inverted.\n",
      "c) Real, direct.\n",
      "d) Virtual, direct.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.75 ms /    22 runs   (    0.58 ms per token,  1725.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1501.64 ms /    64 tokens (   23.46 ms per token,    42.62 tokens per second)\n",
      "llama_print_timings:        eval time =  2562.80 ms /    21 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4129.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.05 ms /    23 runs   (    0.57 ms per token,  1762.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2796.12 ms /    23 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2864.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.41 ms /    22 runs   (    0.56 ms per token,  1772.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2670.70 ms /    22 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2735.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.92 ms /    23 runs   (    0.56 ms per token,  1780.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2849.94 ms /    23 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2916.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.86 ms /    23 runs   (    0.56 ms per token,  1787.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2820.32 ms /    23 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2886.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.87 ms /    23 runs   (    0.56 ms per token,  1786.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2792.51 ms /    23 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2860.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.81 ms /    23 runs   (    0.56 ms per token,  1795.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2809.04 ms /    23 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2876.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.84 ms /    51 runs   (    0.57 ms per token,  1768.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6237.91 ms /    51 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  6389.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.68 ms /    32 runs   (    0.58 ms per token,  1713.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3895.21 ms /    32 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3991.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Considerando o olho esquemático de Gullstrand, qual a característica da imagem formada na retina?\n",
      "a)Real, invertida.\n",
      "b)Virtual, invertida.\n",
      "c)Real, direta.\n",
      "d)Virtual, direta.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.09 ms /    30 runs   (    0.57 ms per token,  1755.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3648.80 ms /    30 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3737.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.56 ms /    32 runs   (    0.58 ms per token,  1723.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1242.33 ms /    67 tokens (   18.54 ms per token,    53.93 tokens per second)\n",
      "llama_print_timings:        eval time =  3832.49 ms /    31 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5171.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.00 ms /    23 runs   (    0.57 ms per token,  1769.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2775.37 ms /    23 runs   (  120.67 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2842.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c} Real, direta.'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.07 ms /    32 runs   (    0.56 ms per token,  1770.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3880.81 ms /    32 runs   (  121.28 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3975.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.75 ms /    33 runs   (    0.57 ms per token,  1759.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4033.75 ms /    33 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4130.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.12 ms /    30 runs   (    0.57 ms per token,  1752.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3654.56 ms /    30 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3743.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.47 ms /    22 runs   (    0.57 ms per token,  1764.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2669.61 ms /    22 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2733.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.17 ms /    32 runs   (    0.57 ms per token,  1761.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3876.05 ms /    32 runs   (  121.13 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3970.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.72 ms /    26 runs   (    0.57 ms per token,  1766.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3172.12 ms /    26 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3247.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.16 ms /    25 runs   (    0.57 ms per token,  1766.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3059.15 ms /    25 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3132.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.74 ms /    12 runs   (    0.56 ms per token,  1781.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1458.79 ms /    12 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  1493.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 30: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the alternative that correctly correlates the classes of antibacterials to their respective main sites of action.\n",
      "\n",
      "I- Cephalosporins\n",
      "II- Tetracyclines\n",
      "III- Quinolones\n",
      "IV- Macrolides\n",
      "\n",
      "A- Protein synthesis (30s inhibitor)\n",
      "B- Protein synthesis (50s inhibitor)\n",
      "C DNA gyrase\n",
      "D- Cell wall synthesis\n",
      "\n",
      "a) I: A; II: D; III: D; IV: b.\n",
      "b)I:D; II: A; III: C; IV: b.\n",
      "c) I: A; II: D; III: B; IV: c.\n",
      "d)I:D; II: B; III: A; IV: c.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    76.95 ms /   133 runs   (    0.58 ms per token,  1728.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3974.68 ms /   180 tokens (   22.08 ms per token,    45.29 tokens per second)\n",
      "llama_print_timings:        eval time = 16294.69 ms /   132 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 20675.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.91 ms /    27 runs   (    0.55 ms per token,  1810.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3293.78 ms /    27 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3372.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.92 ms /   136 runs   (    0.57 ms per token,  1745.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16913.89 ms /   136 runs   (  124.37 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 17329.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.09 ms /   170 runs   (    0.57 ms per token,  1750.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21063.23 ms /   170 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 21587.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.55 ms /   187 runs   (    0.57 ms per token,  1755.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22906.42 ms /   187 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 23480.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    82.80 ms /   145 runs   (    0.57 ms per token,  1751.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17789.22 ms /   145 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 18229.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.80 ms /    61 runs   (    0.57 ms per token,  1752.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7650.55 ms /    61 runs   (  125.42 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  7832.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.39 ms /   155 runs   (    0.57 ms per token,  1753.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18972.51 ms /   155 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 19446.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.35 ms /   187 runs   (    0.57 ms per token,  1758.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22964.04 ms /   187 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 23537.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.75 ms /   165 runs   (    0.57 ms per token,  1760.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20431.35 ms /   165 runs   (  123.83 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 20936.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que correlaciona corretamente as classes de antibacterianos aos seus respectivos principais sítios de ação.\n",
      "\n",
      "I- Cefalosporinas\n",
      "II- Tetraciclínicas\n",
      "III- Quinolonas\n",
      "IV- Macrolídeos\n",
      "\n",
      "A- Síntese proteica (inibidor 30s)\n",
      "B- Síntese proteica (inibidor 50s)\n",
      "C- DNA girase\n",
      "D- Síntese de parede celular\n",
      "\n",
      "a)I: A; II: D; III: D; IV: B.\n",
      "b)I: D; II: A; III: C; IV: B.\n",
      "c)I: A; II: D; III: B; IV: C.\n",
      "d)I: D; II: B; III: A; IV: C.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.44 ms /    44 runs   (    0.58 ms per token,  1729.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3809.11 ms /   206 tokens (   18.49 ms per token,    54.08 tokens per second)\n",
      "llama_print_timings:        eval time =  5328.22 ms /    43 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  9270.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.40 ms /     7 runs   (    0.49 ms per token,  2056.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.88 ms /     7 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.01 ms /    43 runs   (    0.56 ms per token,  1791.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5275.78 ms /    43 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5402.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.21 ms /    44 runs   (    0.55 ms per token,  1817.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5387.96 ms /    44 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5516.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.41 ms /     7 runs   (    0.49 ms per token,  2051.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.26 ms /     7 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   877.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.31 ms /    44 runs   (    0.55 ms per token,  1809.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5437.81 ms /    44 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5568.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.26 ms /    44 runs   (    0.55 ms per token,  1813.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5401.53 ms /    44 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5531.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.43 ms /     7 runs   (    0.49 ms per token,  2038.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.11 ms /     7 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.91 ms /   161 runs   (    0.57 ms per token,  1751.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20014.24 ms /   161 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 20508.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    95.67 ms /   161 runs   (    0.59 ms per token,  1682.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19908.96 ms /   161 runs   (  123.66 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 20412.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 31: \n",
      "Language: english\n",
      "Question: \n",
      "A patient with Sjogren's syndrome started to have improvements in his oral symptoms (increased salivation) after the non-ophthalmologist prescribed:\n",
      "a) Brimonidine, however, evolved with punctiform miosis and low vision.\n",
      "b) Tetracaine, however, evolved with traditional retinal detachment.\n",
      "c) Atropine, however, evolved with medium medriasis and accommodation difficulties.\n",
      "d) Pilocarpine, however, evolved with accommodative spasm.\n",
      "Test #0: \n",
      "{'response': 'd) Pilocarpine'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.45 ms /    32 runs   (    0.58 ms per token,  1734.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2666.97 ms /   127 tokens (   21.00 ms per token,    47.62 tokens per second)\n",
      "llama_print_timings:        eval time =  3769.51 ms /    31 runs   (  121.60 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  6531.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.30 ms /    44 runs   (    0.58 ms per token,  1738.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5407.67 ms /    44 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5538.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine, however, evolved with accommodative spasm.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.55 ms /    14 runs   (    0.61 ms per token,  1637.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1713.76 ms /    14 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1757.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.87 ms /    30 runs   (    0.73 ms per token,  1371.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3620.84 ms /    30 runs   (  120.69 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3723.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine'}\n",
      "Test #4: \n",
      "{'response': 'd) Pilocarpine, however, evolved with accommodative spasm.'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.70 ms /    40 runs   (    0.57 ms per token,  1762.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4877.26 ms /    40 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4996.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.67 ms /    33 runs   (    0.57 ms per token,  1767.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4040.41 ms /    33 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4137.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.07 ms /    41 runs   (    0.56 ms per token,  1777.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5052.03 ms /    41 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5173.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine, however, evolved with accommodative spasm.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.02 ms /    41 runs   (    0.56 ms per token,  1781.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5082.93 ms /    41 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  5204.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine, however, evolved with accommodative spasm.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.85 ms /    30 runs   (    0.56 ms per token,  1780.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3719.93 ms /    30 runs   (  124.00 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3809.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.91 ms /    37 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4623.64 ms /    37 runs   (  124.96 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  4733.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine, however, evolved with accommodative spasm.'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente com síndrome Sjogren passou a ter melhoras dos seus sintomas orais (aumento da salivação) após o médico não-oftalmologista prescrever:\n",
      "a)Brimonidina, todavia, evoluiu com miose puntiforme e baixa de visão.\n",
      "b)Tetracaína, todavia, evoluiu com descolamento de retina tradicional.\n",
      "c)Atropina, todavia, evoluiu com média medríase e dificuldades de acomodação.\n",
      "d)Pilocarpina, todavia, evoluiu com espasmo acomodativo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.93 ms /    48 runs   (    0.58 ms per token,  1718.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3761.16 ms /   159 tokens (   23.66 ms per token,    42.27 tokens per second)\n",
      "llama_print_timings:        eval time =  5861.08 ms /    47 runs   (  124.70 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  9766.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.53 ms /    48 runs   (    0.59 ms per token,  1682.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5941.88 ms /    48 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6087.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.62 ms /    48 runs   (    0.58 ms per token,  1737.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5892.21 ms /    48 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6035.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   880.23 ms /     7 runs   (  125.75 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =   901.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.45 ms /    11 runs   (    0.59 ms per token,  1704.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1344.19 ms /    11 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  1376.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.44 ms /     7 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   889.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1739.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3471.38 ms /    28 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3554.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.61 ms /    48 runs   (    0.58 ms per token,  1738.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5979.25 ms /    48 runs   (  124.57 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  6123.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.68 ms /   115 runs   (    0.58 ms per token,  1724.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14101.88 ms /   115 runs   (  122.62 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 14450.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.55 ms /    49 runs   (    0.58 ms per token,  1716.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6068.83 ms /    49 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6215.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 32: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the use of tissue plasminogen activating factor, it is correct to state:\n",
      "a) This medication in the intracameral space is proscribed.\n",
      "b) Activation of plasmin into plaminogen helps in the degradation of blood.\n",
      "c) Activation of plasminogen to plasmin helps in the degradation of blood.\n",
      "d) Its main indication is in bleeding in the vitreous space.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.61 ms /    25 runs   (    0.58 ms per token,  1711.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2512.99 ms /   107 tokens (   23.49 ms per token,    42.58 tokens per second)\n",
      "llama_print_timings:        eval time =  2915.81 ms /    24 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5503.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.95 ms /   101 runs   (    0.58 ms per token,  1713.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12391.15 ms /   101 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12702.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.97 ms /    25 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3054.23 ms /    25 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3129.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.79 ms /    24 runs   (    0.57 ms per token,  1740.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2926.67 ms /    24 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2996.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.29 ms /    46 runs   (    0.57 ms per token,  1749.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5623.35 ms /    46 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5760.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1723.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3055.07 ms /    25 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3128.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1739.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3054.06 ms /    25 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3127.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.88 ms /    24 runs   (    0.58 ms per token,  1729.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2951.93 ms /    24 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3022.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.50 ms /    25 runs   (    0.58 ms per token,  1724.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3041.58 ms /    25 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3114.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.12 ms /    44 runs   (    0.57 ms per token,  1751.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5339.76 ms /    44 runs   (  121.36 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5469.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação ao uso de fator ativador do plasminogênio tecidual, é correto afirmar:\n",
      "a)Essa medicação no espaço intracameral é proscrita.\n",
      "b)A ativação da plasmina em plaminogênio ajuda na degradação do sangue.\n",
      "c)A ativação do plasminogênio em plasmina ajuda na degradação do sangue.\n",
      "d)Sua maior indicação é em sangramentos no espaço vítreo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.23 ms /     7 runs   (    0.60 ms per token,  1654.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3205.29 ms /   135 tokens (   23.74 ms per token,    42.12 tokens per second)\n",
      "llama_print_timings:        eval time =   725.56 ms /     6 runs   (  120.93 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3952.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.73 ms /    27 runs   (    0.58 ms per token,  1716.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3287.59 ms /    27 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3367.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.30 ms /    62 runs   (    0.59 ms per token,  1707.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7666.27 ms /    62 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  7855.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1741.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2930.63 ms /    24 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3001.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.17 ms /    35 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4352.24 ms /    35 runs   (  124.35 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  4455.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  ####\n",
      "\n",
      "Resposta: c) A ativação do plasminogênio em plasmina ajuda na degradação do sangue.\n",
      "Generating new response...\n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   877.50 ms /     7 runs   (  125.36 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =   897.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.35 ms /    25 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3033.87 ms /    25 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3107.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1741.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2939.06 ms /    24 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3009.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3426.76 ms /    28 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3509.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    28 runs   (    0.58 ms per token,  1732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3526.96 ms /    28 runs   (  125.96 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  3609.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.46 ms /     7 runs   (  126.49 ms per token,     7.91 tokens per second)\n",
      "llama_print_timings:       total time =   906.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 33: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the use of mitomycin-C in trabeculectomy, it is correct to state:\n",
      "a) Because it is a pyrimidine analogue, its action stems from the blockage of thymine synthesis, preventing the production of DNA/RNA.\n",
      "b) Scleral thinning, avascular bleb, postoperative pain and corneal edema are complications related to its use.\n",
      "c) In pregnant women, the concentration should be increased due to a greater tendency to fibrosis.\n",
      "d) It should not be used in melanodermic patients.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.72 ms /   100 runs   (    0.58 ms per token,  1732.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3172.82 ms /   143 tokens (   22.19 ms per token,    45.07 tokens per second)\n",
      "llama_print_timings:        eval time = 12159.51 ms /    99 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 15634.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.73 ms /   131 runs   (    0.58 ms per token,  1729.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16184.64 ms /   131 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 16585.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   129.34 ms /   224 runs   (    0.58 ms per token,  1731.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27673.44 ms /   224 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 28377.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.90 ms /    62 runs   (    0.58 ms per token,  1727.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7617.52 ms /    62 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7802.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.14 ms /    63 runs   (    0.57 ms per token,  1743.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7773.22 ms /    63 runs   (  123.38 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  7961.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.70 ms /    55 runs   (    0.58 ms per token,  1734.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6747.28 ms /    55 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6909.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.20 ms /     9 runs   (    0.58 ms per token,  1731.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1101.11 ms /     9 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1127.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.17 ms /   109 runs   (    0.58 ms per token,  1725.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13441.26 ms /   109 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 13770.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.04 ms /    97 runs   (    0.58 ms per token,  1730.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11900.74 ms /    97 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12192.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.29 ms /   101 runs   (    0.58 ms per token,  1732.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12323.41 ms /   101 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 12630.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação ao uso de mitomicina-C na trabeculectomia, é correto afirmar:\n",
      "a)Por ser um análogo da pirimidina, sua ação decorre do bloqueio da síntese de timina, evitando a produção de DNA/RNA.\n",
      "b)Afinamento escleral, bolha avascular, dor pós-operatória e edema de córnea são complicações relacionadas ao seu uso.\n",
      "c)Nas gestantes, a concentração deve ser aumentada pela maior tendência à fibrose.\n",
      "d)Não deve ser usada em pacientes melanodérmicos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   120.14 ms /   206 runs   (    0.58 ms per token,  1714.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3271.46 ms /   161 tokens (   20.32 ms per token,    49.21 tokens per second)\n",
      "llama_print_timings:        eval time = 25475.78 ms /   205 runs   (  124.27 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 29395.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.57 ms /    81 runs   (    0.57 ms per token,  1739.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9956.42 ms /    81 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10198.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.24 ms /    82 runs   (    0.58 ms per token,  1735.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10132.37 ms /    82 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 10378.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.46 ms /    82 runs   (    0.58 ms per token,  1727.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10048.75 ms /    82 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 10293.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.02 ms /    31 runs   (    0.58 ms per token,  1720.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3780.82 ms /    31 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3874.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.42 ms /     7 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.86 ms /   100 runs   (    0.58 ms per token,  1728.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12353.92 ms /   100 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 12659.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.46 ms /   103 runs   (    0.58 ms per token,  1732.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12720.52 ms /   103 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13037.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.35 ms /     7 runs   (  121.05 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.64 ms /    17 runs   (    0.57 ms per token,  1764.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2091.38 ms /    17 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2144.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 34: \n",
      "Language: english\n",
      "Question: \n",
      "Patients with proliferative diabetic retinopathy will complement their treatment with intravitreal anti-VEGF. We can state that:\n",
      "a) Priority should be given to the inhibition of the B isoforms of VEGF, since they are the main new vessel formers.\n",
      "b)Ranibizumab inhibits all VEGF-B isoforms, but not VEGF-A.\n",
      "c) Bevacizumab does not allow VEGF-A isoforms to bind to their receptors.\n",
      "d) The use of pegaptanib is no longer used, as the drug does not penetrate the retinal layers.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.23 ms /   179 runs   (    0.59 ms per token,  1685.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2586.40 ms /   162 tokens (   15.97 ms per token,    62.64 tokens per second)\n",
      "llama_print_timings:        eval time = 21993.05 ms /   178 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 25147.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3403.79 ms /    28 runs   (  121.56 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3486.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   119.07 ms /   205 runs   (    0.58 ms per token,  1721.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25261.60 ms /   205 runs   (  123.23 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 25903.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    98.13 ms /   170 runs   (    0.58 ms per token,  1732.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21050.83 ms /   170 runs   (  123.83 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 21572.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.31 ms /    56 runs   (    0.58 ms per token,  1732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6790.17 ms /    56 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  6955.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.42 ms /    65 runs   (    0.58 ms per token,  1736.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7989.05 ms /    65 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  8184.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.53 ms /    20 runs   (    0.58 ms per token,  1734.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2491.76 ms /    20 runs   (  124.59 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  2552.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.06 ms /    17 runs   (    0.59 ms per token,  1689.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2207.55 ms /    17 runs   (  129.86 ms per token,     7.70 tokens per second)\n",
      "llama_print_timings:       total time =  2261.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3423.94 ms /    28 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3507.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.69 ms /   205 runs   (    0.58 ms per token,  1727.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25307.35 ms /   205 runs   (  123.45 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 25964.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente com retinopatia diabética proliferativa complementará seu tratamento com anti-VEGF intravítreo. Podemos afirmar que:\n",
      "a)Deve-se priorizar a inibição das isoformas B do VEGF, uma vez que são as principais formadoras de neovasos.\n",
      "b)O ranibizumabe inibe todas as isoformas do VEGF-B, mas não as de VEGF-A.\n",
      "c)O bevacizumabe não permite que as isoformas de VEFG-A se liguem aos seus receptores.\n",
      "d)O uso de pegaptanibe não é mais utilizado, pois a droga não penetra nas camadas da retina.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.02 ms /    86 runs   (    0.59 ms per token,  1685.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3719.99 ms /   186 tokens (   20.00 ms per token,    50.00 tokens per second)\n",
      "llama_print_timings:        eval time = 10417.25 ms /    85 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 14411.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.93 ms /   119 runs   (    0.58 ms per token,  1726.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14707.55 ms /   119 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15076.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.40 ms /   133 runs   (    0.58 ms per token,  1718.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16435.44 ms /   133 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 16841.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   104.22 ms /   181 runs   (    0.58 ms per token,  1736.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22403.46 ms /   181 runs   (  123.78 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 22965.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.12 ms /     7 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.61 ms /    20 runs   (    0.58 ms per token,  1722.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2519.74 ms /    20 runs   (  125.99 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  2578.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   105.73 ms /   181 runs   (    0.58 ms per token,  1711.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22313.09 ms /   181 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 22884.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   104.56 ms /   181 runs   (    0.58 ms per token,  1731.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22414.40 ms /   181 runs   (  123.84 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 22979.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.37 ms /     7 runs   (  120.20 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3497.59 ms /    28 runs   (  124.91 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3580.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 35: \n",
      "Language: english\n",
      "Question: \n",
      "Considering conjunctival tumors, the presence of which parameter below is used to differentiate between conjunctival dysplasia and invasive carcinoma?\n",
      "a) Cellular atypia.\n",
      "b) Involvement of the epithelial full thickness.\n",
      "c)Increase in the number of atypical nucleoli.\n",
      "d) Invasion of the basement membrane.\n",
      " \n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.00 ms /    36 runs   (    0.58 ms per token,  1714.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2265.33 ms /    95 tokens (   23.85 ms per token,    41.94 tokens per second)\n",
      "llama_print_timings:        eval time =  4263.10 ms /    35 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6637.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.20 ms /    35 runs   (    0.58 ms per token,  1732.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4300.58 ms /    35 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4405.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Invasion of the basement membrane.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.14 ms /    71 runs   (    0.58 ms per token,  1725.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8663.00 ms /    71 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  8880.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.46 ms /    79 runs   (    0.58 ms per token,  1737.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9686.67 ms /    79 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  9927.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.80 ms /    64 runs   (    0.57 ms per token,  1739.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7793.61 ms /    64 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  7985.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.43 ms /    77 runs   (    0.58 ms per token,  1733.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9424.11 ms /    77 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  9655.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.85 ms /    36 runs   (    0.61 ms per token,  1647.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4396.46 ms /    36 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4551.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    25 runs   (    0.65 ms per token,  1547.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3056.07 ms /    25 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3228.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.67 ms /    36 runs   (    0.66 ms per token,  1521.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4486.33 ms /    36 runs   (  124.62 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  4733.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.55 ms /   143 runs   (    0.60 ms per token,  1671.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17593.09 ms /   143 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18203.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Considerando os tumores conjuntivais, a presença de qual parâmetro abaixo é utilizado para a diferenciação entre displasia da conjuntiva e carcinoma invasivo?\n",
      "a)Atipia celular.\n",
      "b)Envolvimento da espessura total epitelial.\n",
      "c)Aumento do número de nucleolos atípicos.\n",
      "d)Invasão da membrana basal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.35 ms /    91 runs   (    0.59 ms per token,  1705.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2552.97 ms /   104 tokens (   24.55 ms per token,    40.74 tokens per second)\n",
      "llama_print_timings:        eval time = 11074.84 ms /    90 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 13908.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.67 ms /    41 runs   (    0.58 ms per token,  1732.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5003.86 ms /    41 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5124.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3326.14 ms /    27 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3405.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3311.26 ms /    27 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3391.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.87 ms /    50 runs   (    0.58 ms per token,  1731.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6221.58 ms /    50 runs   (  124.43 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  6371.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   882.52 ms /     7 runs   (  126.07 ms per token,     7.93 tokens per second)\n",
      "llama_print_timings:       total time =   903.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.16 ms /    40 runs   (    0.58 ms per token,  1727.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4885.04 ms /    40 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5005.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    28 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3472.39 ms /    28 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3556.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.67 ms /    99 runs   (    0.58 ms per token,  1716.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12167.58 ms /    99 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 12469.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.93 ms /    27 runs   (    0.59 ms per token,  1694.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3319.61 ms /    27 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3400.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 36: \n",
      "Language: english\n",
      "Question: \n",
      "Fluorescein-labelled monoclonal antibodies (FITC) directed against the outer membrane cell wall protein are a better diagnostic method for which of the agents listed below?\n",
      "a) C. trachomatis.\n",
      "b) Acanthamoeba sp.\n",
      "c)Cryptococcus sp.\n",
      "d) Neisseria meningitidis.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.06 ms /    24 runs   (    0.59 ms per token,  1706.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2270.78 ms /    93 tokens (   24.42 ms per token,    40.96 tokens per second)\n",
      "llama_print_timings:        eval time =  2794.46 ms /    23 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5137.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2954.90 ms /    24 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3026.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.01 ms /    24 runs   (    0.58 ms per token,  1712.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2971.03 ms /    24 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3042.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.92 ms /    24 runs   (    0.58 ms per token,  1724.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2984.90 ms /    24 runs   (  124.37 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3056.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2922.22 ms /    24 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2993.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1727.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2952.30 ms /    24 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3024.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.64 ms /    27 runs   (    0.58 ms per token,  1726.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3329.75 ms /    27 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3410.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.73 ms /    24 runs   (    0.57 ms per token,  1747.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2940.57 ms /    24 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3011.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.48 ms /    25 runs   (    0.58 ms per token,  1726.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3025.42 ms /    25 runs   (  121.02 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3099.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    27 runs   (    0.58 ms per token,  1732.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3292.40 ms /    27 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3372.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Anticorpos monoclonais marcados com fluoresceína (FITC) e dirigidos contra a membrana externa proteica da parede celular são um método diagnóstico mais bem indicado para qual dos agentes listados abaixo?\n",
      "a)C. tracomatis.\n",
      "b)Acanthamoeba sp.\n",
      "c)Cryptococcus sp.\n",
      "d)Neisseria meningitidis.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.28 ms /    28 runs   (    0.58 ms per token,  1720.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2231.53 ms /   109 tokens (   20.47 ms per token,    48.85 tokens per second)\n",
      "llama_print_timings:        eval time =  3294.90 ms /    27 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5610.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.87 ms /    27 runs   (    0.59 ms per token,  1701.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3330.14 ms /    27 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3412.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3286.73 ms /    27 runs   (  121.73 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3367.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.45 ms /    25 runs   (    0.58 ms per token,  1730.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3058.92 ms /    25 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3132.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3282.49 ms /    27 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3362.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.80 ms /    24 runs   (    0.57 ms per token,  1739.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2910.43 ms /    24 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2983.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3312.14 ms /    27 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3392.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3409.37 ms /    28 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3493.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.07 ms /    28 runs   (    0.57 ms per token,  1741.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3473.51 ms /    28 runs   (  124.05 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3557.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.65 ms /    36 runs   (    0.57 ms per token,  1743.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4378.60 ms /    36 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4486.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 37: \n",
      "Language: english\n",
      "Question: \n",
      "The innervation of the cornea is mainly done by which ciliary nerves?\n",
      "a) Short anterior.\n",
      "b) Short posterior.\n",
      "c) Long anterior.\n",
      "d) Long posterior.\n",
      "\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.29 ms /    39 runs   (    0.57 ms per token,  1749.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   762.98 ms /    50 tokens (   15.26 ms per token,    65.53 tokens per second)\n",
      "llama_print_timings:        eval time =  4702.99 ms /    38 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  5584.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    28 runs   (    0.57 ms per token,  1750.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3397.02 ms /    28 runs   (  121.32 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3480.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.85 ms /    28 runs   (    0.57 ms per token,  1766.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3386.84 ms /    28 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3469.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.75 ms /    31 runs   (    0.57 ms per token,  1746.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3739.85 ms /    31 runs   (  120.64 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3832.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.90 ms /    21 runs   (    0.57 ms per token,  1764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2563.43 ms /    21 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2624.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.85 ms /    12 runs   (    0.57 ms per token,  1751.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1454.11 ms /    12 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  1488.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) Short posterior'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.03 ms /    28 runs   (    0.57 ms per token,  1746.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3436.17 ms /    28 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3520.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.41 ms /    27 runs   (    0.57 ms per token,  1752.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3308.63 ms /    27 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3389.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.84 ms /    28 runs   (    0.57 ms per token,  1768.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3380.22 ms /    28 runs   (  120.72 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3463.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c} Long anterior.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.24 ms /    11 runs   (    0.57 ms per token,  1762.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1399.09 ms /    11 runs   (  127.19 ms per token,     7.86 tokens per second)\n",
      "llama_print_timings:       total time =  1431.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A inervação da córnea é feita, principalmente, por quais nervos ciliares?\n",
      "a)Anteriores curtos.\n",
      "b)Posteriores curtos.\n",
      "c)Anteriores longos.\n",
      "d)Posteriores longos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1736.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1709.00 ms /    69 tokens (   24.77 ms per token,    40.37 tokens per second)\n",
      "llama_print_timings:        eval time =  3293.05 ms /    27 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5086.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.71 ms /    28 runs   (    0.56 ms per token,  1782.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3418.98 ms /    28 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3502.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.29 ms /    24 runs   (    0.55 ms per token,  1806.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2905.13 ms /    24 runs   (  121.05 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2976.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.90 ms /    25 runs   (    0.56 ms per token,  1798.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3033.26 ms /    25 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3107.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.14 ms /    27 runs   (    0.56 ms per token,  1783.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3275.28 ms /    27 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3354.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.70 ms /    28 runs   (    0.56 ms per token,  1783.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3432.64 ms /    28 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3515.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.77 ms /    28 runs   (    0.56 ms per token,  1775.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3409.12 ms /    28 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3493.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.43 ms /    24 runs   (    0.56 ms per token,  1786.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2905.73 ms /    24 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2976.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1766.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.37 ms /     7 runs   (  120.62 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.08 ms /    28 runs   (    0.57 ms per token,  1741.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3411.12 ms /    28 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3494.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 38: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following extrinsic ocular muscles is innervated by the superior division of the oculomotor nerve?\n",
      "a) Superior oblique.\n",
      "b) Inferior rectum.\n",
      "c) medial rectus\n",
      "d) Superior rectum.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.64 ms /    25 runs   (    0.59 ms per token,  1707.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1639.82 ms /    66 tokens (   24.85 ms per token,    40.25 tokens per second)\n",
      "llama_print_timings:        eval time =  2883.88 ms /    24 runs   (  120.16 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  4598.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3391.32 ms /    28 runs   (  121.12 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3474.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.65 ms /    29 runs   (    0.57 ms per token,  1741.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3508.76 ms /    29 runs   (  120.99 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3595.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.79 ms /    24 runs   (    0.57 ms per token,  1740.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2910.49 ms /    24 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2981.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3264.57 ms /    27 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3344.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.87 ms /    33 runs   (    0.57 ms per token,  1749.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4030.33 ms /    33 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4129.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.22 ms /    30 runs   (    0.57 ms per token,  1742.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3705.87 ms /    30 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3795.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.75 ms /    24 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2996.76 ms /    24 runs   (  124.87 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3068.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.14 ms /    60 runs   (    0.57 ms per token,  1757.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7300.32 ms /    60 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7480.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.42 ms /    60 runs   (    0.57 ms per token,  1743.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7308.32 ms /    60 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  7489.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual dos músculos oculares extrínsecos abaixo é inervado pela divisão superior do nervo oculomotor?\n",
      "a)Oblíquo superior.\n",
      "b)Reto inferior.\n",
      "c)Reto medial\n",
      "d)Reto superior.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.23 ms /    43 runs   (    0.59 ms per token,  1703.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1698.07 ms /    71 tokens (   23.92 ms per token,    41.81 tokens per second)\n",
      "llama_print_timings:        eval time =  5095.03 ms /    42 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  6921.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.41 ms /    43 runs   (    0.57 ms per token,  1761.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5236.72 ms /    43 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5362.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.38 ms /     7 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   887.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3380.67 ms /    28 runs   (  120.74 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3463.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1720.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.45 ms /     7 runs   (  120.64 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1754.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.51 ms /     7 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   885.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.08 ms /    42 runs   (    0.57 ms per token,  1744.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5095.21 ms /    42 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5219.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.96 ms /     7 runs   (  124.42 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.11 ms /    42 runs   (    0.57 ms per token,  1741.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5100.80 ms /    42 runs   (  121.45 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5226.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 39: \n",
      "Language: english\n",
      "Question: \n",
      "Based on anatomical knowledge, choose the most likely alternative.\n",
      "a) Fracture of the ethmoid bone can cause orbital emphysema.\n",
      "b) Fracture of the lateral part of the orbit can cause intraorbital hemorrhage, due to rupture of the anterior and posterior ethmoidal arteries.\n",
      "c) Fracture of the orbital floor can cause impairment of masticatory movements, due to damage to the maxillary nerve, a branch of the trigeminal nerve.\n",
      "d) Fracture of the lacrimal bone may decrease tear excretion by the main lacrimal gland, by compromising the lacrimal nerve.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.01 ms /    42 runs   (    0.64 ms per token,  1554.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5114.43 ms /    42 runs   (  121.77 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5246.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.00 ms /    24 runs   (    0.58 ms per token,  1714.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3612.94 ms /   165 tokens (   21.90 ms per token,    45.67 tokens per second)\n",
      "llama_print_timings:        eval time =  2899.34 ms /    23 runs   (  126.06 ms per token,     7.93 tokens per second)\n",
      "llama_print_timings:       total time =  6584.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.51 ms /    24 runs   (    0.69 ms per token,  1453.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2984.98 ms /    24 runs   (  124.37 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3062.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n",
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.41 ms /    25 runs   (    0.66 ms per token,  1523.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3102.28 ms /    25 runs   (  124.09 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3181.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.91 ms /    28 runs   (    0.60 ms per token,  1655.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3475.59 ms /    28 runs   (  124.13 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3560.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1740.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3077.14 ms /    25 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3150.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    28 runs   (    0.58 ms per token,  1728.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3443.44 ms /    28 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3527.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2952.87 ms /    24 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3024.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.27 ms /     7 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1725.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3088.47 ms /    25 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3162.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1734.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3428.34 ms /    28 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3510.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com base em conhecimentos anatômicos, escolha a alternativa mais provável.\n",
      "a)Fratura do osso etmoidal pode causar enfisema orbitário.\n",
      "b)Fratura da parte lateral da órbita pode causar hemorragia intraorbital, por ruptura das artérias etmoidais anteriores e posteriores.\n",
      "c)Fratura do assoalho da órbita pode causar comprometimento dos movimentos mastigatórios, por lesão no nervo maxilar, ramo do nervo trigêmeo.\n",
      "d)Fratura do osso lacrimal pode diminuir a excreção de lágrima pela glândula lacrimal principal, por comprometimento do nervo lacrimal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.31 ms /    28 runs   (    0.58 ms per token,  1716.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3234.90 ms /   183 tokens (   17.68 ms per token,    56.57 tokens per second)\n",
      "llama_print_timings:        eval time =  3412.01 ms /    27 runs   (  126.37 ms per token,     7.91 tokens per second)\n",
      "llama_print_timings:       total time =  6730.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.41 ms /   134 runs   (    0.58 ms per token,  1731.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16400.88 ms /   134 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 16808.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1723.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3125.24 ms /    25 runs   (  125.01 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  3199.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.41 ms /    65 runs   (    0.58 ms per token,  1737.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8101.13 ms /    65 runs   (  124.63 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  8296.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.48 ms /   134 runs   (    0.58 ms per token,  1729.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16435.12 ms /   134 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 16843.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.64 ms /     7 runs   (  123.23 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   883.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.74 ms /    17 runs   (    0.57 ms per token,  1745.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2087.73 ms /    17 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2137.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.49 ms /    27 runs   (    0.57 ms per token,  1743.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3356.97 ms /    27 runs   (  124.33 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3436.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.18 ms /    75 runs   (    0.58 ms per token,  1737.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9236.45 ms /    75 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9461.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.83 ms /    24 runs   (    0.58 ms per token,  1735.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2934.86 ms /    24 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3005.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 40: \n",
      "Language: english\n",
      "Question: \n",
      "There are many factors that contribute to the transparency of the cornea, but the main one is:\n",
      "a) Absence of adhesion proteoglycans, increasing the loose interfibrillar space and allowing free passage of light.\n",
      "b) Low metabolic demand, which allows nutrition by a reticular mesh of extremely fine stromal capillaries.\n",
      "c) Hyperosmotic characteristic of Descemet's membrane, which reduces stromal hydration.\n",
      "d) Organization of collagen fibrils in a regular, uniform and parallel way to each other.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.17 ms /    19 runs   (    0.59 ms per token,  1700.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2887.99 ms /   137 tokens (   21.08 ms per token,    47.44 tokens per second)\n",
      "llama_print_timings:        eval time =  2219.12 ms /    18 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5164.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.56 ms /    25 runs   (    0.58 ms per token,  1716.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3067.06 ms /    25 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3141.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3469.85 ms /    28 runs   (  123.92 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3552.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.80 ms /    17 runs   (    0.58 ms per token,  1735.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2088.86 ms /    17 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2138.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.02 ms /    24 runs   (    0.58 ms per token,  1712.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2916.01 ms /    24 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2987.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2449.04 ms /    20 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2507.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1737.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3055.10 ms /    25 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3129.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.55 ms /    20 runs   (    0.58 ms per token,  1731.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2448.86 ms /    20 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2508.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.78 ms /    29 runs   (    0.58 ms per token,  1728.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3516.47 ms /    29 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3602.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.15 ms /    21 runs   (    0.58 ms per token,  1728.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2575.55 ms /    21 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2637.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Muitos são os fatores que contribuem para a transparência da córnea, mas o principal deles é:\n",
      "a)Ausência de proteoglicanos de adesão, aumentando o espaço interfibrilar frouxo e permitindo a passagem livre da luz.\n",
      "b)Baixa demanda metabólica, que permite a nutrição por uma malha reticular de capilares estromais extremamente finos.\n",
      "c)Característica hiperosmótica da membrana de Descemet, que reduz a hidratação estromal.\n",
      "d)Organização das fibrilas de colágeno de forma regular, uniforme e paralela umas às outras.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1694.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3339.48 ms /   173 tokens (   19.30 ms per token,    51.80 tokens per second)\n",
      "llama_print_timings:        eval time =   728.51 ms /     6 runs   (  121.42 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4088.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.72 ms /    20 runs   (    0.59 ms per token,  1706.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2495.45 ms /    20 runs   (  124.77 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  2555.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    27 runs   (    0.59 ms per token,  1682.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3317.72 ms /    27 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3400.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1738.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3444.36 ms /    28 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3527.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.52 ms /    27 runs   (    0.57 ms per token,  1739.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3335.28 ms /    27 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3415.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1745.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3395.29 ms /    28 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3478.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   873.42 ms /     7 runs   (  124.77 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =   893.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.50 ms /    20 runs   (    0.57 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2501.96 ms /    20 runs   (  125.10 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  2561.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1749.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.72 ms /     7 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3458.85 ms /    28 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3543.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 41: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding the anatomy of the posterior segment of the eye.\n",
      "a) The emergence of the two long ciliary nerves at the equator of the eye, approximately at twelve and six o'clock, explains greater sensitivity to pain in these quadrants during panphotocoagulation.\n",
      "b) The subretinal vorticose arteries give the lacy \"tiger\" appearance in the ophthalmoscopic examination of people with diffuse atrophy of the retinal pigment epithelium.\n",
      "c) In the ora serrata, there are small radial meridional folds next to the dentate processes, with, eventually, a small atrophic retinal hole at its base, which does not need to be blocked.\n",
      "d) The foveola, area of ​​greater metabolic activity due to the high concentration of photoreceptors, presents an intense vascular network formed by anastomoses of the superior and inferior temporal arcades.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.50 ms /    78 runs   (    0.58 ms per token,  1714.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3700.39 ms /   230 tokens (   16.09 ms per token,    62.16 tokens per second)\n",
      "llama_print_timings:        eval time =  9507.78 ms /    77 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13447.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.86 ms /    76 runs   (    0.58 ms per token,  1732.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9359.43 ms /    76 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9592.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.47 ms /    79 runs   (    0.58 ms per token,  1737.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9745.00 ms /    79 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9984.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.33 ms /    84 runs   (    0.58 ms per token,  1738.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10367.48 ms /    84 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10621.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1702.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   872.09 ms /     7 runs   (  124.58 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   893.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.95 ms /    77 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9495.13 ms /    77 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9728.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.59 ms /    93 runs   (    0.58 ms per token,  1735.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11472.06 ms /    93 runs   (  123.36 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 11751.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.79 ms /    76 runs   (    0.58 ms per token,  1735.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9386.38 ms /    76 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  9615.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.67 ms /    90 runs   (    0.57 ms per token,  1741.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11088.00 ms /    90 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11361.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.59 ms /    83 runs   (    0.57 ms per token,  1744.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10221.70 ms /    83 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 10473.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Marque a alternativa correta quanto à anatomia do segmento posterior do olho.\n",
      "a)A emergência dos dois nervos ciliares longos no equador do olho, aproximadamente às doze e seis horas, explica maior sensibilidade à dor nesses quadrantes durante a panfotocoagulação.\n",
      "b)As artérias vorticosas sub-retinianas conferem o aspecto rendilhado \"em tigre\" no exame oftalmoscópico de pessoas com atrofia difusa do epitélio pigmentado da retina.\n",
      "c)Na ora serrata encontram-se pequenas pregas meridionais radiais junto aos processos denteados com, eventualmente pequeno buraco retiniano atrófico na sua base, que não necessita ser bloqueado.\n",
      "d)A fovéola, área de maior atividade metabólica devido a alta concentração de fotorreceptores, apresenta intensa rede vascular formada por anastomoses das arcadas temporais superiores e inferiores.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.97 ms /    20 runs   (    0.60 ms per token,  1670.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4591.80 ms /   263 tokens (   17.46 ms per token,    57.28 tokens per second)\n",
      "llama_print_timings:        eval time =  2340.18 ms /    19 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6992.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1715.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.92 ms /     7 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   876.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.69 ms /    97 runs   (    0.60 ms per token,  1652.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12022.96 ms /    97 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 12322.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.17 ms /   104 runs   (    0.61 ms per token,  1646.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12792.16 ms /   104 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 13116.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1728.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   887.23 ms /     7 runs   (  126.75 ms per token,     7.89 tokens per second)\n",
      "llama_print_timings:       total time =   909.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.21 ms /    20 runs   (    0.66 ms per token,  1514.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2505.18 ms /    20 runs   (  125.26 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  2567.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1735.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3527.54 ms /    28 runs   (  125.98 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  3612.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.83 ms /     7 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   885.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.21 ms /    64 runs   (    0.58 ms per token,  1720.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7998.94 ms /    64 runs   (  124.98 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  8193.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.44 ms /    91 runs   (    0.58 ms per token,  1735.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11201.50 ms /    91 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11476.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 42: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding the anatomy of the camerular sinus.\n",
      "a) Schwalbe's line corresponds to the gonioscopic projection of the scleral spur.\n",
      "b) The ciliary body band usually cannot be seen by gonioscopy.\n",
      "c) pectineal iris processes reaching Schwalbe's line are not present in normal eyes; and when found, they are indicative of previous iridocyclitis.\n",
      "d) The drainage flow of aqueous humor occurs mainly in the posterior portion of the trabecular meshwork, which is more pigmented.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.56 ms /   167 runs   (    0.58 ms per token,  1711.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3193.28 ms /   143 tokens (   22.33 ms per token,    44.78 tokens per second)\n",
      "llama_print_timings:        eval time = 20528.94 ms /   166 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 24241.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    89.01 ms /   154 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18969.33 ms /   154 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 19444.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   128.07 ms /   221 runs   (    0.58 ms per token,  1725.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27272.72 ms /   221 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 27967.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.86 ms /    67 runs   (    0.58 ms per token,  1724.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8284.37 ms /    67 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  8486.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.25 ms /    73 runs   (    0.58 ms per token,  1727.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8989.52 ms /    73 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9216.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.04 ms /    24 runs   (    0.58 ms per token,  1709.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2935.05 ms /    24 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3009.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   104.12 ms /   177 runs   (    0.59 ms per token,  1700.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21779.16 ms /   177 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 22343.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.59 ms /    67 runs   (    0.58 ms per token,  1736.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8194.16 ms /    67 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  8392.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.75 ms /    67 runs   (    0.58 ms per token,  1729.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8256.02 ms /    67 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8454.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   115.15 ms /   199 runs   (    0.58 ms per token,  1728.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24528.27 ms /   199 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 25151.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa correta quanto à anatomia do seio camerular.\n",
      "a)A linha de Schwalbe corresponde à projeção gonioscópica do esporão escleral.\n",
      "b)A banda do corpo ciliar geralmente não pode ser observada pela gonioscopia.\n",
      "c)Processos irianos pectíneos que alcançam a linha de Schwalbe não estão presentes em olhos normais; e quando encontrados são indicativos de iridociclite prévia.\n",
      "d)O fluxo de drenagem do humor aquoso ocorre principalmente na porção posterior da malha trabecular, que é mais pigmentada.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.50 ms /    17 runs   (    0.62 ms per token,  1619.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2944.86 ms /   172 tokens (   17.12 ms per token,    58.41 tokens per second)\n",
      "llama_print_timings:        eval time =  1976.75 ms /    16 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4973.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.59 ms /    69 runs   (    0.59 ms per token,  1700.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8527.50 ms /    69 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  8737.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.85 ms /     7 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.52 ms /     7 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    27 runs   (    0.58 ms per token,  1732.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3294.31 ms /    27 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3374.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.77 ms /     7 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.52 ms /    20 runs   (    0.58 ms per token,  1735.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2446.98 ms /    20 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2506.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1695.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.31 ms /     7 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.87 ms /    90 runs   (    0.59 ms per token,  1702.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11135.12 ms /    90 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 11407.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.65 ms /    91 runs   (    0.58 ms per token,  1728.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11189.17 ms /    91 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 11464.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 43: \n",
      "Language: english\n",
      "Question: \n",
      "The sentences below refer to which structure of the human eye?\n",
      "\n",
      "1- Most anterior extension of the uveal tract.\n",
      "2- Formed by blood vessels, connective tissue and malanocytes.\n",
      "3- Presents pigmented epithelium whose basal end of the cells is facing the posterior chamber.\n",
      "4- It has smooth muscle fibers of sympathetic innervation.\n",
      "\n",
      "a) ciliary body.\n",
      "b) iris.\n",
      "c) Camerular sinus.\n",
      "d) Choroidal tract of ora serrata.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.74 ms /    34 runs   (    0.58 ms per token,  1722.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2448.32 ms /   130 tokens (   18.83 ms per token,    53.10 tokens per second)\n",
      "llama_print_timings:        eval time =  4038.33 ms /    33 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6589.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.44 ms /    13 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1602.59 ms /    13 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  1642.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.12 ms /    30 runs   (    0.57 ms per token,  1752.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3705.25 ms /    30 runs   (  123.51 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3793.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.22 ms /    32 runs   (    0.57 ms per token,  1756.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3943.29 ms /    32 runs   (  123.23 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4037.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #4: \n",
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.19 ms /    32 runs   (    0.57 ms per token,  1759.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3873.03 ms /    32 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3967.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.41 ms /    48 runs   (    0.57 ms per token,  1751.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5905.31 ms /    48 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6048.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.43 ms /    25 runs   (    0.58 ms per token,  1732.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3049.65 ms /    25 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3124.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.80 ms /    33 runs   (    0.57 ms per token,  1755.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4116.59 ms /    33 runs   (  124.75 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  4214.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.40 ms /    29 runs   (    0.57 ms per token,  1768.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3566.72 ms /    29 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3652.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.57 ms /    31 runs   (    0.57 ms per token,  1764.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3765.96 ms /    31 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3857.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "As sentenças abaixo dizem respeito a qual estrutura do olho humano?\n",
      "\n",
      "1- Extensão mais anterior do trato uveal.\n",
      "2- Formada por vasos sanguíneos, tecido conjuntivo e malanócitos.\n",
      "3- Apresenta epitélio pigmentado cuja extremidade basal das células está voltada para a câmara posterior.\n",
      "4- Possui fibras musculares lisas de inervação simpática.\n",
      "\n",
      "a)Corpo ciliar.\n",
      "b)Íris.\n",
      "c)Seio camerular.\n",
      "d)Trato coroidal da ora serrata.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.67 ms /    13 runs   (    0.59 ms per token,  1695.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3754.38 ms /   165 tokens (   22.75 ms per token,    43.95 tokens per second)\n",
      "llama_print_timings:        eval time =  1467.54 ms /    12 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5260.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.45 ms /    14 runs   (    0.60 ms per token,  1656.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1735.64 ms /    14 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  1778.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.28 ms /    14 runs   (    0.59 ms per token,  1691.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1748.95 ms /    14 runs   (  124.92 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  1791.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.41 ms /    49 runs   (    0.58 ms per token,  1724.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6056.88 ms /    49 runs   (  123.61 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  6204.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.05 ms /    14 runs   (    0.57 ms per token,  1739.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1693.84 ms /    14 runs   (  120.99 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1735.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.11 ms /    14 runs   (    0.58 ms per token,  1726.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1720.68 ms /    14 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  1761.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.02 ms /    14 runs   (    0.57 ms per token,  1744.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1722.55 ms /    14 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  1763.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.07 ms /    14 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1702.23 ms /    14 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  1743.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.09 ms /    14 runs   (    0.58 ms per token,  1731.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1708.22 ms /    14 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1748.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.11 ms /    14 runs   (    0.58 ms per token,  1726.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1730.93 ms /    14 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  1773.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 44: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the anatomy of the retina, choose the alternative that contains the correct correlation between the two columns below:\n",
      "\n",
      "I - outer plexiform layer\n",
      "II - External limit\n",
      "III - inner nuclear layer\n",
      "IV - Internal limit\n",
      "V - Nerve fiber layer\n",
      "\n",
      "A- It is in contact with the vitreous\n",
      "B- It is between the photoreceptors and the bipolar cells\n",
      "C- Contains amacrine and horizontal cells\n",
      "D - Muller cell processes\n",
      "E- Contains axons of ganglion cells\n",
      "\n",
      "a) A: II; B: III; C: I; D: V; I: IV.\n",
      "b) A: IV; B: I; C: III; D: II; E: V.\n",
      "c) A: IV; B: V; C: III; D: I; I: II.\n",
      "d) A: V; B:II; C: III; D: IV; E:I.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.97 ms /   148 runs   (    0.57 ms per token,  1741.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3862.27 ms /   219 tokens (   17.64 ms per token,    56.70 tokens per second)\n",
      "llama_print_timings:        eval time = 18133.86 ms /   147 runs   (  123.36 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 22453.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.70 ms /   148 runs   (    0.57 ms per token,  1747.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18174.22 ms /   148 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 18629.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.01 ms /    41 runs   (    0.56 ms per token,  1781.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5139.14 ms /    41 runs   (  125.34 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  5260.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A: II; B: III; C: I; D: V'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.38 ms /   148 runs   (    0.57 ms per token,  1754.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18141.16 ms /   148 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 18593.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.08 ms /    48 runs   (    0.56 ms per token,  1772.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5956.69 ms /    48 runs   (  124.10 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  6100.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.71 ms /    93 runs   (    0.57 ms per token,  1764.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11521.12 ms /    93 runs   (  123.88 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 11803.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.49 ms /   148 runs   (    0.57 ms per token,  1751.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18175.09 ms /   148 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 18631.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.22 ms /    48 runs   (    0.59 ms per token,  1700.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5983.69 ms /    48 runs   (  124.66 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  6131.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    74.95 ms /   132 runs   (    0.57 ms per token,  1761.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16276.40 ms /   132 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16683.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A respeito da anatomia da retina, escolha a alternativa que contenha a correlação correta entre as duas colunas abaixo:\n",
      "\n",
      "I- Camada plexiforme externa\n",
      "II- Limitante externa\n",
      "III- Camada nuclear interna\n",
      "IV- Limitante interna\n",
      "V- Camada de fibras nervosas\n",
      "\n",
      "A- Está em contato com o vítreo\n",
      "B- Está entre os fotorreceptores e as células bipolares\n",
      "C- Contém células amácrinas e horizontais\n",
      "D- São processos das células de Muller\n",
      "E- Contém axônios de células ganglionares\n",
      "\n",
      "a)A: II; B: III; C: I; D: V; E: IV.\n",
      "b)A: IV; B: I; C: III; D: II; E: V.\n",
      "c)A: IV; B: V; C: III; D: I; E: II.\n",
      "d)A: V; B: II; C: III; D: IV; E: I.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.70 ms /    39 runs   (    0.56 ms per token,  1797.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4792.61 ms /    39 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4909.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.75 ms /    49 runs   (    0.57 ms per token,  1765.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4158.56 ms /   260 tokens (   15.99 ms per token,    62.52 tokens per second)\n",
      "llama_print_timings:        eval time =  6017.80 ms /    48 runs   (  125.37 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time = 10325.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.19 ms /    49 runs   (    0.58 ms per token,  1738.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6051.39 ms /    49 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6199.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.63 ms /    28 runs   (    0.52 ms per token,  1914.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3449.77 ms /    28 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3532.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.86 ms /   107 runs   (    0.57 ms per token,  1758.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13201.89 ms /   107 runs   (  123.38 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13528.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.77 ms /     7 runs   (    0.54 ms per token,  1855.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   913.46 ms /     7 runs   (  130.49 ms per token,     7.66 tokens per second)\n",
      "llama_print_timings:       total time =   933.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.47 ms /   107 runs   (    0.57 ms per token,  1769.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13338.57 ms /   107 runs   (  124.66 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time = 13664.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.88 ms /   107 runs   (    0.57 ms per token,  1757.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13220.70 ms /   107 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 13547.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.96 ms /    28 runs   (    0.53 ms per token,  1872.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3447.47 ms /    28 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3529.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.84 ms /     7 runs   (    0.55 ms per token,  1821.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.89 ms /     7 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.09 ms /    28 runs   (    0.54 ms per token,  1855.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3488.52 ms /    28 runs   (  124.59 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3572.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 45: \n",
      "Language: english\n",
      "Question: \n",
      "Phakic patient evolved with a significant increase in intraocular pressure and athalamia 15 hours after a trabeculectomy. It is correct to say that:\n",
      "a) This severe ocular condition is more prevalent in aphakic patients.\n",
      "b) The use of topical cycloplegic during the immediate postoperative period is a risk factor for this condition.\n",
      "c) If there is a pervious iridotomy, this would not occur.\n",
      "d) Typically, this condition occurs in eyes with an anteroposterior diameter smaller than those of the general population.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.67 ms /    82 runs   (    0.58 ms per token,  1720.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2498.43 ms /   140 tokens (   17.85 ms per token,    56.04 tokens per second)\n",
      "llama_print_timings:        eval time = 10024.71 ms /    81 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 12774.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.96 ms /    50 runs   (    0.58 ms per token,  1726.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6153.74 ms /    50 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6304.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.22 ms /   106 runs   (    0.58 ms per token,  1731.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13075.50 ms /   106 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 13401.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   127.11 ms /   220 runs   (    0.58 ms per token,  1730.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27088.85 ms /   220 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 27786.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.92 ms /    79 runs   (    0.59 ms per token,  1683.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9717.58 ms /    79 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  9962.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.34 ms /    25 runs   (    0.57 ms per token,  1743.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3029.71 ms /    25 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3102.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.56 ms /    84 runs   (    0.58 ms per token,  1729.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10211.05 ms /    84 runs   (  121.56 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time = 10463.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1737.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3115.18 ms /    25 runs   (  124.61 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3190.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.88 ms /    78 runs   (    0.58 ms per token,  1738.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9690.74 ms /    78 runs   (  124.24 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  9925.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.18 ms /    82 runs   (    0.58 ms per token,  1738.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10067.52 ms /    82 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10317.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente fácico evoluiu com quadro de aumento importante da pressão intraocular e atalamia 15 horas após uma trabeculectomia. É correto afirmar que:\n",
      "a)Esse quadro ocular grave é mais prevalente em pacientes afácicos.\n",
      "b)O uso de cicloplégico tópico durante o pós-operatório imediato é fator de risco para esse quadro.\n",
      "c)Se há iridotomia pérvia, esse quadro não ocorre.\n",
      "d)Tipicamente, esse quadro ocorre em olhos com diâmetro anteroposterior menor que os da população em geral.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.38 ms /    28 runs   (    0.58 ms per token,  1709.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3335.18 ms /   174 tokens (   19.17 ms per token,    52.17 tokens per second)\n",
      "llama_print_timings:        eval time =  3322.26 ms /    27 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6740.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.67 ms /   115 runs   (    0.58 ms per token,  1724.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14182.52 ms /   115 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 14537.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    87.03 ms /   149 runs   (    0.58 ms per token,  1712.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18422.14 ms /   149 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 18889.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.02 ms /    59 runs   (    0.61 ms per token,  1638.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7178.29 ms /    59 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7358.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.70 ms /     7 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.67 ms /     7 runs   (    0.67 ms per token,  1498.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.31 ms /     7 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   880.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.03 ms /   193 runs   (    0.61 ms per token,  1635.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23791.89 ms /   193 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 24414.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1739.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.45 ms /     7 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.75 ms /     7 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.82 ms /     7 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 46: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding cortisonic glaucoma, it is correct to state that:\n",
      "a) Occurs at all ages.\n",
      "b) Corticosteroids in low concentrations do not increase intraocular pressure.\n",
      "c) Glaucoma is typically angle-closure.\n",
      "d) It is more frequent due to the use of oral corticosteroids than in the form of eye drops.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.57 ms /    28 runs   (    0.59 ms per token,  1690.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2259.23 ms /    93 tokens (   24.29 ms per token,    41.16 tokens per second)\n",
      "llama_print_timings:        eval time =  3271.29 ms /    27 runs   (  121.16 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5615.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.35 ms /    44 runs   (    0.58 ms per token,  1735.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5426.48 ms /    44 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5557.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.45 ms /    25 runs   (    0.58 ms per token,  1730.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3063.52 ms /    25 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3137.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.93 ms /    24 runs   (    0.58 ms per token,  1723.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2931.44 ms /    24 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3003.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.43 ms /    25 runs   (    0.58 ms per token,  1732.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3032.51 ms /    25 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3106.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.27 ms /    24 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2998.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.01 ms /    24 runs   (    0.58 ms per token,  1712.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2972.37 ms /    24 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3045.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.20 ms /    54 runs   (    0.58 ms per token,  1730.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6569.09 ms /    54 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  6735.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1725.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3126.13 ms /    25 runs   (  125.05 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  3203.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.70 ms /   107 runs   (    0.58 ms per token,  1734.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13197.50 ms /   107 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 13528.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre o glaucoma cortisônico, é correto afirmar que:\n",
      "a)Ocorre em todas as idades.\n",
      "b)Os corticoides em concentrações baixas não elevam a pressão intraocular.\n",
      "c)O glaucoma é tipicamente de ângulo fechado.\n",
      "d)É mais frequente por uso de corticoide via oral do que na forma de colírio.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.17 ms /     7 runs   (    0.60 ms per token,  1679.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1641.52 ms /   107 tokens (   15.34 ms per token,    65.18 tokens per second)\n",
      "llama_print_timings:        eval time =   719.98 ms /     6 runs   (  120.00 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  2382.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.09 ms /   115 runs   (    0.58 ms per token,  1714.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14247.34 ms /   115 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 14601.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   147.40 ms /   254 runs   (    0.58 ms per token,  1723.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 31222.37 ms /   254 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 32036.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   145.93 ms /   253 runs   (    0.58 ms per token,  1733.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 31125.86 ms /   253 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 31935.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.77 ms /    41 runs   (    0.58 ms per token,  1725.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5055.45 ms /    41 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5177.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   150.33 ms /   260 runs   (    0.58 ms per token,  1729.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 32016.10 ms /   260 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 32841.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.48 ms /     7 runs   (  120.50 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1709.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.23 ms /     7 runs   (  120.46 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   863.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.14 ms /     7 runs   (    0.59 ms per token,  1692.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.09 ms /     7 runs   (  120.73 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.92 ms /    42 runs   (    0.59 ms per token,  1685.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5163.26 ms /    42 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5289.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 47: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the visual field defects below best correlates with localized loss of the peripapillary nerve fiber layer (Hoyt's sign) in the inferior temporal sector?\n",
      "a) Inferior temporal cecal center.\n",
      "b) Upper nasal.\n",
      "c) Wedge-shaped upper temporal.\n",
      "d) Lower vertical.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1842.03 ms /    83 tokens (   22.19 ms per token,    45.06 tokens per second)\n",
      "llama_print_timings:        eval time =   727.62 ms /     6 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2590.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    25 runs   (    0.58 ms per token,  1727.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3058.50 ms /    25 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3132.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1733.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2911.91 ms /    24 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2982.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.53 ms /    33 runs   (    0.59 ms per token,  1689.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4060.28 ms /    33 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4159.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.79 ms /    24 runs   (    0.57 ms per token,  1740.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.08 ms /    24 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2999.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.73 ms /    16 runs   (    0.61 ms per token,  1644.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1975.16 ms /    16 runs   (  123.45 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  2024.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.43 ms /    34 runs   (    0.57 ms per token,  1750.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4127.82 ms /    34 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4229.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.87 ms /    33 runs   (    0.57 ms per token,  1748.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4059.24 ms /    33 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4156.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1762.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   877.49 ms /     7 runs   (  125.36 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =   898.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.25 ms /     7 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual dos defeitos de campo visual abaixo melhor se correlaciona com perda localizada da camada de fibras nervosas peripapilar (sinal de Hoyt) no setor temporal inferior?\n",
      "a)Centro-cecal temporal inferior.\n",
      "b)Nasal superior.\n",
      "c)Temporal superior em cunha.\n",
      "d)Vertical inferior.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.17 ms /    36 runs   (    0.59 ms per token,  1700.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1971.90 ms /    89 tokens (   22.16 ms per token,    45.13 tokens per second)\n",
      "llama_print_timings:        eval time =  4298.86 ms /    35 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6379.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.63 ms /     7 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.30 ms /    37 runs   (    0.58 ms per token,  1737.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4519.79 ms /    37 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4630.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1744.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3369.85 ms /    28 runs   (  120.35 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  3452.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.08 ms /    35 runs   (    0.57 ms per token,  1743.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4268.55 ms /    35 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4373.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.38 ms /     7 runs   (  120.34 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1744.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3428.87 ms /    28 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3513.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.73 ms /    24 runs   (    0.57 ms per token,  1748.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2927.26 ms /    24 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2997.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.01 ms /    35 runs   (    0.57 ms per token,  1748.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4353.54 ms /    35 runs   (  124.39 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  4459.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3302.08 ms /    27 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3383.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 48: \n",
      "Language: english\n",
      "Question: \n",
      "Hemosiderotic glaucoma is caused by: a) Accumulation of macrophages in the trabecular meshwork. b) Accumulation of blood cells incapable of diapedesis in the trabecular meshwork. c) Accumulation of iron present in hemoglobin in the trabecular meshwork. d) Clogging of the trabecular meshwork by fresh red blood cells, fibrin and plasma.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.33 ms /    45 runs   (    0.59 ms per token,  1708.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2193.08 ms /   103 tokens (   21.29 ms per token,    46.97 tokens per second)\n",
      "llama_print_timings:        eval time =  5367.95 ms /    44 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  7699.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.62 ms /    44 runs   (    0.58 ms per token,  1717.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5361.11 ms /    44 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5493.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.13 ms /    37 runs   (    0.60 ms per token,  1672.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4562.53 ms /    37 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4673.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.93 ms /    45 runs   (    0.58 ms per token,  1735.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5520.67 ms /    45 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5655.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.14 ms /    45 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5551.87 ms /    45 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5686.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.48 ms /    44 runs   (    0.58 ms per token,  1726.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5341.14 ms /    44 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5472.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.48 ms /    44 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5400.19 ms /    44 runs   (  122.73 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5531.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.97 ms /    45 runs   (    0.58 ms per token,  1732.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5490.09 ms /    45 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5624.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.19 ms /    37 runs   (    0.65 ms per token,  1529.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4548.95 ms /    37 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4666.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "O glaucoma hemossiderótico é causado por: a) Acúmulo de macrófagos na malha trabecular. b) Acúmulo de células sanguíneas incapazes de diapedese na malha trabecular.  c) Acúmulo de ferro presente na hemoglobina na malha trabecular. d) Entupimento da malha trabecular por hemácias frescas, fibrina e plasma.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.68 ms /    25 runs   (    0.79 ms per token,  1270.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3073.53 ms /    25 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3161.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.97 ms /    24 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2498.17 ms /   116 tokens (   21.54 ms per token,    46.43 tokens per second)\n",
      "llama_print_timings:        eval time =  2804.43 ms /    23 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5375.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.11 ms /    47 runs   (    0.58 ms per token,  1733.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5724.69 ms /    47 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5865.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.44 ms /    20 runs   (    0.57 ms per token,  1747.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2475.38 ms /    20 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  2533.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.56 ms /    27 runs   (    0.58 ms per token,  1734.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3305.66 ms /    27 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3385.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.62 ms /     7 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   880.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.30 ms /    44 runs   (    0.58 ms per token,  1739.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5401.17 ms /    44 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5533.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3350.08 ms /    27 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3432.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.12 ms /    52 runs   (    0.58 ms per token,  1726.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6420.82 ms /    52 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6583.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1738.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2060.95 ms /    17 runs   (  121.23 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2112.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1741.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2958.99 ms /    24 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3033.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 49: \n",
      "Language: english\n",
      "Question: \n",
      "The classic risk factors for the development of primary open-angle glaucoma are: a) Asians, positive family history, young people. b) Elevated intraocular pressure, Caucasian race, age between 25 and 45 years. c) Elevated intraocular pressure, black race, positive family history. d) Female gender, increased corneal thickness, intraocular pressure with wide fluctuation.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.05 ms /    25 runs   (    0.60 ms per token,  1661.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2578.64 ms /   108 tokens (   23.88 ms per token,    41.88 tokens per second)\n",
      "llama_print_timings:        eval time =  2916.82 ms /    24 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5573.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.45 ms /    54 runs   (    0.58 ms per token,  1716.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6594.32 ms /    54 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6763.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.72 ms /    20 runs   (    0.59 ms per token,  1706.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2432.95 ms /    20 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2495.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.51 ms /    20 runs   (    0.58 ms per token,  1738.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2438.73 ms /    20 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2500.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.51 ms /    20 runs   (    0.58 ms per token,  1737.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2456.29 ms /    20 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2518.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3452.95 ms /    28 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3540.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.53 ms /    25 runs   (    0.58 ms per token,  1720.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3025.04 ms /    25 runs   (  121.00 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3101.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.48 ms /    25 runs   (    0.58 ms per token,  1726.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3032.79 ms /    25 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3108.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.48 ms /    25 runs   (    0.58 ms per token,  1726.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3036.50 ms /    25 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3113.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "São fatores de risco clássicos para o desenvolvimento de glaucoma primário de ângulo aberto: a) Asiáticos, história familiar positiva, jovens. b) Pressão intraocular elevada, raça caucasiana, idade entre 25 e 45 anos. c) Pressão intraocular elevada, raça negra, história familiar positiva. d) Sexo feminino, espessura corneal elevada, pressão intraocular com ampla flutuação.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.21 ms /    21 runs   (    0.58 ms per token,  1719.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2528.27 ms /    21 runs   (  120.39 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2593.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.17 ms /    28 runs   (    0.61 ms per token,  1630.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2183.89 ms /   134 tokens (   16.30 ms per token,    61.36 tokens per second)\n",
      "llama_print_timings:        eval time =  3300.05 ms /    27 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5574.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.21 ms /     9 runs   (    0.58 ms per token,  1728.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1091.73 ms /     9 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  1119.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.88 ms /     7 runs   (  120.70 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   867.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.50 ms /     7 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.20 ms /     9 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1103.88 ms /     9 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  1131.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   872.42 ms /     7 runs   (  124.63 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =   893.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.08 ms /    28 runs   (    0.57 ms per token,  1741.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3386.29 ms /    28 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3471.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.17 ms /     7 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.20 ms /    20 runs   (    0.61 ms per token,  1639.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2504.34 ms /    20 runs   (  125.22 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  2568.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.34 ms /     7 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   868.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 50: \n",
      "Language: english\n",
      "Question: \n",
      "Male patient, 25 years old, with recurrent ocular hypertension (between 40 and 60 mmHg), painless, unilateral and of short duration, without loss of vision. Which are the most probable diagnostics? a) Fuchs heterochromic uveitis. b) Attack of acute glaucoma with bombé iris. c) Attack of acute glaucoma with plateau iris. d) Glaucomatocyclic crisis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.86 ms /    64 runs   (    0.61 ms per token,  1646.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2538.25 ms /   118 tokens (   21.51 ms per token,    46.49 tokens per second)\n",
      "llama_print_timings:        eval time =  7689.64 ms /    63 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 10430.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.56 ms /    27 runs   (    0.58 ms per token,  1734.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3306.30 ms /    27 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3387.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.10 ms /    28 runs   (    0.57 ms per token,  1739.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3453.57 ms /    28 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3536.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.45 ms /    27 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3382.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.35 ms /     7 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1744.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3407.45 ms /    28 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3489.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.07 ms /    99 runs   (    0.58 ms per token,  1734.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12191.91 ms /    99 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 12492.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1736.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3296.03 ms /    27 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3376.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1738.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3398.39 ms /    28 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3481.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.12 ms /     7 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente masculino, 25 anos, com quadros reincidentes de hipertensão ocular (entre 40 e 60 mmHg), indolor, unilateral e de curta duração, sem baixa de visão. Qual o diagnóstico mais provável? a) Uveíte heterocrômica de Fuchs. b) Crise de glaucoma agudo com íris bombé. c) Crise de glaucoma agudo com íris em plateau. d) Crise glaucomatocíclica.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.78 ms /    69 runs   (    0.58 ms per token,  1734.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2349.34 ms /   138 tokens (   17.02 ms per token,    58.74 tokens per second)\n",
      "llama_print_timings:        eval time =  8400.17 ms /    68 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10959.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.58 ms /    28 runs   (    0.59 ms per token,  1688.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3456.30 ms /    28 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3541.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.33 ms /    27 runs   (    0.57 ms per token,  1761.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3302.69 ms /    27 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3382.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.73 ms /    40 runs   (    0.57 ms per token,  1759.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4911.46 ms /    40 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5028.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.38 ms /    27 runs   (    0.57 ms per token,  1755.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3289.20 ms /    27 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3368.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.82 ms /    28 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3395.28 ms /    28 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3478.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.59 ms /    62 runs   (    0.57 ms per token,  1742.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7650.46 ms /    62 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  7836.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.10 ms /    49 runs   (    0.57 ms per token,  1743.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5999.76 ms /    49 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6148.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.91 ms /     7 runs   (    0.56 ms per token,  1789.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.90 ms /     7 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1818.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.29 ms /     7 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 51: \n",
      "Language: english\n",
      "Question: \n",
      "A 60-year-old diabetic patient complains of pain and low visual acuity in the right eye. On ophthalmological examination, visual acuity was 0.1, intraocular pressure 45 mmHg, corneal edema, iris neovascularization, open angle in all quadrants on gonioscopy, cup/disc ratio 0.3, and proliferative diabetic retinopathy. After initiating hypotensive clinical treatment, the patient had a good response. Among the options below, which is the most appropriate course of action to follow? a) Cyclophotocoagulation. b) Drainage implant. c) Panretinal photocoagulation. d) Trabeculectomy with mitomycin C.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    94.06 ms /   162 runs   (    0.58 ms per token,  1722.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3049.17 ms /   189 tokens (   16.13 ms per token,    61.98 tokens per second)\n",
      "llama_print_timings:        eval time = 19870.23 ms /   161 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 23425.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.18 ms /    34 runs   (    0.59 ms per token,  1684.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4161.57 ms /    34 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4263.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.82 ms /   169 runs   (    0.58 ms per token,  1727.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20892.59 ms /   169 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 21419.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.67 ms /     7 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.24 ms /    16 runs   (    0.58 ms per token,  1730.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1953.50 ms /    16 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2001.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.77 ms /     7 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.89 ms /    36 runs   (    0.58 ms per token,  1723.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4461.45 ms /    36 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4569.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   103.58 ms /   178 runs   (    0.58 ms per token,  1718.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21945.66 ms /   178 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 22503.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.76 ms /   125 runs   (    0.58 ms per token,  1718.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15447.26 ms /   125 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15840.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.07 ms /    33 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4068.43 ms /    33 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4166.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente diabético com 60 anos queixa-se de dor e baixa de acuidade visual no olho direito. Ao exame oftalmológico apresenta acuidade visual 0,1, pressão intraocular 45 mmHg, edema de cornea, neovascularização de íris, ângulo aberto em todos os quadrantes na gonioscopia, relação escavação/disco 0,3 e retinopatia diabética proliferativa. Após iniciar tratamento clínico hipotensor, apresentou boa resposta. Dentre as opções abaixo, qual é a conduta mais adequada a seguir? a) Ciclofotocoagulação. b) Implante de drenagem. c) Panfotocoagulação retiniana. d) Trabeculectomia com mitomicina C.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    19 runs   (    0.61 ms per token,  1647.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4200.43 ms /   216 tokens (   19.45 ms per token,    51.42 tokens per second)\n",
      "llama_print_timings:        eval time =  2234.62 ms /    18 runs   (  124.15 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  6493.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.84 ms /    19 runs   (    0.62 ms per token,  1605.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2354.24 ms /    19 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2414.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.25 ms /    19 runs   (    0.59 ms per token,  1689.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2352.81 ms /    19 runs   (  123.83 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  2411.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #3: \n",
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.97 ms /    19 runs   (    0.58 ms per token,  1731.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2320.69 ms /    19 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2378.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1732.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2477.49 ms /    20 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2537.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.75 ms /    20 runs   (    0.59 ms per token,  1702.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2471.82 ms /    20 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  2532.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.12 ms /    19 runs   (    0.59 ms per token,  1708.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2322.72 ms /    19 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2379.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.20 ms /    19 runs   (    0.59 ms per token,  1696.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2336.35 ms /    19 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2393.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.53 ms /    20 runs   (    0.58 ms per token,  1735.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2449.27 ms /    20 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2509.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.00 ms /    19 runs   (    0.58 ms per token,  1728.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2332.18 ms /    19 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2388.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 52: \n",
      "Language: english\n",
      "Question: \n",
      "Among the options below, which would be the most suggestive finding of glaucoma? a) Cupping asymmetry of 0.2 between the eyes. b) Peripapillary atrophy with alpha zone in the temporal region of the nerve. c) Bilateral excavation/disk ratio of 0.5. d) Optic nerve cup/disk ratio of 0.4 with the presence of an inferior temporal notch.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    28 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2115.01 ms /   105 tokens (   20.14 ms per token,    49.65 tokens per second)\n",
      "llama_print_timings:        eval time =  3302.58 ms /    27 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5501.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1729.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3343.72 ms /    27 runs   (  123.84 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3424.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.92 ms /     7 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.11 ms /     7 runs   (  119.73 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =   858.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.02 ms /    28 runs   (    0.57 ms per token,  1748.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3406.55 ms /    28 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3489.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.56 ms /    27 runs   (    0.58 ms per token,  1735.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3277.91 ms /    27 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3358.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    28 runs   (    0.58 ms per token,  1717.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3410.95 ms /    28 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3494.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   103.70 ms /   181 runs   (    0.57 ms per token,  1745.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22301.49 ms /   181 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 22861.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.66 ms /    24 runs   (    0.57 ms per token,  1756.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2929.53 ms /    24 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2999.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.21 ms /    51 runs   (    0.57 ms per token,  1745.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6260.07 ms /    51 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6412.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.60 ms /    74 runs   (    0.58 ms per token,  1737.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9025.51 ms /    74 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  9248.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Dentre as opções abaixo, qual seria o achado mais sugestivo de glaucoma? a) Assimetria de escavação de 0,2 entre os olhos. b) Atrofia peripapilar com zona alfa na região temporal do nervo. c) Relação escavação/disco bilateral de 0,5. d) Relação escavação/disco do nervo óptico de 0,4 com a presença de um notch temporal inferior.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.02 ms /    56 runs   (    0.59 ms per token,  1695.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2484.84 ms /   124 tokens (   20.04 ms per token,    49.90 tokens per second)\n",
      "llama_print_timings:        eval time =  6749.38 ms /    55 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  9406.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.63 ms /     8 runs   (    0.58 ms per token,  1726.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   963.47 ms /     8 runs   (  120.43 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   987.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd)'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.00 ms /    52 runs   (    0.58 ms per token,  1733.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6423.14 ms /    52 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6579.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.87 ms /    38 runs   (    0.58 ms per token,  1737.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4640.11 ms /    38 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4752.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd)'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.30 ms /    39 runs   (    0.57 ms per token,  1748.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4788.12 ms /    39 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4903.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.56 ms /    39 runs   (    0.58 ms per token,  1728.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4745.58 ms /    39 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4861.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.55 ms /    60 runs   (    0.58 ms per token,  1736.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7287.55 ms /    60 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  7466.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.48 ms /    39 runs   (    0.58 ms per token,  1734.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4766.19 ms /    39 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4882.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.96 ms /    59 runs   (    0.58 ms per token,  1737.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7216.06 ms /    59 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7396.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.34 ms /    60 runs   (    0.59 ms per token,  1697.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7347.54 ms /    60 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7528.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 53: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Topical use of alpha-2-agonist eye drops, such as brimonidine tartrate, should be avoided in which of the following situations? a) Children under two years old. b) Renal lithiasis. c) Asthma. d) Sickle cell anemia.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.19 ms /     7 runs   (    0.60 ms per token,  1671.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1354.81 ms /    73 tokens (   18.56 ms per token,    53.88 tokens per second)\n",
      "llama_print_timings:        eval time =   719.52 ms /     6 runs   (  119.92 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =  2095.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.57 ms /    32 runs   (    0.58 ms per token,  1722.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3845.97 ms /    32 runs   (  120.19 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  3941.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.14 ms /    36 runs   (    0.59 ms per token,  1702.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4435.75 ms /    36 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4542.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.53 ms /    25 runs   (    0.58 ms per token,  1720.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3040.69 ms /    25 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3113.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.84 ms /    17 runs   (    0.58 ms per token,  1727.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2037.94 ms /    17 runs   (  119.88 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =  2087.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.98 ms /    78 runs   (    0.58 ms per token,  1733.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9484.96 ms /    78 runs   (  121.60 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  9718.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.07 ms /   168 runs   (    0.58 ms per token,  1730.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20477.54 ms /   168 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 20994.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.71 ms /    25 runs   (    0.59 ms per token,  1699.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3071.53 ms /    25 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3146.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.82 ms /    17 runs   (    0.58 ms per token,  1730.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2045.84 ms /    17 runs   (  120.34 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2094.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.83 ms /    17 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2081.84 ms /    17 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2131.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "O uso tópico de colírio de alfa-2-agonista, como tartarato de brimonidina, deve ser evitado em qual situação, dentre as abaixo? a) Crianças abaixo de dois anos. b) Litíase renal. c) Asma. d) Anemia falciforme.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1716.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2190.22 ms /    88 tokens (   24.89 ms per token,    40.18 tokens per second)\n",
      "llama_print_timings:        eval time =   729.24 ms /     6 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2939.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.63 ms /    69 runs   (    0.63 ms per token,  1581.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8454.17 ms /    69 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8669.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.48 ms /    69 runs   (    0.64 ms per token,  1551.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8458.26 ms /    69 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8677.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.55 ms /     7 runs   (    0.79 ms per token,  1262.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.12 ms /     7 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   872.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.38 ms /    72 runs   (    0.67 ms per token,  1488.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8808.80 ms /    72 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  9045.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.94 ms /    31 runs   (    0.71 ms per token,  1413.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3809.47 ms /    31 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3911.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1762.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.52 ms /     7 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   892.12 ms /     7 runs   (  127.45 ms per token,     7.85 tokens per second)\n",
      "llama_print_timings:       total time =   912.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.97 ms /    71 runs   (    0.58 ms per token,  1732.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8657.17 ms /    71 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  8873.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 54: \n",
      "Language: english\n",
      "Question: \n",
      "Which finding is most commonly associated with primary congenital glaucoma? a) Optic nerve edema. b) Ruptures in Descemet's membrane. c) Dislocation of the lens. d) Tent-like peripheral anterior synechiae.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1755.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.94 ms /     7 runs   (  120.42 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   863.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.87 ms /    39 runs   (    0.59 ms per token,  1705.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1668.71 ms /    69 tokens (   24.18 ms per token,    41.35 tokens per second)\n",
      "llama_print_timings:        eval time =  4592.09 ms /    38 runs   (  120.84 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  6376.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #1: \n",
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.54 ms /    39 runs   (    0.58 ms per token,  1730.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4783.20 ms /    39 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4900.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.41 ms /    38 runs   (    0.59 ms per token,  1695.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4662.92 ms /    38 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4778.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.95 ms /    38 runs   (    0.58 ms per token,  1731.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4629.27 ms /    38 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4742.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #4: \n",
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.50 ms /    39 runs   (    0.58 ms per token,  1733.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4834.32 ms /    39 runs   (  123.96 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4948.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.57 ms /    39 runs   (    0.58 ms per token,  1728.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4751.12 ms /    39 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4867.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.15 ms /    21 runs   (    0.58 ms per token,  1728.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2574.15 ms /    21 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2636.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.60 ms /    25 runs   (    0.58 ms per token,  1712.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3025.09 ms /    25 runs   (  121.00 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3098.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.57 ms /    39 runs   (    0.58 ms per token,  1728.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4746.65 ms /    39 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4862.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.97 ms /    38 runs   (    0.58 ms per token,  1729.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4626.62 ms /    38 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4738.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual achado é mais comumente associado ao glaucoma congênito primário? a) Edema de nervo óptico. b) Rupturas na membrana de Descemet. c) Luxação do cristalino. d) Sinéquias anteriores periféricas em tenda.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.11 ms /    38 runs   (    0.58 ms per token,  1719.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2036.10 ms /    78 tokens (   26.10 ms per token,    38.31 tokens per second)\n",
      "llama_print_timings:        eval time =  4526.57 ms /    37 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6674.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.63 ms /     7 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1731.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3384.26 ms /    28 runs   (  120.87 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3465.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.10 ms /    28 runs   (    0.65 ms per token,  1546.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3420.32 ms /    28 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3508.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.19 ms /    28 runs   (    0.65 ms per token,  1539.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3388.78 ms /    28 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3475.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.03 ms /    44 runs   (    0.59 ms per token,  1690.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5403.71 ms /    44 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5537.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.61 ms /    20 runs   (    0.58 ms per token,  1722.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2430.48 ms /    20 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2491.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3382.95 ms /    28 runs   (  120.82 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3468.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3319.84 ms /    27 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3402.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.54 ms /    25 runs   (    0.58 ms per token,  1719.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3039.77 ms /    25 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3115.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 55: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the pinhole test, it is correct to state: a) If the patient's visual acuity does not improve, it is a case of amblyopia. b) Decrease the depth of focus, due to the reduction of the pupil. c) Reduces diffusion circles on the retina. d) The size of the pinhole hole should be between 4 and 5 mm.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.12 ms /    20 runs   (    0.61 ms per token,  1650.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2503.49 ms /    93 tokens (   26.92 ms per token,    37.15 tokens per second)\n",
      "llama_print_timings:        eval time =  2314.09 ms /    19 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4879.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.51 ms /    28 runs   (    0.59 ms per token,  1696.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3432.48 ms /    28 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3520.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.53 ms /    20 runs   (    0.58 ms per token,  1734.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2449.26 ms /    20 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2510.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1724.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3436.18 ms /    28 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3522.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.58 ms /    20 runs   (    0.58 ms per token,  1727.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2467.03 ms /    20 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  2527.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.03 ms /    28 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3407.33 ms /    28 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3492.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.52 ms /    27 runs   (    0.57 ms per token,  1739.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3297.18 ms /    27 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3378.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3526.55 ms /    28 runs   (  125.95 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  3608.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1745.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3402.18 ms /    28 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3484.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.81 ms /    17 runs   (    0.58 ms per token,  1733.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2095.44 ms /    17 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  2145.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre o teste do buraco estenopeico, é correto afirmar: a) Se a acuidade visual do paciente não melhorar, trata-se de um caso de ambliopia. b) Diminui a profundidade de foco, por haver redução da pupila. c) Reduz os círculos de difusão na retina. d) O tamanho do buraco estenopeico deve ser entre 4 e 5 mm.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1663.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1896.90 ms /   116 tokens (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:        eval time =   722.15 ms /     6 runs   (  120.36 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2640.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.41 ms /    23 runs   (    0.58 ms per token,  1714.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2811.68 ms /    23 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2880.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.78 ms /     7 runs   (  126.54 ms per token,     7.90 tokens per second)\n",
      "llama_print_timings:       total time =   906.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.50 ms /     7 runs   (  120.36 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.78 ms /     7 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.80 ms /    17 runs   (    0.58 ms per token,  1734.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2069.37 ms /    17 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2119.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.10 ms /     7 runs   (  120.16 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.48 ms /     7 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   882.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.24 ms /     7 runs   (  124.46 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   891.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1695.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   890.75 ms /     7 runs   (  127.25 ms per token,     7.86 tokens per second)\n",
      "llama_print_timings:       total time =   911.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 56: \n",
      "Language: english\n",
      "Question: \n",
      "With regard to the Snellen chart, it is correct to state: a) A visual acuity of 0.05 in one eye allows for a professional D driver's license. b) Facectomy with implantation of an intraocular lens is necessary in phakic patients with visual acuity of 1.5 with the best fix. c) The patient with a visual acuity of 0.25 has a visual angle of 0.5 minutes. d) The patient with a visual acuity of 0.2 has subnormal vision.\n",
      "Test #0: \n",
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   136.62 ms /   235 runs   (    0.58 ms per token,  1720.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2911.62 ms /   132 tokens (   22.06 ms per token,    45.34 tokens per second)\n",
      "llama_print_timings:        eval time = 28757.73 ms /   234 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 32414.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.50 ms /    46 runs   (    0.58 ms per token,  1735.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5598.81 ms /    46 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5738.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.88 ms /   136 runs   (    0.57 ms per token,  1746.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16727.90 ms /   136 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 17144.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n",
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.92 ms /    82 runs   (    0.57 ms per token,  1747.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10083.81 ms /    82 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 10329.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.85 ms /   120 runs   (    0.57 ms per token,  1742.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14751.22 ms /   120 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 15116.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n",
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.98 ms /    28 runs   (    0.57 ms per token,  1752.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3421.45 ms /    28 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3504.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.52 ms /    53 runs   (    0.58 ms per token,  1736.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6513.61 ms /    53 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6671.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.70 ms /    24 runs   (    0.57 ms per token,  1751.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2909.81 ms /    24 runs   (  121.24 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2981.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.08 ms /    58 runs   (    0.57 ms per token,  1753.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7128.57 ms /    58 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7301.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.02 ms /    28 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3430.18 ms /    28 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3514.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação à tabela de Snellen, é correto afirmar: a) A acuidade visual de 0,05 em um olho permite a carteira profissional de direção letra D. b) É necessária a facectomia com implante de lente intraocular em pacientes fácicos com acuidades visuais de 1,5 com a melhor correção. c) O paciente com acuidade visual de 0,25 tem um ângulo visual de 0,5 minuto. d) O paciente com acuidade visual de 0,2 tem visão subnormal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1708.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2980.35 ms /   152 tokens (   19.61 ms per token,    51.00 tokens per second)\n",
      "llama_print_timings:        eval time =   737.96 ms /     6 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3738.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   124.33 ms /   215 runs   (    0.58 ms per token,  1729.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26571.31 ms /   215 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 27256.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) O paciente com acuidade visual de 0,2 tem visão subnormal.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.87 ms /     7 runs   (  124.12 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   890.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   102.71 ms /   180 runs   (    0.57 ms per token,  1752.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22222.92 ms /   180 runs   (  123.46 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 22785.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   124.05 ms /   215 runs   (    0.58 ms per token,  1733.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26565.50 ms /   215 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 27244.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.22 ms /    86 runs   (    0.57 ms per token,  1747.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10600.17 ms /    86 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 10857.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.11 ms /    84 runs   (    0.57 ms per token,  1746.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10312.81 ms /    84 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10564.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.86 ms /     7 runs   (    0.55 ms per token,  1811.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   893.83 ms /     7 runs   (  127.69 ms per token,     7.83 tokens per second)\n",
      "llama_print_timings:       total time =   913.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   123.89 ms /   215 runs   (    0.58 ms per token,  1735.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26548.40 ms /   215 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 27220.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.36 ms /    45 runs   (    0.56 ms per token,  1774.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5508.45 ms /    45 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5642.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 57: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the materials below has the highest Abbe index? a) CR-39 resin b) Trivex. c) High index resin. d) Polycarbonate.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1738.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1097.01 ms /    46 tokens (   23.85 ms per token,    41.93 tokens per second)\n",
      "llama_print_timings:        eval time =  2801.28 ms /    23 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3969.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.35 ms /    25 runs   (    0.57 ms per token,  1742.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3014.41 ms /    25 runs   (  120.58 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3089.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.09 ms /    61 runs   (    0.58 ms per token,  1738.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7429.48 ms /    61 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  7612.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.75 ms /    28 runs   (    0.60 ms per token,  1672.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3382.08 ms /    28 runs   (  120.79 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3466.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.56 ms /     7 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.22 ms /    25 runs   (    0.57 ms per token,  1758.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3001.14 ms /    25 runs   (  120.05 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  3075.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.93 ms /     7 runs   (    0.56 ms per token,  1779.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.75 ms /     7 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.77 ms /    54 runs   (    0.59 ms per token,  1699.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6598.00 ms /    54 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  6761.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n",
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2896.70 ms /    24 runs   (  120.70 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2968.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.90 ms /     7 runs   (    0.56 ms per token,  1793.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.06 ms /     7 runs   (  120.58 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual dos materiais abaixo apresenta maior índice Abbe? a) Resina CR-39 b) Trivex. c) Resina de alto índice. d) Policarbonato.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.97 ms /    24 runs   (    0.58 ms per token,  1718.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1378.11 ms /    56 tokens (   24.61 ms per token,    40.64 tokens per second)\n",
      "llama_print_timings:        eval time =  2800.46 ms /    23 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4250.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1723.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   904.61 ms /     7 runs   (  129.23 ms per token,     7.74 tokens per second)\n",
      "llama_print_timings:       total time =   925.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.22 ms /     7 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1755.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.57 ms /     7 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.04 ms /     7 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   886.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.82 ms /     7 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.11 ms /    25 runs   (    0.56 ms per token,  1771.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3100.53 ms /    25 runs   (  124.02 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3174.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.13 ms /     7 runs   (  121.73 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.21 ms /    16 runs   (    0.58 ms per token,  1737.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1972.37 ms /    16 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  2018.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.20 ms /     7 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 58: \n",
      "Language: english\n",
      "Question: \n",
      "A 65-year-old patient, myopic to -1.00 spherical diopters in both eyes, can read at 66 cm without lens correction. What is his accommodative range and what eyeglasses are sufficient for him to read at 33 cm, respectively? a) 0.50 spherical diopters; +1.00 spherical diopters. b) 0.50 spherical diopters; +1.50 spherical diopters. c) 1.00 spherical diopters; +1.50 spherical diopters. d) 1.00 spherical diopters; +2.00 spherical diopters.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   110.97 ms /   198 runs   (    0.56 ms per token,  1784.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4085.70 ms /   169 tokens (   24.18 ms per token,    41.36 tokens per second)\n",
      "llama_print_timings:        eval time = 24462.31 ms /   197 runs   (  124.17 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 29161.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   109.04 ms /   193 runs   (    0.56 ms per token,  1770.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23816.58 ms /   193 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 24421.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.17 ms /   198 runs   (    0.57 ms per token,  1765.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24428.66 ms /   198 runs   (  123.38 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 25046.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.00 ms /   198 runs   (    0.57 ms per token,  1752.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24538.80 ms /   198 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 25163.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.06 ms /   198 runs   (    0.57 ms per token,  1751.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24494.36 ms /   198 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 25108.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.82 ms /   198 runs   (    0.57 ms per token,  1754.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24457.27 ms /   198 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 25069.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.12 ms /   198 runs   (    0.57 ms per token,  1765.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24502.37 ms /   198 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 25122.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.34 ms /    48 runs   (    0.53 ms per token,  1894.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5903.91 ms /    48 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6044.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.89 ms /    51 runs   (    0.55 ms per token,  1828.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6269.71 ms /    51 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6420.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.09 ms /    50 runs   (    0.54 ms per token,  1845.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6086.41 ms /    50 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  6233.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente de 65 anos, míope de -1,00 dioptrias esfericas em ambos olhos, consegue ler a 66 cm, sem correção de lentes. Qual a sua amplitude acomodativa e qual grau de óculos é suficiente para ele ler a 33 cm, respectivamente? a) 0,50 dioptrias esfericas; +1,00 dioptrias esfericas. b) 0,50 dioptrias esfericas; +1,50 dioptrias esfericas. c) 1,00 dioptrias esfericas; +1,50 dioptrias esfericas. d) 1,00 dioptrias esfericas; +2,00 dioptrias esfericas.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.69 ms /     7 runs   (    0.53 ms per token,  1895.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3398.21 ms /   188 tokens (   18.08 ms per token,    55.32 tokens per second)\n",
      "llama_print_timings:        eval time =   727.08 ms /     6 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4145.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.51 ms /     7 runs   (    0.50 ms per token,  1992.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.76 ms /     7 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.49 ms /     7 runs   (    0.50 ms per token,  2007.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.22 ms /     7 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.47 ms /     7 runs   (    0.50 ms per token,  2015.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.77 ms /     7 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   878.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.48 ms /     7 runs   (    0.50 ms per token,  2014.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.38 ms /     7 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.49 ms /     7 runs   (    0.50 ms per token,  2008.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.20 ms /     7 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   869.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.47 ms /     7 runs   (    0.50 ms per token,  2017.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.36 ms /     7 runs   (  126.48 ms per token,     7.91 tokens per second)\n",
      "llama_print_timings:       total time =   905.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.54 ms /     7 runs   (    0.51 ms per token,  1980.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.50 ms /     7 runs   (  124.07 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.52 ms /     7 runs   (    0.50 ms per token,  1990.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.01 ms /     7 runs   (  124.29 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   890.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.48 ms /     7 runs   (    0.50 ms per token,  2011.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.89 ms /     7 runs   (  121.56 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 59: \n",
      "Language: english\n",
      "Question: \n",
      "What range of accommodation is expected for a 30-year-old? a) 1.00 spherical diopters. b) 4.00 spherical diopters. c) 7.00 spherical diopters. d) 12.00 spherical diopters.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.52 ms /    36 runs   (    0.54 ms per token,  1843.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1863.36 ms /    76 tokens (   24.52 ms per token,    40.79 tokens per second)\n",
      "llama_print_timings:        eval time =  4237.63 ms /    35 runs   (  121.08 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  6207.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.37 ms /    39 runs   (    0.55 ms per token,  1825.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4791.48 ms /    39 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4906.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.20 ms /    28 runs   (    0.54 ms per token,  1841.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3413.21 ms /    28 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3494.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.58 ms /    27 runs   (    0.54 ms per token,  1851.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3258.98 ms /    27 runs   (  120.70 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3336.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.81 ms /    89 runs   (    0.59 ms per token,  1685.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10922.07 ms /    89 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 11197.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.86 ms /    36 runs   (    0.55 ms per token,  1812.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4395.40 ms /    36 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4502.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.43 ms /    39 runs   (    0.55 ms per token,  1819.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4815.89 ms /    39 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  4929.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.17 ms /    40 runs   (    0.55 ms per token,  1804.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4864.71 ms /    40 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4982.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.06 ms /    40 runs   (    0.55 ms per token,  1813.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4880.13 ms /    40 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4999.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.06 ms /    37 runs   (    0.54 ms per token,  1844.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4495.18 ms /    37 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4606.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual amplitude de acomodação esperada para uma pessoa de 30 anos de idade? a) 1,00 dioptria esferica. b) 4,00 dioptria esferica. c) 7,00 dioptria esferica. d) 12,00 dioptria esferica.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.62 ms /     7 runs   (    0.52 ms per token,  1933.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2065.73 ms /    85 tokens (   24.30 ms per token,    41.15 tokens per second)\n",
      "llama_print_timings:        eval time =   722.59 ms /     6 runs   (  120.43 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2808.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.91 ms /    65 runs   (    0.57 ms per token,  1761.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7962.61 ms /    65 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8163.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    30 runs   (    0.52 ms per token,  1924.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3646.61 ms /    30 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3736.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.21 ms /    20 runs   (    0.51 ms per token,  1957.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2479.39 ms /    20 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2536.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.09 ms /    85 runs   (    0.57 ms per token,  1767.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10436.65 ms /    85 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10694.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.32 ms /    33 runs   (    0.52 ms per token,  1905.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4034.09 ms /    33 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4132.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.41 ms /    37 runs   (    0.55 ms per token,  1812.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4500.59 ms /    37 runs   (  121.64 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4610.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.98 ms /    20 runs   (    0.50 ms per token,  2004.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2424.37 ms /    20 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2483.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.46 ms /    41 runs   (    0.55 ms per token,  1825.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4968.57 ms /    41 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5091.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.44 ms /    20 runs   (    0.52 ms per token,  1916.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2445.92 ms /    20 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2505.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 60: \n",
      "Language: english\n",
      "Question: \n",
      "An electronics technician performs, without correction, an accommodative effort of 6.00 DE when working at 20 cm. Which alternative best represents this patient's refraction? a) +1.50 spherical diopters -2.00 cylindrical diopters x 180°. b) +1.50 spherical diopters -3.00 cylindrical diopters x 90°. c) +2.50 spherical diopters -3.00 cylindrical diopters x 180°. d) +3.50 spherical diopters -3.00 cylindrical diopters x 90°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    71.71 ms /   126 runs   (    0.57 ms per token,  1757.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3106.58 ms /   164 tokens (   18.94 ms per token,    52.79 tokens per second)\n",
      "llama_print_timings:        eval time = 15355.10 ms /   125 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 18854.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.89 ms /    99 runs   (    0.56 ms per token,  1771.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12245.07 ms /    99 runs   (  123.69 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 12548.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.15 ms /    56 runs   (    0.56 ms per token,  1797.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6839.00 ms /    56 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7006.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.55 ms /    56 runs   (    0.56 ms per token,  1774.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6877.99 ms /    56 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7045.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.32 ms /    51 runs   (    0.56 ms per token,  1800.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6214.16 ms /    51 runs   (  121.85 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6365.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.66 ms /    55 runs   (    0.56 ms per token,  1793.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6806.16 ms /    55 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6969.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.25 ms /    35 runs   (    0.52 ms per token,  1917.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4325.61 ms /    35 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4426.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.20 ms /    55 runs   (    0.59 ms per token,  1707.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6728.06 ms /    55 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6892.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.48 ms /    55 runs   (    0.55 ms per token,  1804.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6734.31 ms /    55 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6896.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.20 ms /    55 runs   (    0.57 ms per token,  1762.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6802.53 ms /    55 runs   (  123.68 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  6966.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um técnico em eletrônica realiza, sem correção, esforço acomodativo de 6,00 DE quando trabalha a 20 cm. Qual alternativa melhor representa a refração deste paciente? a) +1,50 dioptrias esfericas -2,00 dioptrias cilindricas x 180°. b) +1,50 dioptrias esfericas -3,00 dioptrias cilindricas x 90°. c) +2,50 dioptrias esfericas -3,00 dioptrias cilindricas x 180°. d) +3,50 dioptrias esfericas -3,00 dioptrias cilindricas x 90°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.84 ms /     7 runs   (    0.55 ms per token,  1822.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3297.02 ms /   189 tokens (   17.44 ms per token,    57.32 tokens per second)\n",
      "llama_print_timings:        eval time =   741.81 ms /     6 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4058.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.44 ms /    38 runs   (    0.56 ms per token,  1772.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4704.93 ms /    38 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4817.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.80 ms /    59 runs   (    0.57 ms per token,  1745.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7309.28 ms /    59 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  7486.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.83 ms /     7 runs   (    0.55 ms per token,  1827.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.42 ms /     7 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.84 ms /     7 runs   (    0.55 ms per token,  1821.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.68 ms /     7 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.15 ms /    38 runs   (    0.56 ms per token,  1796.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4682.11 ms /    38 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4794.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.31 ms /    38 runs   (    0.56 ms per token,  1783.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4646.74 ms /    38 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4759.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.28 ms /    38 runs   (    0.56 ms per token,  1785.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4640.50 ms /    38 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4753.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.45 ms /    88 runs   (    0.58 ms per token,  1710.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10817.72 ms /    88 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 11087.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.19 ms /    38 runs   (    0.56 ms per token,  1793.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4687.99 ms /    38 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4801.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 61: \n",
      "Language: english\n",
      "Question: \n",
      "A three-year-old child has an esotropia of 70 prismatic diopters (uncorrected), an accommodative convergence/accommodation ratio of 6, and refraction under cycloplegia of +3.50 spherical diopters in both eyes. After prescription of refraction, it is more likely that the deviation with the use of glasses, in prismatic diopters, is approximately: a) Zero. b) 20. c) 50. d) 70.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.22 ms /    21 runs   (    0.58 ms per token,  1718.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2923.88 ms /   124 tokens (   23.58 ms per token,    42.41 tokens per second)\n",
      "llama_print_timings:        eval time =  2451.91 ms /    20 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5438.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   140.49 ms /   243 runs   (    0.58 ms per token,  1729.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 29830.00 ms /   243 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 30600.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.19 ms /    28 runs   (    0.58 ms per token,  1729.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3412.23 ms /    28 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3496.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) 70'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.41 ms /   113 runs   (    0.58 ms per token,  1727.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13816.41 ms /   113 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 14170.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1725.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3425.41 ms /    28 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3512.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) 70'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3428.02 ms /    28 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3513.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.00 ms /    99 runs   (    0.58 ms per token,  1736.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12079.24 ms /    99 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 12392.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.96 ms /    24 runs   (    0.58 ms per token,  1719.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3013.12 ms /    24 runs   (  125.55 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  3089.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1735.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3445.33 ms /    28 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3531.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Criança de três anos apresenta esotropia de 70 dioptrias prismáticas (sem correção), relação convergência acomodativa/acomodação de 6, e refração sob cicloplegia de +3.50 dioptrias esfericas em ambos os olhos. Após a prescrição da refração, é mais provável que o desvio com o uso dos óculos, em dioptrias prismáticas, seja de aproximadamente: a) Zero. b) 20. c) 50. d) 70.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    89.93 ms /   153 runs   (    0.59 ms per token,  1701.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18862.47 ms /   153 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 19359.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.84 ms /    70 runs   (    0.58 ms per token,  1714.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2220.64 ms /   143 tokens (   15.53 ms per token,    64.40 tokens per second)\n",
      "llama_print_timings:        eval time =  8560.33 ms /    69 runs   (  124.06 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 11004.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.78 ms /     7 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.73 ms /     7 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.58 ms /     7 runs   (  121.23 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.59 ms /   134 runs   (    0.58 ms per token,  1727.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16522.56 ms /   134 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16948.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.43 ms /    32 runs   (    0.58 ms per token,  1736.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3902.79 ms /    32 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4001.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1706.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.31 ms /     7 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    86.17 ms /   149 runs   (    0.58 ms per token,  1729.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18355.43 ms /   149 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 18825.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.34 ms /    11 runs   (    0.58 ms per token,  1735.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1345.72 ms /    11 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1378.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   124.19 ms /   215 runs   (    0.58 ms per token,  1731.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26607.64 ms /   215 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 27280.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 62: \n",
      "Language: english\n",
      "Question: \n",
      "The measurement of the amplitude of fusional convergence is made by placing prisms in front of the eyes. Which of the alternatives below best represents the proper position of the prisms, considering a patient without strabismus? a) Temporal base in the eye with better visual acuity and nasal base in the other eye. b) Temporal base in the right eye. c) Nasal base in the eye with better visual acuity and temporal base in the other eye. d) Nasal base in the left eye.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.00 ms /    45 runs   (    0.58 ms per token,  1730.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2334.09 ms /   117 tokens (   19.95 ms per token,    50.13 tokens per second)\n",
      "llama_print_timings:        eval time =  5382.59 ms /    44 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7850.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.50 ms /    45 runs   (    0.57 ms per token,  1764.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5523.95 ms /    45 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5656.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.59 ms /    24 runs   (    0.57 ms per token,  1765.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2972.60 ms /    24 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3043.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.70 ms /    24 runs   (    0.57 ms per token,  1752.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2929.76 ms /    24 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3000.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.50 ms /     7 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.85 ms /    59 runs   (    0.57 ms per token,  1743.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7203.41 ms /    59 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7383.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.69 ms /    24 runs   (    0.57 ms per token,  1752.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2933.51 ms /    24 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3005.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.44 ms /    46 runs   (    0.57 ms per token,  1740.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5646.21 ms /    46 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5784.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.03 ms /    46 runs   (    0.57 ms per token,  1767.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5644.01 ms /    46 runs   (  122.70 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5782.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A medida da amplitude de convergência fusional é feita pela colocação de prismas diante dos olhos. Qual das alternativas abaixo melhor representa a posição adequada dos prismas, considerando um paciente sem estrabismo? a) Base temporal no olho de melhor acuidade visual e base nasal no outro olho. b) Base temporal no olho direito. c) Base nasal no olho de melhor acuidade visual e base temporal no outro olho. d) Base nasal no olho esquerdo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.16 ms /    27 runs   (    0.56 ms per token,  1780.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3340.92 ms /    27 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3421.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1708.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2654.56 ms /   134 tokens (   19.81 ms per token,    50.48 tokens per second)\n",
      "llama_print_timings:        eval time =   751.80 ms /     6 runs   (  125.30 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  3427.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.79 ms /    28 runs   (    0.60 ms per token,  1668.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3399.29 ms /    28 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3486.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   873.59 ms /     7 runs   (  124.80 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =   894.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.36 ms /    27 runs   (    0.57 ms per token,  1757.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.90 ms /    27 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3381.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.38 ms /    27 runs   (    0.57 ms per token,  1754.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3318.07 ms /    27 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3399.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.67 ms /     7 runs   (  120.24 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1735.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3518.71 ms /    28 runs   (  125.67 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  3603.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.97 ms /    38 runs   (    0.58 ms per token,  1729.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4685.44 ms /    38 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4800.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.52 ms /     7 runs   (  120.50 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3337.91 ms /    27 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3419.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 63: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding atropine 1% eye drops, mark the correct alternative. a) It is contraindicated for the treatment of amblyopia b) It causes good cycloplegia, but mild mydriasis. c) It causes prolonged cycloplegia, with an effect that lasts for up to 15 days after instillation. d) Its maximum action occurs four hours after instillation.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    86.73 ms /   150 runs   (    0.58 ms per token,  1729.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2444.61 ms /    98 tokens (   24.94 ms per token,    40.09 tokens per second)\n",
      "llama_print_timings:        eval time = 18315.78 ms /   149 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 21226.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.37 ms /    60 runs   (    0.57 ms per token,  1745.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7290.01 ms /    60 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  7468.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.56 ms /    20 runs   (    0.58 ms per token,  1729.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2461.70 ms /    20 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2520.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1733.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2404.92 ms /    20 runs   (  120.25 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  2463.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.64 ms /    64 runs   (    0.57 ms per token,  1746.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7794.08 ms /    64 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  7986.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2899.10 ms /    24 runs   (  120.80 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2970.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.52 ms /   143 runs   (    0.58 ms per token,  1712.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17559.19 ms /   143 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 18020.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.58 ms /    25 runs   (    0.58 ms per token,  1714.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3056.89 ms /    25 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3135.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.65 ms /    48 runs   (    0.58 ms per token,  1735.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5889.21 ms /    48 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6035.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   108.08 ms /   185 runs   (    0.58 ms per token,  1711.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22824.05 ms /   185 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 23408.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação ao colírio de atropina 1%, assinale a alternativa correta. a) É contraindicado para tratamento de ambliopia b) Provoca boa cicloplegia, mas midríase discreta. c) Provoca cicloplegia prolongada, com efeito que se estende por, até, 15 dias após a instilação. d) Sua ação máxima ocorre quatro horas após a instilação.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.59 ms /    28 runs   (    0.59 ms per token,  1687.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1867.99 ms /   118 tokens (   15.83 ms per token,    63.17 tokens per second)\n",
      "llama_print_timings:        eval time =  3306.03 ms /    27 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5259.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.69 ms /    74 runs   (    0.58 ms per token,  1733.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9033.42 ms /    74 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  9260.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.80 ms /    20 runs   (    0.59 ms per token,  1694.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2437.44 ms /    20 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2496.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.20 ms /     9 runs   (    0.58 ms per token,  1729.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1087.01 ms /     9 runs   (  120.78 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  1113.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.56 ms /    53 runs   (    0.58 ms per token,  1734.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6556.74 ms /    53 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6716.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.15 ms /   130 runs   (    0.58 ms per token,  1729.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16068.35 ms /   130 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 16472.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.10 ms /    71 runs   (    0.58 ms per token,  1727.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8715.95 ms /    71 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  8932.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.59 ms /    20 runs   (    0.58 ms per token,  1725.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2447.54 ms /    20 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2506.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.45 ms /    17 runs   (    0.61 ms per token,  1627.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2132.38 ms /    17 runs   (  125.43 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  2184.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 64: \n",
      "Language: english\n",
      "Question: \n",
      "A 6-year-old emmetropic child has an exophoria of 6 prismatic diopters (PD). After placement of minus lenses of -2.00 spherical diopters, he presented esophoria of 2 SD. Its accommodative convergence/accommodation ratio is: a) 2. b) 4. c) 6. d) 8.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3400.44 ms /    28 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3484.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.43 ms /    31 runs   (    0.59 ms per token,  1682.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2248.97 ms /    98 tokens (   22.95 ms per token,    43.58 tokens per second)\n",
      "llama_print_timings:        eval time =  3661.16 ms /    30 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6004.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.58 ms /    32 runs   (    0.58 ms per token,  1722.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3895.93 ms /    32 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3992.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.96 ms /    31 runs   (    0.58 ms per token,  1726.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3819.51 ms /    31 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3912.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.22 ms /    23 runs   (    0.57 ms per token,  1740.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2789.87 ms /    23 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2858.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.86 ms /    31 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3787.91 ms /    31 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3880.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.44 ms /    27 runs   (    0.57 ms per token,  1748.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3297.61 ms /    27 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3378.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.55 ms /    20 runs   (    0.58 ms per token,  1732.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2514.61 ms /    20 runs   (  125.73 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =  2574.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.15 ms /    23 runs   (    0.57 ms per token,  1748.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2782.63 ms /    23 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2850.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    81.52 ms /   141 runs   (    0.58 ms per token,  1729.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17295.48 ms /   141 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 17733.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.87 ms /    31 runs   (    0.58 ms per token,  1734.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3770.02 ms /    31 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3863.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Criança de 6 anos de idade, emétrope, apresenta exoforia de 6 dioptrias prismáticas (DP). Após colocação de lentes negativas de -2,00 dioptrias esféricas, apresentou esoforia de 2 DP. Sua relação convergência acomodativa/acomodação é: a) 2. b) 4. c) 6. d) 8.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.03 ms /   114 runs   (    0.58 ms per token,  1726.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2054.13 ms /   112 tokens (   18.34 ms per token,    54.52 tokens per second)\n",
      "llama_print_timings:        eval time = 13859.62 ms /   113 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 16268.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   120.71 ms /   210 runs   (    0.57 ms per token,  1739.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25749.31 ms /   210 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 26412.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.78 ms /   112 runs   (    0.58 ms per token,  1728.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13715.77 ms /   112 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 14059.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    70.70 ms /   123 runs   (    0.57 ms per token,  1739.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15046.90 ms /   123 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 15423.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1735.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3424.71 ms /    28 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3509.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.19 ms /    23 runs   (    0.57 ms per token,  1743.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2826.78 ms /    23 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2895.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.55 ms /   126 runs   (    0.58 ms per token,  1713.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15440.34 ms /   126 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 15832.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3509.47 ms /    28 runs   (  125.34 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  3592.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.91 ms /   118 runs   (    0.58 ms per token,  1737.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14522.98 ms /   118 runs   (  123.08 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 14885.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.43 ms /   162 runs   (    0.58 ms per token,  1733.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19919.94 ms /   162 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 20424.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 65: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding Fresnel prisms, mark the correct alternative. a) Those with high values ​​are associated with reduced visual acuity. b) Are obtained from prisms of equal power joined by their bases. c) They are obtained from prisms of equal power joined by their apexes. d) They are little used, mainly due to the discomfort caused by their high weight.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2145.24 ms /    89 tokens (   24.10 ms per token,    41.49 tokens per second)\n",
      "llama_print_timings:        eval time =  2765.18 ms /    23 runs   (  120.23 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  4982.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1737.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2083.57 ms /    17 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2135.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.86 ms /    17 runs   (    0.58 ms per token,  1723.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2081.33 ms /    17 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2132.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.72 ms /    17 runs   (    0.57 ms per token,  1748.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2077.47 ms /    17 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2128.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.77 ms /    24 runs   (    0.57 ms per token,  1743.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.93 ms /    24 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3000.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.79 ms /    17 runs   (    0.58 ms per token,  1737.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2066.92 ms /    17 runs   (  121.58 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2118.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.03 ms /    28 runs   (    0.57 ms per token,  1747.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3414.87 ms /    28 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3499.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.42 ms /    27 runs   (    0.57 ms per token,  1750.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3372.02 ms /    27 runs   (  124.89 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3452.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.72 ms /    17 runs   (    0.57 ms per token,  1748.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2048.10 ms /    17 runs   (  120.48 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2098.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.53 ms /     7 runs   (    0.65 ms per token,  1546.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.33 ms /     7 runs   (  120.19 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   863.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação aos prismas de Fresnel, assinale a alternativa correta. a) Os de altos valores são associados à redução da acuidade visual. b) São obtidos a partir de prismas de igual poder unidos por suas bases. c) São obtidos a partir de prismas de igual poder unidos por seus ápices.d) São pouco usados, principalmente pelo desconforto causado pelo seu alto peso.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.14 ms /     7 runs   (    0.59 ms per token,  1690.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2271.70 ms /   110 tokens (   20.65 ms per token,    48.42 tokens per second)\n",
      "llama_print_timings:        eval time =   734.09 ms /     6 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3026.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3415.12 ms /    28 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3500.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.66 ms /    24 runs   (    0.57 ms per token,  1756.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2937.17 ms /    24 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3008.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1729.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.54 ms /    27 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3381.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.75 ms /    17 runs   (    0.57 ms per token,  1742.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2065.55 ms /    17 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2116.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.65 ms /    17 runs   (    0.57 ms per token,  1762.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2113.04 ms /    17 runs   (  124.30 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  2163.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.24 ms /    25 runs   (    0.57 ms per token,  1755.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3097.51 ms /    25 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3172.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3430.33 ms /    28 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3514.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.41 ms /    58 runs   (    0.58 ms per token,  1736.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7251.07 ms /    58 runs   (  125.02 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  7425.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3292.23 ms /    27 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3372.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 66: \n",
      "Language: english\n",
      "Question: \n",
      "A 45-year-old +1.00 spherical diopter hyperopic patient no longer has accommodative tolerance. Therefore, to carry out an activity at 25 cm, which correction below will you need? a) +1.00 spherical diopters. b) +2.00 spherical diopters. c) +4.00 spherical diopters. d) +5.00 spherical diopters.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.77 ms /   163 runs   (    0.58 ms per token,  1738.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2186.34 ms /   107 tokens (   20.43 ms per token,    48.94 tokens per second)\n",
      "llama_print_timings:        eval time = 19905.02 ms /   162 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 22605.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.63 ms /    39 runs   (    0.55 ms per token,  1802.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4741.56 ms /    39 runs   (  121.58 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4858.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.47 ms /    40 runs   (    0.56 ms per token,  1780.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4849.55 ms /    40 runs   (  121.24 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4971.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.16 ms /    36 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4364.93 ms /    36 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4474.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    29 runs   (    0.54 ms per token,  1848.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3548.66 ms /    29 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3635.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.02 ms /    39 runs   (    0.56 ms per token,  1771.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4780.32 ms /    39 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4897.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.39 ms /    38 runs   (    0.56 ms per token,  1776.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4634.18 ms /    38 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4747.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.91 ms /    31 runs   (    0.55 ms per token,  1833.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3847.61 ms /    31 runs   (  124.12 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3938.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.52 ms /    39 runs   (    0.58 ms per token,  1731.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4835.22 ms /    39 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4951.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.91 ms /    39 runs   (    0.56 ms per token,  1779.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4775.47 ms /    39 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4890.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente hipermétrope de +1,00 dioptrias esfericas de 45 anos não possui mais tolerância acomodativa. Logo, para exercer uma atividade a 25 cm necessitará de qual correção abaixo? a) +1,00 Dioptrias esfericas. b) +2,00 dioptrias esfericas. c) +4,00 dioptrias esfericas. d) +5,00 dioptrias esfericas.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1817.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2552.01 ms /   127 tokens (   20.09 ms per token,    49.76 tokens per second)\n",
      "llama_print_timings:        eval time =   732.15 ms /     6 runs   (  122.03 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3304.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.60 ms /    41 runs   (    0.55 ms per token,  1814.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4985.06 ms /    41 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5107.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    92.48 ms /   162 runs   (    0.57 ms per token,  1751.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19914.13 ms /   162 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 20422.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.74 ms /     7 runs   (    0.53 ms per token,  1873.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.02 ms /     7 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   887.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.42 ms /    32 runs   (    0.54 ms per token,  1836.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3899.77 ms /    32 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3995.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.67 ms /     7 runs   (    0.52 ms per token,  1908.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.36 ms /     7 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.30 ms /    35 runs   (    0.55 ms per token,  1813.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4299.96 ms /    35 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4404.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.68 ms /   128 runs   (    0.58 ms per token,  1737.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15669.32 ms /   128 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 16068.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.69 ms /     7 runs   (    0.53 ms per token,  1898.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.61 ms /     7 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.77 ms /     7 runs   (    0.54 ms per token,  1856.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   872.18 ms /     7 runs   (  124.60 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   893.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 67: \n",
      "Language: english\n",
      "Question: \n",
      "A six-year-old child with a learning disability has a static refraction of +2.00 spherical diopters in both eyes, achieving a visual acuity of 1.0. No ocular deviation. What is the best course of action in this case? a) It is not necessary to prescribe glasses. b) Full prescription. c) Prescription of +1.00 pherical diopters in both eyes. d) Prescription of reading glasses.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.43 ms /    28 runs   (    0.59 ms per token,  1704.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2171.15 ms /   114 tokens (   19.05 ms per token,    52.51 tokens per second)\n",
      "llama_print_timings:        eval time =  3272.14 ms /    27 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5528.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    25 runs   (    0.58 ms per token,  1734.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3119.70 ms /    25 runs   (  124.79 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3194.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.99 ms /   107 runs   (    0.58 ms per token,  1726.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13188.34 ms /   107 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 13513.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1740.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3033.66 ms /    25 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3107.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2911.96 ms /    24 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2983.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.53 ms /     7 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.40 ms /    25 runs   (    0.58 ms per token,  1736.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3085.20 ms /    25 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3159.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.66 ms /    34 runs   (    0.58 ms per token,  1728.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4154.30 ms /    34 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4257.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3478.09 ms /    28 runs   (  124.22 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3562.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.27 ms /     7 runs   (    0.61 ms per token,  1637.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.94 ms /     7 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   886.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Uma criança de seis anos de idade com dificuldade de aprendizado, apresenta refração estática de +2,00 DE em ambos os olhos, alcançando acuidade visual 1,0. Não apresenta desvio ocular. Qual a melhor conduta neste caso? a) Não é necessária a prescrição de óculos. b) Prescrição total. c) Prescrição de +1,00 dioptrias esfericas em ambos os olhos. d) Prescrição de óculos de leitura.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    69.92 ms /   120 runs   (    0.58 ms per token,  1716.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2216.96 ms /   138 tokens (   16.06 ms per token,    62.25 tokens per second)\n",
      "llama_print_timings:        eval time = 14641.05 ms /   119 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 17236.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.49 ms /    46 runs   (    0.58 ms per token,  1736.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5724.43 ms /    46 runs   (  124.44 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  5865.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.38 ms /   146 runs   (    0.58 ms per token,  1730.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17983.30 ms /   146 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 18444.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   114.39 ms /   198 runs   (    0.58 ms per token,  1730.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24342.38 ms /   198 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 24973.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   101.77 ms /   176 runs   (    0.58 ms per token,  1729.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21590.30 ms /   176 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 22151.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.04 ms /    50 runs   (    0.58 ms per token,  1721.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6120.72 ms /    50 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6275.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.45 ms /     7 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   874.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.36 ms /     7 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.74 ms /   153 runs   (    0.58 ms per token,  1724.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18838.55 ms /   153 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 19320.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 68: \n",
      "Language: english\n",
      "Question: \n",
      "What is the anisometropia of the patient who uses -3.00 spherical diopters in the right eye and +1.00 spherical diopters -2.00 cylindrical diopters x 90° in the left eye? a) 0 DE. b) 1 spherical diopters. c) 2 spherical diopters. d) 3 spherical diopters.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   927.96 ms /     7 runs   (  132.57 ms per token,     7.54 tokens per second)\n",
      "llama_print_timings:       total time =   948.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.27 ms /    32 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2457.70 ms /   101 tokens (   24.33 ms per token,    41.10 tokens per second)\n",
      "llama_print_timings:        eval time =  3749.64 ms /    31 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  6305.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   131.70 ms /   230 runs   (    0.57 ms per token,  1746.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28290.51 ms /   230 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 29020.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   150.65 ms /   266 runs   (    0.57 ms per token,  1765.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 32715.79 ms /   266 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 33560.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.31 ms /    32 runs   (    0.57 ms per token,  1747.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3959.61 ms /    32 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4055.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.11 ms /    34 runs   (    0.65 ms per token,  1537.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4121.36 ms /    34 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4228.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   139.01 ms /   242 runs   (    0.57 ms per token,  1740.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 29708.92 ms /   242 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 30484.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.63 ms /    33 runs   (    0.56 ms per token,  1771.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4098.86 ms /    33 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  4198.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   141.78 ms /   252 runs   (    0.56 ms per token,  1777.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 30929.88 ms /   252 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 31735.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   121.43 ms /   214 runs   (    0.57 ms per token,  1762.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26425.04 ms /   214 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 27097.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    99.99 ms /   175 runs   (    0.57 ms per token,  1750.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21500.21 ms /   175 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 22046.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual a anisometropia do paciente que usa -3,00 dioptrias esfericas no olho direito e +1,00 dioptrias esfericas -2,00 dioptrias cilindricas x 90° no olho esquerdo? a) 0 DE. b) 1 dioptrias esfericas. c) 2 dioptrias esfericas. d) 3 dioptrias esfericas.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.80 ms /    36 runs   (    0.58 ms per token,  1730.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2556.14 ms /   111 tokens (   23.03 ms per token,    43.42 tokens per second)\n",
      "llama_print_timings:        eval time =  4257.02 ms /    35 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  6922.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.62 ms /    36 runs   (    0.57 ms per token,  1745.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4399.71 ms /    36 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4508.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.93 ms /    16 runs   (    0.56 ms per token,  1791.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1935.96 ms /    16 runs   (  121.00 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  1983.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.52 ms /    34 runs   (    0.57 ms per token,  1741.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4151.80 ms /    34 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4254.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.92 ms /    16 runs   (    0.56 ms per token,  1794.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1988.33 ms /    16 runs   (  124.27 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  2036.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.29 ms /    34 runs   (    0.57 ms per token,  1762.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4190.29 ms /    34 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4292.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.16 ms /    35 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4239.55 ms /    35 runs   (  121.13 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4343.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.59 ms /    17 runs   (    0.56 ms per token,  1772.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2111.94 ms /    17 runs   (  124.23 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  2162.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.57 ms /    41 runs   (    0.57 ms per token,  1739.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5007.07 ms /    41 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5130.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.48 ms /    36 runs   (    0.57 ms per token,  1757.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4370.15 ms /    36 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4476.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 69: \n",
      "Language: english\n",
      "Question: \n",
      "An examiner located 0.67 m from the examined eye uses a retinoscope and scans the horizontal meridian (vertical axis), observing a movement in favor. After adding plus lenses, the flare is neutralized with +1.50 diopter. With this lens, when sweeping the vertical meridian (horizontal axis), a movement in favor is observed. Which of the following could be a prescription for the patient? a) +1.00 spherical diopter - 1.00 x 90°. b) +1.00 spherical diopter - 1.00 x 180°. c) -1.00 spherical diopter + 1.00 X 90°. d) -1.00 spherical diopter + 1.00 X 180°.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.85 ms /    49 runs   (    0.57 ms per token,  1759.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3386.05 ms /   197 tokens (   17.19 ms per token,    58.18 tokens per second)\n",
      "llama_print_timings:        eval time =  5959.28 ms /    48 runs   (  124.15 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  9494.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.96 ms /   130 runs   (    0.57 ms per token,  1757.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16137.36 ms /   130 runs   (  124.13 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 16537.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.44 ms /    49 runs   (    0.56 ms per token,  1786.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6071.70 ms /    49 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6218.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.31 ms /    49 runs   (    0.56 ms per token,  1794.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6053.10 ms /    49 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6200.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.24 ms /    49 runs   (    0.56 ms per token,  1798.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6155.98 ms /    49 runs   (  125.63 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  6303.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.66 ms /    27 runs   (    0.54 ms per token,  1842.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3338.74 ms /    27 runs   (  123.66 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3419.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    76.94 ms /   135 runs   (    0.57 ms per token,  1754.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16590.71 ms /   135 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 17011.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.75 ms /    48 runs   (    0.56 ms per token,  1794.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5896.19 ms /    48 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6040.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.92 ms /    50 runs   (    0.56 ms per token,  1791.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6128.01 ms /    50 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6276.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.07 ms /    49 runs   (    0.55 ms per token,  1809.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6090.45 ms /    49 runs   (  124.29 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  6235.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um examinador localizado a 0,67 m do olho examinado utiliza um retinoscópio e varre o meridiano horizontal (eixo vertical), observando um movimento a favor. Após adicionar lentes positivas, o reflexo é neutralizado com +1,50 dioptria. Com esta lente, ao varrer o meridiano vertical (eixo horizontal), observa-se um movimento a favor. Qual das alternativas abaixo pode ser uma prescrição para o paciente? a) +1,00 dioptria esferica - 1,00 x 90°. b) +1,00 dioptria esferica - 1,00 x 180°. c) -1,00 dioptria esferica + 1,00 X 90°. d) -1,00 dioptria esferica + 1,00 X 180°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.91 ms /     7 runs   (    0.56 ms per token,  1789.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4698.79 ms /   232 tokens (   20.25 ms per token,    49.37 tokens per second)\n",
      "llama_print_timings:        eval time =   736.61 ms /     6 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5456.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    30 runs   (    0.54 ms per token,  1855.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3698.05 ms /    30 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3789.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n",
      "Error converting respose to json: {: response: 'a'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.36 ms /     8 runs   (    0.54 ms per token,  1835.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   999.02 ms /     8 runs   (  124.88 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  1022.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.73 ms /     7 runs   (    0.53 ms per token,  1878.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.24 ms /     7 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.67 ms /    31 runs   (    0.54 ms per token,  1860.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3850.70 ms /    31 runs   (  124.22 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3945.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.92 ms /    30 runs   (    0.53 ms per token,  1884.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3737.95 ms /    30 runs   (  124.60 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3829.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.77 ms /     7 runs   (    0.54 ms per token,  1857.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   874.49 ms /     7 runs   (  124.93 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =   895.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.64 ms /   135 runs   (    0.58 ms per token,  1738.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16694.14 ms /   135 runs   (  123.66 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 17118.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.80 ms /     7 runs   (    0.54 ms per token,  1841.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.55 ms /     7 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   886.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.34 ms /    52 runs   (    0.56 ms per token,  1772.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6474.23 ms /    52 runs   (  124.50 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  6632.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    30 runs   (    0.53 ms per token,  1869.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3677.31 ms /    30 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3768.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 70: \n",
      "Language: english\n",
      "Question: \n",
      "A previously emmetropic 40-year-old patient with a history of epilepsy reports sudden onset blurred vision in both eyes. He has myopia of -4.50 spherical diopters in both eyes, reaching normal visual acuity. What is the likely cause? a) Stroke. b) Use of topiramate. c) Ectopia lentis. d) Cataract.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1699.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2254.97 ms /   103 tokens (   21.89 ms per token,    45.68 tokens per second)\n",
      "llama_print_timings:        eval time =   726.21 ms /     6 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3002.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.23 ms /    25 runs   (    0.73 ms per token,  1371.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3016.20 ms /    25 runs   (  120.65 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3101.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.48 ms /   125 runs   (    0.68 ms per token,  1462.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15276.55 ms /   125 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 15705.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.48 ms /     7 runs   (  120.93 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.68 ms /    84 runs   (    0.63 ms per token,  1594.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10307.37 ms /    84 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10573.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    24 runs   (    0.60 ms per token,  1658.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2910.03 ms /    24 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2981.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.97 ms /    24 runs   (    0.58 ms per token,  1717.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2956.92 ms /    24 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3027.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1739.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2042.92 ms /    17 runs   (  120.17 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  2092.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.36 ms /    25 runs   (    0.57 ms per token,  1741.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3041.29 ms /    25 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3114.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.36 ms /    70 runs   (    0.58 ms per token,  1734.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8546.52 ms /    70 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8755.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente previamente emétrope de 40 anos de idade com histórico de epilepsia refere visão embaçada para longe de aparecimento súbito em ambos os olhos. Apresenta miopia de -4,50 dioptrias esfericas em ambos os olhos atingindo acuidade visual normal. Qual a provável causa? a) Acidente vascular cerebral. b) Uso de topiramato. c) Ectopia lentis. d) Catarata.\n",
      "Test #0: \n",
      "{'response': 'd) Catarata.'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.48 ms /    73 runs   (    0.58 ms per token,  1718.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2747.83 ms /   133 tokens (   20.66 ms per token,    48.40 tokens per second)\n",
      "llama_print_timings:        eval time =  8771.43 ms /    72 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time = 11740.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1725.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.90 ms /     7 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.64 ms /    72 runs   (    0.58 ms per token,  1729.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8830.83 ms /    72 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  9047.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.23 ms /     9 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1114.61 ms /     9 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  1140.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.48 ms /     7 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    82.67 ms /   143 runs   (    0.58 ms per token,  1729.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17476.85 ms /   143 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 17916.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Catarata.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1718.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   836.11 ms /     7 runs   (  119.44 ms per token,     8.37 tokens per second)\n",
      "llama_print_timings:       total time =   856.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.20 ms /   168 runs   (    0.58 ms per token,  1728.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20698.62 ms /   168 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 21221.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.96 ms /    12 runs   (    0.58 ms per token,  1722.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1494.45 ms /    12 runs   (  124.54 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  1530.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Catarata.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.26 ms /    16 runs   (    0.58 ms per token,  1727.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1953.23 ms /    16 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2002.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 71: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the alternative that correctly correlates the columns. I - Compound hypermetropic astigmatism in favor of the rule. II - Compound myopic astigmatism against the rule. III- Astigmatic anisometropia. IV - Antimetropic anisometropia. A - Right eye: -1.00 spherical diopters -1.50 cylindrical diopters x 90° Left eye: -1.00 spherical diopters -1.50 cylindrical diopters x 90°. B - Right eye: +5.00 spherical diopters Left eye: -1.00 spherical diopters. C - right eye: +5.00 spherical diopters -5.00 cylindrical diopters x 90° left eye: +1.00 spherical diopters -1.00 cylindrical diopters x 90°. D - right eye: +5.00 spherical diopters +2.50 cylindrical diopters x 90° left eye: +5.00 spherical diopters +2.50 cylindrical diopters x 90°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.28 ms /    82 runs   (    0.61 ms per token,  1630.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4937.72 ms /   285 tokens (   17.33 ms per token,    57.72 tokens per second)\n",
      "llama_print_timings:        eval time = 10096.24 ms /    81 runs   (  124.64 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time = 15292.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.05 ms /    82 runs   (    0.56 ms per token,  1780.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10085.98 ms /    82 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 10334.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.24 ms /    82 runs   (    0.58 ms per token,  1735.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10177.94 ms /    82 runs   (  124.12 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 10430.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.68 ms /    82 runs   (    0.57 ms per token,  1756.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10120.14 ms /    82 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10366.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.66 ms /    82 runs   (    0.61 ms per token,  1651.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10080.22 ms /    82 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 10337.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.55 ms /    82 runs   (    0.63 ms per token,  1590.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10175.65 ms /    82 runs   (  124.09 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 10440.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.27 ms /    82 runs   (    0.63 ms per token,  1599.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10123.23 ms /    82 runs   (  123.45 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10385.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.84 ms /    27 runs   (    0.55 ms per token,  1819.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3338.35 ms /    27 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3418.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n",
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.42 ms /    82 runs   (    0.57 ms per token,  1766.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10108.77 ms /    82 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 10357.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.21 ms /    82 runs   (    0.56 ms per token,  1774.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10239.68 ms /    82 runs   (  124.87 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time = 10486.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que correlaciona corretamente as colunas. I - Astigmatismo hipermetrópico composto a favor da regra. II - Astigmatismo miópico composto contra a regra. III- Anisometropia astigmática. IV - Anisometropia antimetrópica. A - Olho direito: -1,00 dioptrias esfericas -1,50 dioptrias cilindricas x 90° Olho esquerdo: -1,00 dioptrias esfericas -1,50 dioptrias cilindricas x 90°. B - Olho direito: +5,00 dioptrias esfericas Olho esquerdo: -1,00 dioptrias esfericas. C - olho direito: +5,00 dioptrias esfericas -5,00 dioptrais cilindricas x 90° olho esquerdo: +1,00 dioptrias esfericas -1,00 dioptrias cilindricas x 90°.  D - olho direito: +5,00 dioptrias esfericas +2,50 dioptrias cilindricas x 90° olho esquerdo: +5,00 dioptrias esfericas +2,50 dioptrias cilindricas x 90°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.30 ms /     7 runs   (    0.61 ms per token,  1629.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  5067.91 ms /   337 tokens (   15.04 ms per token,    66.50 tokens per second)\n",
      "llama_print_timings:        eval time =   731.45 ms /     6 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5821.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.57 ms /    27 runs   (    0.58 ms per token,  1734.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3327.19 ms /    27 runs   (  123.23 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3409.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.45 ms /    27 runs   (    0.57 ms per token,  1747.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3353.83 ms /    27 runs   (  124.22 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3436.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.20 ms /     7 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   876.58 ms /     7 runs   (  125.23 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   898.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #5: \n",
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.29 ms /    11 runs   (    0.57 ms per token,  1747.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1382.62 ms /    11 runs   (  125.69 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  1415.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3335.59 ms /    27 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3416.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n",
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.14 ms /     7 runs   (  124.45 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   892.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.36 ms /    27 runs   (    0.57 ms per token,  1758.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3354.75 ms /    27 runs   (  124.25 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3436.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.56 ms /    28 runs   (    0.59 ms per token,  1691.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3490.03 ms /    28 runs   (  124.64 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3576.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 72: \n",
      "Language: english\n",
      "Question: \n",
      "Classify the astigmatisms below according to the central keratometry. Consider insignificant internal astigmatism.\n",
      "\n",
      "I- 44.00 @ 90° x 42.00 @ 180°.\n",
      "II- 44.00 @ 180° x 42.00 @ 90°.\n",
      "III- 44.00 @ 45° x 42.00 @ 135°.\n",
      "\n",
      "A- Astigmatism in favor of the rule.\n",
      "B- Astigmatism against the rule.\n",
      "C- Oblique astigmatism.\n",
      "\n",
      "a) I: A, II: B, III: C.\n",
      "b) I: A, II: C, III: B.\n",
      "c) I: B, II: A, III: C.\n",
      "d) I: B, II: C, III: A.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.80 ms /    91 runs   (    0.57 ms per token,  1756.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3790.71 ms /   214 tokens (   17.71 ms per token,    56.45 tokens per second)\n",
      "llama_print_timings:        eval time = 11128.85 ms /    90 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15202.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.38 ms /   153 runs   (    0.56 ms per token,  1791.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19010.41 ms /   153 runs   (  124.25 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 19486.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.11 ms /   126 runs   (    0.57 ms per token,  1747.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15500.29 ms /   126 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 15892.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.74 ms /    27 runs   (    0.55 ms per token,  1832.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3287.09 ms /    27 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3367.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.73 ms /   130 runs   (    0.57 ms per token,  1763.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16040.89 ms /   130 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 16440.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.27 ms /    66 runs   (    0.56 ms per token,  1771.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8166.25 ms /    66 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  8367.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.54 ms /    20 runs   (    0.53 ms per token,  1897.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2477.22 ms /    20 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2535.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.41 ms /    89 runs   (    0.57 ms per token,  1765.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10934.79 ms /    89 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11203.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    87.36 ms /   153 runs   (    0.57 ms per token,  1751.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18909.90 ms /   153 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 19381.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.60 ms /    20 runs   (    0.53 ms per token,  1886.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2442.04 ms /    20 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2500.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Classifique os astigmatismos abaixo de acordo com a ceratometria central. Considere o astigmatismo interno insignificante.\n",
      "\n",
      "I- 44,00 @ 90° x 42,00 @ 180°.\n",
      "II- 44,00 @ 180° x 42,00 @ 90°.\n",
      "III- 44,00 @ 45° x 42,00 @ 135°.\n",
      "\n",
      "A- Astigmatismo a favor da regra.\n",
      "B- Astigmatismo contra a regra.\n",
      "C- Astigmatismo oblíquo.\n",
      "\n",
      "a)I: A, II: B, III: C.\n",
      "b)I: A, II: C, III: B.\n",
      "c)I: B, II: A, III: C.\n",
      "d)I: B, II: C, III: A.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.35 ms /    97 runs   (    0.57 ms per token,  1752.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3683.07 ms /   228 tokens (   16.15 ms per token,    61.90 tokens per second)\n",
      "llama_print_timings:        eval time = 11787.56 ms /    96 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 15766.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.52 ms /     7 runs   (    0.50 ms per token,  1986.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   876.52 ms /     7 runs   (  125.22 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   897.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.48 ms /     7 runs   (    0.50 ms per token,  2013.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.85 ms /     7 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.62 ms /     9 runs   (    0.51 ms per token,  1948.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1114.18 ms /     9 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  1140.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.88 ms /    73 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9045.96 ms /    73 runs   (  123.92 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  9265.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.72 ms /    27 runs   (    0.55 ms per token,  1833.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.69 ms /    27 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3379.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.90 ms /    92 runs   (    0.56 ms per token,  1772.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11492.31 ms /    92 runs   (  124.92 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time = 11771.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.51 ms /     7 runs   (    0.50 ms per token,  1996.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   880.90 ms /     7 runs   (  125.84 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =   901.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.50 ms /     7 runs   (    0.50 ms per token,  1997.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.87 ms /     7 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.55 ms /     7 runs   (    0.51 ms per token,  1973.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.60 ms /     7 runs   (  124.51 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   891.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 73: \n",
      "Language: english\n",
      "Question: \n",
      "A patient moves away from the Greens so as not to fog up his lenses due to the use of a mask during the exam. Which of the following is correct if he stays away from the Greens and the ophthalmologist doesn't notice? a) If he is myopic, there will be undercorrection in his prescription. b) If he is myopic, there will be overcorrection in his prescription. c) If he is nearsighted, there will be no change in his prescription. d) If he is farsighted, he will need greater accommodative effort.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.31 ms /   110 runs   (    0.58 ms per token,  1710.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2744.23 ms /   140 tokens (   19.60 ms per token,    51.02 tokens per second)\n",
      "llama_print_timings:        eval time = 13343.75 ms /   109 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 16427.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.57 ms /    98 runs   (    0.58 ms per token,  1732.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11984.62 ms /    98 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 12283.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.00 ms /    31 runs   (    0.58 ms per token,  1722.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3781.17 ms /    31 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3873.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.02 ms /     7 runs   (  124.00 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.37 ms /   111 runs   (    0.58 ms per token,  1724.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13735.88 ms /   111 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 14077.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.88 ms /    24 runs   (    0.58 ms per token,  1729.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2900.55 ms /    24 runs   (  120.86 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2972.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.28 ms /    44 runs   (    0.57 ms per token,  1740.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5376.72 ms /    44 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5511.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.63 ms /   107 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13096.12 ms /   107 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 13425.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    87.74 ms /   152 runs   (    0.58 ms per token,  1732.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18649.18 ms /   152 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 19124.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.44 ms /    75 runs   (    0.58 ms per token,  1726.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9180.79 ms /    75 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  9408.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente se afasta do Greens para não embaçar as lentes devido ao uso de máscara durante o exame. Qual das alternativas abaixo é correta caso ele permaneça afastado do Greens e o oftalmologista não perceba? a) Se ele for míope, haverá hipocorreção em sua prescrição. b) Se ele for míope, haverá hipercorreção em sua prescrição. c) Se ele for míope, não haverá mudança em sua prescrição. d) Se ele for hipermetrope, necessitará de maior esforço acomodativo.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.22 ms /     7 runs   (    0.60 ms per token,  1657.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2921.76 ms /   156 tokens (   18.73 ms per token,    53.39 tokens per second)\n",
      "llama_print_timings:        eval time =   739.29 ms /     6 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3682.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.21 ms /   110 runs   (    0.60 ms per token,  1661.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13485.26 ms /   110 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 13833.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1716.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.42 ms /     7 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.15 ms /    85 runs   (    0.58 ms per token,  1729.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10443.75 ms /    85 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10701.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.17 ms /     7 runs   (  124.45 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1762.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.68 ms /     7 runs   (  120.81 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.22 ms /     7 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.98 ms /    26 runs   (    0.58 ms per token,  1735.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3158.04 ms /    26 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3235.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.09 ms /     7 runs   (  120.73 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   865.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.15 ms /     7 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   871.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 74: \n",
      "Language: english\n",
      "Question: \n",
      "What is the function of the \"P\" setting on the Greens refractor? a) Increase positive spherical power to test near refraction. b) Increase the negative spherical power to discount the working distance in skiascopy. c) Insert a 6 DP prism and allow the evaluation of the refractometric balance. d) Separate the images and allow evaluation of refractometric balance and stereopsis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.76 ms /    27 runs   (    0.58 ms per token,  1713.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2820.43 ms /   100 tokens (   28.20 ms per token,    35.46 tokens per second)\n",
      "llama_print_timings:        eval time =  3187.01 ms /    26 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6089.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'd)'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.47 ms /    46 runs   (    0.58 ms per token,  1737.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5728.98 ms /    46 runs   (  124.54 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  5868.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.01 ms /    73 runs   (    0.58 ms per token,  1737.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8929.04 ms /    73 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9149.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.75 ms /    85 runs   (    0.57 ms per token,  1743.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10321.30 ms /    85 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time = 10579.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1724.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3435.11 ms /    28 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3518.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.00 ms /    64 runs   (    0.58 ms per token,  1729.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7823.95 ms /    64 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  8022.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.29 ms /    44 runs   (    0.57 ms per token,  1740.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5343.10 ms /    44 runs   (  121.43 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5478.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.01 ms /    27 runs   (    0.59 ms per token,  1686.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3296.81 ms /    27 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3380.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.48 ms /    27 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3386.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.08 ms /    28 runs   (    0.57 ms per token,  1740.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3393.46 ms /    28 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3481.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual a função do ajuste \"P\" no refrator de Greens? a) Aumentar o poder esférico positivo para testar a refração para perto. b) Aumentar o poder esférico negativo para descontar a distância de trabalho na esquiascopia. c) Inserir um prisma de 6 DP e possibilitar a avaliação do balanço refratométrico. d) Separar as imagens e possibilitar avaliação do balanço refratométrico e da estereopsia.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.68 ms /    57 runs   (    0.59 ms per token,  1692.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2784.45 ms /   140 tokens (   19.89 ms per token,    50.28 tokens per second)\n",
      "llama_print_timings:        eval time =  6879.24 ms /    56 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  9838.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.82 ms /     7 runs   (  120.69 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1738.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.44 ms /    27 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3380.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   916.33 ms /     7 runs   (  130.90 ms per token,     7.64 tokens per second)\n",
      "llama_print_timings:       total time =   936.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.63 ms /    80 runs   (    0.58 ms per token,  1715.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9841.66 ms /    80 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 10085.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.24 ms /     7 runs   (  120.89 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.33 ms /    87 runs   (    0.59 ms per token,  1694.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10735.57 ms /    87 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 11014.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.14 ms /    92 runs   (    0.58 ms per token,  1731.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11337.62 ms /    92 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 11618.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.65 ms /    27 runs   (    0.58 ms per token,  1724.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3290.22 ms /    27 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3371.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.94 ms /    52 runs   (    0.58 ms per token,  1736.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6336.92 ms /    52 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6493.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 75: \n",
      "Language: english\n",
      "Question: \n",
      "An undercorrected myopic person often tilts his glasses to see better. What effect does this maneuver have on your corrective lenses? a) Increased optical divergence and positive cylinder induction on the tilt axis. b) Increased optical convergence and negative cylinder induction on the tilt axis. c) Increased optical divergence and negative cylinder induction on the tilt axis. d) Increased optical convergence and positive cylinder induction on the tilt axis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.83 ms /   128 runs   (    0.59 ms per token,  1687.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2478.21 ms /   113 tokens (   21.93 ms per token,    45.60 tokens per second)\n",
      "llama_print_timings:        eval time = 15498.57 ms /   127 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 18378.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.49 ms /    45 runs   (    0.57 ms per token,  1765.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5480.99 ms /    45 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5614.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.26 ms /    27 runs   (    0.57 ms per token,  1769.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3266.27 ms /    27 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3345.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.95 ms /   143 runs   (    0.59 ms per token,  1683.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17490.43 ms /   143 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 17942.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.16 ms /   112 runs   (    0.57 ms per token,  1745.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13727.72 ms /   112 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 14073.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.20 ms /    27 runs   (    0.56 ms per token,  1776.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3279.05 ms /    27 runs   (  121.45 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3358.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    28 runs   (    0.56 ms per token,  1785.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3446.01 ms /    28 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3529.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.18 ms /   102 runs   (    0.57 ms per token,  1753.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12494.38 ms /   102 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 12805.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.03 ms /   115 runs   (    0.57 ms per token,  1741.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14157.95 ms /   115 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 14516.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.49 ms /    79 runs   (    0.58 ms per token,  1736.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9828.67 ms /    79 runs   (  124.41 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 10071.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um míope hipocorrigido frequentemente inclina seus óculos para enxergar melhor. Qual o efeito desta manobra em suas lentes corretoras? a) Aumento da divergência óptica e indução de cilindro positivo no eixo da inclinação. b) Aumento da convergência óptica e indução de cilindro negativo no eixo da inclinação. c) Aumento da divergência óptica e indução de cilindro negativo no eixo da inclinação. d) Aumento da convergência óptica e indução de cilindro positivo no eixo da inclinação.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.34 ms /    80 runs   (    0.58 ms per token,  1726.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4015.87 ms /   172 tokens (   23.35 ms per token,    42.83 tokens per second)\n",
      "llama_print_timings:        eval time =  9759.86 ms /    79 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 14019.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.70 ms /     7 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.80 ms /    72 runs   (    0.65 ms per token,  1538.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8936.38 ms /    72 runs   (  124.12 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  9436.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   101.75 ms /   159 runs   (    0.64 ms per token,  1562.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19661.06 ms /   159 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 20696.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   872.51 ms /     7 runs   (  124.64 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =   893.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.65 ms /     7 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1764.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.24 ms /     7 runs   (  120.32 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.90 ms /    76 runs   (    0.58 ms per token,  1731.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9418.75 ms /    76 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  9650.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.66 ms /     7 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.94 ms /     7 runs   (    0.56 ms per token,  1774.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.55 ms /     7 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   877.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 76: \n",
      "Language: english\n",
      "Question: \n",
      "During the refraction outpatient clinic, the first-year resident instilled a cycloplegic eye drop in the patients, but lost the bottle. His preceptor decided to measure the accommodation effect to find out which drops were used and noticed that the patients had good mydriasis and had a maximum reduction in accommodation 20 to 30 minutes after instillation, with a fleeting effect. What eye drops did the resident instill? a) Atropine. b) Cyclopentolate. c) Phenylephrine. d) Tropicamide.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.77 ms /    53 runs   (    0.58 ms per token,  1722.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3192.84 ms /   136 tokens (   23.48 ms per token,    42.60 tokens per second)\n",
      "llama_print_timings:        eval time =  6434.45 ms /    52 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  9790.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.01 ms /     7 runs   (  120.29 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.13 ms /    52 runs   (    0.58 ms per token,  1726.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6399.82 ms /    52 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6558.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.16 ms /     9 runs   (    0.57 ms per token,  1744.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1093.06 ms /     9 runs   (  121.45 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  1120.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.85 ms /    32 runs   (    0.59 ms per token,  1697.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3923.86 ms /    32 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4022.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1756.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   883.04 ms /     7 runs   (  126.15 ms per token,     7.93 tokens per second)\n",
      "llama_print_timings:       total time =   904.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.93 ms /     7 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.93 ms /     7 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   879.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.86 ms /    52 runs   (    0.57 ms per token,  1741.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6371.88 ms /    52 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6531.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tropicamide'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.20 ms /    23 runs   (    0.57 ms per token,  1742.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2831.69 ms /    23 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2900.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Tropicamide.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1765.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.44 ms /     7 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Durante o ambulatório de refração o residente do primeiro ano instilou um colírio cicloplégico nos pacientes, mas perdeu o frasco. Seu preceptor resolveu medir o efeito de acomodação para descobrir qual colírio foi usado e notou que os pacientes estavam com boa midríase e tiveram redução máxima na acomodação 20 a 30 minutos após a instilação, com efeito fugaz. Qual colírio o residente instilou? a) Atropina. b) Ciclopentolato. c) Fenilefrina. d) Tropicamida.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1694.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3556.32 ms /   167 tokens (   21.30 ms per token,    46.96 tokens per second)\n",
      "llama_print_timings:        eval time =   732.07 ms /     6 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4310.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1697.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.91 ms /     7 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   877.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.49 ms /     7 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.07 ms /     7 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   885.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.63 ms /     7 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.81 ms /     7 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.33 ms /     7 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.21 ms /     7 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   887.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1710.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.76 ms /     7 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   868.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.34 ms /     7 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 77: \n",
      "Language: english\n",
      "Question: \n",
      "During a patient's skiascopy, which of the following characteristics indicates that the examiner is closest to the point of neutrality? a) Fast beam speed, high brightness, wide beam. b) Fast beam speed, low brightness, narrow beam. c) Slow beam speed, high brightness, wide beam. d) Slow beam speed, low brightness, narrow beam.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.62 ms /    34 runs   (    0.58 ms per token,  1733.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1655.95 ms /    88 tokens (   18.82 ms per token,    53.14 tokens per second)\n",
      "llama_print_timings:        eval time =  4029.29 ms /    33 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5789.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.82 ms /    42 runs   (    0.57 ms per token,  1763.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5153.27 ms /    42 runs   (  122.70 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5280.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.94 ms /    39 runs   (    0.56 ms per token,  1777.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4746.72 ms /    39 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4864.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.50 ms /    28 runs   (    0.55 ms per token,  1807.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3398.72 ms /    28 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3482.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.02 ms /    34 runs   (    0.56 ms per token,  1788.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4148.78 ms /    34 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4250.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.45 ms /    40 runs   (    0.56 ms per token,  1782.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4928.89 ms /    40 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5049.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.04 ms /    32 runs   (    0.56 ms per token,  1773.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3895.02 ms /    32 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3991.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.44 ms /    40 runs   (    0.56 ms per token,  1782.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4908.55 ms /    40 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5028.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.86 ms /     7 runs   (    0.55 ms per token,  1812.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.97 ms /     7 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.84 ms /    41 runs   (    0.56 ms per token,  1794.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5058.09 ms /    41 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5181.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Durante a esquiascopia de um paciente, qual das características abaixo indica que o examinador está mais próximo do ponto de neutralidade? a) Velocidade do feixe rápida, brilho alto, feixe largo. b) Velocidade do feixe rápida, brilho baixo, feixe estreito. c) Velocidade do feixe lenta, brilho alto, feixe largo. d) Velocidade do feixe lenta, brilho baixo, feixe estreito.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1703.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3228.10 ms /   140 tokens (   23.06 ms per token,    43.37 tokens per second)\n",
      "llama_print_timings:        eval time =   734.12 ms /     6 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3983.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1758.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.00 ms /     7 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   871.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.31 ms /    20 runs   (    0.57 ms per token,  1768.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2448.23 ms /    20 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2509.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.93 ms /     7 runs   (    0.56 ms per token,  1782.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.96 ms /     7 runs   (  120.57 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.05 ms /    63 runs   (    0.57 ms per token,  1747.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7706.99 ms /    63 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7899.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.66 ms /    52 runs   (    0.57 ms per token,  1753.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6397.77 ms /    52 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6554.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1819.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   880.81 ms /     7 runs   (  125.83 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =   901.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1818.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.41 ms /     7 runs   (  124.06 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.76 ms /    21 runs   (    0.56 ms per token,  1785.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2631.41 ms /    21 runs   (  125.31 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  2693.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.08 ms /    23 runs   (    0.57 ms per token,  1758.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2785.65 ms /    23 runs   (  121.12 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2854.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 78: \n",
      "Language: english\n",
      "Question: \n",
      "On examination of a phakic patient, the closest point of accommodation was found in the right eye at 30 cm and in the left eye at 50 cm. In this case, it can be stated: a) The left eye must be more myopic than the right eye. b) More likely there is a need to adjust the patient's refraction. c) It is a common condition, as accommodation is rarely similar in both eyes. d) A disease that moves the retina forward, such as central serous chorioretinopathy, is the cause of this shorter distance in the right eye.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.89 ms /    25 runs   (    0.60 ms per token,  1679.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2952.49 ms /   141 tokens (   20.94 ms per token,    47.76 tokens per second)\n",
      "llama_print_timings:        eval time =  2950.35 ms /    24 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5978.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.34 ms /    28 runs   (    0.58 ms per token,  1713.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3401.18 ms /    28 runs   (  121.47 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3485.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.56 ms /    25 runs   (    0.58 ms per token,  1717.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3061.79 ms /    25 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3136.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.65 ms /    20 runs   (    0.58 ms per token,  1717.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2440.63 ms /    20 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2501.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.84 ms /    17 runs   (    0.58 ms per token,  1728.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2068.35 ms /    17 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2118.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.24 ms /     7 runs   (  120.75 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   865.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.01 ms /     7 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.88 ms /    74 runs   (    0.59 ms per token,  1686.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9259.07 ms /    74 runs   (  125.12 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  9486.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.12 ms /    87 runs   (    0.58 ms per token,  1735.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10604.68 ms /    87 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 10868.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1733.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3086.75 ms /    25 runs   (  123.47 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3161.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "No exame de um paciente fácico, foi encontrado o ponto próximo de acomodação no olho direito a 30 cm e no olho esquerdo a 50 cm. Neste caso, pode-se afirmar: a) O olho esquerdo deve ser mais míope que o olho direito. b) Mais provavelmente há necessidade de se ajustar a refração do paciente. c) É uma condição comum, já que a acomodação é raramente semelhante nos dois olhos. d) Uma doença que desloque a retina para frente, como a coriorretinopatia central serosa, é causa dessa menor distância no olho direito.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.92 ms /   115 runs   (    0.58 ms per token,  1718.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2765.37 ms /   177 tokens (   15.62 ms per token,    64.01 tokens per second)\n",
      "llama_print_timings:        eval time = 14130.72 ms /   114 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 17252.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.26 ms /    94 runs   (    0.58 ms per token,  1732.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11543.52 ms /    94 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11827.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.56 ms /    27 runs   (    0.58 ms per token,  1735.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3316.91 ms /    27 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3396.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.80 ms /   111 runs   (    0.58 ms per token,  1712.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13732.81 ms /   111 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 14072.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.70 ms /    27 runs   (    0.58 ms per token,  1720.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.12 ms /    27 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3384.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3433.22 ms /    28 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3516.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.32 ms /   113 runs   (    0.58 ms per token,  1729.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13888.60 ms /   113 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 14233.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1710.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.24 ms /     7 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.50 ms /    20 runs   (    0.58 ms per token,  1738.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2502.25 ms /    20 runs   (  125.11 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  2561.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1710.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.24 ms /     7 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   874.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 79: \n",
      "Language: english\n",
      "Question: \n",
      "If the patient's refraction is +1.50 spherical diopters and -0.50 cylindrical diopters x 180° and his keratometry is 42.00 diopters x 180° and 44.00 diopters x 90°, we can say that the internal astigmatism is : a) +1.50 cylindrical diopters x 90°. b) +2.50 cylindrical diopters x 180°. c) -1.50 cylindrical diopters x 90°. d) -2.50 cylindrical diopters x 180°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.77 ms /    46 runs   (    0.56 ms per token,  1784.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3167.71 ms /   169 tokens (   18.74 ms per token,    53.35 tokens per second)\n",
      "llama_print_timings:        eval time =  5535.88 ms /    45 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8841.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.41 ms /    44 runs   (    0.55 ms per token,  1802.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5372.01 ms /    44 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5502.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.10 ms /    45 runs   (    0.56 ms per token,  1793.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5522.88 ms /    45 runs   (  122.73 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5656.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.56 ms /    46 runs   (    0.56 ms per token,  1799.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5646.66 ms /    46 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5782.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.87 ms /    46 runs   (    0.56 ms per token,  1778.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5704.64 ms /    46 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  5841.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.17 ms /    46 runs   (    0.57 ms per token,  1757.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5599.77 ms /    46 runs   (  121.73 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5737.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.64 ms /    44 runs   (    0.56 ms per token,  1786.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5417.28 ms /    44 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5548.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.86 ms /    45 runs   (    0.57 ms per token,  1739.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5534.30 ms /    45 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5671.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.64 ms /    28 runs   (    0.56 ms per token,  1790.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3422.89 ms /    28 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3506.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Se a refração do paciente é +1,50 dioptrias esfericas e -0,50 dioptrias cilindricas x 180° e sua ceratometria é 42,00 Dioptrias x 180° e 44,00 Dioptrias x 90°, podemos afirmar que o astigmatismo interno é: a) +1,50 dioptrias cilindricas x 90°. b) +2,50 dioptrias cilindricas x 180°. c) -1,50 dioptrias cilindricas x 90°. d) -2,50 dioptrias cilindricas x 180°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.00 ms /    46 runs   (    0.57 ms per token,  1769.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5630.20 ms /    46 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5769.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.18 ms /     9 runs   (    0.58 ms per token,  1737.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3068.61 ms /   187 tokens (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:        eval time =  1006.87 ms /     8 runs   (  125.86 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =  4103.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.72 ms /    26 runs   (    0.57 ms per token,  1766.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3206.22 ms /    26 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3284.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.89 ms /    51 runs   (    0.61 ms per token,  1651.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6256.57 ms /    51 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6414.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.73 ms /     7 runs   (    0.53 ms per token,  1876.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.11 ms /     7 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    96.10 ms /   157 runs   (    0.61 ms per token,  1633.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19348.19 ms /   157 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 19853.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.59 ms /    47 runs   (    0.63 ms per token,  1588.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5804.39 ms /    47 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  5949.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.89 ms /    26 runs   (    0.61 ms per token,  1635.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3168.63 ms /    26 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3253.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'a'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.87 ms /     9 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1101.10 ms /     9 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1127.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3414.19 ms /    28 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3502.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.88 ms /    26 runs   (    0.76 ms per token,  1307.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3206.02 ms /    26 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3295.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 80: \n",
      "Language: english\n",
      "Question: \n",
      "A pseudophakic patient with a refraction of +1.00 spherical diopters and -3.00 cylindrical diopters x 180° is likely to notice less blurry vision at: a) 0.5 m. b) 1 m. c) 2 m. d) 4 m.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    89.08 ms /   150 runs   (    0.59 ms per token,  1683.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1864.02 ms /    82 tokens (   22.73 ms per token,    43.99 tokens per second)\n",
      "llama_print_timings:        eval time = 18222.07 ms /   149 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 20568.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.36 ms /    32 runs   (    0.57 ms per token,  1743.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3867.14 ms /    32 runs   (  120.85 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3962.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.07 ms /    28 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3422.12 ms /    28 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3505.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.11 ms /   162 runs   (    0.57 ms per token,  1739.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19761.38 ms /   162 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 20262.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.39 ms /    27 runs   (    0.57 ms per token,  1753.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3276.97 ms /    27 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3355.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   105.66 ms /   180 runs   (    0.59 ms per token,  1703.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22098.73 ms /   180 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 22664.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.43 ms /   126 runs   (    0.57 ms per token,  1739.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15451.41 ms /   126 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 15840.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    74.86 ms /   129 runs   (    0.58 ms per token,  1723.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15861.68 ms /   129 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 16262.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.31 ms /   159 runs   (    0.57 ms per token,  1741.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19454.09 ms /   159 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 19948.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.19 ms /   145 runs   (    0.59 ms per token,  1702.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17869.03 ms /   145 runs   (  123.23 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 18320.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente pseudofácico com refração de +1,00 dioptrias esfericas e -3,00 dioptrias cilindricas x 180° provavelmente notará um visão menos borrada a: a) 0,5 m. b) 1 m. c) 2 m. d) 4 m.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   172.68 ms /   278 runs   (    0.62 ms per token,  1609.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2180.92 ms /    89 tokens (   24.50 ms per token,    40.81 tokens per second)\n",
      "llama_print_timings:        eval time = 34085.51 ms /   277 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 37190.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.12 ms /   132 runs   (    0.64 ms per token,  1550.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16163.91 ms /   132 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 16606.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    74.89 ms /   130 runs   (    0.58 ms per token,  1735.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15871.68 ms /   130 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 16268.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.75 ms /    33 runs   (    0.57 ms per token,  1759.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4028.94 ms /    33 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4126.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3259.56 ms /    27 runs   (  120.72 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3340.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.30 ms /   103 runs   (    0.58 ms per token,  1737.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12566.05 ms /   103 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 12882.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.44 ms /   100 runs   (    0.57 ms per token,  1741.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12193.37 ms /   100 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 12499.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.17 ms /   103 runs   (    0.57 ms per token,  1740.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12614.15 ms /   103 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12927.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.82 ms /   106 runs   (    0.57 ms per token,  1742.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12879.12 ms /   106 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time = 13201.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 81: \n",
      "Language: english\n",
      "Question: \n",
      "Patient returns complaining of diplopia after making eyeglasses. Has anisometropia, but previously wore glasses without problems. There was no change in the prescription. Optical centers are properly mounted. The most likely explanation is: a) Change in the base curve of one of the lenses. b) Change in frame format. c) Disappearance of the central suppression scotoma. d) Loss of cerebral compensation capacity for the difference in aniseikonia.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.56 ms /    39 runs   (    0.58 ms per token,  1728.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4831.83 ms /    39 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4948.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.03 ms /    31 runs   (    0.58 ms per token,  1719.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2036.32 ms /   118 tokens (   17.26 ms per token,    57.95 tokens per second)\n",
      "llama_print_timings:        eval time =  3703.91 ms /    30 runs   (  123.46 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  5834.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2927.31 ms /    24 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2998.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.67 ms /    45 runs   (    0.57 ms per token,  1752.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5484.03 ms /    45 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5618.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Test #3: \n",
      "{'response': 'd) Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.66 ms /    27 runs   (    0.58 ms per token,  1724.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.35 ms /    27 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3381.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.86 ms /    45 runs   (    0.57 ms per token,  1740.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5467.26 ms /    45 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5602.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.92 ms /    45 runs   (    0.58 ms per token,  1736.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5508.96 ms /    45 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5642.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.57 ms /   115 runs   (    0.58 ms per token,  1727.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14170.28 ms /   115 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 14525.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.83 ms /    45 runs   (    0.57 ms per token,  1742.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5488.75 ms /    45 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5624.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Test #8: \n",
      "{'response': 'd) Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.88 ms /    45 runs   (    0.57 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5525.05 ms /    45 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5662.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.39 ms /    44 runs   (    0.58 ms per token,  1732.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5449.56 ms /    44 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  5582.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente retorna com queixa de diplopia após confeccionar óculos. Tem anisometropia, mas usava óculos anteriormente sem problemas. Não houve modificação na prescrição. Os centros ópticos estão montados adequadamente. A explicação mais provável é: a) Mudança na curva base de uma das lentes. b) Mudança no formato da armação. c) Desaparecimento do escotoma central de supressão. d) Perda da capacidade de compensação cerebral da diferença da aniseiconia.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.08 ms /    29 runs   (    0.59 ms per token,  1697.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2830.97 ms /   146 tokens (   19.39 ms per token,    51.57 tokens per second)\n",
      "llama_print_timings:        eval time =  3429.80 ms /    28 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6349.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Perda da capacidade de compensação cerebral da diferença da aniseiconia.'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.44 ms /     7 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   879.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.68 ms /    29 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3548.24 ms /    29 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3636.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Perda da capacidade de compensação cerebral da diferença da aniseiconia.'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.42 ms /     7 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.56 ms /     7 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.30 ms /     7 runs   (  120.61 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.73 ms /    43 runs   (    0.58 ms per token,  1738.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5295.28 ms /    43 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5424.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.94 ms /   154 runs   (    0.58 ms per token,  1731.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19029.60 ms /   154 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 19503.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.42 ms /    79 runs   (    0.57 ms per token,  1739.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9668.12 ms /    79 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  9906.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   896.25 ms /     7 runs   (  128.04 ms per token,     7.81 tokens per second)\n",
      "llama_print_timings:       total time =   916.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 82: \n",
      "Language: english\n",
      "Question: \n",
      "The best alternative to including time-based prisms in eyeglass lenses for a -4.00 spherical diopters myopic patient with 4 prism diopters binocular diplopia is: a) Prescription of a lens with a neutral filter in one eye. b) Prescription of lenses with polarized filters in both eyes. c) Reduction of the distance between the optical centers of the lenses. d) Do not prescribe refraction in one eye to promote suppression of that eye.\n",
      "\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.07 ms /    38 runs   (    0.58 ms per token,  1721.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3043.64 ms /   124 tokens (   24.55 ms per token,    40.74 tokens per second)\n",
      "llama_print_timings:        eval time =  4529.42 ms /    37 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7687.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.60 ms /   154 runs   (    0.58 ms per token,  1738.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18954.76 ms /   154 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 19427.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.90 ms /    93 runs   (    0.60 ms per token,  1663.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11533.59 ms /    93 runs   (  124.02 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 11822.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.09 ms /    42 runs   (    0.60 ms per token,  1674.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5139.31 ms /    42 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5266.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.27 ms /    25 runs   (    0.57 ms per token,  1752.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3062.02 ms /    25 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3136.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.08 ms /    42 runs   (    0.57 ms per token,  1744.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5178.10 ms /    42 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5303.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.77 ms /    24 runs   (    0.57 ms per token,  1743.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2921.46 ms /    24 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2992.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.81 ms /    38 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4666.89 ms /    38 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4780.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.88 ms /    38 runs   (    0.58 ms per token,  1736.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4637.77 ms /    38 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4750.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.93 ms /    25 runs   (    0.60 ms per token,  1674.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3055.42 ms /    25 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3130.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A melhor alternativa à inclusão de prismas de base temporal nas lentes dos óculos para paciente míope de -4,00 dioptrias esfericas com diplopia binocular de 4 dioptrias prismaticas é: a) Prescrição de lente com filtro neutro em um dos olhos. b) Prescrição de lentes com filtros polarizados em ambos os olhos. c) Redução da distância entre os centros ópticos das lentes. d) Não prescrever a refração em um dos olhos para promover a supressão deste olho.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.76 ms /     7 runs   (    0.68 ms per token,  1469.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3047.45 ms /   152 tokens (   20.05 ms per token,    49.88 tokens per second)\n",
      "llama_print_timings:        eval time =   734.59 ms /     6 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3805.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.56 ms /     7 runs   (    0.79 ms per token,  1258.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.37 ms /     7 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   872.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    69.56 ms /   115 runs   (    0.60 ms per token,  1653.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14128.60 ms /   115 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 14497.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.86 ms /    26 runs   (    0.57 ms per token,  1749.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3253.74 ms /    26 runs   (  125.14 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  3330.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1765.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.83 ms /     7 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.32 ms /     7 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.01 ms /    26 runs   (    0.58 ms per token,  1731.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3192.14 ms /    26 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3269.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.43 ms /    48 runs   (    0.61 ms per token,  1631.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5946.94 ms /    48 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6098.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.70 ms /     7 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   886.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 83: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the conditions below is most typically associated with finding a \"partially empty\" sella turcica on magnetic resonance imaging? a) Optic nerve glioma. b) Pituitary macroadenoma. c) Cerebral pseudotumor. d) Tolosa-Hunt syndrome.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.92 ms /    26 runs   (    0.57 ms per token,  1742.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3182.01 ms /    26 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3260.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.82 ms /    44 runs   (    0.59 ms per token,  1704.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1838.11 ms /    75 tokens (   24.51 ms per token,    40.80 tokens per second)\n",
      "llama_print_timings:        eval time =  5292.82 ms /    43 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7264.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.36 ms /    37 runs   (    0.58 ms per token,  1732.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4513.81 ms /    37 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4625.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.59 ms /    48 runs   (    0.57 ms per token,  1739.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5812.88 ms /    48 runs   (  121.10 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  5956.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.73 ms /    34 runs   (    0.58 ms per token,  1723.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4136.64 ms /    34 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4239.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    28 runs   (    0.58 ms per token,  1728.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3443.82 ms /    28 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3527.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.60 ms /    34 runs   (    0.58 ms per token,  1734.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4133.65 ms /    34 runs   (  121.58 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4235.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.05 ms /    36 runs   (    0.58 ms per token,  1710.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4457.13 ms /    36 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4566.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3280.72 ms /    27 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3361.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.14 ms /    33 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4143.44 ms /    33 runs   (  125.56 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  4243.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.33 ms /    28 runs   (    0.58 ms per token,  1714.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3455.31 ms /    28 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3538.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das condições abaixo está mais tipicamente associada ao achado de sela túrcica \"parcialmente vazia\" em um exame de imagem por ressonância nuclear magnética? a) Glioma de nervo óptico. b) Macroadenoma de hipófise. c) Pseudotumor cerebral. d) Síndrome de Tolosa-Hunt.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.25 ms /     7 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1939.63 ms /   101 tokens (   19.20 ms per token,    52.07 tokens per second)\n",
      "llama_print_timings:        eval time =   738.32 ms /     6 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2699.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.91 ms /    17 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2094.82 ms /    17 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2145.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.71 ms /    27 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3372.70 ms /    27 runs   (  124.91 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3454.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.80 ms /     7 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.79 ms /    17 runs   (    0.58 ms per token,  1736.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2072.87 ms /    17 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2123.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.40 ms /     7 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.72 ms /    17 runs   (    0.57 ms per token,  1749.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2053.43 ms /    17 runs   (  120.79 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2103.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.12 ms /     7 runs   (  121.73 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.31 ms /     7 runs   (    0.76 ms per token,  1318.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.09 ms /     7 runs   (  120.58 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   867.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    25 runs   (    0.62 ms per token,  1603.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3109.84 ms /    25 runs   (  124.39 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3187.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 84: \n",
      "Language: english\n",
      "Question: \n",
      "About fourth cranial nerve palsy, it is correct to state: a) Associated facial nerve palsy is often present. b) In the examination of ocular motricity, there is an increase in the excursion of the paralyzed eye when looking down. c) The patient evolves with vertical diplopia, vicious head position and hypotropia of the paralyzed eye. d) Nuclear or infranuclear involvement of the IV nerve may have the same clinical picture.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.07 ms /    17 runs   (    0.59 ms per token,  1688.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2481.22 ms /   124 tokens (   20.01 ms per token,    49.98 tokens per second)\n",
      "llama_print_timings:        eval time =  1994.65 ms /    16 runs   (  124.67 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  4527.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.54 ms /    25 runs   (    0.58 ms per token,  1719.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3054.04 ms /    25 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3130.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.12 ms /    61 runs   (    0.58 ms per token,  1736.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7555.36 ms /    61 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  7741.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1738.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2116.02 ms /    17 runs   (  124.47 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  2166.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3492.16 ms /    28 runs   (  124.72 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3577.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.39 ms /    49 runs   (    0.58 ms per token,  1726.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5985.66 ms /    49 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6134.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.83 ms /    17 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2080.35 ms /    17 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2131.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.41 ms /    49 runs   (    0.58 ms per token,  1724.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5979.71 ms /    49 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6129.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.78 ms /     7 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.45 ms /    44 runs   (    0.58 ms per token,  1728.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5468.65 ms /    44 runs   (  124.29 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  5603.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a paralisia do IV nervo craniano, é correto afirmar: a) Frequentemente, apresenta-se paralisia de nervo facial associada. b) No exame da motricidade ocular, existe um aumento da excursão do olho paralisado no olhar para baixo. c) O paciente evolui com diplopia vertical, posição viciosa de cabeça e hipotropia do olho paralisado. d) O acometimento nuclear ou infranuclear do IV nervo pode ter o mesmo quadro clínico.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    24 runs   (    0.60 ms per token,  1653.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2826.11 ms /   141 tokens (   20.04 ms per token,    49.89 tokens per second)\n",
      "llama_print_timings:        eval time =  2827.70 ms /    23 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5729.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   910.47 ms /     7 runs   (  130.07 ms per token,     7.69 tokens per second)\n",
      "llama_print_timings:       total time =   931.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1713.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.66 ms /     7 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.32 ms /     7 runs   (  124.19 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   889.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.77 ms /     7 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.73 ms /     7 runs   (  125.10 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   896.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1708.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   912.65 ms /     7 runs   (  130.38 ms per token,     7.67 tokens per second)\n",
      "llama_print_timings:       total time =   933.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.92 ms /     7 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   887.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.79 ms /     7 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.51 ms /     7 runs   (  124.22 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   889.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 85: \n",
      "Language: english\n",
      "Question: \n",
      "Eight-year-old child with subacute bilateral vertical gaze palsy, papilledema and light-near dissociation. It is correct to state: a) Mesencephalic lesions, such as tumors, should be investigated. b) This is a classic case of vertically transmitted neurological syphilis. c) It is most likely a lesion of the optic chiasm. d) Frontal lobe lesion is the main diagnostic hypothesis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.11 ms /    24 runs   (    0.59 ms per token,  1701.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2402.98 ms /   116 tokens (   20.72 ms per token,    48.27 tokens per second)\n",
      "llama_print_timings:        eval time =  2844.65 ms /    23 runs   (  123.68 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5320.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.53 ms /    91 runs   (    0.58 ms per token,  1732.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11186.87 ms /    91 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 11462.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.94 ms /    27 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3384.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   144.92 ms /   251 runs   (    0.58 ms per token,  1732.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 30953.23 ms /   251 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 31749.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.02 ms /    40 runs   (    0.58 ms per token,  1737.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4985.33 ms /    40 runs   (  124.63 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  5105.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.94 ms /     7 runs   (  123.99 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.80 ms /    43 runs   (    0.58 ms per token,  1733.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5376.82 ms /    43 runs   (  125.04 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  5506.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1741.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.09 ms /     7 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.22 ms /    23 runs   (    0.57 ms per token,  1740.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2889.64 ms /    23 runs   (  125.64 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  2957.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.83 ms /    24 runs   (    0.58 ms per token,  1735.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2929.94 ms /    24 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3001.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Criança de oito anos de idade com quadro bilateral subagudo de paralisia do olhar vertical, papiledema e dissociação luz-perto. É correto afirmar: a) Lesões mesencefálicas, como tumores, devem ser investigadas. b) Trata-se de um caso clássico de sífilis neurológica de transmissão vertical. c) Trata-se, mais provavelmente, de uma lesão de quiasma óptico. d) Lesão do lobo frontal é a principal hipótese diagnóstica.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.29 ms /     7 runs   (    0.61 ms per token,  1631.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3077.18 ms /   145 tokens (   21.22 ms per token,    47.12 tokens per second)\n",
      "llama_print_timings:        eval time =   728.24 ms /     6 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3826.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.35 ms /    29 runs   (    0.60 ms per token,  1671.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3557.07 ms /    29 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3645.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.86 ms /     7 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1663.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.76 ms /     7 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1693.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.83 ms /     7 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   874.53 ms /     7 runs   (  124.93 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =   895.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1715.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.47 ms /     7 runs   (  121.92 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1718.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   908.07 ms /     7 runs   (  129.72 ms per token,     7.71 tokens per second)\n",
      "llama_print_timings:       total time =   929.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.26 ms /     7 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.71 ms /    29 runs   (    0.58 ms per token,  1735.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3519.64 ms /    29 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3607.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 86: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "A 35-year-old female patient, after sensory loss in the right upper limb, evolved with diplopia. Among the diagnostic hypotheses, the most likely is: a) Pituitary adenoma. b) Multiple sclerosis. c) Idiopathic intracranial hypertension. d) Meningioma of the optic nerve.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1661.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1664.97 ms /    94 tokens (   17.71 ms per token,    56.46 tokens per second)\n",
      "llama_print_timings:        eval time =   727.99 ms /     6 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2413.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.25 ms /     9 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1081.34 ms /     9 runs   (  120.15 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  1108.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.88 ms /     7 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.18 ms /    20 runs   (    0.61 ms per token,  1641.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2442.52 ms /    20 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2503.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.37 ms /    11 runs   (    0.58 ms per token,  1725.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1341.00 ms /    11 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1373.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3417.51 ms /    28 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3500.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.33 ms /     7 runs   (  119.76 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =   859.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.43 ms /    20 runs   (    0.57 ms per token,  1749.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2460.78 ms /    20 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2520.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1740.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2051.56 ms /    17 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2100.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3400.93 ms /    28 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3484.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente de 35 anos, sexo feminino, após quadro de perda sensitiva no membro superior direito, evoluiu com diplopia. Dentre as hipóteses diagnósticas a mais provável é: a) Adenoma hipofisário. b) Esclerose múltipla. c) Hipertensão intracraniana idiopática. d) Meningeoma do nervo óptico.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.12 ms /    24 runs   (    0.59 ms per token,  1700.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2729.97 ms /   107 tokens (   25.51 ms per token,    39.19 tokens per second)\n",
      "llama_print_timings:        eval time =  2863.54 ms /    23 runs   (  124.50 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  5666.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.00 ms /     7 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   877.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1739.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3049.48 ms /    25 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3123.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.30 ms /    18 runs   (    0.57 ms per token,  1747.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2188.93 ms /    18 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2242.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Meningeoma do nervo óptico.'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.87 ms /     7 runs   (  119.84 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'd) Meningeoma do nervo óptico.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.64 ms /    36 runs   (    0.57 ms per token,  1744.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4402.40 ms /    36 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4509.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.94 ms /     7 runs   (  119.85 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.62 ms /     7 runs   (  120.52 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.12 ms /     7 runs   (  120.59 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   835.67 ms /     7 runs   (  119.38 ms per token,     8.38 tokens per second)\n",
      "llama_print_timings:       total time =   856.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 87: \n",
      "Language: english\n",
      "Question: \n",
      "The patient has unilateral paralysis of the third, fourth and sixth cranial nerves. It is correct to state: a) When painless, it is called Tolosa-Hunt syndrome. b) Involvement of the olfactory nerve suggests involvement of the cavernous sinus. c) One way to find out if there is a lesion in the cavernous sinus is to test the trigeminal sensitivity. d) If the vision is normal, but the three branches of the trigeminal are affected, possibly the lesion is restricted to the apex of the orbit.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.59 ms /    56 runs   (    0.58 ms per token,  1718.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2350.08 ms /   139 tokens (   16.91 ms per token,    59.15 tokens per second)\n",
      "llama_print_timings:        eval time =  6764.86 ms /    55 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  9285.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.43 ms /     7 runs   (    0.63 ms per token,  1581.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.73 ms /     7 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.02 ms /    66 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8149.62 ms /    66 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8349.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.12 ms /   139 runs   (    0.58 ms per token,  1734.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17096.62 ms /   139 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 17528.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.71 ms /   135 runs   (    0.58 ms per token,  1737.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16537.58 ms /   135 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 16953.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'd) If the vision is normal, but the three branches of the trigeminal are affected, possibly the lesion is restricted to the apex of the orbit.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   131.06 ms /   228 runs   (    0.57 ms per token,  1739.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28060.21 ms /   228 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 28781.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.17 ms /    56 runs   (    0.57 ms per token,  1740.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6851.73 ms /    56 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7017.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.37 ms /    32 runs   (    0.57 ms per token,  1742.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3903.40 ms /    32 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3998.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.02 ms /    61 runs   (    0.57 ms per token,  1741.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7491.35 ms /    61 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7676.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   131.94 ms /   228 runs   (    0.58 ms per token,  1728.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28333.74 ms /   228 runs   (  124.27 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 29057.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente apresenta paralisia unilateral do terceiro, quarto e sexto nervos cranianos. É correto afirmar: a) Quando indolor, denomina-se síndrome de Tolosa-Hunt. b) O envolvimento do nervo olfatório sugere acometimento do seio cavernoso. c) Uma maneira de localizar se há lesão no seio cavernoso é testar a sensibilidade trigeminal. d) Se a visão está normal, mas os três ramos do trigêmeo estiverem afetados, possivelmente a lesão está restrita ao ápice da órbita.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.23 ms /     7 runs   (    0.60 ms per token,  1654.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3539.78 ms /   165 tokens (   21.45 ms per token,    46.61 tokens per second)\n",
      "llama_print_timings:        eval time =   751.42 ms /     6 runs   (  125.24 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  4312.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1698.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.72 ms /     7 runs   (  125.10 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   897.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.16 ms /     9 runs   (    0.57 ms per token,  1742.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1088.20 ms /     9 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1115.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.64 ms /    27 runs   (    0.58 ms per token,  1726.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3293.07 ms /    27 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3373.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.67 ms /     7 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.24 ms /     7 runs   (    0.61 ms per token,  1652.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.66 ms /     7 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   877.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.66 ms /     7 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   875.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n",
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.70 ms /     7 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.71 ms /     7 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.00 ms /     7 runs   (  120.57 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   863.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 88: \n",
      "Language: english\n",
      "Question: \n",
      "After bariatric surgery, the patient evolved with low serum levels of vitamin B12. In this case, it is correct to state that: a) Dyschromatopsia is an atypical finding. b) Visual improvement is not possible even with vitamin replacement. c) Peripheral scotomas and preservation of the foveal area are typical in perimetry. d) Pernicious anemia is associated with bilateral, symmetrical, painless and progressive visual loss.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.53 ms /    48 runs   (    0.59 ms per token,  1682.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2270.57 ms /   118 tokens (   19.24 ms per token,    51.97 tokens per second)\n",
      "llama_print_timings:        eval time =  5779.16 ms /    47 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8195.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.83 ms /    24 runs   (    0.58 ms per token,  1735.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2948.16 ms /    24 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3018.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.54 ms /     7 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.21 ms /    28 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3447.31 ms /    28 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3530.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.32 ms /    28 runs   (    0.58 ms per token,  1716.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3445.71 ms /    28 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3531.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.57 ms /   131 runs   (    0.58 ms per token,  1733.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16135.91 ms /   131 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 16550.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.54 ms /    49 runs   (    0.62 ms per token,  1604.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6001.36 ms /    49 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6158.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.03 ms /   154 runs   (    0.59 ms per token,  1691.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18836.36 ms /   154 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 19318.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.90 ms /    24 runs   (    0.58 ms per token,  1726.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2931.83 ms /    24 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3002.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.15 ms /    49 runs   (    0.57 ms per token,  1740.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5948.69 ms /    49 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  6096.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Após cirurgia bariátrica, paciente evoluiu com níveis séricos baixos de vitamina B12. Nesse caso, é correto afirmar que: a) A discromatopsia é um achado atípico. b) Não é possível a melhora visual mesmo com a reposição da vitamina. c) Escotomas periféricos e preservação da área foveal são típicos nas campimetrias. d) A anemia perniciosa está associada a perda visual bilateral, simétrica, indolor e progressiva.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.16 ms /     7 runs   (    0.59 ms per token,  1684.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2673.23 ms /   147 tokens (   18.19 ms per token,    54.99 tokens per second)\n",
      "llama_print_timings:        eval time =   748.42 ms /     6 runs   (  124.74 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3443.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1716.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.24 ms /     7 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.50 ms /     7 runs   (  120.93 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1720.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.46 ms /     7 runs   (  120.49 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1725.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.70 ms /     7 runs   (  120.39 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   863.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   129.13 ms /   220 runs   (    0.59 ms per token,  1703.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27155.37 ms /   220 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 27861.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.35 ms /     7 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.48 ms /     7 runs   (  120.78 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.23 ms /     7 runs   (  120.75 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   867.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.53 ms /     7 runs   (  121.08 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   869.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 89: \n",
      "Language: english\n",
      "Question: \n",
      "After a vascular accident affecting the lateral portion of the cervical spinal cord (Wallenberg syndrome), the patient developed anisocoria. It is correct to state that: a) Anisocoria will worsen in the dark. b) There will be worsening of anisocoria in light. c) Will be unresponsive to the instillation of sympathomimetic eye drops. d) Involvement of the stellate ganglion is the most likely diagnosis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.77 ms /   101 runs   (    0.58 ms per token,  1718.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2643.56 ms /   118 tokens (   22.40 ms per token,    44.64 tokens per second)\n",
      "llama_print_timings:        eval time = 12280.84 ms /   100 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 15242.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.31 ms /     7 runs   (  120.19 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1722.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3034.56 ms /    25 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3110.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.46 ms /    25 runs   (    0.58 ms per token,  1729.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3045.76 ms /    25 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3121.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.63 ms /   147 runs   (    0.58 ms per token,  1736.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18027.79 ms /   147 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 18481.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   114.13 ms /   197 runs   (    0.58 ms per token,  1726.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24309.51 ms /   197 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 24925.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.90 ms /    24 runs   (    0.58 ms per token,  1726.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2931.49 ms /    24 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3002.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    95.60 ms /   166 runs   (    0.58 ms per token,  1736.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20406.95 ms /   166 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 20926.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.07 ms /   127 runs   (    0.58 ms per token,  1738.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15653.08 ms /   127 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16055.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.68 ms /   102 runs   (    0.58 ms per token,  1738.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12620.41 ms /   102 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 12935.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Após acidente vascular acometendo a porção lateral da medula cervical (síndrome de Wallenberg), o paciente desenvolveu anisocoria. É correto afirmar que: a) Haverá piora da anisocoria no escuro. b) Haverá piora da anisocoria no claro. c) Será não responsivo à instilação de colírios simpatomiméticos. d) O acometimento do gânglio estrelado é o diagnóstico mais provável.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.28 ms /     7 runs   (    0.61 ms per token,  1637.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2906.14 ms /   137 tokens (   21.21 ms per token,    47.14 tokens per second)\n",
      "llama_print_timings:        eval time =   732.88 ms /     6 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3660.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1700.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.20 ms /     7 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1694.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.01 ms /     7 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   874.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1706.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.58 ms /     7 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.28 ms /   134 runs   (    0.58 ms per token,  1733.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16519.53 ms /   134 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16934.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   900.48 ms /     7 runs   (  128.64 ms per token,     7.77 tokens per second)\n",
      "llama_print_timings:       total time =   920.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1725.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.54 ms /     7 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.37 ms /     7 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   881.80 ms /     7 runs   (  125.97 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =   902.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   833.42 ms /     7 runs   (  119.06 ms per token,     8.40 tokens per second)\n",
      "llama_print_timings:       total time =   854.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 90: \n",
      "Language: english\n",
      "Question: \n",
      "A patient arrives at the emergency room complaining of pain, reduced vision and hyperemia in the right eye for two days. On examination, he has a visual acuity of 0.1, anterior chamber reaction two crosses out of four, granulomatous keratic precipitates and a white-yellowish lesion with poorly defined limits on the periphery of the retina in the right eye. The left eye has no changes. What is the most appropriate initial course of action? a) Eye ultrasound. b) Use of topical corticosteroids and cycloplegic. c) Use of oral corticosteroids. d) Serology for toxoplasmosis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.73 ms /   161 runs   (    0.58 ms per token,  1717.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3378.33 ms /   164 tokens (   20.60 ms per token,    48.54 tokens per second)\n",
      "llama_print_timings:        eval time = 19756.47 ms /   160 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 23637.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.12 ms /     7 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1750.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2951.24 ms /    24 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3022.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   108.14 ms /   188 runs   (    0.58 ms per token,  1738.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23117.15 ms /   188 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 23703.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   117.58 ms /   203 runs   (    0.58 ms per token,  1726.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25075.50 ms /   203 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 25715.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   104.79 ms /   181 runs   (    0.58 ms per token,  1727.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22362.71 ms /   181 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 22934.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   115.59 ms /   198 runs   (    0.58 ms per token,  1712.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24485.10 ms /   198 runs   (  123.66 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 25107.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.54 ms /   203 runs   (    0.58 ms per token,  1712.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25061.74 ms /   203 runs   (  123.46 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 25698.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.93 ms /   197 runs   (    0.58 ms per token,  1729.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24222.94 ms /   197 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 24842.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   117.30 ms /   203 runs   (    0.58 ms per token,  1730.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24932.49 ms /   203 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 25580.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente chega ao pronto-socorro com queixa de dor, redução da visão e hiperemia do olho direito há dois dias. Ao exame, apresenta acuidade visual 0,1, reação de câmara anterior duas cruzes em quatro, precipitados ceráticos granulomatosos e lesão branco-amarelada de limites pouco definidos na periferia da retina no olho direito. O olho esquerdo não tem alterações. Qual a conduta inicial mais apropriada? a) Ultrassonografia ocular. b) Uso de corticoide e cicloplégico tópicos. c) Uso de corticoide oral. d) Sorologia para toxoplasmose.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.20 ms /     7 runs   (    0.60 ms per token,  1666.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3745.35 ms /   188 tokens (   19.92 ms per token,    50.20 tokens per second)\n",
      "llama_print_timings:        eval time =   733.03 ms /     6 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4499.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1707.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.53 ms /     7 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   884.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.17 ms /     7 runs   (    0.60 ms per token,  1679.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.16 ms /     7 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.53 ms /     7 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1708.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.09 ms /     7 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.96 ms /     7 runs   (  123.99 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   889.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    74.00 ms /   128 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15871.09 ms /   128 runs   (  123.99 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 16263.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.12 ms /     7 runs   (  120.59 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.05 ms /     7 runs   (  120.44 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.33 ms /    11 runs   (    0.58 ms per token,  1736.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1344.36 ms /    11 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  1376.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 91: \n",
      "Language: english\n",
      "Question: \n",
      "An 8-year-old patient with a diagnosis of juvenile idiopathic arthritis, without other comorbidities, still untreated, presents with recurrent anterior uveitis associated with posterior synechiae, band keratopathy and cataract. What is the most appropriate conduct at this time among the alternatives below? a) Facectomy with acrylic intraocular lens implantation. b) Use of systemic immunomodulator. c) Use of oral corticosteroids. d) Use of topical EDTA.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.22 ms /    36 runs   (    0.59 ms per token,  1696.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3114.22 ms /   136 tokens (   22.90 ms per token,    43.67 tokens per second)\n",
      "llama_print_timings:        eval time =  4290.04 ms /    35 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  7514.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   133.59 ms /   231 runs   (    0.58 ms per token,  1729.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28490.44 ms /   231 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 29222.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   133.44 ms /   231 runs   (    0.58 ms per token,  1731.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28476.44 ms /   231 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 29207.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.57 ms /   118 runs   (    0.57 ms per token,  1746.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14587.26 ms /   118 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 14947.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.75 ms /   185 runs   (    0.58 ms per token,  1733.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22731.50 ms /   185 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 23307.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.35 ms /   152 runs   (    0.58 ms per token,  1720.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18737.04 ms /   152 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 19208.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   129.82 ms /   224 runs   (    0.58 ms per token,  1725.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27605.30 ms /   224 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 28315.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.91 ms /   138 runs   (    0.58 ms per token,  1727.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17084.01 ms /   138 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 17507.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.16 ms /    35 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4260.39 ms /    35 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4365.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    94.78 ms /   163 runs   (    0.58 ms per token,  1719.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20106.43 ms /   163 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 20612.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente de 8 anos com diagnóstico de artrite juvenil idiopática, sem outras comorbidades, ainda sem tratamento, apresenta quadro recidivante de uveíte anterior associada a sinéquias posteriores, ceratopatia em faixa e catarata. Qual conduta mais apropriada neste momento dentre as alternativas abaixo? a) Facectomia com implante de lente intraocular acrílica. b) Uso de imunomodulador sistêmico. c) Uso de corticoide oral. d) Uso de EDTA tópico.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1660.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3179.95 ms /   152 tokens (   20.92 ms per token,    47.80 tokens per second)\n",
      "llama_print_timings:        eval time =   736.96 ms /     6 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3937.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.19 ms /     7 runs   (    0.60 ms per token,  1672.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.20 ms /     7 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   887.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.72 ms /     8 runs   (    0.59 ms per token,  1694.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1040.72 ms /     8 runs   (  130.09 ms per token,     7.69 tokens per second)\n",
      "llama_print_timings:       total time =  1064.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.17 ms /     7 runs   (    0.60 ms per token,  1677.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.37 ms /     7 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.58 ms /     7 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.75 ms /     7 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.66 ms /    27 runs   (    0.58 ms per token,  1724.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3339.52 ms /    27 runs   (  123.69 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3419.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.90 ms /     7 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   870.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.36 ms /     7 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   882.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 92: \n",
      "Language: english\n",
      "Question: \n",
      "What is the immunosuppressant of choice for children with anterior uveitis secondary to juvenile idiopathic arthritis? a) Azathioprine. b) Tacrolimus. c) Cyclophosphamide. d) Methotrexate.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    94.37 ms /   164 runs   (    0.58 ms per token,  1737.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20148.30 ms /   164 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 20658.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.06 ms /    24 runs   (    0.59 ms per token,  1706.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1714.74 ms /    71 tokens (   24.15 ms per token,    41.41 tokens per second)\n",
      "llama_print_timings:        eval time =  2807.93 ms /    23 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4595.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.08 ms /    24 runs   (    0.59 ms per token,  1704.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2906.09 ms /    24 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2978.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1727.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2925.94 ms /    24 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2996.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.54 ms /    32 runs   (    0.58 ms per token,  1725.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3891.91 ms /    32 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3987.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.87 ms /    31 runs   (    0.58 ms per token,  1735.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3749.88 ms /    31 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3841.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.91 ms /     7 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   863.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.17 ms /     9 runs   (    0.57 ms per token,  1739.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1105.20 ms /     9 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  1131.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.14 ms /    42 runs   (    0.57 ms per token,  1740.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5103.21 ms /    42 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5228.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.89 ms /    38 runs   (    0.58 ms per token,  1735.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4681.63 ms /    38 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4796.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.87 ms /    31 runs   (    0.58 ms per token,  1734.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3751.22 ms /    31 runs   (  121.01 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3843.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual é o imunossupressor de escolha para crianças com uveíte anterior secundária à artrite juvenil idiopática? a) Azatioprina. b) Tacrolimus. c) Ciclofosfamida. d) Metotrexato.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.18 ms /     7 runs   (    0.60 ms per token,  1675.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1742.32 ms /    75 tokens (   23.23 ms per token,    43.05 tokens per second)\n",
      "llama_print_timings:        eval time =   737.56 ms /     6 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2501.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.21 ms /    39 runs   (    0.57 ms per token,  1756.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4750.17 ms /    39 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4866.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.72 ms /    36 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4396.12 ms /    36 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4501.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.36 ms /     7 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   884.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.93 ms /     7 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1702.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.34 ms /     7 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.17 ms /    42 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5101.65 ms /    42 runs   (  121.47 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5226.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.91 ms /     7 runs   (  120.70 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   865.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.17 ms /     9 runs   (    0.57 ms per token,  1740.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1083.15 ms /     9 runs   (  120.35 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  1109.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.66 ms /     7 runs   (    0.67 ms per token,  1501.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.86 ms /     7 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   882.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 93: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Among the alternatives below, which exam is the most appropriate for the follow-up of a patient with panuveitis secondary to Behçet's disease, using cyclosporine? a) Creatinine. b) Ferritin. c) Fasting blood glucose. d) HLA-B51.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.26 ms /   163 runs   (    0.57 ms per token,  1747.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1823.25 ms /    78 tokens (   23.38 ms per token,    42.78 tokens per second)\n",
      "llama_print_timings:        eval time = 19764.05 ms /   162 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 22093.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} HLA-B51.'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.03 ms /    78 runs   (    0.58 ms per token,  1732.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9504.65 ms /    78 runs   (  121.85 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  9739.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.41 ms /    86 runs   (    0.57 ms per token,  1740.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10468.46 ms /    86 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time = 10728.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.63 ms /    27 runs   (    0.58 ms per token,  1727.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3294.20 ms /    27 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3375.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) HLA-B51'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.02 ms /    24 runs   (    0.58 ms per token,  1712.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2929.84 ms /    24 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3002.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) HLA-B51'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.78 ms /    27 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3384.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) HLA-B51'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.16 ms /    84 runs   (    0.57 ms per token,  1744.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10308.83 ms /    84 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10563.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) HLA-B51'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.45 ms /    32 runs   (    0.58 ms per token,  1734.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3877.52 ms /    32 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3972.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} HLA-B51.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.29 ms /    70 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8525.15 ms /    70 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  8735.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.74 ms /    80 runs   (    0.57 ms per token,  1749.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9770.34 ms /    80 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 10012.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Dentre as alternativas abaixo, qual exame é o mais apropriado para o seguimento de um paciente com panuveite secundária à doença de Behçet, em uso de ciclosporina? a) Creatinina. b) Ferritina. c) Glicemia de jejum. d) HLA-B51.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.80 ms /    85 runs   (    0.59 ms per token,  1706.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1917.59 ms /    89 tokens (   21.55 ms per token,    46.41 tokens per second)\n",
      "llama_print_timings:        eval time = 10311.97 ms /    84 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12491.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.65 ms /     7 runs   (  120.52 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.71 ms /    29 runs   (    0.58 ms per token,  1736.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3498.38 ms /    29 runs   (  120.63 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3584.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.51 ms /    32 runs   (    0.58 ms per token,  1729.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3888.09 ms /    32 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3983.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'd) HLA-B51'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.87 ms /    24 runs   (    0.58 ms per token,  1730.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2973.39 ms /    24 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3045.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.93 ms /    12 runs   (    0.58 ms per token,  1732.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1451.86 ms /    12 runs   (  120.99 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1487.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.57 ms /    20 runs   (    0.58 ms per token,  1728.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2418.28 ms /    20 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2479.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.97 ms /    75 runs   (    0.57 ms per token,  1745.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9265.58 ms /    75 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  9492.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.43 ms /    25 runs   (    0.58 ms per token,  1732.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3041.41 ms /    25 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3115.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 94: \n",
      "Language: english\n",
      "Question: \n",
      "A 25-year-old female patient reported reduced visual acuity for a few days, preceded by fever, headache and malaise. On examination, she has a two-cross anterior chamber reaction, vitreitis, a four-cross, and retinal detachment at the posterior pole, compromising the macula, without holes in both eyes. What is the most appropriate treatment for retinal detachment? a) Posterior vitrectomy with SF6 infusion and head position. b) oral corticosteroid. c) Pneumatic retinopexy. d) Scleral introflexion with macular explant.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.91 ms /    84 runs   (    0.58 ms per token,  1717.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10300.66 ms /    84 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10553.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1692.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4092.01 ms /   148 tokens (   27.65 ms per token,    36.17 tokens per second)\n",
      "llama_print_timings:        eval time =   735.46 ms /     6 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4848.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.71 ms /     7 runs   (  124.39 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.16 ms /     9 runs   (    0.57 ms per token,  1744.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1107.62 ms /     9 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  1134.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   122.39 ms /   213 runs   (    0.57 ms per token,  1740.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26332.90 ms /   213 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 26997.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.24 ms /    28 runs   (    0.58 ms per token,  1724.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3468.26 ms /    28 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3552.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1692.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.84 ms /     7 runs   (  124.55 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   893.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.12 ms /   144 runs   (    0.58 ms per token,  1732.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17694.56 ms /   144 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 18148.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   110.69 ms /   190 runs   (    0.58 ms per token,  1716.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23355.42 ms /   190 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 23962.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.01 ms /     7 runs   (  120.29 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente de 25 anos, sexo feminino, refere redução da acuidade visual há poucos dias, precedida de febre, cefaleia e mal-estar. Ao exame, apresenta reação de câmara anterior duas cruzes, vitreíte uma cruz em quatro e descolamento da retina no polo posterior comprometendo a mácula, sem roturas em ambos os olhos. Qual o tratamento mais apropriado para o descolamento de retina? a) Vitrectomia posterior com infusão de SF6 e posição de cabeça. b) Corticoide oral. c) Retinopexia pneumática. d) Introflexão escleral com explante macular.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1735.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3309.01 ms /    27 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3388.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1709.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3290.76 ms /   180 tokens (   18.28 ms per token,    54.70 tokens per second)\n",
      "llama_print_timings:        eval time =   727.16 ms /     6 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4039.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1710.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.88 ms /     7 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.74 ms /     7 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.16 ms /     7 runs   (    0.59 ms per token,  1681.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.36 ms /     7 runs   (  125.05 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =   896.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1714.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.33 ms /     7 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.28 ms /     7 runs   (    0.61 ms per token,  1637.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   882.07 ms /     7 runs   (  126.01 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =   903.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.45 ms /     7 runs   (  121.92 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.40 ms /     7 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.58 ms /     7 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.92 ms /     7 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   879.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 95: \n",
      "Language: english\n",
      "Question: \n",
      "Patient with a history of open ocular trauma in the right eye one year ago, presents anterior chamber reaction to a cross, iris color change, mild vitreous clouding and glued retina. The electroretinogram shows extinguished responses in the photopic and scotopic phases. The left eye shows no alterations. What is the most likely cause? a) Bacterial endophthalmitis. b) Fungal endophthalmitis. c) Sympathetic ophthalmia. d) Retention of metallic intraocular foreign body.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   109.32 ms /   189 runs   (    0.58 ms per token,  1728.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3100.64 ms /   140 tokens (   22.15 ms per token,    45.15 tokens per second)\n",
      "llama_print_timings:        eval time = 23147.84 ms /   188 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 26846.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   131.10 ms /   227 runs   (    0.58 ms per token,  1731.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27982.91 ms /   227 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 28704.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   103.06 ms /   178 runs   (    0.58 ms per token,  1727.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21929.45 ms /   178 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 22492.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.57 ms /    20 runs   (    0.58 ms per token,  1728.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2444.87 ms /    20 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2505.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.67 ms /    34 runs   (    0.58 ms per token,  1728.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4168.48 ms /    34 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4275.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.90 ms /   204 runs   (    0.58 ms per token,  1715.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25269.36 ms /   204 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 25912.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.16 ms /    40 runs   (    0.58 ms per token,  1727.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4906.40 ms /    40 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5026.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retention of metallic intraocular foreign body'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   129.07 ms /   222 runs   (    0.58 ms per token,  1720.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27422.93 ms /   222 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 28126.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'd} Retention of metallic intraocular foreign body.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.10 ms /    21 runs   (    0.58 ms per token,  1735.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2595.50 ms /    21 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  2657.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    94.63 ms /   164 runs   (    0.58 ms per token,  1732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20046.28 ms /   164 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 20556.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente com história de trauma ocular aberto no olho direito há um ano apresenta reação de câmara anterior uma cruz, alteração da cor da íris, turvação vítrea leve e retina colada. O eletrorretinograma apresenta respostas extintas nas fases fotópica e escotópica. O olho esquerdo não apresenta alterações. Qual a causa mais provável? a) Endoftalmite bacteriana. b) Endoftalmite fúngica. c) Oftalmia simpática. d) Retenção de corpo estranho intraocular metálico.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.14 ms /    24 runs   (    0.59 ms per token,  1696.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3208.10 ms /   161 tokens (   19.93 ms per token,    50.19 tokens per second)\n",
      "llama_print_timings:        eval time =  2846.71 ms /    23 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6129.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retenção de corpo estranho intraocular metálico'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.50 ms /    41 runs   (    0.60 ms per token,  1673.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5047.90 ms /    41 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5173.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retenção de corpo estranho intraocular metálico'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1732.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2914.40 ms /    24 runs   (  121.43 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2986.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retenção de corpo estranho intraocular metálico'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1736.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3112.02 ms /    25 runs   (  124.48 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3186.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retenção de corpo estranho intraocular metálico.'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1741.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2999.16 ms /    24 runs   (  124.97 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  3071.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retenção de corpo estranho intraocular metálico'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1738.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2967.97 ms /    24 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3039.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retenção de corpo estranho intraocular metálico'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1737.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3073.58 ms /    25 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3148.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retenção de corpo estranho intraocular metálico.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   104.07 ms /   178 runs   (    0.58 ms per token,  1710.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21969.33 ms /   178 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 22539.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retenção de corpo estranho intraocular metálico.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.61 ms /    41 runs   (    0.58 ms per token,  1736.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5029.50 ms /    41 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5153.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retenção de corpo estranho intraocular metálico'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.83 ms /    24 runs   (    0.58 ms per token,  1735.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.51 ms /    24 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3000.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retenção de corpo estranho intraocular metálico'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 96: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Among the alternatives below, which microorganism is associated with Eales disease? a) Bartonella henselae. b) Mycobacterium tuberculosis. c) Toxoplasma gondii. d) Epstein-Barr virus.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.94 ms /    17 runs   (    0.58 ms per token,  1710.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1374.18 ms /    67 tokens (   20.51 ms per token,    48.76 tokens per second)\n",
      "llama_print_timings:        eval time =  1925.78 ms /    16 runs   (  120.36 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  3351.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.74 ms /    27 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3259.03 ms /    27 runs   (  120.70 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3341.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.39 ms /    29 runs   (    0.60 ms per token,  1667.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3510.16 ms /    29 runs   (  121.04 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3599.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.04 ms /    35 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4272.50 ms /    35 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4377.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.48 ms /    20 runs   (    0.57 ms per token,  1742.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2404.38 ms /    20 runs   (  120.22 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  2464.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1764.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   835.36 ms /     7 runs   (  119.34 ms per token,     8.38 tokens per second)\n",
      "llama_print_timings:       total time =   855.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.96 ms /    28 runs   (    0.57 ms per token,  1754.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3448.30 ms /    28 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3532.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.25 ms /    37 runs   (    0.57 ms per token,  1741.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4504.03 ms /    37 runs   (  121.73 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4614.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.47 ms /    41 runs   (    0.57 ms per token,  1746.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4975.02 ms /    41 runs   (  121.34 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5097.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.19 ms /    27 runs   (    0.56 ms per token,  1777.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3294.52 ms /    27 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3373.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Dentre as alternativas abaixo, qual microorganismo está associado à doença de Eales? a)Bartonella henselae. b)Mycobacterium tuberculosis. c)Toxoplasma gondii. d) Vírus Epstein-Barr.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.23 ms /     7 runs   (    0.60 ms per token,  1656.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1820.61 ms /    76 tokens (   23.96 ms per token,    41.74 tokens per second)\n",
      "llama_print_timings:        eval time =   723.08 ms /     6 runs   (  120.51 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2564.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.50 ms /    28 runs   (    0.59 ms per token,  1696.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3413.33 ms /    28 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3498.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.82 ms /    29 runs   (    0.58 ms per token,  1724.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3555.00 ms /    29 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3641.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.19 ms /    28 runs   (    0.58 ms per token,  1729.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3392.16 ms /    28 runs   (  121.15 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3475.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    27 runs   (    0.58 ms per token,  1720.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3299.61 ms /    27 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3380.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.76 ms /    24 runs   (    0.57 ms per token,  1744.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2945.03 ms /    24 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3016.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.50 ms /     7 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.77 ms /    24 runs   (    0.57 ms per token,  1742.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2901.87 ms /    24 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2972.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.52 ms /    35 runs   (    0.59 ms per token,  1705.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4272.87 ms /    35 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4378.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.17 ms /    35 runs   (    0.58 ms per token,  1734.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4249.70 ms /    35 runs   (  121.42 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4354.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 97: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding ocular involvement in ankylosing spondylitis, it is correct to state: a) It is bilateral, not simultaneous, in most cases. b) The most characteristic picture corresponds to episodes of intermediate uveitis. c) Posterior synechiae of the iris is a rare complication. d) It is a granulomatous inflammatory process.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.97 ms /    74 runs   (    0.58 ms per token,  1722.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1606.42 ms /    93 tokens (   17.27 ms per token,    57.89 tokens per second)\n",
      "llama_print_timings:        eval time =  8936.35 ms /    73 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10772.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.83 ms /    73 runs   (    0.57 ms per token,  1745.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8948.15 ms /    73 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  9169.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.16 ms /    66 runs   (    0.58 ms per token,  1729.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8042.92 ms /    66 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  8242.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3373.63 ms /    28 runs   (  120.49 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  3457.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.82 ms /    17 runs   (    0.58 ms per token,  1730.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2139.58 ms /    17 runs   (  125.86 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =  2189.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.70 ms /    22 runs   (    0.58 ms per token,  1732.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2741.10 ms /    22 runs   (  124.60 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  2806.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.99 ms /     7 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1740.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2076.57 ms /    17 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2127.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.93 ms /    17 runs   (    0.58 ms per token,  1711.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2059.87 ms /    17 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2111.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.00 ms /    17 runs   (    0.59 ms per token,  1699.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2052.89 ms /    17 runs   (  120.76 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2103.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre o acometimento ocular na espondilite ancilosante, é correto afirmar: a) É bilateral, não simultâneo, na maioria dos casos. b) O quadro mais característico corresponde a episódios de uveíte intermediária. c) Sinéquia posterior da íris é complicação rara. d) Trata-se de processo inflamatório granulomatoso.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.20 ms /     7 runs   (    0.60 ms per token,  1667.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2772.35 ms /   111 tokens (   24.98 ms per token,    40.04 tokens per second)\n",
      "llama_print_timings:        eval time =   729.46 ms /     6 runs   (  121.58 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3522.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.01 ms /     7 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   873.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.79 ms /     7 runs   (    0.68 ms per token,  1460.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.53 ms /     7 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   878.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.01 ms /   129 runs   (    0.58 ms per token,  1719.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15885.78 ms /   129 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 16286.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.17 ms /     7 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.01 ms /     7 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.39 ms /     7 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   878.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.87 ms /     7 runs   (  121.12 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1717.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.75 ms /     7 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 98: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following findings, on optical coherence tomography, represents a greater risk of retinal pigment epithelium rupture in antiangiogenic treatment of neovascular membranes? a) Retinochoroidal anastomosis with retinal hemorrhage. b) Elevated detachment of the retinal pigment epithelium. c) Marked and diffuse increase in the thickness of the choroid and choriocapillaries. d) Large amount of subretinal fluid with few intraretinal cysts.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.88 ms /     7 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.70 ms /    25 runs   (    0.59 ms per token,  1700.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2253.48 ms /   137 tokens (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:        eval time =  2971.59 ms /    24 runs   (  123.82 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  5300.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.92 ms /    24 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2946.97 ms /    24 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3018.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1724.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3107.83 ms /    25 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3181.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1740.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3042.58 ms /    25 runs   (  121.70 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3116.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1733.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2921.94 ms /    24 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2992.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.65 ms /    93 runs   (    0.58 ms per token,  1733.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11459.47 ms /    93 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11740.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.08 ms /    90 runs   (    0.58 ms per token,  1728.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11022.51 ms /    90 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 11295.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    25 runs   (    0.58 ms per token,  1727.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3043.51 ms /    25 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3117.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.22 ms /     7 runs   (    0.60 ms per token,  1657.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.31 ms /     7 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   871.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual dos achados abaixo, ao exame de tomografia de coerência óptica, representa maior risco de ruptura do epitélio pigmentado da retina no tratamento com antiangiogênico de membranas neovasculares? a) Anastomose retinocoroidal com hemorragia retiniana. b) Descolamento elevado do epitélio pigmentado da retina. c) Aumento acentuado e difuso da espessura da coroide e coriocapilares. d) Grande quantidade de líquido subretiniano com poucos cistos intraretinianos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.61 ms /    25 runs   (    0.58 ms per token,  1711.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3045.76 ms /    25 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3120.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.20 ms /     7 runs   (    0.60 ms per token,  1667.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3335.09 ms /   163 tokens (   20.46 ms per token,    48.87 tokens per second)\n",
      "llama_print_timings:        eval time =   730.49 ms /     6 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4086.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.84 ms /    27 runs   (    0.59 ms per token,  1704.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3345.09 ms /    27 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3426.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    27 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3317.00 ms /    27 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3398.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3440.01 ms /    28 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3523.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.81 ms /     7 runs   (  120.69 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.66 ms /     7 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.53 ms /     7 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.35 ms /   118 runs   (    0.58 ms per token,  1726.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14602.76 ms /   118 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 14965.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.64 ms /     7 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 99: \n",
      "Language: english\n",
      "Question: \n",
      "The acute phase of some retinal diseases typically presents only with reversible glare of the ellipsoid zone on optical coherence tomography of the macula. Mark the alternative that best exemplifies one of these conditions. a) Paracentral acute medium maculopathy. b) Occlusion of the central retinal artery. c) Acute macular neuroretinopathy. d) Retinal venous occlusion.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.72 ms /    27 runs   (    0.58 ms per token,  1717.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3338.33 ms /    27 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3419.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.03 ms /    36 runs   (    0.58 ms per token,  1711.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1944.06 ms /   104 tokens (   18.69 ms per token,    53.50 tokens per second)\n",
      "llama_print_timings:        eval time =  4271.05 ms /    35 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6324.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.08 ms /    40 runs   (    0.58 ms per token,  1733.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4870.48 ms /    40 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4991.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.60 ms /    74 runs   (    0.58 ms per token,  1736.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9131.02 ms /    74 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  9354.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.50 ms /    46 runs   (    0.58 ms per token,  1735.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5605.65 ms /    46 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5744.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.28 ms /    39 runs   (    0.57 ms per token,  1750.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4788.45 ms /    39 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4904.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.36 ms /    48 runs   (    0.57 ms per token,  1754.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5872.49 ms /    48 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6014.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.96 ms /    40 runs   (    0.57 ms per token,  1741.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4944.11 ms /    40 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5062.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.14 ms /    47 runs   (    0.58 ms per token,  1731.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5859.34 ms /    47 runs   (  124.67 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  6000.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.56 ms /    41 runs   (    0.57 ms per token,  1740.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4977.46 ms /    41 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5100.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.39 ms /    48 runs   (    0.57 ms per token,  1752.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5888.53 ms /    48 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6032.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A fase aguda de algumas doenças da retina apresenta-se tipicamente, apenas, com apagamento reversível da zona elipsoide ao exame de tomografia de coerência óptica da mácula. Assinale a alternativa que melhor exemplifica uma destas condições. a) Maculopatia média aguda paracentral. b) Oclusão da artéria central da retina. c) Neurorretinopatia macular aguda. d) Oclusão venosa retiniana.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2512.80 ms /   127 tokens (   19.79 ms per token,    50.54 tokens per second)\n",
      "llama_print_timings:        eval time =   742.43 ms /     6 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3276.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.56 ms /    91 runs   (    0.58 ms per token,  1731.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11161.43 ms /    91 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 11440.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1765.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   922.44 ms /     7 runs   (  131.78 ms per token,     7.59 tokens per second)\n",
      "llama_print_timings:       total time =   943.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.55 ms /    40 runs   (    0.59 ms per token,  1698.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4871.83 ms /    40 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4992.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.87 ms /    38 runs   (    0.58 ms per token,  1737.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4646.67 ms /    38 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4760.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.36 ms /     7 runs   (  124.48 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   891.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.62 ms /    94 runs   (    0.58 ms per token,  1721.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11601.31 ms /    94 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 11887.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.05 ms /     9 runs   (    0.56 ms per token,  1782.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1084.81 ms /     9 runs   (  120.53 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  1110.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.09 ms /     7 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   874.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 100: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following retinal dystrophies is most typically associated with central macular cystoid spaces in a radial pattern? a) Choroideremia. b) Cone dystrophy. c) Fundus flavimaculatus. d) Congenital X-linked retinoschisis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.51 ms /     7 runs   (  120.22 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   861.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.54 ms /    33 runs   (    0.59 ms per token,  1688.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1650.16 ms /    73 tokens (   22.60 ms per token,    44.24 tokens per second)\n",
      "llama_print_timings:        eval time =  3959.86 ms /    32 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  5710.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.83 ms /    36 runs   (    0.58 ms per token,  1728.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4378.11 ms /    36 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4487.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.06 ms /     7 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   875.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.76 ms /    43 runs   (    0.58 ms per token,  1736.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5228.62 ms /    43 runs   (  121.60 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5359.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.18 ms /    35 runs   (    0.58 ms per token,  1734.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4268.22 ms /    35 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4373.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2903.57 ms /    24 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2975.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   840.49 ms /     7 runs   (  120.07 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =   861.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.64 ms /    15 runs   (    0.58 ms per token,  1735.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1818.36 ms /    15 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  1863.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.88 ms /    36 runs   (    0.58 ms per token,  1724.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4370.84 ms /    36 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4480.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.00 ms /    24 runs   (    0.58 ms per token,  1714.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2969.43 ms /    24 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3041.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das distrofias retinianas abaixo está mais tipicamente associada a espaços cistoides maculares centrais em padrão radial? a) Coroideremia. b) Distrofia de cones. c) Fundus flavimaculatus. d) Retinosquise congênita ligada ao X.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    27 runs   (    0.60 ms per token,  1678.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1475.93 ms /    85 tokens (   17.36 ms per token,    57.59 tokens per second)\n",
      "llama_print_timings:        eval time =  3147.97 ms /    26 runs   (  121.08 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4707.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.33 ms /    16 runs   (    0.58 ms per token,  1715.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1935.48 ms /    16 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1983.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.33 ms /    16 runs   (    0.58 ms per token,  1714.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1936.12 ms /    16 runs   (  121.01 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  1984.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1688.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.28 ms /     7 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.14 ms /     7 runs   (  120.59 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.22 ms /    16 runs   (    0.58 ms per token,  1735.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1931.61 ms /    16 runs   (  120.73 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  1978.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1723.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.86 ms /     7 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3278.27 ms /    27 runs   (  121.42 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3358.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.00 ms /    33 runs   (    0.58 ms per token,  1736.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3996.08 ms /    33 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4097.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 101: \n",
      "Language: english\n",
      "Question: \n",
      "Bilateral diffuse uveal melanocytic proliferation is best classified as: a) Paraneoplastic disorder. b) Severe presentation of choroidal melanoma. c) Variant of Vogt-Koyanagi-Harada syndrome. d) Disorder secondary to retinal detachment treatment.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.63 ms /    15 runs   (    0.58 ms per token,  1738.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1819.90 ms /    15 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  1864.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.40 ms /     7 runs   (    0.63 ms per token,  1589.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1894.28 ms /    83 tokens (   22.82 ms per token,    43.82 tokens per second)\n",
      "llama_print_timings:        eval time =   719.71 ms /     6 runs   (  119.95 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =  2635.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.62 ms /    42 runs   (    0.59 ms per token,  1705.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5141.90 ms /    42 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5271.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.38 ms /    25 runs   (    0.57 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3018.06 ms /    25 runs   (  120.72 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3093.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1724.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3419.49 ms /    28 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3504.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.16 ms /    63 runs   (    0.57 ms per token,  1742.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7649.43 ms /    63 runs   (  121.42 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  7838.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1733.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3031.62 ms /    25 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3105.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.30 ms /    37 runs   (    0.58 ms per token,  1737.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4583.99 ms /    37 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4692.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.55 ms /    41 runs   (    0.57 ms per token,  1740.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4938.17 ms /    41 runs   (  120.44 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  5058.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.52 ms /    25 runs   (    0.58 ms per token,  1721.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3076.62 ms /    25 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3150.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.58 ms /    69 runs   (    0.57 ms per token,  1743.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8501.83 ms /    69 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8709.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A proliferação melanocítica uveal difusa bilateral é melhor classificada como: a) Desordem paraneoplásica. b) Apresentação grave do melanoma de coroide. c) Variante da síndrome de Vogt-Koyanagi-Harada. d) Desordem secundária a tratamento de descolamento de retina.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.72 ms /    25 runs   (    0.59 ms per token,  1698.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1954.94 ms /    97 tokens (   20.15 ms per token,    49.62 tokens per second)\n",
      "llama_print_timings:        eval time =  2901.22 ms /    24 runs   (  120.88 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4932.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   884.10 ms /     7 runs   (  126.30 ms per token,     7.92 tokens per second)\n",
      "llama_print_timings:       total time =   904.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.72 ms /    48 runs   (    0.58 ms per token,  1731.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5960.73 ms /    48 runs   (  124.18 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  6104.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.79 ms /     7 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   871.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.89 ms /     7 runs   (  119.84 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.34 ms /    25 runs   (    0.57 ms per token,  1743.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3034.94 ms /    25 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3108.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1741.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2909.84 ms /    24 runs   (  121.24 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2980.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.76 ms /    24 runs   (    0.57 ms per token,  1744.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2956.09 ms /    24 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3027.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.79 ms /    26 runs   (    0.57 ms per token,  1757.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3170.80 ms /    26 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3247.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.69 ms /    50 runs   (    0.57 ms per token,  1742.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6157.10 ms /    50 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6307.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 102: \n",
      "Language: english\n",
      "Question: \n",
      "In the examination of the periphery of the retina, in order to evaluate a certain region: a) The patient must look to the opposite side of the region to be observed and the doctor should position himself on the same side. b) The patient should look to the side of the region to be observed and the doctor should position himself on the opposite side. c) The patient must look to the side of the region to be observed and the doctor also position himself on the same side. d) The patient should look at the opposite side of the region to be observed and the doctor should also position himself on the opposite side.\n",
      "Test #0: \n",
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1725.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3424.89 ms /   135 tokens (   25.37 ms per token,    39.42 tokens per second)\n",
      "llama_print_timings:        eval time =  3293.46 ms /    27 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  6803.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.31 ms /    28 runs   (    0.58 ms per token,  1716.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3467.31 ms /    28 runs   (  123.83 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3552.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.07 ms /    28 runs   (    0.57 ms per token,  1742.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3395.80 ms /    28 runs   (  121.28 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3479.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1734.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3414.86 ms /    28 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3500.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.59 ms /    28 runs   (    0.59 ms per token,  1687.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3487.87 ms /    28 runs   (  124.57 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3573.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.97 ms /    28 runs   (    0.57 ms per token,  1752.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3385.02 ms /    28 runs   (  120.89 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3468.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n",
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.97 ms /    28 runs   (    0.57 ms per token,  1753.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3437.35 ms /    28 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3521.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.47 ms /    27 runs   (    0.57 ms per token,  1744.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.64 ms /    27 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3382.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3438.22 ms /    28 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3524.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n",
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "No exame da periferia da retina, para avaliar uma determinada região: a) O paciente deve olhar para o lado oposto da região que se deseja observar e o médico se posicionar no mesmo lado. b) O paciente deve olhar para o lado da região que se deseja observar e o médico se posicionar no lado oposto. c) O paciente deve olhar para o lado da região que se deseja observar e o médico se posicionar também no mesmo lado. d) O paciente deve olhar para o lado oposto da região que se deseja observar e o médico se posicionar também no lado oposto.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1745.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3443.59 ms /    28 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3529.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.49 ms /    59 runs   (    0.58 ms per token,  1710.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2605.21 ms /   162 tokens (   16.08 ms per token,    62.18 tokens per second)\n",
      "llama_print_timings:        eval time =  7109.82 ms /    58 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  9897.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.90 ms /    80 runs   (    0.57 ms per token,  1742.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9852.18 ms /    80 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 10094.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.94 ms /    28 runs   (    0.57 ms per token,  1757.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3419.85 ms /    28 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3503.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.56 ms /    60 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7391.67 ms /    60 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7573.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.38 ms /    60 runs   (    0.57 ms per token,  1745.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7290.58 ms /    60 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  7467.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.47 ms /    27 runs   (    0.57 ms per token,  1745.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3342.53 ms /    27 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3423.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.82 ms /     7 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.60 ms /    60 runs   (    0.58 ms per token,  1734.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7337.13 ms /    60 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7521.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1738.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3404.52 ms /    28 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3490.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 103: \n",
      "Language: english\n",
      "Question: \n",
      "Check the alternative that correctly correlates the change in the fluorescein angiography exam and its description. a) Accumulation (pooling): late appearance, area increases throughout the exam. b) Staining: early appearance, area increases throughout the exam. c) Window defect: early appearance, area maintained throughout the exam. d) Extravasation: late appearance, area maintained throughout the examination.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.59 ms /    60 runs   (    0.58 ms per token,  1734.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7365.73 ms /    60 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  7551.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   151.48 ms /   263 runs   (    0.58 ms per token,  1736.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1969.49 ms /    92 tokens (   21.41 ms per token,    46.71 tokens per second)\n",
      "llama_print_timings:        eval time = 32397.18 ms /   262 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 35219.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Extravasation: late appearance, area maintained throughout the examination.'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.31 ms /    95 runs   (    0.57 ms per token,  1749.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11734.75 ms /    95 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 12023.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.90 ms /    44 runs   (    0.57 ms per token,  1767.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5372.72 ms /    44 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5504.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Extravasation: late appearance, area maintained throughout the examination.'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.80 ms /    80 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9776.13 ms /    80 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 10017.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.13 ms /    32 runs   (    0.57 ms per token,  1765.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3892.97 ms /    32 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3988.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.49 ms /   114 runs   (    0.57 ms per token,  1740.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13995.57 ms /   114 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 14345.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.63 ms /   101 runs   (    0.57 ms per token,  1752.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12402.97 ms /   101 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 12712.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.90 ms /    23 runs   (    0.56 ms per token,  1782.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2784.51 ms /    23 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2853.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Extravasation: late appearance, area maintained throughout the examination.'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.76 ms /    33 runs   (    0.57 ms per token,  1759.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4086.78 ms /    33 runs   (  123.84 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4184.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.00 ms /    37 runs   (    0.57 ms per token,  1761.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4551.84 ms /    37 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4661.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que correlaciona corretamente a alteração no exame de angiofluoresceinografia e sua descrição. a) Acúmulo (pooling): aparecimento tardio, área aumenta ao longo do exame. b) Impregnação (staining): aparecimento precoce, área aumenta ao longo do exame. c) Defeito em janela: aparecimento precoce, área mantida ao longo do exame. d) Extravazamento: aparecimento tardio, área mantida ao longo do exame.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.45 ms /    64 runs   (    0.59 ms per token,  1709.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2907.67 ms /   140 tokens (   20.77 ms per token,    48.15 tokens per second)\n",
      "llama_print_timings:        eval time =  7708.05 ms /    63 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10815.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.47 ms /    27 runs   (    0.57 ms per token,  1745.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3288.54 ms /    27 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3371.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.30 ms /    53 runs   (    0.57 ms per token,  1749.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6509.68 ms /    53 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6674.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.57 ms /    34 runs   (    0.58 ms per token,  1737.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4189.70 ms /    34 runs   (  123.23 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4294.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.35 ms /    27 runs   (    0.57 ms per token,  1758.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.39 ms /    27 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3384.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.91 ms /    35 runs   (    0.57 ms per token,  1757.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4266.80 ms /    35 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4371.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.92 ms /    87 runs   (    0.57 ms per token,  1742.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10653.59 ms /    87 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10915.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.46 ms /    53 runs   (    0.57 ms per token,  1739.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6568.78 ms /    53 runs   (  123.94 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6729.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.66 ms /    27 runs   (    0.58 ms per token,  1724.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3378.61 ms /    27 runs   (  125.13 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  3459.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.34 ms /    27 runs   (    0.57 ms per token,  1760.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3327.93 ms /    27 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3407.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 104: \n",
      "Language: english\n",
      "Question: \n",
      "Considering the classification of diabetic retinopathy based on funduscopic findings and its prognostic significance, we can state: a) If there are no new vessels in the fundus examination, the risk of developing proliferative diabetic retinopathy in one year is less than 20%. b) The presence of only microhemorrhages and microaneurysms in three quadrants allows us to state that this patient will not develop proliferative diabetic retinopathy in one year. c) The presence of engorged veins associated with microaneurysms and microhemorrhages in all quadrants is considered a normal finding in diabetic retinopathy and suggests a risk below 10% of developing proliferative diabetic retinopathy in one year. d) The presence of intraretinal microvascular alterations (IRMA), moderate, in two quadrants, indicates that more than half of the patients will develop proliferative diabetic retinopathy in five years.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.66 ms /    25 runs   (    0.59 ms per token,  1705.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  5217.58 ms /   247 tokens (   21.12 ms per token,    47.34 tokens per second)\n",
      "llama_print_timings:        eval time =  2931.58 ms /    24 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8224.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.92 ms /    24 runs   (    0.58 ms per token,  1724.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2979.89 ms /    24 runs   (  124.16 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3051.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.18 ms /    17 runs   (    0.60 ms per token,  1669.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2077.89 ms /    17 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2128.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3458.92 ms /    28 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3541.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.85 ms /    17 runs   (    0.58 ms per token,  1725.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2091.73 ms /    17 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2142.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.84 ms /    17 runs   (    0.58 ms per token,  1727.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2079.12 ms /    17 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2129.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.44 ms /    25 runs   (    0.58 ms per token,  1730.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3083.52 ms /    25 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3157.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3480.76 ms /    28 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3565.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1737.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3432.45 ms /    28 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3516.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Considerando a classificação da retinopatia diabética a partir dos achados fundoscópicos e seu significado prognóstico, podemos afirmar: a) Se não existem neovasos no exame de fundo de olho, o risco de desenvolver retinopatia diabética proliferativa em um ano é menor que 20%. b) A presença apenas de microhemorragias e microaneurismas em três quadrantes permite afirmar que este paciente não desenvolverá retinopatia diabética proliferativa em um ano. c) A presença de veias ingurgitadas associada a microaneurismas e microhemorragias em todos os quadrantes é considerada achado normal na retinopatia diabética e sugere um risco abaixo de 10% de desenvolver retinopatia diabética proliferativa em um ano. d) A presença de alterações microvasculares intrarretinianas (IRMA), moderadas, em dois quadrantes, indica que mais da metade dos pacientes desenvolverá retinopatia diabética proliferativa em cinco anos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.85 ms /    17 runs   (    0.58 ms per token,  1725.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2188.23 ms /    17 runs   (  128.72 ms per token,     7.77 tokens per second)\n",
      "llama_print_timings:       total time =  2239.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.52 ms /    28 runs   (    0.59 ms per token,  1695.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4984.40 ms /   278 tokens (   17.93 ms per token,    55.77 tokens per second)\n",
      "llama_print_timings:        eval time =  3319.44 ms /    27 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8388.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.84 ms /    27 runs   (    0.59 ms per token,  1704.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3344.07 ms /    27 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3426.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3345.95 ms /    27 runs   (  123.92 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3425.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.24 ms /     7 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1724.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3456.02 ms /    28 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3539.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.76 ms /    28 runs   (    0.60 ms per token,  1670.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3473.48 ms /    28 runs   (  124.05 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3558.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3485.46 ms /    28 runs   (  124.48 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3568.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.34 ms /    11 runs   (    0.58 ms per token,  1734.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1349.68 ms /    11 runs   (  122.70 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  1382.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.00 ms /     7 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   884.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3476.65 ms /    28 runs   (  124.17 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3560.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 105: \n",
      "Language: english\n",
      "Question: \n",
      "In an optical coherence tomography exam, what is the correct correlation between the classification and the description of neovascular membranes? a) Membranes located below the retinal pigment epithelium are called type 1. b) Type 2 membranes are located below the retinal pigment epithelium, but extend into the region between the retinal pigment epithelium and the sensorineural retina. c) The membranes located below the retinal pigment epithelium are called type 3. d) The membranes that grow well delimited in the space between the sensorineural retina and the retinal pigment epithelium are called type 3.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.03 ms /   102 runs   (    0.58 ms per token,  1727.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3336.28 ms /   169 tokens (   19.74 ms per token,    50.66 tokens per second)\n",
      "llama_print_timings:        eval time = 12494.89 ms /   101 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 16142.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.81 ms /    76 runs   (    0.58 ms per token,  1734.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9418.46 ms /    76 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  9651.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n",
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    25 runs   (    0.58 ms per token,  1735.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3098.62 ms /    25 runs   (  123.94 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3174.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.72 ms /    81 runs   (    0.58 ms per token,  1733.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9880.78 ms /    81 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 10127.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.88 ms /    24 runs   (    0.58 ms per token,  1729.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2920.07 ms /    24 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2991.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.97 ms /    48 runs   (    0.58 ms per token,  1716.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5961.67 ms /    48 runs   (  124.20 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  6108.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.96 ms /   103 runs   (    0.66 ms per token,  1515.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12633.61 ms /   103 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12969.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.48 ms /    25 runs   (    0.62 ms per token,  1614.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3062.33 ms /    25 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3140.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.15 ms /    75 runs   (    0.58 ms per token,  1738.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9229.34 ms /    75 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  9457.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.70 ms /    47 runs   (    0.59 ms per token,  1696.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5833.90 ms /    47 runs   (  124.13 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  5977.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Num exame de tomografia de coerência óptica, qual a correlação correta entre a classificação e a descrição das membranas neovasculares? a) As membranas localizadas abaixo do epitélio pigmentado da retina são denominadas tipo 1. b) As membranas do tipo 2 localizam-se abaixo do epitélio pigmentado da retina, mas se estendem para a região entre o epitélio pigmentado da retina e a retina neurossensorial. c) As membranas localizadas abaixo do epitélio pigmentado da retina são denominadas tipo 3. d) As membranas que crescem bem delimitadas no espaço entre a retina neurossensorial e o epitélio pigmentado da retina são denominadas tipo 3.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.19 ms /     7 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4066.00 ms /   210 tokens (   19.36 ms per token,    51.65 tokens per second)\n",
      "llama_print_timings:        eval time =   724.76 ms /     6 runs   (  120.79 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  4812.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.22 ms /     7 runs   (    0.60 ms per token,  1656.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.49 ms /     7 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   879.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1714.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.37 ms /     7 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   885.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    90.78 ms /   157 runs   (    0.58 ms per token,  1729.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19393.97 ms /   157 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 19883.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.41 ms /    92 runs   (    0.58 ms per token,  1722.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11385.17 ms /    92 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 11665.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.08 ms /    73 runs   (    0.58 ms per token,  1734.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9032.16 ms /    73 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  9252.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    28 runs   (    0.58 ms per token,  1732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3491.95 ms /    28 runs   (  124.71 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3575.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    69.95 ms /   121 runs   (    0.58 ms per token,  1729.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14929.93 ms /   121 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 15303.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.56 ms /    95 runs   (    0.57 ms per token,  1741.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11664.92 ms /    95 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11954.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1735.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3302.96 ms /    27 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3383.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 106: \n",
      "Language: english\n",
      "Question: \n",
      "When considering the treatment of a patient with age-related macular degeneration, the best approach based on the findings of the AREDS studies is: a) Vitamin and antioxidant supplementation is indicated in patients with a family history, even before retinal changes appear. b) The presence of intermediate and large drusen is an indication of vitamin and antioxidant supplementation. c) Supplementation in smokers should include beta-carotene. d) When there is an advanced lesion in one of the eyes, vitamin and antioxidant supplementation is not recommended.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.88 ms /    74 runs   (    0.59 ms per token,  1686.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2380.43 ms /   143 tokens (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:        eval time =  8995.03 ms /    73 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11605.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.34 ms /    77 runs   (    0.58 ms per token,  1736.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9517.12 ms /    77 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  9749.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    25 runs   (    0.58 ms per token,  1728.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3043.44 ms /    25 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3118.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.27 ms /    70 runs   (    0.58 ms per token,  1738.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8581.30 ms /    70 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8795.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n",
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.85 ms /    71 runs   (    0.58 ms per token,  1738.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8670.80 ms /    71 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8887.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.99 ms /    81 runs   (    0.58 ms per token,  1723.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9911.03 ms /    81 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10158.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n",
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1737.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3086.94 ms /    25 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3161.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.83 ms /    81 runs   (    0.58 ms per token,  1729.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10011.95 ms /    81 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 10257.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    24 runs   (    0.60 ms per token,  1656.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2985.14 ms /    24 runs   (  124.38 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3058.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.67 ms /    27 runs   (    0.58 ms per token,  1723.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.68 ms /    27 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3383.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Quando consideramos o tratamento de um paciente com degeneração macular relacionada à idade, a melhor conduta baseada nos achados dos estudos AREDS é: a) A suplementação de vitaminas e antioxidantes está indicada em pacientes com histórico familiar, mesmo antes de aparecerem alterações retinianas. b) A presença de drusas intermediárias e grandes é indicação de suplementação de vitaminas e antioxidantes. c) A suplementação em pacientes fumantes deve incluir betacaroteno. d) Quando há lesão avançada em um dos olhos, não se recomenda a suplementação de vitaminas e antioxidantes.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.28 ms /     7 runs   (    0.61 ms per token,  1637.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3411.64 ms /   178 tokens (   19.17 ms per token,    52.17 tokens per second)\n",
      "llama_print_timings:        eval time =   771.43 ms /     6 runs   (  128.57 ms per token,     7.78 tokens per second)\n",
      "llama_print_timings:       total time =  4204.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.71 ms /    75 runs   (    0.58 ms per token,  1715.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9207.73 ms /    75 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  9438.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.31 ms /    27 runs   (    0.60 ms per token,  1655.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3295.09 ms /    27 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3379.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.49 ms /    20 runs   (    0.57 ms per token,  1740.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2430.65 ms /    20 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2490.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   879.28 ms /     7 runs   (  125.61 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =   899.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.22 ms /     7 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   867.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.84 ms /     7 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.19 ms /     7 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.60 ms /    83 runs   (    0.57 ms per token,  1743.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10255.62 ms /    83 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 10507.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.48 ms /     7 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 107: \n",
      "Language: english\n",
      "Question: \n",
      "The electrical response of the Müller cell is best represented by: a) \"a\" wave of the electroretinogram. b) Wave \"b\" of the electroretinogram. c) Wave \"c\" of the electroretinogram. d) Arden ratio on the electro-oculogram.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1737.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1742.91 ms /    76 tokens (   22.93 ms per token,    43.61 tokens per second)\n",
      "llama_print_timings:        eval time =  3265.64 ms /    27 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  5092.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.19 ms /    24 runs   (    0.59 ms per token,  1691.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2897.80 ms /    24 runs   (  120.74 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2971.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1736.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3302.33 ms /    27 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3382.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.81 ms /    17 runs   (    0.58 ms per token,  1732.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2040.82 ms /    17 runs   (  120.05 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  2090.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.44 ms /    25 runs   (    0.58 ms per token,  1731.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3034.66 ms /    25 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3109.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1750.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2918.66 ms /    24 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2990.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.57 ms /    27 runs   (    0.58 ms per token,  1734.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3319.31 ms /    27 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3399.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.47 ms /    27 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3258.80 ms /    27 runs   (  120.70 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3339.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.08 ms /    28 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3396.40 ms /    28 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3479.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.03 ms /    28 runs   (    0.57 ms per token,  1746.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3398.73 ms /    28 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3483.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A resposta elétrica da célula de Müller está melhor representada pela: a) Onda \"a\" do eletrorretinograma. b) Onda \"b\" do eletrorretinograma. c) Onda \"c\" do eletrorretinograma. d) Relação de Arden no eletro-oculograma.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.25 ms /     7 runs   (    0.61 ms per token,  1648.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1769.89 ms /    91 tokens (   19.45 ms per token,    51.42 tokens per second)\n",
      "llama_print_timings:        eval time =   735.38 ms /     6 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2527.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.49 ms /    28 runs   (    0.59 ms per token,  1698.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3419.45 ms /    28 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3505.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1735.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3378.11 ms /    28 runs   (  120.65 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3463.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   839.21 ms /     7 runs   (  119.89 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   860.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.89 ms /     7 runs   (  120.84 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1731.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2933.91 ms /    24 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3005.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.57 ms /    27 runs   (    0.58 ms per token,  1733.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3262.49 ms /    27 runs   (  120.83 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3342.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1725.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3063.35 ms /    25 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3138.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   840.07 ms /     7 runs   (  120.01 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =   860.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3275.01 ms /    27 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3355.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 108: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following is the best course of action for a 65-year-old patient with total retinal detachment due to a superior 155-degree arcuate peripheral retinal tear with a rolled-up posterior edge? a) Laser photocoagulation followed by scleral introflexion, with explant positioned superiorly. b) Scleral introflexion, with explant positioned superiorly and use of SF6 gas at the end of surgery. c) Pneumatic retinopexy followed by cryotherapy or laser photocoagulation. d) Posterior vitrectomy using perfluorocarbon and laser photocoagulation.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.05 ms /   110 runs   (    0.58 ms per token,  1717.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3621.40 ms /   160 tokens (   22.63 ms per token,    44.18 tokens per second)\n",
      "llama_print_timings:        eval time = 13403.81 ms /   109 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 17374.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.27 ms /   110 runs   (    0.58 ms per token,  1738.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13705.65 ms /   110 runs   (  124.60 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time = 14055.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.32 ms /   153 runs   (    0.58 ms per token,  1732.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18842.06 ms /   153 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 19324.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3490.18 ms /    28 runs   (  124.65 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3574.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.29 ms /   115 runs   (    0.58 ms per token,  1734.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14060.53 ms /   115 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 14411.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.08 ms /   108 runs   (    0.57 ms per token,  1739.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13393.18 ms /   108 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 13721.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    89.36 ms /   155 runs   (    0.58 ms per token,  1734.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19028.06 ms /   155 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 19508.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.18 ms /   108 runs   (    0.58 ms per token,  1737.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13312.39 ms /   108 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 13650.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.59 ms /   112 runs   (    0.58 ms per token,  1734.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13831.81 ms /   112 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 14183.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n",
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual a melhor conduta, entre as abaixo, para um paciente de 65 anos com descolamento de retina total decorrente de rasgadura retiniana periférica arqueada em 155 graus superiores, com borda posterior enrolada? a) Fotocoagulação a laser seguido de introflexão escleral, com explante posicionado superiormente. b) Introflexão escleral, com explante posicionado superiormente e uso de gás SF6 ao final da cirurgia. c) Retinopexia pneumática seguida de crioterapia ou fotocoagulação a laser. d) Vitrectomia posterior com uso de perfluorcarbono e fotocoagulação laser.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.19 ms /   110 runs   (    0.57 ms per token,  1740.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13595.53 ms /   110 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 13932.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.18 ms /     7 runs   (    0.60 ms per token,  1674.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3113.74 ms /   184 tokens (   16.92 ms per token,    59.09 tokens per second)\n",
      "llama_print_timings:        eval time =   735.61 ms /     6 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3870.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.46 ms /     7 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   882.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.06 ms /     7 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   878.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.85 ms /   102 runs   (    0.59 ms per token,  1704.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12716.18 ms /   102 runs   (  124.67 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time = 13031.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.30 ms /   183 runs   (    0.61 ms per token,  1629.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22498.37 ms /   183 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 23094.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'd be happy to help! Based on the information provided, the best course of action for a patient with a total retinal detachment due to a peripheral arcuate retinal tear would be:\n",
      "\n",
      "b) Introflexão escleral, com explante posicionado superiormente e uso de gás SF6 ao final da cirurgia.\n",
      "\n",
      "This is because the introduction of a gas bubble into the eye can help to push the retina back into place and relieve the detachment. The use of gás SF6 (sulfur hexafluoride) is particularly effective in this situation as it is less likely to cause cataracts or other complications compared to other gases.\n",
      "\n",
      "Here's the response in JSON format:\n",
      "\n",
      "{\"response\": \"b\") Introflexão escleral\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    82.44 ms /   142 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17551.06 ms /   142 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 17989.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.46 ms /     7 runs   (  121.92 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.49 ms /     7 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1756.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.45 ms /     7 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1765.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.42 ms /     7 runs   (  124.06 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 109: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Which of the systemic diseases below is most often associated with angioid striae? a) Sickle cell anemia. b) Megaloblastic anemia c) Rheumatoid arthritis. d) Polyarteritis nodosa.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.21 ms /     7 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.80 ms /    32 runs   (    0.59 ms per token,  1702.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1611.27 ms /    67 tokens (   24.05 ms per token,    41.58 tokens per second)\n",
      "llama_print_timings:        eval time =  3772.95 ms /    31 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5481.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.57 ms /    32 runs   (    0.58 ms per token,  1723.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3890.63 ms /    32 runs   (  121.58 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3986.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    24 runs   (    0.58 ms per token,  1725.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2919.93 ms /    24 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2991.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.55 ms /     7 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1731.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2874.77 ms /    24 runs   (  119.78 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =  2945.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.05 ms /    33 runs   (    0.58 ms per token,  1732.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4009.21 ms /    33 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4107.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1736.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3381.75 ms /    28 runs   (  120.78 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3464.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.50 ms /    32 runs   (    0.58 ms per token,  1729.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3955.99 ms /    32 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4050.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1732.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2888.28 ms /    24 runs   (  120.34 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2959.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2898.17 ms /    24 runs   (  120.76 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2969.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das doenças sistêmicas abaixo está mais frequentemente associada a um quadro de estrias angioides? a) Anemia falciforme. b) Anemia megaloblástica c) Artrite reumatoide.d) Poliarterite nodosa.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.64 ms /    36 runs   (    0.60 ms per token,  1663.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1312.34 ms /    74 tokens (   17.73 ms per token,    56.39 tokens per second)\n",
      "llama_print_timings:        eval time =  4239.55 ms /    35 runs   (  121.13 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  5663.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.50 ms /     7 runs   (    0.64 ms per token,  1557.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.41 ms /     7 runs   (  120.77 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.32 ms /    56 runs   (    0.58 ms per token,  1732.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6818.91 ms /    56 runs   (  121.77 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6986.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.45 ms /    25 runs   (    0.58 ms per token,  1730.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3029.72 ms /    25 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3103.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.19 ms /    16 runs   (    0.57 ms per token,  1741.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1935.61 ms /    16 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1983.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.28 ms /    37 runs   (    0.58 ms per token,  1738.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4599.41 ms /    37 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  4710.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.81 ms /    33 runs   (    0.57 ms per token,  1754.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4006.98 ms /    33 runs   (  121.42 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4106.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.95 ms /    33 runs   (    0.57 ms per token,  1741.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4051.54 ms /    33 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4148.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1723.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.47 ms /     7 runs   (  120.64 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {'response': 'A'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   839.90 ms /     7 runs   (  119.99 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =   860.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.22 ms /    37 runs   (    0.57 ms per token,  1743.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4459.51 ms /    37 runs   (  120.53 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  4569.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 110: \n",
      "Language: english\n",
      "Question: \n",
      "In addition to the classic triad of blepharoptosis, epicanthus inversus, and telecanthus, which of the findings below appears frequently in blepharophimosis syndrome? a) Trichiasis major. b) Lateral ectropion of the lower eyelid. c) Lacrimal obstruction due to imperforation of the Hasner valve. d) Shortening of the superior conjunctival cul-de-sac.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.35 ms /    40 runs   (    0.58 ms per token,  1713.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2273.04 ms /   112 tokens (   20.30 ms per token,    49.27 tokens per second)\n",
      "llama_print_timings:        eval time =  4770.32 ms /    39 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7164.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.70 ms /    43 runs   (    0.57 ms per token,  1740.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5245.99 ms /    43 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5376.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.33 ms /    63 runs   (    0.58 ms per token,  1734.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7816.78 ms /    63 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  8008.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.74 ms /    50 runs   (    0.57 ms per token,  1739.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6164.91 ms /    50 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  6317.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.51 ms /     7 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   874.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    25 runs   (    0.58 ms per token,  1735.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3037.47 ms /    25 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3113.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.10 ms /    28 runs   (    0.58 ms per token,  1739.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3405.51 ms /    28 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3490.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1733.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3048.91 ms /    25 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3123.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.72 ms /   154 runs   (    0.58 ms per token,  1735.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19076.71 ms /   154 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 19556.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1739.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2067.12 ms /    17 runs   (  121.60 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2116.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Além da tríade clássica de blefaroptose, epicanto inverso e telecanto, qual dos achados abaixo aparece com frequência na síndrome da blefarofimose? a) Triquíase maior. b) Ectrópio lateral da pálpebra inferior. c) Obstrução lacrimal por imperfuração da válvula de Hasner. d) Encurtamento do fundo de saco conjuntival superior.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.47 ms /    49 runs   (    0.58 ms per token,  1721.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2674.55 ms /   116 tokens (   23.06 ms per token,    43.37 tokens per second)\n",
      "llama_print_timings:        eval time =  5892.82 ms /    48 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  8716.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.95 ms /     7 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.93 ms /     7 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.65 ms /    48 runs   (    0.58 ms per token,  1736.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5923.94 ms /    48 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6069.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.20 ms /     7 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1741.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.29 ms /     7 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.16 ms /    68 runs   (    0.58 ms per token,  1736.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8306.00 ms /    68 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8516.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   840.86 ms /     7 runs   (  120.12 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   861.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.45 ms /    27 runs   (    0.57 ms per token,  1747.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3321.91 ms /    27 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3403.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.84 ms /     7 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   885.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 111: \n",
      "Language: english\n",
      "Question: \n",
      "Check the correct alternative regarding lower blepharoplasty surgery for aesthetic purposes. a) Removal of the lateral fat pad mainly suffered postoperative diplopia due to an injury to the inferior oblique. b) When performed via the transconjunctival route, there is a greater risk of eyelid retraction. c) Greater horizontal flaccidity of the head in the pre-surgical evaluation indicates the need for a lateral canthoplasty. d) In young patients, who have a greater healing response, the preferred route is transcutaneous.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.50 ms /    54 runs   (    0.60 ms per token,  1661.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2250.10 ms /   137 tokens (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:        eval time =  6522.28 ms /    53 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8944.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    98.35 ms /   170 runs   (    0.58 ms per token,  1728.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21006.85 ms /   170 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 21557.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.22 ms /    47 runs   (    0.58 ms per token,  1726.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5797.05 ms /    47 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5945.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1724.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3070.39 ms /    25 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3147.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.41 ms /    38 runs   (    0.59 ms per token,  1695.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4662.75 ms /    38 runs   (  122.70 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4783.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1735.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3429.26 ms /    28 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3517.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.27 ms /    28 runs   (    0.58 ms per token,  1720.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3431.28 ms /    28 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3518.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.19 ms /    28 runs   (    0.58 ms per token,  1729.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3426.62 ms /    28 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3514.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n",
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.36 ms /    49 runs   (    0.58 ms per token,  1727.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5989.55 ms /    49 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  6144.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.33 ms /    58 runs   (    0.57 ms per token,  1740.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7101.52 ms /    58 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7278.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa correta quanto a cirurgia de blefaroplastia inferior para fins estéticos.  a) Remoção da bolsa de gordura lateral tem como principal complicação a diplopia pós-operatória por lesão no obliquo inferior. b) Quando realizada por via transconjuntival há maior risco de retração palpebral. c) Maior flacidez horizontal da pálpebra na avaliação pré-operatória indica a necessidade de associação de cantoplastia lateral. d) Em pacientes jovens, que possuem maior resposta cicatricial, a via preferencial é a transcutânea.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.64 ms /    30 runs   (    0.59 ms per token,  1700.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2895.84 ms /   170 tokens (   17.03 ms per token,    58.70 tokens per second)\n",
      "llama_print_timings:        eval time =  3643.67 ms /    29 runs   (  125.64 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  6629.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.96 ms /    31 runs   (    0.58 ms per token,  1726.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3769.16 ms /    31 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3863.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    69.27 ms /   119 runs   (    0.58 ms per token,  1718.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14708.06 ms /   119 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15076.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.03 ms /     7 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.86 ms /     7 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.73 ms /    76 runs   (    0.58 ms per token,  1738.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9312.32 ms /    76 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  9543.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1729.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3290.18 ms /    27 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3371.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.07 ms /     7 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.22 ms /     7 runs   (  120.17 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   861.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.69 ms /     7 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 112: \n",
      "Language: english\n",
      "Question: \n",
      "Choose the correct alternative. a) The following side effects of the application of periocular botulinum toxin can be considered: aponeurotic blepharoptosis, spastic entropion and restrictive strabismus. b) Unlike essential blepharospasm, treatment with oral myorelaxant drugs shows a good response to hemifacial spasm. c) The application of botulinum toxin type B is the most common treatment for essential blepharospasm. d) The adjuvant application of botulinum toxin in case of peripheral facial paralysis is performed on the unaffected side.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.67 ms /    75 runs   (    0.61 ms per token,  1642.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2802.26 ms /   155 tokens (   18.08 ms per token,    55.31 tokens per second)\n",
      "llama_print_timings:        eval time =  9055.57 ms /    74 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12093.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.84 ms /    24 runs   (    0.58 ms per token,  1733.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2923.62 ms /    24 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2994.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.14 ms /    63 runs   (    0.59 ms per token,  1696.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7844.35 ms /    63 runs   (  124.51 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  8038.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    28 runs   (    0.58 ms per token,  1728.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3437.43 ms /    28 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3520.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.64 ms /    34 runs   (    0.58 ms per token,  1730.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4142.00 ms /    34 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4243.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.95 ms /    24 runs   (    0.58 ms per token,  1720.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2921.05 ms /    24 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2992.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.14 ms /     7 runs   (    0.59 ms per token,  1689.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   892.43 ms /     7 runs   (  127.49 ms per token,     7.84 tokens per second)\n",
      "llama_print_timings:       total time =   912.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.95 ms /    24 runs   (    0.58 ms per token,  1720.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3063.71 ms /    24 runs   (  127.65 ms per token,     7.83 tokens per second)\n",
      "llama_print_timings:       total time =  3137.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    27 runs   (    0.58 ms per token,  1730.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3331.53 ms /    27 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3413.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Escolha a alternativa correta. a) Podem ser considerados efeitos colaterais da aplicação da toxina botulínica periocular: blefaroptose aponeurótica, entrópio espástico e estrabismo restritivo. b) Diferentemente do blefaroespasmo essencial, o tratamento com drogas miorrelaxantes orais apresenta boa resposta para o espasmo hemifacial. c) A aplicação de toxina botulínica tipo B é o tratamento mais realizado para blefaroespasmo essencial. d) A aplicação adjuvante de toxina botulínica em caso de paralisia facial periférica é realizada no lado não acometido.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1734.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3041.82 ms /    25 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3118.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.63 ms /   160 runs   (    0.59 ms per token,  1708.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3540.79 ms /   183 tokens (   19.35 ms per token,    51.68 tokens per second)\n",
      "llama_print_timings:        eval time = 19557.80 ms /   159 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 23603.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.53 ms /     7 runs   (    0.65 ms per token,  1545.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.68 ms /     7 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   881.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   100.48 ms /   173 runs   (    0.58 ms per token,  1721.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21375.65 ms /   173 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 21913.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.45 ms /     7 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1729.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3337.28 ms /    27 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3417.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.92 ms /     7 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.92 ms /     7 runs   (  121.13 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.34 ms /   184 runs   (    0.58 ms per token,  1730.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22778.19 ms /   184 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 23353.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   880.29 ms /     7 runs   (  125.76 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =   901.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.75 ms /     7 runs   (  123.68 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   886.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 113: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Which suture thread used in eyelid surgeries has the greatest potential for tissue inflammatory reaction? a) Silk, as it is organic. b) Polyester (Mersilene®), as it is absorbable. c) Polyamide (Nylon®), as it is monofilament. d) Polypropylene (Prolene®), as it is multifilament braided.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.72 ms /   100 runs   (    0.58 ms per token,  1732.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2591.84 ms /   106 tokens (   24.45 ms per token,    40.90 tokens per second)\n",
      "llama_print_timings:        eval time = 12203.97 ms /    99 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 15100.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.62 ms /    43 runs   (    0.57 ms per token,  1746.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5241.21 ms /    43 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5368.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.33 ms /    25 runs   (    0.57 ms per token,  1744.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3130.22 ms /    25 runs   (  125.21 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  3205.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.60 ms /    48 runs   (    0.57 ms per token,  1739.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5878.66 ms /    48 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6026.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3410.76 ms /    28 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3495.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.31 ms /    89 runs   (    0.58 ms per token,  1734.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10833.19 ms /    89 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time = 11108.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3063.73 ms /    25 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3139.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.74 ms /    45 runs   (    0.57 ms per token,  1748.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5598.56 ms /    45 runs   (  124.41 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  5734.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.82 ms /    17 runs   (    0.58 ms per token,  1731.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2048.19 ms /    17 runs   (  120.48 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2099.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.80 ms /    52 runs   (    0.57 ms per token,  1744.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6407.24 ms /    52 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6566.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual fio de sutura utilizado em cirurgias palpebrais tem maior potencial de reação inflamatória tecidual? a) Seda, por ser orgânico. b) Poliester (Mersilene®), por ser absorvível. c) Poliamida (Nylon®), por ser monofilamentar. d) Polipropilene (Prolene®), por ser multifilamentar trançado.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.42 ms /     7 runs   (    0.63 ms per token,  1582.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1796.25 ms /   112 tokens (   16.04 ms per token,    62.35 tokens per second)\n",
      "llama_print_timings:        eval time =   728.26 ms /     6 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2546.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.16 ms /     7 runs   (    0.59 ms per token,  1682.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.66 ms /     7 runs   (  120.67 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1700.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.10 ms /     7 runs   (  122.73 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.83 ms /     7 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1706.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.49 ms /     7 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.77 ms /     7 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   874.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'd) Polipropilene (Prolene®)'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.97 ms /    19 runs   (    0.58 ms per token,  1731.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2300.41 ms /    19 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2357.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.86 ms /     7 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3287.99 ms /    27 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3368.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.10 ms /     7 runs   (  122.73 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 114: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding the chalazion. a) In elderly patients, malignant transformation to sebaceous carcinoma is common. b) Histologically, it is characterized by chronic lipogranulomatous inflammation. c) In most cases, it originates from the apocrine gland attached to the eyelashes. d) Use of topical ivermectin in ointment is the preferred clinical treatment due to the demonstrated association with the Demodex folliculorum mite.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.70 ms /    56 runs   (    0.58 ms per token,  1712.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2392.11 ms /   127 tokens (   18.84 ms per token,    53.09 tokens per second)\n",
      "llama_print_timings:        eval time =  6752.87 ms /    55 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  9317.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.40 ms /    56 runs   (    0.58 ms per token,  1728.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6863.86 ms /    56 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  7032.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.80 ms /    55 runs   (    0.58 ms per token,  1729.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6739.39 ms /    55 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6904.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.37 ms /    56 runs   (    0.58 ms per token,  1729.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6824.06 ms /    56 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6992.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.25 ms /    49 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6067.53 ms /    49 runs   (  123.83 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6214.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.77 ms /    56 runs   (    0.59 ms per token,  1708.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6857.49 ms /    56 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7027.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.16 ms /    59 runs   (    0.58 ms per token,  1727.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7237.95 ms /    59 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  7416.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.78 ms /    55 runs   (    0.58 ms per token,  1730.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6696.30 ms /    55 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6862.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.37 ms /    63 runs   (    0.58 ms per token,  1732.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7739.06 ms /    63 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7930.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.27 ms /    49 runs   (    0.58 ms per token,  1733.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5954.65 ms /    49 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  6101.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      " Assinale a alternativa correta quanto ao calázio. a) Em pacientes idosos é comum a transformação maligna para carcinoma sebáceo. b) Histologicamente caracteriza-se por inflamação crônica lipogranulomatosa. c) Na maioria das vezes origina-se de glândula apócrina atrelada aos cílios. d) Uso de ivermectina tópica em pomada é o tratamento clínico preferido devido a associação demonstrada com o ácaro Demodex foliculorum.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.02 ms /    98 runs   (    0.58 ms per token,  1718.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3287.59 ms /   144 tokens (   22.83 ms per token,    43.80 tokens per second)\n",
      "llama_print_timings:        eval time = 12048.40 ms /    97 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 15639.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.16 ms /    54 runs   (    0.58 ms per token,  1733.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6653.19 ms /    54 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6818.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.97 ms /    59 runs   (    0.58 ms per token,  1736.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7232.30 ms /    59 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  7411.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.17 ms /    61 runs   (    0.58 ms per token,  1734.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7509.74 ms /    61 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7697.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.30 ms /     7 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   868.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.14 ms /    66 runs   (    0.58 ms per token,  1730.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8082.72 ms /    66 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  8283.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.09 ms /    61 runs   (    0.58 ms per token,  1738.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7588.59 ms /    61 runs   (  124.40 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  7772.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1736.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3481.28 ms /    28 runs   (  124.33 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3564.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.23 ms /    61 runs   (    0.58 ms per token,  1731.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7473.19 ms /    61 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  7657.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 115: \n",
      "Language: english\n",
      "Question: \n",
      "A 60-year-old woman with tonic-clonic contractions that started in the periocular muscles on the right and in three months progressed to the entire hemiface. Although the contractions vary during the day, they usually don't let her sleep, as they \"don't stop at night\". Tick ​​the correct alternative. a) This is a case of benign essential blepharospasm. b) Contractions tend to progressively affect the contralateral side and become bilateral and symmetrical. c) A possible cause is intracranial vascular compression of the ipsilateral facial nerve. d) Medications that modulate serotonin production in the basal nuclei, although not completely effective, help control contractions.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    69.87 ms /   121 runs   (    0.58 ms per token,  1731.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14804.14 ms /   121 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 15182.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.92 ms /    53 runs   (    0.58 ms per token,  1714.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3051.68 ms /   183 tokens (   16.68 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:        eval time =  6349.97 ms /    52 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  9562.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Medications that modulate serotonin production in the basal nuclei, although not completely effective, help control contractions.'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.34 ms /    56 runs   (    0.58 ms per token,  1731.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6942.93 ms /    56 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  7112.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.39 ms /    17 runs   (    0.61 ms per token,  1636.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2082.93 ms /    17 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2133.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   901.54 ms /     7 runs   (  128.79 ms per token,     7.76 tokens per second)\n",
      "llama_print_timings:       total time =   922.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1737.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3460.30 ms /    28 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3543.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.41 ms /    53 runs   (    0.57 ms per token,  1742.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6626.64 ms /    53 runs   (  125.03 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  6785.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.72 ms /    50 runs   (    0.57 ms per token,  1740.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6154.93 ms /    50 runs   (  123.10 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6305.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.50 ms /    53 runs   (    0.58 ms per token,  1737.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6546.82 ms /    53 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6706.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3457.81 ms /    28 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3541.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.31 ms /    28 runs   (    0.58 ms per token,  1716.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3440.69 ms /    28 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3525.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Mulher de 60 anos com contrações tônico-clônicas que se iniciaram na musculatura periocular à direita e em três meses evoluiram para toda a hemiface. Embora as contrações variem durante o dia, geralmente não a deixam dormir, pois \"não param a noite\". Assinale a alternativa correta. a) Trata-se de um caso de blefaroespasmo essencial benigno. b) As contrações tendem a acometer progressivamente o lado contralateral e tornarem-se bilaterais e simétricas. c) Uma possível causa é compressão intracraniana vascular do nervo facial ipsolateral. d) Medicações que modulam produção de serotonina nos núcleos da base, embora não sejam completamente efetivas, auxiliam no controle das contrações.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1661.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3960.24 ms /   222 tokens (   17.84 ms per token,    56.06 tokens per second)\n",
      "llama_print_timings:        eval time =   751.65 ms /     6 runs   (  125.28 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  4733.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.72 ms /    20 runs   (    0.59 ms per token,  1705.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2462.99 ms /    20 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2524.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1694.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.22 ms /     7 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   880.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.66 ms /     7 runs   (  123.38 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.02 ms /    57 runs   (    0.58 ms per token,  1726.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7049.05 ms /    57 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  7221.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.57 ms /   145 runs   (    0.58 ms per token,  1735.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17965.68 ms /   145 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 18414.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.56 ms /     7 runs   (  124.51 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   892.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.79 ms /     7 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.01 ms /     7 runs   (  124.14 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   889.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1685.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.08 ms /     7 runs   (  120.30 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 116: \n",
      "Language: english\n",
      "Question: \n",
      "The technique of tarsal fracture with marginal rotation is most indicated for the treatment of which type of eyelid entropion, among the following? a) Involutional (senile). b) Spastic. c) Congenital. d) Scarring.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.30 ms /     7 runs   (    0.61 ms per token,  1627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1527.86 ms /    66 tokens (   23.15 ms per token,    43.20 tokens per second)\n",
      "llama_print_timings:        eval time =   742.38 ms /     6 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  2291.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.96 ms /    17 runs   (    0.59 ms per token,  1706.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2056.25 ms /    17 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2107.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.85 ms /    17 runs   (    0.58 ms per token,  1725.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2054.46 ms /    17 runs   (  120.85 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2105.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.21 ms /    28 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3418.55 ms /    28 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3501.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.83 ms /    17 runs   (    0.58 ms per token,  1729.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2066.18 ms /    17 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2116.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.52 ms /    27 runs   (    0.57 ms per token,  1739.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3266.92 ms /    27 runs   (  121.00 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3346.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2916.09 ms /    24 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2987.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.12 ms /    21 runs   (    0.58 ms per token,  1733.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2534.65 ms /    21 runs   (  120.70 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2596.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2066.69 ms /    17 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2116.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.19 ms /     7 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   886.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A técnica de fratura tarsal com rotação marginal é mais indicada para tratamento de qual tipo de entrópio palpebral, dentre os abaixo? a) Involucional (senil). b) Espástico. c) Congênito. d) Cicatricial.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.69 ms /     9 runs   (    0.63 ms per token,  1582.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1790.49 ms /    77 tokens (   23.25 ms per token,    43.01 tokens per second)\n",
      "llama_print_timings:        eval time =   960.28 ms /     8 runs   (  120.04 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  2778.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.05 ms /     7 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   885.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.07 ms /    21 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2550.98 ms /    21 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2614.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1738.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2935.94 ms /    24 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3007.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.08 ms /    59 runs   (    0.58 ms per token,  1731.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7179.03 ms /    59 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7356.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.94 ms /     7 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.66 ms /    29 runs   (    0.57 ms per token,  1740.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3529.39 ms /    29 runs   (  121.70 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3615.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b} Espástico.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.81 ms /     7 runs   (  120.26 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1736.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3439.49 ms /    28 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3521.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.82 ms /     7 runs   (  120.55 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   863.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 117: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the alternatives best correlates with the measurements in the table below? Palpebral fissure09 mm Upper margin-reflex distance 01 mm Lower margin-reflex distance 08 mm Function of the eyelid levator muscle 14 mm Upper eyelid crease height 16 mm a) Possible case of senile blepharoptosis associated with senile ectropion. b) Possible case of congenital reverse eyelid ptosis. c) Probable case of eyelid retraction due to Graves' inflammatory orbitopathy d) If the patient is Caucasian, these measurements can be considered normal.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.89 ms /    77 runs   (    0.58 ms per token,  1715.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2912.09 ms /   160 tokens (   18.20 ms per token,    54.94 tokens per second)\n",
      "llama_print_timings:        eval time =  9333.56 ms /    76 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 12481.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.76 ms /     7 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.08 ms /   205 runs   (    0.58 ms per token,  1736.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25095.74 ms /   205 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 25733.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.03 ms /    95 runs   (    0.58 ms per token,  1726.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11650.85 ms /    95 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 11940.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   119.25 ms /   207 runs   (    0.58 ms per token,  1735.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25534.42 ms /   207 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 26186.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   928.09 ms /     7 runs   (  132.58 ms per token,     7.54 tokens per second)\n",
      "llama_print_timings:       total time =   948.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.53 ms /    32 runs   (    0.58 ms per token,  1727.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3980.01 ms /    32 runs   (  124.38 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  4075.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.19 ms /     7 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.04 ms /   167 runs   (    0.58 ms per token,  1720.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20604.92 ms /   167 runs   (  123.38 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 21125.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.33 ms /   168 runs   (    0.58 ms per token,  1726.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20596.97 ms /   168 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 21122.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das alternativas melhor se correlaciona com as medidas da tabela abaixo? Fenda palpebral 09 mm Distância margem-reflexo superior 01 mm Distância margem-reflexo inferior 08 mm Função do músculo levantador da pálpebra 14 mm Altura da prega palpebral superior 16 mm a) Possível caso de blefaroptose senil associada a ectrópio senil. b) Possível caso de ptose palpebral reversa congênita. c) Provável caso de retração palpebral por orbitopatia inflamatória de Graves d) Caso o paciente seja caucasiano, essas medidas podem ser consideradas normais.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1686.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3183.06 ms /   191 tokens (   16.67 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:        eval time =   734.85 ms /     6 runs   (  122.47 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3939.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   101.14 ms /   176 runs   (    0.57 ms per token,  1740.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21689.62 ms /   176 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 22237.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.42 ms /     7 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.27 ms /     7 runs   (  121.32 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1755.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.06 ms /     7 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.79 ms /     7 runs   (  121.11 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   839.22 ms /     7 runs   (  119.89 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   100.92 ms /   176 runs   (    0.57 ms per token,  1743.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21629.76 ms /   176 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 22172.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.85 ms /     7 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.93 ms /     7 runs   (    0.56 ms per token,  1779.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   878.50 ms /     7 runs   (  125.50 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =   898.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 118: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding the lacrimal system. a) Approximately 50% of newborns maintain obstruction of the Hasner valve until the sixth month of life, and 90% of them require probing. b) In most newborns, tear secretion is less than in healthy adults. c) Complete canalization of the nasolacrimal duct usually occurs around the sixth week of extrauterine life. d) The newborn generally presents complete canalization of the nasolacrimal sac and duct; however, the canaliculi open around the sixth week of extrauterine life.\n",
      "\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.40 ms /    28 runs   (    0.59 ms per token,  1707.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3303.46 ms /   144 tokens (   22.94 ms per token,    43.59 tokens per second)\n",
      "llama_print_timings:        eval time =  3392.50 ms /    27 runs   (  125.65 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  6780.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.01 ms /    55 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6825.58 ms /    55 runs   (  124.10 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  6993.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.27 ms /    72 runs   (    0.57 ms per token,  1744.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8798.53 ms /    72 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9013.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.75 ms /    50 runs   (    0.58 ms per token,  1738.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6178.66 ms /    50 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  6328.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.30 ms /    93 runs   (    0.57 ms per token,  1744.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11455.96 ms /    93 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11738.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2916.56 ms /    24 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2987.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1738.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2073.35 ms /    17 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2123.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.02 ms /    24 runs   (    0.58 ms per token,  1711.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2939.33 ms /    24 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3012.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   129.02 ms /   223 runs   (    0.58 ms per token,  1728.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27475.30 ms /   223 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 28183.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.26 ms /    49 runs   (    0.58 ms per token,  1733.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6004.07 ms /    49 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6150.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa correta quanto ao sistema lacrimal. a) Aproximadamente 50% dos recém-nascidos mantém obstrução da valva de Hasner até o sexto mês de vida, sendo que 90% deles necessitam de sondagem. b) Na maioria dos recém-nascidos a secreção lacrimal é menor que a do adulto saudável. c) A canalização completa do ducto nasolacrimal geralmente ocorre por volta da sexta semana de vida extrauterina. d) O recém-nascido geralmente apresenta canalização completa do saco e ducto nasolacrimal; no entanto os canalículos abrem-se por volta da sexta semana de vida extrauterina.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.01 ms /    27 runs   (    0.59 ms per token,  1686.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2924.49 ms /   195 tokens (   15.00 ms per token,    66.68 tokens per second)\n",
      "llama_print_timings:        eval time =  3160.29 ms /    26 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  6166.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.22 ms /    75 runs   (    0.58 ms per token,  1735.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9240.66 ms /    75 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9468.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.32 ms /    70 runs   (    0.58 ms per token,  1735.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8657.44 ms /    70 runs   (  123.68 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  8868.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.69 ms /    75 runs   (    0.58 ms per token,  1716.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9223.34 ms /    75 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  9450.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1725.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.85 ms /     7 runs   (  124.55 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   892.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.20 ms /    89 runs   (    0.58 ms per token,  1738.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10870.88 ms /    89 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 11141.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.56 ms /    27 runs   (    0.58 ms per token,  1735.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3367.82 ms /    27 runs   (  124.73 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3448.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.88 ms /    76 runs   (    0.58 ms per token,  1732.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9367.14 ms /    76 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9597.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.53 ms /     7 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.04 ms /     7 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   882.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 119: \n",
      "Language: english\n",
      "Question: \n",
      "Choose the alternative that best fills the gap: In adults, __________ is only performed for diagnosis, as for treatment it is potentially traumatic and rarely effective in permanently relieving lacrimal obstruction. a) Intubation with a silicone probe. b) Irrigation with mucolytic solution. c) Probing with metallic rod. d) Use of argon laser probe.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.69 ms /    37 runs   (    0.59 ms per token,  1705.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1922.79 ms /    99 tokens (   19.42 ms per token,    51.49 tokens per second)\n",
      "llama_print_timings:        eval time =  4466.76 ms /    36 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  6502.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.57 ms /    37 runs   (    0.58 ms per token,  1715.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4566.86 ms /    37 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  4679.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.30 ms /    35 runs   (    0.58 ms per token,  1723.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4277.81 ms /    35 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4382.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.03 ms /    33 runs   (    0.58 ms per token,  1734.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4046.73 ms /    33 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4147.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.82 ms /    29 runs   (    0.58 ms per token,  1723.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3513.21 ms /    29 runs   (  121.15 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3601.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.84 ms /    36 runs   (    0.58 ms per token,  1727.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4338.47 ms /    36 runs   (  120.51 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  4446.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.94 ms /    36 runs   (    0.58 ms per token,  1719.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4357.04 ms /    36 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4466.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.07 ms /    40 runs   (    0.58 ms per token,  1733.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4853.92 ms /    40 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4974.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.95 ms /    26 runs   (    0.57 ms per token,  1739.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3136.99 ms /    26 runs   (  120.65 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3215.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.95 ms /    74 runs   (    0.58 ms per token,  1723.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9080.72 ms /    74 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  9309.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Escolha a alternativa que melhor preencha a lacuna: Em adultos, a __________ é apenas realizada para diagnóstico, pois para tratamento é potencialmente traumática e raramente efetiva para aliviar permanentemente a obstrução lacrimal. a) Intubação com sonda de silicone. b) Irrigação com solução mucolítica. c) Sondagem com haste metálica. d) Utilização de sonda de laser de argônio.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.85 ms /    98 runs   (    0.59 ms per token,  1694.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2170.08 ms /   129 tokens (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:        eval time = 11954.63 ms /    97 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 14433.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.81 ms /    38 runs   (    0.57 ms per token,  1742.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4635.79 ms /    38 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4748.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.30 ms /    25 runs   (    0.57 ms per token,  1747.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3026.85 ms /    25 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3100.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.32 ms /    39 runs   (    0.57 ms per token,  1746.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4772.55 ms /    39 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4888.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.20 ms /     7 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.81 ms /    38 runs   (    0.57 ms per token,  1742.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4606.81 ms /    38 runs   (  121.23 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4719.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3392.05 ms /    28 runs   (  121.14 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3474.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.89 ms /    38 runs   (    0.58 ms per token,  1735.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4648.16 ms /    38 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4761.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.50 ms /    39 runs   (    0.58 ms per token,  1732.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4794.32 ms /    39 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4910.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.79 ms /     7 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 120: \n",
      "Language: english\n",
      "Question: \n",
      "In the semiotics of obstructions of the lacrimal drainage pathways, the test that uses technetium-99m instillation in the lacrimal cul-de-sac is: a) Zapata-Milder. b) Jones II modified. c) Dacryocystography. d) Dacryocintigraphy.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    28 runs   (    0.58 ms per token,  1717.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2146.44 ms /    90 tokens (   23.85 ms per token,    41.93 tokens per second)\n",
      "llama_print_timings:        eval time =  3296.82 ms /    27 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5527.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.79 ms /    36 runs   (    0.58 ms per token,  1731.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4372.48 ms /    36 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4480.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3466.00 ms /    28 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3549.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    28 runs   (    0.58 ms per token,  1728.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3438.50 ms /    28 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3521.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1739.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2077.24 ms /    17 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2128.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.81 ms /    15 runs   (    0.59 ms per token,  1702.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1814.26 ms /    15 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1858.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.44 ms /    45 runs   (    0.59 ms per token,  1701.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5576.01 ms /    45 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  5713.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1736.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3397.86 ms /    28 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3480.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3379.01 ms /    28 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3461.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1741.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3294.38 ms /    27 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3373.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Na semiótica das obstruções das vias lacrimais de drenagem, o teste que usa a instilação de tecnécio-99m no fundo de saco lacrimal é de: a) Zapata-Milder. b) Jones II modificado. c) Dacriocistografia. d) Dacriocintilografia.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.01 ms /    31 runs   (    0.58 ms per token,  1720.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1998.16 ms /    91 tokens (   21.96 ms per token,    45.54 tokens per second)\n",
      "llama_print_timings:        eval time =  3671.73 ms /    30 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5762.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.12 ms /    14 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1696.69 ms /    14 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  1738.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.72 ms /    27 runs   (    0.58 ms per token,  1717.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3260.95 ms /    27 runs   (  120.78 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3342.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1736.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3400.15 ms /    28 runs   (  121.43 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3483.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.41 ms /     7 runs   (  121.06 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3414.84 ms /    28 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3500.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.15 ms /     7 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    27 runs   (    0.60 ms per token,  1664.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3309.30 ms /    27 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3391.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.46 ms /    37 runs   (    0.58 ms per token,  1724.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4490.50 ms /    37 runs   (  121.36 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4602.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1694.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.25 ms /     7 runs   (  121.04 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   867.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 121: \n",
      "Language: english\n",
      "Question: \n",
      "Check the alternative that contains a treatment for acquired obstruction of the nasolacrimal duct. a) Transnasal dacrhinostomy. b) Pyrex tube implant. c) Enlargement of the lacrimal point. d) Crigler hydrostatic massage.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.34 ms /    28 runs   (    0.58 ms per token,  1713.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1701.93 ms /    71 tokens (   23.97 ms per token,    41.72 tokens per second)\n",
      "llama_print_timings:        eval time =  3346.70 ms /    27 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  5133.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.06 ms /     7 runs   (  120.29 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   863.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   125.96 ms /   217 runs   (    0.58 ms per token,  1722.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26573.45 ms /   217 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 27260.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.84 ms /    71 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8671.59 ms /    71 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8887.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1771.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   836.24 ms /     7 runs   (  119.46 ms per token,     8.37 tokens per second)\n",
      "llama_print_timings:       total time =   857.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.53 ms /    78 runs   (    0.58 ms per token,  1713.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9585.28 ms /    78 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  9828.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.74 ms /    64 runs   (    0.57 ms per token,  1741.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7806.39 ms /    64 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  8005.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.13 ms /    16 runs   (    0.57 ms per token,  1751.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1936.65 ms /    16 runs   (  121.04 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  1985.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    28 runs   (    0.57 ms per token,  1750.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3451.13 ms /    28 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3537.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1746.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3447.58 ms /    28 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3532.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que contenha um tratamento para obstrução adquirida do ducto lacrimonasal. a) Dacriorrinostomia transnasal. b) Implante de tubo de pirex. c) Ampliação do ponto lacrimal. d) Massagem hidrostática de Crigler.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2054.08 ms /    85 tokens (   24.17 ms per token,    41.38 tokens per second)\n",
      "llama_print_timings:        eval time =   734.25 ms /     6 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2809.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.29 ms /    28 runs   (    0.58 ms per token,  1719.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3447.37 ms /    28 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3533.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.16 ms /     7 runs   (    0.59 ms per token,  1684.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.00 ms /     7 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.33 ms /     7 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   887.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    28 runs   (    0.58 ms per token,  1732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3484.13 ms /    28 runs   (  124.43 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3569.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.58 ms /     7 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.01 ms /     7 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   885.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.64 ms /   114 runs   (    0.58 ms per token,  1710.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13983.28 ms /   114 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 14343.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.35 ms /    49 runs   (    0.58 ms per token,  1728.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5928.06 ms /    49 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  6076.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.21 ms /    28 runs   (    0.58 ms per token,  1727.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3416.00 ms /    28 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3499.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 122: \n",
      "Language: english\n",
      "Question: \n",
      "Preseptal orbital cellulitis in adults is usually: a) Caused by dissemination by continuity of ethmoidal sinusitis. b) Does not cause strabismus or optic disc edema. c) Should be treated with intravenous antibiotic therapy during hospitalization. d) Its etiology is Gram-negative and anaerobic germs.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.38 ms /     7 runs   (    0.63 ms per token,  1598.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2252.85 ms /    95 tokens (   23.71 ms per token,    42.17 tokens per second)\n",
      "llama_print_timings:        eval time =   734.84 ms /     6 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3009.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.72 ms /    31 runs   (    0.60 ms per token,  1655.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3775.14 ms /    31 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3872.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.75 ms /    27 runs   (    0.58 ms per token,  1714.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3281.97 ms /    27 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3363.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.63 ms /    60 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7340.06 ms /    60 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7521.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.35 ms /    58 runs   (    0.58 ms per token,  1738.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7089.67 ms /    58 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7264.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.22 ms /     9 runs   (    0.58 ms per token,  1723.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1100.95 ms /     9 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1127.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3360.16 ms /    28 runs   (  120.01 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  3444.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.74 ms /    28 runs   (    0.60 ms per token,  1672.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3427.27 ms /    28 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3511.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.87 ms /    24 runs   (    0.58 ms per token,  1730.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2927.58 ms /    24 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2998.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.42 ms /    70 runs   (    0.58 ms per token,  1731.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8624.67 ms /    70 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8834.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A celulite orbitaria pré-septal no adulto geralmente: a) É causada por disseminação por continuidade de sinusite etmoidal. b) Não causa estrabismo ou edema de disco óptico. c) Deve ser tratada com antibioticoterapia endovenosa durante internação hospitalar. d) Tem como etiologia germes Gram-negativos e anaeróbios.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.81 ms /    27 runs   (    0.59 ms per token,  1707.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2520.44 ms /   107 tokens (   23.56 ms per token,    42.45 tokens per second)\n",
      "llama_print_timings:        eval time =  3138.95 ms /    26 runs   (  120.73 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  5740.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.17 ms /     7 runs   (  120.31 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.41 ms /    72 runs   (    0.58 ms per token,  1738.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8754.75 ms /    72 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  8970.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.36 ms /    25 runs   (    0.57 ms per token,  1740.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3024.85 ms /    25 runs   (  120.99 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3098.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1752.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.62 ms /     7 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1749.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.70 ms /     7 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   877.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.24 ms /    73 runs   (    0.58 ms per token,  1728.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8926.02 ms /    73 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9145.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.77 ms /    52 runs   (    0.57 ms per token,  1746.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6406.00 ms /    52 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6562.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   100.17 ms /   173 runs   (    0.58 ms per token,  1727.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21216.53 ms /   173 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 21761.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.31 ms /     7 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 123: \n",
      "Language: english\n",
      "Question: \n",
      "Topical or systemic application of beta-blockers presents positive therapeutic results in which orbital disease, among the following: a) Low-output carotid-cavernous fistula. b) Lymphoma associated with mucosal tissue (MALT). c) Capillary hemangioma of childhood. d) Graves orbitopathy in the acute phase.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.64 ms /    25 runs   (    0.59 ms per token,  1708.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2101.62 ms /    96 tokens (   21.89 ms per token,    45.68 tokens per second)\n",
      "llama_print_timings:        eval time =  2937.54 ms /    24 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5114.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n",
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.56 ms /    25 runs   (    0.58 ms per token,  1717.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3058.39 ms /    25 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3134.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.55 ms /    25 runs   (    0.58 ms per token,  1718.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3077.22 ms /    25 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3152.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    24 runs   (    0.58 ms per token,  1725.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2914.36 ms /    24 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2985.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1725.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3035.26 ms /    25 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3109.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.50 ms /    25 runs   (    0.58 ms per token,  1724.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3094.58 ms /    25 runs   (  123.78 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3169.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    25 runs   (    0.64 ms per token,  1562.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3044.34 ms /    25 runs   (  121.77 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3124.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.46 ms /    25 runs   (    0.58 ms per token,  1728.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3052.80 ms /    25 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3132.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1706.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.50 ms /     7 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.48 ms /    25 runs   (    0.58 ms per token,  1726.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3035.66 ms /    25 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3113.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Aplicação tópica ou sistêmica de betabloqueadores apresenta resultados terapêuticos positivos em qual doença orbitária, entre as abaixo: a) Fístula carótido-cavernosa de baixo débito. b) Linfoma associado a tecido mucoso (MALT). c) Hemangioma capilar da infância. d) Orbitopatia de Graves na fase aguda.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1706.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2009.79 ms /   110 tokens (   18.27 ms per token,    54.73 tokens per second)\n",
      "llama_print_timings:        eval time =   744.88 ms /     6 runs   (  124.15 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  2776.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1697.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.09 ms /     7 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   883.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.32 ms /     7 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   876.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   834.63 ms /     7 runs   (  119.23 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =   854.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.86 ms /     7 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3443.93 ms /    28 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3528.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1729.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.06 ms /     7 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.81 ms /     7 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1741.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.04 ms /     7 runs   (  121.01 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   867.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1723.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.94 ms /     7 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 124: \n",
      "Language: english\n",
      "Question: \n",
      "In inflammatory orbital disease associated with thyroid disorders, there is a typical ophthalmological sign, known as temporal flare, which corresponds to: a) Exotropia due to lateral rectus fibrosis. b) Chemosis and conjunctivochalasis in the lateral region of the inferior bulbar conjunctiva. c) Marked exophthalmos causing lateral dystopia of the eye. d) Pattern of eyelid retraction with the lateral region of the eyelid more retracted than the medial.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.75 ms /    28 runs   (    0.60 ms per token,  1671.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2217.51 ms /   133 tokens (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:        eval time =  3370.08 ms /    27 runs   (  124.82 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  5674.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.69 ms /    28 runs   (    0.60 ms per token,  1677.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3473.19 ms /    28 runs   (  124.04 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3560.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.25 ms /    28 runs   (    0.58 ms per token,  1723.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3536.02 ms /    28 runs   (  126.29 ms per token,     7.92 tokens per second)\n",
      "llama_print_timings:       total time =  3621.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1729.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3271.28 ms /    27 runs   (  121.16 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3351.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.29 ms /    28 runs   (    0.58 ms per token,  1718.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3459.38 ms /    28 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3543.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.65 ms /    27 runs   (    0.58 ms per token,  1725.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3275.22 ms /    27 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3358.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.17 ms /    61 runs   (    0.58 ms per token,  1734.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7463.50 ms /    61 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7647.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1733.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3315.55 ms /    27 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3395.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.73 ms /    28 runs   (    0.63 ms per token,  1578.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3432.72 ms /    28 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3524.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.24 ms /    28 runs   (    0.58 ms per token,  1724.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3440.21 ms /    28 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3524.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Na doença orbitária inflamatória associada a distúrbios da tireoide existe um sinal oftalmológico típico, conhecido como flare temporal, que corresponde a: a) Exotropia por fibrose do reto lateral. b) Quemose e conjuntivocalase na região lateral da conjuntiva bulbar inferior. c) Exoftalmia acentuada causando distopia lateral do olho. d) Padrão de retração palpebral com a região lateral da pálpebra mais retraída que a medial.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.50 ms /     9 runs   (    0.61 ms per token,  1636.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3259.48 ms /   142 tokens (   22.95 ms per token,    43.57 tokens per second)\n",
      "llama_print_timings:        eval time =   971.50 ms /     8 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4258.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1722.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3037.97 ms /    25 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3112.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   916.20 ms /     7 runs   (  130.89 ms per token,     7.64 tokens per second)\n",
      "llama_print_timings:       total time =   936.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    28 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3433.20 ms /    28 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3517.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.83 ms /    57 runs   (    0.58 ms per token,  1736.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6957.23 ms /    57 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7129.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1725.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3435.79 ms /    28 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3520.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.59 ms /    57 runs   (    0.59 ms per token,  1697.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7018.97 ms /    57 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7192.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.42 ms /     7 runs   (  121.20 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1736.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3290.83 ms /    27 runs   (  121.88 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3370.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2952.88 ms /    24 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3023.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 125: \n",
      "Language: english\n",
      "Question: \n",
      "Choose the alternative that best fills in the blank: In __________ , chronic maxillary sinusitis causes enophthalmos by collapsing the orbital floor. a) Silent sinus syndrome. b) Tolosa-Hunt syndrome. c) Mucocele. d) Fibrous dysplasia.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.97 ms /    25 runs   (    0.60 ms per token,  1670.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1918.62 ms /    81 tokens (   23.69 ms per token,    42.22 tokens per second)\n",
      "llama_print_timings:        eval time =  2896.45 ms /    24 runs   (  120.69 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  4891.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.06 ms /    33 runs   (    0.58 ms per token,  1731.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3978.34 ms /    33 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  4076.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.34 ms /    44 runs   (    0.58 ms per token,  1736.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5406.48 ms /    44 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5537.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.26 ms /    28 runs   (    0.58 ms per token,  1721.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3426.41 ms /    28 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3510.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.61 ms /    32 runs   (    0.58 ms per token,  1719.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3904.72 ms /    32 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4001.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.98 ms /    33 runs   (    0.58 ms per token,  1738.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3990.22 ms /    33 runs   (  120.92 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4089.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.03 ms /    33 runs   (    0.58 ms per token,  1734.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4022.33 ms /    33 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4120.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.00 ms /    25 runs   (    0.60 ms per token,  1667.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3059.59 ms /    25 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3135.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    24 runs   (    0.58 ms per token,  1724.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2918.60 ms /    24 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2990.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.80 ms /    24 runs   (    0.57 ms per token,  1739.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2890.32 ms /    24 runs   (  120.43 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2961.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Escolha a alternativa que melhor preencha a lacuna: Na __________ , uma sinusite maxilar crônica causa enoftalmo pelo colapso do assoalho da órbita. a) Síndrome do seio silencioso. b) Síndrome de Tolosa-Hunt. c) Mucocele. d) Displasia fibrosa.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.80 ms /    37 runs   (    0.59 ms per token,  1697.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1870.12 ms /    97 tokens (   19.28 ms per token,    51.87 tokens per second)\n",
      "llama_print_timings:        eval time =  4409.67 ms /    36 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6391.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.95 ms /    33 runs   (    0.57 ms per token,  1741.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4036.41 ms /    33 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4134.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.84 ms /    29 runs   (    0.58 ms per token,  1722.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3542.62 ms /    29 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3628.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.05 ms /    47 runs   (    0.58 ms per token,  1737.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5750.96 ms /    47 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5890.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1733.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3097.83 ms /    25 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3172.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.03 ms /    33 runs   (    0.58 ms per token,  1733.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4043.87 ms /    33 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4141.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.95 ms /     7 runs   (  120.85 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.11 ms /    47 runs   (    0.58 ms per token,  1733.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5701.65 ms /    47 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5841.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.04 ms /     7 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 126: \n",
      "Language: english\n",
      "Question: \n",
      "During the subjective refraction of the patient with low vision, the best visual acuity was obtained using a -5.00 spherical diopter -2.00 cylindrical diopter x 180° lens in the trial frame with the visual acuity table positioned at 1 m of the patient. Which of the alternatives below represents the most appropriate prescription for correction for distance? a) -3.00 spherical diopter -2.00 cylindrical diopter x 180°. b) -4.00 spherical diopter -2.00 cylindrical diopter x 180°. c) -2.00 cylindrical diopter x 180°. d) -6.00 spherical diopter -2.00 cylindrical diopter x 180°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1725.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3450.65 ms /    28 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3534.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.83 ms /    27 runs   (    0.55 ms per token,  1820.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3940.77 ms /   196 tokens (   20.11 ms per token,    49.74 tokens per second)\n",
      "llama_print_timings:        eval time =  3219.72 ms /    26 runs   (  123.84 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  7241.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.85 ms /    31 runs   (    0.54 ms per token,  1839.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3781.26 ms /    31 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3873.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.85 ms /   171 runs   (    0.57 ms per token,  1747.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21234.68 ms /   171 runs   (  124.18 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 21769.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.88 ms /   163 runs   (    0.56 ms per token,  1774.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20129.21 ms /   163 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 20636.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.85 ms /    28 runs   (    0.53 ms per token,  1885.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3461.86 ms /    28 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3545.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.44 ms /    27 runs   (    0.53 ms per token,  1869.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3315.97 ms /    27 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3396.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.57 ms /    27 runs   (    0.54 ms per token,  1853.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3286.30 ms /    27 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3367.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.46 ms /    27 runs   (    0.54 ms per token,  1866.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.85 ms /    27 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3381.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.40 ms /    29 runs   (    0.53 ms per token,  1883.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3542.52 ms /    29 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3629.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.01 ms /    28 runs   (    0.54 ms per token,  1865.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3457.67 ms /    28 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3540.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Durante a refração subjetiva do paciente com baixa visão, obteve-se a melhor acuidade visual utilizando-se lentes -5,00 dioptria esferica -2,00 dioptria cilindrica x 180° na armação de prova com a tabela de acuidade visual posicionada a 1 m do paciente. Qual dentre as alternativas abaixo representa a prescrição mais adequada da correção para longe? a) -3,00 dioptria esferica -2,00 dioptria cilindrica x 180°. b) -4,00 dioptria esferica -2,00 dioptria cilindrica x 180°. c) -2,00 dioptria cilindrica x 180°. d) -6,00 dioptria esferica -2,00 dioptria cilindrica x 180°.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.32 ms /    28 runs   (    0.58 ms per token,  1715.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4291.33 ms /   241 tokens (   17.81 ms per token,    56.16 tokens per second)\n",
      "llama_print_timings:        eval time =  3317.51 ms /    27 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7694.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.92 ms /     7 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   891.13 ms /     7 runs   (  127.30 ms per token,     7.86 tokens per second)\n",
      "llama_print_timings:       total time =   912.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.88 ms /     7 runs   (    0.55 ms per token,  1804.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   878.49 ms /     7 runs   (  125.50 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =   898.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1770.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.31 ms /     7 runs   (  121.47 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.19 ms /    20 runs   (    0.56 ms per token,  1787.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2447.50 ms /    20 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2506.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.89 ms /     7 runs   (    0.56 ms per token,  1800.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.93 ms /     7 runs   (  121.56 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.98 ms /    28 runs   (    0.57 ms per token,  1752.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3438.65 ms /    28 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3524.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.79 ms /    28 runs   (    0.56 ms per token,  1772.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3477.20 ms /    28 runs   (  124.19 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3563.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.16 ms /    20 runs   (    0.56 ms per token,  1791.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2460.92 ms /    20 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2521.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1820.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.02 ms /     7 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 127: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Regarding non-optical aids, evaluate the following statements as true (T) or false (F) and mark the correct alternative: I. Also called functional adaptation aids, they are those that modify materials and environmental conditions. II. Enlarging letters is the most common aid and reduces the spatial frequency of the image. III. The typoscope is a guide for reading whose function is to reduce the light reflected on the white paper and thus reduce glare and increase the contrast of the line of text with the background. IV. A 65-year-old patient prefers approximately three times less lighting than a 20-year-old person to perform the same tasks. a) I: True; II: False; III: True; IV: False. b) I: True; II: True; III: False; IV: True. c) I: True; II: True; III: True; IV: False. d) I: False; II: False; III: False; IV: True.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.93 ms /   144 runs   (    0.56 ms per token,  1779.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3415.09 ms /   224 tokens (   15.25 ms per token,    65.59 tokens per second)\n",
      "llama_print_timings:        eval time = 17600.56 ms /   143 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 21464.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.38 ms /   144 runs   (    0.56 ms per token,  1791.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17780.08 ms /   144 runs   (  123.47 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 18224.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.77 ms /   144 runs   (    0.56 ms per token,  1782.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17750.40 ms /   144 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 18193.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.58 ms /   144 runs   (    0.56 ms per token,  1787.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17875.14 ms /   144 runs   (  124.13 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 18318.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.22 ms /   144 runs   (    0.56 ms per token,  1794.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17913.23 ms /   144 runs   (  124.40 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 18355.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.79 ms /   144 runs   (    0.56 ms per token,  1782.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17709.31 ms /   144 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18152.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    81.12 ms /   144 runs   (    0.56 ms per token,  1775.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17875.44 ms /   144 runs   (  124.14 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 18318.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.59 ms /   144 runs   (    0.56 ms per token,  1786.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17704.24 ms /   144 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18143.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.34 ms /   144 runs   (    0.56 ms per token,  1792.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17675.15 ms /   144 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 18113.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.73 ms /   144 runs   (    0.56 ms per token,  1783.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17907.26 ms /   144 runs   (  124.36 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 18353.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre os auxílios não-ópticos, avalie as assertivas a seguir como verdadeiras (V) ou falsas (F) e assinale a alternativa correta: I. Também denominados auxílios de adaptação funcional, são aqueles que modificam materiais e condições do ambiente. II. A ampliação de letras é o auxílio mais comum e reduz a frequência espacial da imagem. III. O tiposcópio é um guia para leitura cuja função é diminuir a luz refletida sobre o papel branco e assim diminuir o ofuscamento e aumentar o contraste da linha de texto com o fundo. IV. Um paciente com 65 anos prefere aproximadamente três vezes menos iluminação que uma pessoa com 20 anos para realizar as mesmas tarefas. a) I: Verdadeiro; II: Falso; III: Verdadeiro; IV: Falso. b) I: Verdadeiro; II: Verdadeiro; III: Falso; IV: Verdadeiro. c) I: Verdadeiro; II: Verdadeiro; III: Verdadeiro; IV: Falso. d) I: Falso; II: Falso; III: Falso; IV: Verdadeiro.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.50 ms /    56 runs   (    0.56 ms per token,  1777.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  5254.18 ms /   312 tokens (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:        eval time =  6731.06 ms /    55 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12152.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.43 ms /    56 runs   (    0.54 ms per token,  1840.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6899.60 ms /    56 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7064.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.94 ms /    56 runs   (    0.55 ms per token,  1810.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6919.40 ms /    56 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  7084.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.23 ms /    56 runs   (    0.58 ms per token,  1737.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6978.24 ms /    56 runs   (  124.61 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  7150.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.72 ms /    56 runs   (    0.55 ms per token,  1823.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6920.91 ms /    56 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  7087.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.52 ms /     7 runs   (    0.50 ms per token,  1985.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.71 ms /     7 runs   (  123.96 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.32 ms /    56 runs   (    0.56 ms per token,  1787.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7029.15 ms /    56 runs   (  125.52 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  7198.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.10 ms /    56 runs   (    0.56 ms per token,  1800.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6977.06 ms /    56 runs   (  124.59 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  7146.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.41 ms /    56 runs   (    0.56 ms per token,  1783.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6994.53 ms /    56 runs   (  124.90 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  7166.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.90 ms /    56 runs   (    0.55 ms per token,  1812.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6936.38 ms /    56 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  7106.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 128: \n",
      "Language: english\n",
      "Question: \n",
      "The subjective refraction of a patient with low vision achieves the best binocular acuity for distance without the interposition of corrective lenses. At close range, the best result is achieved with the addition of +8.00 spherical diopters in both eyes. To improve comfort while reading, it was decided to prescribe spheroprismatic lenses. What is the most appropriate value of the prisms in each eye? a) 4 prismatic diopters time base. b) 4 prismatic diopters at the nasal base. c) 10 prismatic diopters time basis. d) 10 prismatic diopters at the nasal base.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.33 ms /     7 runs   (    0.62 ms per token,  1614.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2672.33 ms /   160 tokens (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:        eval time =   726.42 ms /     6 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3421.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.67 ms /   109 runs   (    0.58 ms per token,  1711.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13390.69 ms /   109 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 13730.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.40 ms /     7 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.69 ms /     7 runs   (  126.53 ms per token,     7.90 tokens per second)\n",
      "llama_print_timings:       total time =   907.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.33 ms /    95 runs   (    0.57 ms per token,  1748.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11674.74 ms /    95 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11964.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   119.21 ms /   207 runs   (    0.58 ms per token,  1736.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25542.05 ms /   207 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 26194.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.85 ms /     7 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   877.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.61 ms /   128 runs   (    0.58 ms per token,  1738.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15710.19 ms /   128 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 16103.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    86.54 ms /   150 runs   (    0.58 ms per token,  1733.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18505.29 ms /   150 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 18974.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1771.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.00 ms /     7 runs   (  121.14 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   868.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "À refração subjetiva de um paciente com visão subnormal, atinge-se a melhor acuidade binocular para distância sem a interposição de lentes corretivas. Já para perto, o melhor resultado é atingido com adição de +8,00 Dioptrias esferiacs em ambos os olhos. Para melhorar o conforto durante a leitura, optou-se por prescrever lentes esferoprismáticas. Qual o valor mais adequado dos prismas em cada olho? a) 4 Dioptrias prismaticas base temporal. b) 4 Dioptrias prismaticas base nasal. c) 10 Dioptrias prismaticas base temporal. d) 10 Dioptrias prismaticas base nasal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.33 ms /    22 runs   (    0.56 ms per token,  1784.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3712.20 ms /   198 tokens (   18.75 ms per token,    53.34 tokens per second)\n",
      "llama_print_timings:        eval time =  2560.59 ms /    21 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  6338.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.20 ms /    22 runs   (    0.55 ms per token,  1802.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2718.99 ms /    22 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  2784.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    21 runs   (    0.55 ms per token,  1819.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2558.34 ms /    21 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2619.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.74 ms /     7 runs   (    0.53 ms per token,  1872.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.46 ms /     7 runs   (  121.92 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.63 ms /    33 runs   (    0.56 ms per token,  1771.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4081.93 ms /    33 runs   (  123.69 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4179.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.50 ms /    42 runs   (    0.58 ms per token,  1714.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5174.72 ms /    42 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5301.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.78 ms /     7 runs   (    0.54 ms per token,  1853.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.42 ms /     7 runs   (  121.20 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {:response: \"A\"}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.74 ms /     7 runs   (    0.53 ms per token,  1870.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.73 ms /     7 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.82 ms /     7 runs   (    0.55 ms per token,  1830.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.17 ms /     7 runs   (  124.17 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   890.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.69 ms /     7 runs   (    0.53 ms per token,  1895.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.98 ms /     7 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.79 ms /     7 runs   (    0.54 ms per token,  1845.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.14 ms /     7 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   875.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 129: \n",
      "Language: english\n",
      "Question: \n",
      "The Credé method uses silver nitrate eye drops at what concentration? to 1%. b) 5%. c) 10%. d) 20%.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    28 runs   (    0.57 ms per token,  1750.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1003.41 ms /    42 tokens (   23.89 ms per token,    41.86 tokens per second)\n",
      "llama_print_timings:        eval time =  3272.72 ms /    27 runs   (  121.21 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4360.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.90 ms /    28 runs   (    0.57 ms per token,  1761.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3365.76 ms /    28 runs   (  120.21 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  3450.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.25 ms /    25 runs   (    0.57 ms per token,  1754.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3038.31 ms /    25 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3114.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.29 ms /    27 runs   (    0.57 ms per token,  1766.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3262.34 ms /    27 runs   (  120.83 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3344.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.87 ms /    28 runs   (    0.57 ms per token,  1764.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3384.16 ms /    28 runs   (  120.86 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3467.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.97 ms /    28 runs   (    0.57 ms per token,  1753.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3456.25 ms /    28 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3539.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.94 ms /    28 runs   (    0.57 ms per token,  1756.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3368.53 ms /    28 runs   (  120.30 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  3450.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.62 ms /    24 runs   (    0.57 ms per token,  1762.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2926.78 ms /    24 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2997.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3379.35 ms /    28 runs   (  120.69 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3462.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "O método de Credé utiliza colírio de nitrato de prata em qual concentração? a) 1%. b) 5%. c) 10%. d) 20%.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.09 ms /    30 runs   (    0.57 ms per token,  1755.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3632.92 ms /    30 runs   (  121.10 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3722.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.38 ms /    11 runs   (    0.58 ms per token,  1723.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1234.08 ms /    52 tokens (   23.73 ms per token,    42.14 tokens per second)\n",
      "llama_print_timings:        eval time =  1222.62 ms /    10 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2489.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) 5%'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.48 ms /    32 runs   (    0.58 ms per token,  1731.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3888.72 ms /    32 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3985.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) 5%'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3388.61 ms /    28 runs   (  121.02 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3472.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    28 runs   (    0.57 ms per token,  1749.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3423.17 ms /    28 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3505.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.17 ms /    32 runs   (    0.60 ms per token,  1669.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3887.76 ms /    32 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3983.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.91 ms /    33 runs   (    0.57 ms per token,  1744.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4002.54 ms /    33 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4098.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) 5%'}\n",
      "Test #6: \n",
      "{'response': 'b) 5%'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.84 ms /    31 runs   (    0.58 ms per token,  1738.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3844.16 ms /    31 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3934.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.23 ms /    11 runs   (    0.57 ms per token,  1765.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1354.79 ms /    11 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  1386.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) 5%'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.25 ms /    11 runs   (    0.57 ms per token,  1758.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1317.37 ms /    11 runs   (  119.76 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =  1349.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) 5%'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 130: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Which of the topical drugs below is most indicated for the initial treatment of fungal keratitis caused by Fusarium? a) Terbinafine. b) Natamycin. c) Miconazole. d) Amphotericin B.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.01 ms /    28 runs   (    0.57 ms per token,  1749.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3417.15 ms /    28 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3500.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.35 ms /    30 runs   (    0.58 ms per token,  1728.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1597.44 ms /    67 tokens (   23.84 ms per token,    41.94 tokens per second)\n",
      "llama_print_timings:        eval time =  3523.56 ms /    29 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5211.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.97 ms /    33 runs   (    0.57 ms per token,  1739.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3997.42 ms /    33 runs   (  121.13 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4095.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2976.97 ms /    24 runs   (  124.04 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3047.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.67 ms /     7 runs   (    0.67 ms per token,  1497.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.04 ms /     7 runs   (  120.15 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   863.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    28 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3414.55 ms /    28 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3497.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.65 ms /    34 runs   (    0.58 ms per token,  1730.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4156.02 ms /    34 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4256.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.42 ms /    30 runs   (    0.58 ms per token,  1721.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3648.33 ms /    30 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3739.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.86 ms /    31 runs   (    0.58 ms per token,  1735.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3744.66 ms /    31 runs   (  120.80 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3837.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1737.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3398.38 ms /    28 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3480.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3294.28 ms /    27 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3374.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das drogas de uso tópico, abaixo, é a mais indicada para o tratamento inicial de ceratite fúngica causada por Fusarium? a) Terbinafina. b) Natamicina. c) Miconazol. d) Anfotericina B.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.50 ms /    23 runs   (    0.59 ms per token,  1703.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1948.04 ms /    76 tokens (   25.63 ms per token,    39.01 tokens per second)\n",
      "llama_print_timings:        eval time =  2642.84 ms /    22 runs   (  120.13 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  4660.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.93 ms /    32 runs   (    0.59 ms per token,  1690.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3961.53 ms /    32 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4058.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1740.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2049.54 ms /    17 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2099.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.80 ms /    24 runs   (    0.58 ms per token,  1739.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2896.80 ms /    24 runs   (  120.70 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2967.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c) Miconazol.'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.12 ms /    35 runs   (    0.57 ms per token,  1739.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4243.66 ms /    35 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4347.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.53 ms /    20 runs   (    0.58 ms per token,  1735.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2440.28 ms /    20 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2498.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.39 ms /     7 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1755.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.45 ms /     7 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.64 ms /     7 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.55 ms /    20 runs   (    0.58 ms per token,  1731.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2409.78 ms /    20 runs   (  120.49 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2470.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 131: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding penetrating corneal transplantation performed in children under two years of age. a) Typically, healing between the bed and the graft occurs more slowly than in adults. b) The incidence of rejection is significantly lower than that observed in adult transplants. c) In an uneventful postoperative period, suture removal should occur earlier than in adults. d) Generally, large grafts with more than 10 mm in diameter are used.\n",
      "\n",
      "Test #0: \n",
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.55 ms /    25 runs   (    0.58 ms per token,  1718.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1915.06 ms /   116 tokens (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:        eval time =  2922.60 ms /    24 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4914.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.60 ms /    25 runs   (    0.58 ms per token,  1711.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3053.69 ms /    25 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3129.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.66 ms /    55 runs   (    0.58 ms per token,  1737.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6768.66 ms /    55 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6936.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.59 ms /    81 runs   (    0.58 ms per token,  1738.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9885.95 ms /    81 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 10131.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    89.37 ms /   154 runs   (    0.58 ms per token,  1723.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18914.45 ms /   154 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 19393.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.71 ms /    97 runs   (    0.57 ms per token,  1741.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11885.37 ms /    97 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 12188.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.19 ms /    42 runs   (    0.58 ms per token,  1736.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5157.99 ms /    42 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5284.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.18 ms /    47 runs   (    0.58 ms per token,  1729.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5717.47 ms /    47 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5858.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.22 ms /    96 runs   (    0.58 ms per token,  1738.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11844.59 ms /    96 runs   (  123.38 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 12137.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.20 ms /    42 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5161.47 ms /    42 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5288.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa correta com relação ao transplante penetrante de córnea realizado em crianças abaixo de dois anos de idade. a) Tipicamente, a cicatrização entre o leito e o enxerto ocorre mais lentamente do que no adulto. b) A incidência de rejeição é significativamente menor que a observada nos transplantes de adultos. c) Em um pós-operatório sem intercorrências, a remoção das suturas deve ocorrer mais precocemente do que nos adultos. d) Geralmente são utilizados enxertos grandes, com mais de 10 mm de diâmetro.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.72 ms /    67 runs   (    0.58 ms per token,  1730.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3373.37 ms /   169 tokens (   19.96 ms per token,    50.10 tokens per second)\n",
      "llama_print_timings:        eval time =  8150.26 ms /    66 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 11728.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.29 ms /   100 runs   (    0.57 ms per token,  1745.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12347.66 ms /   100 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 12652.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.71 ms /   106 runs   (    0.57 ms per token,  1746.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13089.99 ms /   106 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13413.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.35 ms /    53 runs   (    0.57 ms per token,  1746.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6536.07 ms /    53 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  6696.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.45 ms /    64 runs   (    0.57 ms per token,  1755.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7873.60 ms /    64 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8069.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1771.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.80 ms /     7 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.14 ms /    25 runs   (    0.57 ms per token,  1767.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3068.59 ms /    25 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3143.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1763.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.31 ms /     7 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.30 ms /    60 runs   (    0.57 ms per token,  1749.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7425.12 ms /    60 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  7604.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.29 ms /    20 runs   (    0.56 ms per token,  1771.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2484.88 ms /    20 runs   (  124.24 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  2544.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 132: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding posterior lamellar corneal transplantation using the \"DSEK\" technique (Descemet Stripping Endothelial Keratoplasty): a) Immediately after the surgery, the patient must remain in the prone position for about twenty to thirty minutes. b) Only endothelium and Descemet's membrane are grafted into the recipient eye. c) Diffuse lamellar keratitis (also known as \"sands of the Sahara syndrome\"), is a complication of this procedure. d) The presence of a correctly positioned lamella will probably induce a positive spherical degree that will be added to the patient's previous refraction (\"hypermetropic shift\").\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.35 ms /   195 runs   (    0.58 ms per token,  1720.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3056.49 ms /   172 tokens (   17.77 ms per token,    56.27 tokens per second)\n",
      "llama_print_timings:        eval time = 24001.48 ms /   194 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 27685.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #1: \n",
      "{'response': 'D'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.56 ms /   195 runs   (    0.58 ms per token,  1732.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23982.14 ms /   195 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 24593.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.26 ms /   195 runs   (    0.58 ms per token,  1736.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24080.21 ms /   195 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 24691.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.97 ms /    74 runs   (    0.58 ms per token,  1722.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9145.75 ms /    74 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  9376.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.06 ms /   191 runs   (    0.59 ms per token,  1704.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23474.63 ms /   191 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 24083.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.66 ms /   195 runs   (    0.58 ms per token,  1715.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24195.68 ms /   195 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 24808.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.80 ms /   105 runs   (    0.58 ms per token,  1727.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12930.36 ms /   105 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 13249.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.13 ms /    35 runs   (    0.58 ms per token,  1738.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4283.97 ms /    35 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4387.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.09 ms /   195 runs   (    0.58 ms per token,  1724.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24031.98 ms /   195 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 24641.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.27 ms /   195 runs   (    0.58 ms per token,  1736.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24149.35 ms /   195 runs   (  123.84 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 24766.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa correta com relação ao transplante de córnea lamelar posterior pela técnica \"DSEK\" (Descemet Stripping Endothelial Keratoplasty): a) Imediatamente após a cirurgia o paciente deve permanecer em decúbito ventral por cerca de vinte a trinta minutos. b) Apenas endotélio e membrana de Descemet são enxertados no olho receptor. c) Ceratite lamelar difusa (também conhecida como \"síndrome das areias do Saara\"), é uma complicação desse procedimento. d) A presença da lamela corretamente posicionada provavelmente induzirá grau esférico positivo que se somará à refração prévia do paciente (\"shift hipermetrópico\").\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.40 ms /     7 runs   (    0.63 ms per token,  1591.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4285.70 ms /   209 tokens (   20.51 ms per token,    48.77 tokens per second)\n",
      "llama_print_timings:        eval time =   736.95 ms /     6 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5043.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.24 ms /     7 runs   (    0.61 ms per token,  1649.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.60 ms /     7 runs   (  123.23 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   884.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.65 ms /    49 runs   (    0.58 ms per token,  1710.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6018.40 ms /    49 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6170.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.28 ms /   124 runs   (    0.58 ms per token,  1715.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15318.84 ms /   124 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15710.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.23 ms /     7 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1739.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.23 ms /     7 runs   (  120.75 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   865.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.07 ms /    47 runs   (    0.58 ms per token,  1736.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5799.74 ms /    47 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  5941.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.21 ms /     7 runs   (  124.46 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   891.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   873.29 ms /     7 runs   (  124.76 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =   894.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1693.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.32 ms /     7 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 133: \n",
      "Language: english\n",
      "Question: \n",
      "Paralysis of the fifth cranial nerve can trigger in the cornea, most commonly: a) Neurotrophic ulcer. b) Disciform endothelitis. c) Exposure keratitis. d) Interstitial keratitis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.25 ms /    36 runs   (    0.59 ms per token,  1693.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1589.15 ms /    65 tokens (   24.45 ms per token,    40.90 tokens per second)\n",
      "llama_print_timings:        eval time =  4264.51 ms /    35 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5964.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.03 ms /    25 runs   (    0.60 ms per token,  1663.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3100.07 ms /    25 runs   (  124.00 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3176.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.66 ms /    15 runs   (    0.58 ms per token,  1731.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1830.01 ms /    15 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1875.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.73 ms /    36 runs   (    0.58 ms per token,  1736.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4363.96 ms /    36 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4471.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.30 ms /    35 runs   (    0.58 ms per token,  1723.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4257.12 ms /    35 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4362.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.71 ms /    36 runs   (    0.58 ms per token,  1738.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4400.54 ms /    36 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4507.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.73 ms /    36 runs   (    0.58 ms per token,  1736.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4385.01 ms /    36 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4492.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1739.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3022.39 ms /    25 runs   (  120.90 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3096.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.75 ms /    36 runs   (    0.58 ms per token,  1735.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4390.29 ms /    36 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4498.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2464.22 ms /    20 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2523.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paralisia do quinto nervo craniano pode desencadear na córnea, mais comumente: a) Úlcera neurotrófica. b) Endotelite disciforme. c) Ceratite de exposição. d) Ceratite intersticial.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.86 ms /    89 runs   (    0.58 ms per token,  1716.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1563.62 ms /    69 tokens (   22.66 ms per token,    44.13 tokens per second)\n",
      "llama_print_timings:        eval time = 10778.33 ms /    88 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 12613.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.39 ms /    32 runs   (    0.57 ms per token,  1740.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3908.10 ms /    32 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4002.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.89 ms /    45 runs   (    0.58 ms per token,  1738.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5427.65 ms /    45 runs   (  120.61 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  5562.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.81 ms /     7 runs   (  120.54 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3459.59 ms /    28 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3542.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.16 ms /    16 runs   (    0.57 ms per token,  1747.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1981.74 ms /    16 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2028.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.98 ms /    26 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3151.72 ms /    26 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3228.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.79 ms /    36 runs   (    0.58 ms per token,  1731.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4360.99 ms /    36 runs   (  121.14 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4469.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.46 ms /    32 runs   (    0.58 ms per token,  1733.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3870.00 ms /    32 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3965.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.28 ms /    44 runs   (    0.57 ms per token,  1740.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5353.19 ms /    44 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5485.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 134: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding congenital and hereditary corneal endothelial dystrophy, it is correct to state: a) The most common pattern of transmission is the dominant autosomal one. b) Most patients have associated nystagmus and, rarely, glaucoma. c) Patients usually present with intense photophobia and epiphora immediately after birth. d) It is usually unilateral, with progressive increase in corneal opacity from birth onwards.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.13 ms /    24 runs   (    0.59 ms per token,  1698.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2743.45 ms /   115 tokens (   23.86 ms per token,    41.92 tokens per second)\n",
      "llama_print_timings:        eval time =  2787.71 ms /    23 runs   (  121.20 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5603.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.13 ms /    21 runs   (    0.58 ms per token,  1730.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2562.95 ms /    21 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2625.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.11 ms /    21 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2591.04 ms /    21 runs   (  123.38 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  2653.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.16 ms /    21 runs   (    0.58 ms per token,  1726.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2609.59 ms /    21 runs   (  124.27 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  2672.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.58 ms /    46 runs   (    0.58 ms per token,  1730.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5647.82 ms /    46 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5785.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.19 ms /    21 runs   (    0.58 ms per token,  1723.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2546.85 ms /    21 runs   (  121.28 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2610.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.09 ms /    21 runs   (    0.58 ms per token,  1737.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2537.66 ms /    21 runs   (  120.84 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2600.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    25 runs   (    0.58 ms per token,  1728.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3049.73 ms /    25 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3126.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.16 ms /    21 runs   (    0.58 ms per token,  1726.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2546.70 ms /    21 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2609.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.08 ms /    21 runs   (    0.58 ms per token,  1737.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2571.30 ms /    21 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2634.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação à distrofia endotelial congênita e hereditária da córnea, é correto afirmar: a) O padrão de transmissão mais comum é o autossômico dominante. b) A maioria dos pacientes apresenta nistagmo associado e, raramente, glaucoma. c) Os pacientes costumam apresentar intensa fotofobia e epífora imediatamente após o nascimento. d) Geralmente é unilateral, com aumento progressivo da opacidade da córnea a partir do nascimento.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    96.23 ms /   165 runs   (    0.58 ms per token,  1714.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2564.91 ms /   150 tokens (   17.10 ms per token,    58.48 tokens per second)\n",
      "llama_print_timings:        eval time = 20215.53 ms /   164 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 23297.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.34 ms /   205 runs   (    0.58 ms per token,  1732.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25336.58 ms /   205 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 25981.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.60 ms /     7 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    25 runs   (    0.58 ms per token,  1734.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3063.56 ms /    25 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3138.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    90.99 ms /   157 runs   (    0.58 ms per token,  1725.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19370.41 ms /   157 runs   (  123.38 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 19861.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   125.32 ms /   217 runs   (    0.58 ms per token,  1731.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26770.26 ms /   217 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 27455.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.53 ms /    20 runs   (    0.58 ms per token,  1735.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2455.21 ms /    20 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2514.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   131.95 ms /   217 runs   (    0.61 ms per token,  1644.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26849.55 ms /   217 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 27927.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.61 ms /     7 runs   (    0.66 ms per token,  1520.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.83 ms /     7 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   916.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.27 ms /    20 runs   (    0.66 ms per token,  1507.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2444.62 ms /    20 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2582.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 135: \n",
      "Language: english\n",
      "Question: \n",
      "In a patient with bullous keratopathy and corneal edema secondary to endothelial insufficiency, which of the following topical products should be avoided?\n",
      "a) Sodium hyaluronate.\n",
      "b) Sodium chloride.\n",
      "c) Inhibitors of carbonic anhydrase.\n",
      "d) Cyclopentolate.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    78.85 ms /   131 runs   (    0.60 ms per token,  1661.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2131.49 ms /    92 tokens (   23.17 ms per token,    43.16 tokens per second)\n",
      "llama_print_timings:        eval time = 15846.72 ms /   130 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 18589.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.17 ms /    93 runs   (    0.58 ms per token,  1716.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11319.35 ms /    93 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time = 11608.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.27 ms /   102 runs   (    0.58 ms per token,  1720.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12546.20 ms /   102 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 12862.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.38 ms /    92 runs   (    0.58 ms per token,  1723.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11189.16 ms /    92 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time = 11471.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.73 ms /    90 runs   (    0.57 ms per token,  1739.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11060.24 ms /    90 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11335.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.20 ms /    37 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4534.58 ms /    37 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4645.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.62 ms /    20 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2451.68 ms /    20 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2511.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.65 ms /    93 runs   (    0.58 ms per token,  1733.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11414.43 ms /    93 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 11700.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.43 ms /    93 runs   (    0.57 ms per token,  1740.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11342.75 ms /    93 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 11626.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.73 ms /    93 runs   (    0.58 ms per token,  1731.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11432.07 ms /    93 runs   (  122.93 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11718.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Em paciente com ceratopatia bolhosa e edema de córnea secundário à insuficiência endotelial, qual dos produtos de uso tópico, dentre os abaixo, deve ser evitado?\n",
      "a)Hialuronato de sódio.\n",
      "b)Cloreto de sódio.\n",
      "c)Inibidores da anidrase carbônica.\n",
      "d)Ciclopentolato.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.53 ms /    62 runs   (    0.59 ms per token,  1697.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2198.89 ms /   111 tokens (   19.81 ms per token,    50.48 tokens per second)\n",
      "llama_print_timings:        eval time =  7454.63 ms /    61 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9844.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.42 ms /    86 runs   (    0.57 ms per token,  1740.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10499.55 ms /    86 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 10761.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.91 ms /     7 runs   (    0.56 ms per token,  1791.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.59 ms /     7 runs   (  119.80 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =   859.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.55 ms /   107 runs   (    0.58 ms per token,  1738.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13128.20 ms /   107 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 13454.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.88 ms /    73 runs   (    0.57 ms per token,  1743.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8996.27 ms /    73 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9216.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.88 ms /     7 runs   (    0.55 ms per token,  1805.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   880.10 ms /     7 runs   (  125.73 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =   900.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.60 ms /     7 runs   (  125.09 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   897.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1766.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.22 ms /     7 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.93 ms /     7 runs   (    0.56 ms per token,  1780.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.60 ms /     7 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.91 ms /     7 runs   (    0.56 ms per token,  1790.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.33 ms /     7 runs   (  125.05 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =   895.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 136: \n",
      "Language: english\n",
      "Question: \n",
      "Palpebral infestation by Phtirus pubis, can be preferably treated with which of the options below?\n",
      "\n",
      "a) Doxycycline orally.\n",
      "b) Tea tree oil-based shampoo.\n",
      "c) Multiple sessions of application of high-intensity regulated pulsed light (IRPL) in the periocular region.\n",
      "d) Ivermectin orally. \n",
      "d) Cyclopentolate.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.25 ms /    33 runs   (    0.58 ms per token,  1714.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2277.87 ms /   109 tokens (   20.90 ms per token,    47.85 tokens per second)\n",
      "llama_print_timings:        eval time =  3922.21 ms /    32 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6299.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.76 ms /    24 runs   (    0.57 ms per token,  1744.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2926.61 ms /    24 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2997.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.32 ms /    70 runs   (    0.58 ms per token,  1736.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8696.33 ms /    70 runs   (  124.23 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  8909.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.59 ms /    34 runs   (    0.58 ms per token,  1735.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4169.58 ms /    34 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4271.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.77 ms /     7 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   883.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.84 ms /     7 runs   (  120.41 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.25 ms /    37 runs   (    0.57 ms per token,  1741.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4516.61 ms /    37 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4627.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.38 ms /    25 runs   (    0.58 ms per token,  1738.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3097.05 ms /    25 runs   (  123.88 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3171.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.57 ms /    34 runs   (    0.58 ms per token,  1737.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4155.42 ms /    34 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4256.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Ivermectin orally.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.80 ms /    34 runs   (    0.58 ms per token,  1716.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4133.75 ms /    34 runs   (  121.58 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4234.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Infestação palpebral pelo Phtirus pubis, pode ser tratada, preferencialmente, com qual das opções abaixo?\n",
      "\n",
      "a)Doxiciclina via oral.\n",
      "b)Xampu a base de óleo de melaleuca (tea tree oil).\n",
      "c)Múltiplas sessões de aplicação de luz pulsada regulada, de alta intensidade (IRPL), na região periocular.\n",
      "d)Ivermectina via oral.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.18 ms /     7 runs   (    0.60 ms per token,  1673.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2421.01 ms /   124 tokens (   19.52 ms per token,    51.22 tokens per second)\n",
      "llama_print_timings:        eval time =   735.05 ms /     6 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3177.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1709.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.73 ms /     7 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.01 ms /    69 runs   (    0.58 ms per token,  1724.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8489.62 ms /    69 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8702.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2918.18 ms /    24 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2990.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   840.46 ms /     7 runs   (  120.07 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =   861.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.84 ms /    69 runs   (    0.58 ms per token,  1731.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8438.59 ms /    69 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  8650.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.17 ms /    87 runs   (    0.58 ms per token,  1734.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10632.52 ms /    87 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 10898.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.08 ms /     7 runs   (  121.58 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.60 ms /    69 runs   (    0.57 ms per token,  1742.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8513.71 ms /    69 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8725.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.64 ms /    69 runs   (    0.57 ms per token,  1740.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8454.02 ms /    69 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8663.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 137: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the manifestations of conjunctivitis, it is correct to state:\n",
      "a) In vernal keratoconjunctivitis, papillary hypertrophy often occurs in both the upper and lower tarsal conjunctiva, with similar appearance and intensity.\n",
      "b) In giant papillary conjunctivitis secondary to the use of ocular prostheses, contact lenses and suture threads, the lower tarsal conjunctiva rarely presents papillary hypertrophy.\n",
      "c) In atopic dermatokeratoconjunctivitis, papillary hypertrophy characteristically occurs in the upper tarsal conjunctiva.\n",
      "d) Perennial allergic conjunctivitis often develops papillae, usually located in the upper tarsal conjunctiva, with a diameter greater than one millimeter.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.56 ms /    63 runs   (    0.58 ms per token,  1723.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3300.10 ms /   191 tokens (   17.28 ms per token,    57.88 tokens per second)\n",
      "llama_print_timings:        eval time =  7659.26 ms /    62 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 11151.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.60 ms /    60 runs   (    0.58 ms per token,  1734.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7423.01 ms /    60 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  7602.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.66 ms /    43 runs   (    0.57 ms per token,  1743.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5272.90 ms /    43 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5400.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.46 ms /    53 runs   (    0.57 ms per token,  1740.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6559.59 ms /    53 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6719.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.18 ms /     7 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   868.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.49 ms /    28 runs   (    0.59 ms per token,  1698.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3467.42 ms /    28 runs   (  123.84 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3552.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.82 ms /    53 runs   (    0.58 ms per token,  1719.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6523.41 ms /    53 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6682.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.90 ms /    53 runs   (    0.58 ms per token,  1715.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6522.31 ms /    53 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6684.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.62 ms /    53 runs   (    0.58 ms per token,  1730.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6506.32 ms /    53 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6666.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação às manifestações das conjuntivites, é correto afirmar:\n",
      "a)Na ceratoconjuntivite vernal, a hipertrofia papilar ocorre frequentemente tanto na conjuntiva tarsal superior quanto na inferior, com aspecto e intensidade semelhantes.\n",
      "b)Na conjuntivite papilar gigante secundária ao uso de próteses oculares, lentes de contato e fios de sutura, raramente a conjuntiva tarsal inferior apresenta hipertrofia papilar.\n",
      "c)Na dermatoceratoconjuntivite atópica a hipertrofia papilar ocorre caracteristicamente na conjuntiva tarsal superior.\n",
      "d)Conjuntivite alérgica perene frequentemente desenvolve papilas, localizadas geralmente na conjuntiva tarsal superior, com diâmetro superior a um milímetro.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1728.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2954.59 ms /    24 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3026.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.14 ms /    63 runs   (    0.59 ms per token,  1696.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4380.33 ms /   225 tokens (   19.47 ms per token,    51.37 tokens per second)\n",
      "llama_print_timings:        eval time =  7649.17 ms /    62 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 12224.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.94 ms /    24 runs   (    0.58 ms per token,  1721.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2996.82 ms /    24 runs   (  124.87 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3069.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.64 ms /    20 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2453.33 ms /    20 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2513.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.06 ms /    45 runs   (    0.58 ms per token,  1726.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5527.02 ms /    45 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5664.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.95 ms /    45 runs   (    0.58 ms per token,  1733.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5516.41 ms /    45 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5652.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "Error converting respose to json: {:response: \"c\"}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.97 ms /     7 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   878.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.92 ms /     7 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.53 ms /     7 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.91 ms /     7 runs   (  125.13 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   896.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {'response': 'A'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.58 ms /     7 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   877.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1717.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.74 ms /     7 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 138: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding adenoviral conjunctivitis, it is correct to state:\n",
      "a) The removal of pseudomembranes is associated with a higher risk of symblepharon formation and therefore should be avoided.\n",
      "b) Use of low-concentration topical corticosteroids is indicated to prevent the appearance of pseudomembranes, and therefore, they are prescribed soon after the onset of symptoms.\n",
      "c) Topical corticosteroids, used in the acute phase, favor viral replication with increased viral load on the ocular surface.\n",
      "d) Controlled studies have shown the effectiveness of using ketorolac 0.5% in the acute phase of conjunctivitis to relieve symptoms, with a reduction in the duration of the contagion period, compared to the use of lubricating eye drops.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.38 ms /     7 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.42 ms /    77 runs   (    0.59 ms per token,  1695.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3548.77 ms /   196 tokens (   18.11 ms per token,    55.23 tokens per second)\n",
      "llama_print_timings:        eval time =  9358.80 ms /    76 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 13145.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.59 ms /    17 runs   (    0.74 ms per token,  1350.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2100.30 ms /    17 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  2158.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n",
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.67 ms /    24 runs   (    0.69 ms per token,  1439.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3014.93 ms /    24 runs   (  125.62 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  3096.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    25 runs   (    0.62 ms per token,  1602.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3047.20 ms /    25 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3129.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.91 ms /    70 runs   (    0.67 ms per token,  1492.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8637.71 ms /    70 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8869.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.64 ms /    20 runs   (    0.58 ms per token,  1718.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2457.66 ms /    20 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2522.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n",
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1737.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2119.57 ms /    17 runs   (  124.68 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  2170.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    90.86 ms /   158 runs   (    0.58 ms per token,  1738.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19501.14 ms /   158 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 19994.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    98.88 ms /   171 runs   (    0.58 ms per token,  1729.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21196.51 ms /   171 runs   (  123.96 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 21730.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.26 ms /    25 runs   (    0.57 ms per token,  1752.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3129.88 ms /    25 runs   (  125.20 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  3204.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação às conjuntivites adenovirais, é correto afirmar:\n",
      "a)A remoção de pseudomembranas está associada a maior risco de formação de simbléfaro e por isso deve ser evitada.\n",
      "b)Uso de corticosteroides tópicos de baixa concentração está indicado para prevenção do aparecimento de pseudomembranas, e por isso, eles são prescritos logo após o início dos sintomas.\n",
      "c)Corticosteroides tópicos, utilizados na fase aguda, favorecem replicação viral com aumento da carga viral na superfície ocular.\n",
      "d)Estudos controlados demonstraram eficácia do uso do cetorolaco 0,5% na fase aguda da conjuntivite para alívio dos sintomas, com redução da duração do período de contágio, em comparação ao uso de colírios lubrificantes.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1703.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4234.74 ms /   240 tokens (   17.64 ms per token,    56.67 tokens per second)\n",
      "llama_print_timings:        eval time =   741.14 ms /     6 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  4997.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.27 ms /    28 runs   (    0.58 ms per token,  1721.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3449.38 ms /    28 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3535.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1709.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   899.81 ms /     7 runs   (  128.54 ms per token,     7.78 tokens per second)\n",
      "llama_print_timings:       total time =   921.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.22 ms /   100 runs   (    0.58 ms per token,  1717.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12455.14 ms /   100 runs   (  124.55 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time = 12768.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   897.07 ms /     7 runs   (  128.15 ms per token,     7.80 tokens per second)\n",
      "llama_print_timings:       total time =   918.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n",
      "{'response': 'D'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.96 ms /   127 runs   (    0.57 ms per token,  1740.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15626.57 ms /   127 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 16021.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.93 ms /   127 runs   (    0.57 ms per token,  1741.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15721.23 ms /   127 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 16111.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.40 ms /    87 runs   (    0.58 ms per token,  1726.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10796.03 ms /    87 runs   (  124.09 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 11063.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.86 ms /     7 runs   (  126.55 ms per token,     7.90 tokens per second)\n",
      "llama_print_timings:       total time =   906.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.51 ms /     7 runs   (    0.64 ms per token,  1552.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.34 ms /     7 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   881.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 139: \n",
      "Language: english\n",
      "Question: \n",
      "Considering corneal transplants performed for optical purposes, what is the most appropriate association?\n",
      "\n",
      "I. Fuchs dystrophy.\n",
      "II. granular dystrophy.\n",
      "III. Opacity after hydrops.\n",
      "IV. bullous keratopathy.\n",
      "\n",
      "A- Indication for posterior lamellar transplantation.\n",
      "B- Contraindication for performing a deep anterior lamellar transplant.\n",
      "C- Contraindication for performing a superficial anterior lamellar transplant.\n",
      "D- Indication for deep anterior lamellar transplantation.\n",
      "\n",
      "a) I: A, II: B, III: D, IV: C.\n",
      "b) I: B, II: D, III: C, IV: A.\n",
      "c) I: C, II: A, III: D, IV: B.\n",
      "d) I: D, II: C, III: A, IV: B.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.01 ms /    51 runs   (    0.57 ms per token,  1758.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3503.31 ms /   221 tokens (   15.85 ms per token,    63.08 tokens per second)\n",
      "llama_print_timings:        eval time =  6176.84 ms /    50 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  9835.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #1: \n",
      "{'response': 'D'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.96 ms /    50 runs   (    0.56 ms per token,  1788.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6174.92 ms /    50 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6326.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.75 ms /    53 runs   (    0.56 ms per token,  1781.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6518.94 ms /    53 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6677.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.01 ms /    50 runs   (    0.58 ms per token,  1723.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6144.90 ms /    50 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6299.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.31 ms /    51 runs   (    0.56 ms per token,  1801.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6261.00 ms /    51 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6417.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.43 ms /    50 runs   (    0.63 ms per token,  1590.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6156.06 ms /    50 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6313.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.49 ms /    75 runs   (    0.57 ms per token,  1765.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9211.10 ms /    75 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  9438.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.80 ms /    27 runs   (    0.55 ms per token,  1824.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3320.52 ms /    27 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3401.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.50 ms /    49 runs   (    0.56 ms per token,  1782.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6016.66 ms /    49 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6166.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.89 ms /    48 runs   (    0.56 ms per token,  1784.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5918.11 ms /    48 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  6061.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Considerando os transplantes de córnea realizados com finalidade óptica, qual a associação mais adequada?\n",
      "\n",
      "I. Distrofia de Fuchs.\n",
      "II. Distrofia granular.\n",
      "III. Opacidade após hidrópsia.\n",
      "IV. Ceratopatia bolhosa.\n",
      "\n",
      "A- Indicação para realização de transplante lamelar posterior.\n",
      "B- Contraindicação para a realização de transplante lamelar anterior profundo.\n",
      "C- Contraindicação para realização de transplante lamelar anterior superficial.\n",
      "D- Indicação para a realização de transplante lamelar anterior profundo.\n",
      "\n",
      "a)I: A, II: B, III: D, IV: C.\n",
      "b)I: B, II: D, III: C, IV: A.\n",
      "c)I: C, II: A, III: D, IV: B.\n",
      "d)I: D, II: C, III: A, IV: B.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.86 ms /   120 runs   (    0.57 ms per token,  1742.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4739.18 ms /   246 tokens (   19.26 ms per token,    51.91 tokens per second)\n",
      "llama_print_timings:        eval time = 14669.78 ms /   119 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 19780.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.53 ms /     7 runs   (    0.50 ms per token,  1984.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.12 ms /     7 runs   (  122.73 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #2: \n",
      "{'response': 'D'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.13 ms /    54 runs   (    0.56 ms per token,  1792.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6673.67 ms /    54 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  6837.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.59 ms /    74 runs   (    0.58 ms per token,  1737.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9129.90 ms /    74 runs   (  123.38 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9356.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.64 ms /   120 runs   (    0.56 ms per token,  1774.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14841.51 ms /   120 runs   (  123.68 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15214.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.98 ms /    52 runs   (    0.56 ms per token,  1794.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6378.41 ms /    52 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6535.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.41 ms /    53 runs   (    0.55 ms per token,  1802.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6654.85 ms /    53 runs   (  125.56 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  6816.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.33 ms /    20 runs   (    0.52 ms per token,  1936.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2449.12 ms /    20 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2508.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    27 runs   (    0.54 ms per token,  1861.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3342.39 ms /    27 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3423.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.05 ms /    54 runs   (    0.56 ms per token,  1796.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6721.60 ms /    54 runs   (  124.47 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  6885.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 140: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding ophthalmic herpes zoster, it is correct to state:\n",
      "a) In the treatment of immunocompetent adult patients when performed with valaciclovir, a total daily dose of 3 g is used.\n",
      "b) Disciform endothelitis, followed by neurotrophic ulcer, are the two most frequent clinical manifestations of corneal involvement, considering the first two months after the onset of infection.\n",
      "c) Hutchinson's sign indicates involvement of the maxillary and mandibular branches of the trigeminal nerve and indicates an increased probability of ocular involvement during infection.\n",
      "d) A single dermatome will be affected in the same occurrence of the infection.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.93 ms /    82 runs   (    0.58 ms per token,  1710.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3617.58 ms /   170 tokens (   21.28 ms per token,    46.99 tokens per second)\n",
      "llama_print_timings:        eval time = 10011.26 ms /    81 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 13882.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.59 ms /    71 runs   (    0.57 ms per token,  1749.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8740.05 ms /    71 runs   (  123.10 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8957.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.25 ms /    67 runs   (    0.57 ms per token,  1751.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8363.36 ms /    67 runs   (  124.83 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  8566.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.19 ms /    67 runs   (    0.57 ms per token,  1754.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8275.78 ms /    67 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8478.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.86 ms /    66 runs   (    0.57 ms per token,  1743.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8251.51 ms /    66 runs   (  125.02 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  8454.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.50 ms /    67 runs   (    0.57 ms per token,  1740.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8268.34 ms /    67 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8470.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.43 ms /    67 runs   (    0.57 ms per token,  1743.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8273.41 ms /    67 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8476.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.29 ms /    73 runs   (    0.58 ms per token,  1726.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8923.84 ms /    73 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9144.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2986.63 ms /    24 runs   (  124.44 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3057.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.75 ms /     7 runs   (  124.39 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação ao herpes zoster oftálmico, é correto afirmar:\n",
      "a)No tratamento de pacientes adultos imunocompetentes quando realizado com o valaciclovir, é utilizada a dose total diária de 3 g.\n",
      "b)A endotelite disciforme, seguida da úlcera neurotrófica, são as duas manifestações clínicas mais frequentes do comprometimento da córnea, considerando os dois primeiros meses após o início da infecção.\n",
      "c)O sinal de Hutchinson indica comprometimento dos ramos maxilar e mandibular do nervo trigêmeo e sinaliza aumento de probabilidade do acometimento ocular durante a infecção.\n",
      "d)Um único dermátomo será acometido numa mesma ocorrência da infecção.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.28 ms /     7 runs   (    0.61 ms per token,  1634.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4203.39 ms /   209 tokens (   20.11 ms per token,    49.72 tokens per second)\n",
      "llama_print_timings:        eval time =   739.83 ms /     6 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4964.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.14 ms /     7 runs   (    0.59 ms per token,  1692.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.82 ms /     7 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1700.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   876.96 ms /     7 runs   (  125.28 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =   898.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.00 ms /     7 runs   (  121.14 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   868.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1764.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.62 ms /     7 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1725.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.35 ms /     7 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1754.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.24 ms /     7 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {'response': 'b'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.63 ms /     7 runs   (  126.52 ms per token,     7.90 tokens per second)\n",
      "llama_print_timings:       total time =   906.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.30 ms /     7 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   878.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   902.07 ms /     7 runs   (  128.87 ms per token,     7.76 tokens per second)\n",
      "llama_print_timings:       total time =   923.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 141: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding preoperative exams in refractive surgery, mark the correct alternative.\n",
      "a) Placido disc topography generates the pachymetric or corneal thickness map.\n",
      "b) Placido's disc topography and the Scheimpflug system are capable of generating both axial and tangential maps of the cornea.\n",
      "c) The maps generated by Plácido's disk topography are derived from the reflection of the anterior and posterior surface of the cornea.\n",
      "d) The Scheimpflug system evaluates the anterior curvature, the thickness map, but not the posterior face.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.40 ms /    11 runs   (    0.58 ms per token,  1718.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1340.95 ms /    11 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1373.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   133.06 ms /   229 runs   (    0.58 ms per token,  1720.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3242.48 ms /   138 tokens (   23.50 ms per token,    42.56 tokens per second)\n",
      "llama_print_timings:        eval time = 28020.37 ms /   228 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 31991.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.10 ms /    63 runs   (    0.59 ms per token,  1698.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7712.55 ms /    63 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7908.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.75 ms /    17 runs   (    0.57 ms per token,  1743.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2082.55 ms /    17 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2132.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    87.78 ms /   153 runs   (    0.57 ms per token,  1742.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18835.90 ms /   153 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 19311.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   107.28 ms /   186 runs   (    0.58 ms per token,  1733.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23020.82 ms /   186 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 23600.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.74 ms /   206 runs   (    0.58 ms per token,  1734.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25407.18 ms /   206 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 26052.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.12 ms /    66 runs   (    0.58 ms per token,  1731.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8176.10 ms /    66 runs   (  123.88 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  8374.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   132.65 ms /   229 runs   (    0.58 ms per token,  1726.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28199.35 ms /   229 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 28924.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.28 ms /   146 runs   (    0.58 ms per token,  1732.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17905.42 ms /   146 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 18353.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   132.31 ms /   229 runs   (    0.58 ms per token,  1730.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28180.94 ms /   229 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 28904.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Em relação aos exames pré-operatórios em cirurgia refrativa, assinale a alternativa correta.\n",
      "a)A topografia de disco de Plácido gera o mapa paquimétrico ou de espessura corneana.\n",
      "b)A topografia de disco de Plácido e o sistema de Scheimpflug são capazes de gerar tanto os mapas axiais como os tangenciais da córnea.\n",
      "c)Os mapas gerados pela topografia de disco de Plácido são derivados da reflexão da face anterior e posterior da córnea.\n",
      "d)O sistema de Scheimpflug avalia a curvatura anterior, o mapa de espessura, mas não a face posterior.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.14 ms /   136 runs   (    0.58 ms per token,  1718.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4208.74 ms /   172 tokens (   24.47 ms per token,    40.87 tokens per second)\n",
      "llama_print_timings:        eval time = 16746.79 ms /   135 runs   (  124.05 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 21377.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.49 ms /    27 runs   (    0.57 ms per token,  1743.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3340.86 ms /    27 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3421.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.60 ms /   147 runs   (    0.58 ms per token,  1737.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18142.86 ms /   147 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 18601.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    70.33 ms /   122 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15125.82 ms /   122 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 15499.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.06 ms /   115 runs   (    0.57 ms per token,  1740.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14208.60 ms /   115 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 14561.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    95.57 ms /   167 runs   (    0.57 ms per token,  1747.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20566.96 ms /   167 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 21085.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1759.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.68 ms /     7 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   887.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.15 ms /    56 runs   (    0.57 ms per token,  1741.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6836.50 ms /    56 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7009.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3289.65 ms /    27 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3369.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.54 ms /    59 runs   (    0.57 ms per token,  1759.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7236.06 ms /    59 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  7411.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 142: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the conditions below is at increased risk after LASIK surgery?\n",
      "a) Cataract.\n",
      "b) Glaucoma.\n",
      "c) Dry eye.\n",
      "d) retinal detachment.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    28 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1213.61 ms /    52 tokens (   23.34 ms per token,    42.85 tokens per second)\n",
      "llama_print_timings:        eval time =  3322.62 ms /    27 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4619.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.61 ms /    22 runs   (    0.57 ms per token,  1744.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2667.94 ms /    22 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2733.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.89 ms /    28 runs   (    0.57 ms per token,  1761.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3390.17 ms /    28 runs   (  121.08 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3473.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n",
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.97 ms /     7 runs   (  120.42 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.51 ms /    29 runs   (    0.57 ms per token,  1756.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3511.50 ms /    29 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3596.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.75 ms /     7 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1761.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.08 ms /     7 runs   (  120.15 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   861.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2920.16 ms /    24 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2991.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.83 ms /    28 runs   (    0.57 ms per token,  1769.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3383.48 ms /    28 runs   (  120.84 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3466.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.42 ms /    27 runs   (    0.57 ms per token,  1750.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3269.36 ms /    27 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3349.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das condições abaixo tem seu risco aumentado após cirurgia de LASIK?\n",
      "a)Catarata.\n",
      "b)Glaucoma.\n",
      "c)Olho seco.\n",
      "d)Descolamento de retina.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.73 ms /    13 runs   (    0.59 ms per token,  1681.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1465.94 ms /    63 tokens (   23.27 ms per token,    42.98 tokens per second)\n",
      "llama_print_timings:        eval time =  1467.02 ms /    12 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2972.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.16 ms /     7 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.46 ms /    13 runs   (    0.57 ms per token,  1741.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1588.04 ms /    13 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  1626.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.04 ms /    33 runs   (    0.58 ms per token,  1733.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4056.82 ms /    33 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4156.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.50 ms /    13 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1554.22 ms /    13 runs   (  119.56 ms per token,     8.36 tokens per second)\n",
      "llama_print_timings:       total time =  1593.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.50 ms /    13 runs   (    0.58 ms per token,  1733.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1572.20 ms /    13 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1610.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.44 ms /    13 runs   (    0.57 ms per token,  1747.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1563.65 ms /    13 runs   (  120.28 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  1601.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.46 ms /    13 runs   (    0.57 ms per token,  1743.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1568.85 ms /    13 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  1607.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.41 ms /    13 runs   (    0.57 ms per token,  1754.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1583.87 ms /    13 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  1622.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.46 ms /    13 runs   (    0.57 ms per token,  1742.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1576.90 ms /    13 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  1616.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 143: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the use of therapeutic contact lenses, mark the correct alternative.\n",
      "a) Silicone-hydrogel lenses potentiate the action of medications.\n",
      "b) In the case of ocular perforation, the lens must not be used without association with tissue adhesive or suture.\n",
      "c) In cases of epithelial defects, the change is daily.\n",
      "d) Its adaptation is carried out with greater changes than usual.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.26 ms /   107 runs   (    0.58 ms per token,  1718.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2530.65 ms /   109 tokens (   23.22 ms per token,    43.07 tokens per second)\n",
      "llama_print_timings:        eval time = 12961.80 ms /   106 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 15825.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.34 ms /    96 runs   (    0.58 ms per token,  1734.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11809.83 ms /    96 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 12103.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.33 ms /    88 runs   (    0.58 ms per token,  1714.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10903.83 ms /    88 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 11171.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n",
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   116.55 ms /   201 runs   (    0.58 ms per token,  1724.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24723.99 ms /   201 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 25357.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.73 ms /   102 runs   (    0.58 ms per token,  1736.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12488.12 ms /   102 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12797.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   148.30 ms /   258 runs   (    0.57 ms per token,  1739.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 31984.83 ms /   258 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 32808.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.56 ms /    84 runs   (    0.58 ms per token,  1729.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10264.15 ms /    84 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 10519.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.05 ms /    99 runs   (    0.59 ms per token,  1705.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12123.78 ms /    99 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12441.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.83 ms /    78 runs   (    0.65 ms per token,  1534.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9643.02 ms /    78 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 10190.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.97 ms /    17 runs   (    0.65 ms per token,  1548.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2094.30 ms /    17 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2211.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Em relação ao uso de lente de contato terapêutica, assinale a alternativa correta.\n",
      "a)As lentes de silicone-hidrogel potencializam a ação de medicamentos.\n",
      "b)No caso de perfuração ocular a lente não deve ser utilizada sem a associação com adesivo tecidual ou sutura.\n",
      "c)Nos casos de defeitos epiteliais a troca é diária.\n",
      "d)Sua adaptação é realizada com maiores trocas que a habitual.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.67 ms /     7 runs   (    0.67 ms per token,  1500.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3121.22 ms /   134 tokens (   23.29 ms per token,    42.93 tokens per second)\n",
      "llama_print_timings:        eval time =   741.20 ms /     6 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3910.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   137.19 ms /   233 runs   (    0.59 ms per token,  1698.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28820.67 ms /   233 runs   (  123.69 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 29693.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.77 ms /   128 runs   (    0.58 ms per token,  1735.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15734.64 ms /   128 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 16131.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.76 ms /   109 runs   (    0.58 ms per token,  1736.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13483.10 ms /   109 runs   (  123.70 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 13817.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.37 ms /   114 runs   (    0.57 ms per token,  1743.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13934.91 ms /   114 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 14286.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.47 ms /   119 runs   (    0.58 ms per token,  1737.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14643.39 ms /   119 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 15012.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.43 ms /    65 runs   (    0.58 ms per token,  1736.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7937.63 ms /    65 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8136.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.20 ms /   107 runs   (    0.59 ms per token,  1693.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13152.56 ms /   107 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 13489.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.53 ms /    71 runs   (    0.58 ms per token,  1709.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8747.43 ms /    71 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8966.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 144: \n",
      "Language: english\n",
      "Question: \n",
      "One patient with a keratometry of 44.00/48.00 opted for contact lens fitting. One with a base curve of 45.00 was adapted. It is correct to say that:\n",
      "a) The lacrimal lens formed will be +3.00 diopters, since the difference between the most curved meridian of the lens and the base curve corresponds to this value.\n",
      "b) The concept of K applies to the flattest meridian, and its difference with the base curve results in a positive lens of +1.00 diopter.\n",
      "c) The patient with this keratometry value could not wear contact lenses, since there is very important corneal ectasia.\n",
      "d) The value of the most curved meridian of the corneal lens is called K, and adapted lenses with a base curve more curved than K form a lacrimal lens with a dioptric power of -1.00 Diopter.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.45 ms /     7 runs   (  120.64 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.52 ms /   138 runs   (    0.58 ms per token,  1713.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3470.83 ms /   229 tokens (   15.16 ms per token,    65.98 tokens per second)\n",
      "llama_print_timings:        eval time = 16837.82 ms /   137 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 20747.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.72 ms /   138 runs   (    0.58 ms per token,  1731.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17081.44 ms /   138 runs   (  123.78 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 17519.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.99 ms /   138 runs   (    0.58 ms per token,  1725.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17086.37 ms /   138 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 17521.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.50 ms /    20 runs   (    0.57 ms per token,  1739.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2444.44 ms /    20 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2503.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.53 ms /   138 runs   (    0.58 ms per token,  1735.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17038.26 ms /   138 runs   (  123.47 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 17463.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.84 ms /    20 runs   (    0.59 ms per token,  1689.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2523.98 ms /    20 runs   (  126.20 ms per token,     7.92 tokens per second)\n",
      "llama_print_timings:       total time =  2585.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.67 ms /   138 runs   (    0.58 ms per token,  1732.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16954.67 ms /   138 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 17383.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.45 ms /   138 runs   (    0.58 ms per token,  1736.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17003.02 ms /   138 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 17432.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.50 ms /   138 runs   (    0.58 ms per token,  1714.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17025.17 ms /   138 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 17456.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1737.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3413.14 ms /    28 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3496.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente com a ceratometria de 44,00/48,00 optou por adaptação de lente de contato. Foi adaptada uma de curva base 45,00. É correto afirmar que:\n",
      "a)A lente lacrimal formada será de +3,00 dioptrias, uma vez que a diferença entre o meridiano mais curvo da lente e a curva base corresponde a esse valor.\n",
      "b)O conceito de K se aplica ao meridiano mais plano, e sua diferença com a curva base resulta em uma lente positiva de +1,00 dioptria.\n",
      "c)O paciente com esse valor de ceratometria não poderia usar lentes de contato, uma vez que há ectasia corneana muito importante.\n",
      "d)O valor do meridiano mais curvo da lente da córnea é chamado de K, e lentes adaptadas com curva base mais curva que K formam uma lente lacrimal com poder dióptrico de -1,00 Dioptria.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.45 ms /    28 runs   (    0.59 ms per token,  1701.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  5168.10 ms /   265 tokens (   19.50 ms per token,    51.28 tokens per second)\n",
      "llama_print_timings:        eval time =  3309.06 ms /    27 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8562.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1705.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.17 ms /     7 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.36 ms /    11 runs   (    0.58 ms per token,  1730.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1362.74 ms /    11 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  1396.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.14 ms /   102 runs   (    0.58 ms per token,  1724.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12672.78 ms /   102 runs   (  124.24 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 12984.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.89 ms /     7 runs   (  123.70 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   886.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   968.65 ms /     7 runs   (  138.38 ms per token,     7.23 tokens per second)\n",
      "llama_print_timings:       total time =   989.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.85 ms /     7 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   872.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.66 ms /   102 runs   (    0.58 ms per token,  1738.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12639.59 ms /   102 runs   (  123.92 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 12950.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.85 ms /   102 runs   (    0.58 ms per token,  1733.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12776.69 ms /   102 runs   (  125.26 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time = 13092.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.24 ms /    61 runs   (    0.58 ms per token,  1730.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7532.70 ms /    61 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  7719.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 145: \n",
      "Language: english\n",
      "Question: \n",
      "A patient has a static refraction of -8.00 spherical dioptry in both eyes and intends to wear contact lenses. With regard to glasses, your contact lens prescription will be:\n",
      "a)-7.50 Dioptres.\n",
      "b)-8.00 Dioptres.\n",
      "c)-8.50 Dioptres.\n",
      "d) It is not possible to determine lens graduation without performing corneal topography.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.86 ms /    37 runs   (    0.59 ms per token,  1692.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2062.43 ms /   108 tokens (   19.10 ms per token,    52.37 tokens per second)\n",
      "llama_print_timings:        eval time =  4394.65 ms /    36 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6571.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.69 ms /    34 runs   (    0.58 ms per token,  1726.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4131.94 ms /    34 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4234.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.73 ms /    17 runs   (    0.57 ms per token,  1747.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2064.40 ms /    17 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2116.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)'}\n",
      "Test #3: \n",
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.37 ms /    37 runs   (    0.58 ms per token,  1731.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4546.65 ms /    37 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4660.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.48 ms /    34 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4191.31 ms /    34 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4294.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.93 ms /    38 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4637.12 ms /    38 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4754.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.06 ms /    40 runs   (    0.58 ms per token,  1734.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4911.07 ms /    40 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5032.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.41 ms /    37 runs   (    0.58 ms per token,  1728.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4587.98 ms /    37 runs   (  124.00 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  4698.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.27 ms /    37 runs   (    0.57 ms per token,  1739.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4538.23 ms /    37 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4648.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.32 ms /    37 runs   (    0.58 ms per token,  1735.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4548.55 ms /    37 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4658.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente apresenta na refração estática -8,00 dioptria esferica em ambos os olhos e pretende utilizar lentes de contato. Com relação aos óculos, o grau da sua lente de contato será:\n",
      "a)-7,50 Dioptrias.\n",
      "b)-8,00 Dioptrias.\n",
      "c)-8,50 Dioptrias.\n",
      "d)Não é possível determinar a graduação da lente sem a realização da topografia de córnea.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.99 ms /    17 runs   (    0.59 ms per token,  1702.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2733.81 ms /   131 tokens (   20.87 ms per token,    47.92 tokens per second)\n",
      "llama_print_timings:        eval time =  1931.77 ms /    16 runs   (  120.74 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  4716.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.19 ms /    16 runs   (    0.57 ms per token,  1741.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1950.83 ms /    16 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1998.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #2: \n",
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.66 ms /    41 runs   (    0.58 ms per token,  1732.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4994.99 ms /    41 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5117.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.76 ms /    36 runs   (    0.58 ms per token,  1734.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4359.97 ms /    36 runs   (  121.11 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4467.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.70 ms /    36 runs   (    0.57 ms per token,  1739.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4439.67 ms /    36 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4546.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.38 ms /    37 runs   (    0.58 ms per token,  1730.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4558.52 ms /    37 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4671.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.82 ms /    36 runs   (    0.58 ms per token,  1729.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4386.80 ms /    36 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4494.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.20 ms /    16 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1967.40 ms /    16 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2015.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #8: \n",
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.69 ms /    36 runs   (    0.57 ms per token,  1740.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4391.12 ms /    36 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4499.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 146: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Regarding intermittent exotropia, mark the correct alternative.\n",
      "a) Orthoptic exercises are contraindicated if there is insufficient convergence.\n",
      "b) It resolves spontaneously in the vast majority of cases.\n",
      "c) Treatment with occlusion is contraindicated if there is no amblyopia.\n",
      "d) The use of negative lenses (or farsightedness) provides better results if the accommodative convergence/accommodation ratio is high.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.32 ms /    16 runs   (    0.58 ms per token,  1716.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2005.30 ms /    16 runs   (  125.33 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  2053.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.90 ms /    61 runs   (    0.59 ms per token,  1699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2453.34 ms /   119 tokens (   20.62 ms per token,    48.51 tokens per second)\n",
      "llama_print_timings:        eval time =  7372.82 ms /    60 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10013.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.97 ms /    59 runs   (    0.58 ms per token,  1736.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7212.40 ms /    59 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7390.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.89 ms /    61 runs   (    0.59 ms per token,  1699.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7588.71 ms /    61 runs   (  124.41 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  7774.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.08 ms /   105 runs   (    0.62 ms per token,  1613.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12911.26 ms /   105 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 13250.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.72 ms /    56 runs   (    0.67 ms per token,  1484.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6895.52 ms /    56 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7080.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.99 ms /    60 runs   (    0.58 ms per token,  1714.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7348.16 ms /    60 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7529.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.06 ms /    61 runs   (    0.57 ms per token,  1739.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7452.16 ms /    61 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7635.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.65 ms /   126 runs   (    0.58 ms per token,  1734.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15455.19 ms /   126 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 15843.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.65 ms /    60 runs   (    0.58 ms per token,  1731.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7394.58 ms /    60 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  7575.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    78.31 ms /   135 runs   (    0.58 ms per token,  1723.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16619.46 ms /   135 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 17038.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação à exotropia intermitente, assinale a alternativa correta.\n",
      "a)Exercícios ortópticos são contraindicados se houver insuficiência de convergência.\n",
      "b)Resolve-se espontaneamente na grande maioria dos casos.\n",
      "c)O tratamento com oclusão é contraindicado se não houver ambliopia.\n",
      "d)O uso de lentes negativas (ou hipermetropização), proporciona melhor resultado se a relação convergência acomodativa/acomodação for alta.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.34 ms /     7 runs   (    0.62 ms per token,  1612.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2997.81 ms /   138 tokens (   21.72 ms per token,    46.03 tokens per second)\n",
      "llama_print_timings:        eval time =   724.89 ms /     6 runs   (  120.81 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3743.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.40 ms /   183 runs   (    0.58 ms per token,  1719.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22445.42 ms /   183 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 23024.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n",
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   100.16 ms /   174 runs   (    0.58 ms per token,  1737.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21563.66 ms /   174 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 22102.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.86 ms /    67 runs   (    0.58 ms per token,  1724.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8174.08 ms /    67 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  8376.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.42 ms /   206 runs   (    0.57 ms per token,  1739.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25333.46 ms /   206 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 25976.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   115.70 ms /   193 runs   (    0.60 ms per token,  1668.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23774.32 ms /   193 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 24393.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    95.31 ms /   166 runs   (    0.57 ms per token,  1741.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20336.58 ms /   166 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 20855.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.36 ms /    65 runs   (    0.57 ms per token,  1739.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8001.11 ms /    65 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8198.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.31 ms /   148 runs   (    0.58 ms per token,  1734.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18320.57 ms /   148 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 18777.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n",
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 147: \n",
      "Language: english\n",
      "Question: \n",
      "Among the findings below, which one is associated with the sensory binocular function considered to be the most refined:\n",
      "a) Stereopsis.\n",
      "b) Binocular fusion.\n",
      "c) Diplopia.\n",
      "d) Simultaneous macular perception.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.09 ms /   196 runs   (    0.58 ms per token,  1733.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24219.85 ms /   196 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 24834.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.71 ms /    27 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1735.51 ms /    66 tokens (   26.30 ms per token,    38.03 tokens per second)\n",
      "llama_print_timings:        eval time =  3143.60 ms /    26 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4961.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.50 ms /    27 runs   (    0.57 ms per token,  1742.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3265.65 ms /    27 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3346.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.44 ms /    20 runs   (    0.57 ms per token,  1748.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2435.09 ms /    20 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2494.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3389.80 ms /    28 runs   (  121.06 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3473.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.44 ms /    20 runs   (    0.57 ms per token,  1747.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2450.64 ms /    20 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2509.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    27 runs   (    0.58 ms per token,  1732.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3281.57 ms /    27 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3362.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.44 ms /    20 runs   (    0.57 ms per token,  1747.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2435.11 ms /    20 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2494.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.45 ms /    20 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2499.99 ms /    20 runs   (  125.00 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  2559.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.47 ms /    20 runs   (    0.57 ms per token,  1744.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2418.95 ms /    20 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2478.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.89 ms /    21 runs   (    0.57 ms per token,  1766.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2584.46 ms /    21 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2647.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Entre os achados abaixo, qual está associado a função binocular sensorial considerada como a mais refinada:\n",
      "a)Estereopsia.\n",
      "b)Fusão binocular.\n",
      "c)Diplopia.\n",
      "d)Percepção macular simultânea.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1788.86 ms /    74 tokens (   24.17 ms per token,    41.37 tokens per second)\n",
      "llama_print_timings:        eval time =  3280.75 ms /    27 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5154.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    27 runs   (    0.58 ms per token,  1730.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3255.04 ms /    27 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3336.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.54 ms /    36 runs   (    0.57 ms per token,  1752.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4407.28 ms /    36 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4515.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) Fusão binocular'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.44 ms /    27 runs   (    0.57 ms per token,  1748.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3273.90 ms /    27 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3355.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.46 ms /    34 runs   (    0.57 ms per token,  1747.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4146.48 ms /    34 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4247.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.42 ms /    34 runs   (    0.57 ms per token,  1750.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4152.00 ms /    34 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4253.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    27 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3275.94 ms /    27 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3358.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1757.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.25 ms /     7 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.30 ms /   100 runs   (    0.57 ms per token,  1745.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12200.35 ms /   100 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 12508.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 148: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the anomalous retinal correspondence, mark the correct alternative.\n",
      "a) It is a phenomenon of monocular sensory adaptation.\n",
      "b) It is more frequent in small angle deviations.\n",
      "c) It is considered a protective factor for diplopia in the postoperative period of strabismus surgery.\n",
      "d) It is considered a protective factor against recurrence in the postoperative period of strabismus surgery.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.98 ms /    28 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3473.55 ms /    28 runs   (  124.06 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3557.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.38 ms /    25 runs   (    0.58 ms per token,  1739.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2405.86 ms /   102 tokens (   23.59 ms per token,    42.40 tokens per second)\n",
      "llama_print_timings:        eval time =  2917.28 ms /    24 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5398.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2912.12 ms /    24 runs   (  121.34 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2984.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.62 ms /    24 runs   (    0.57 ms per token,  1761.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2922.75 ms /    24 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2993.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1749.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2984.34 ms /    24 runs   (  124.35 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3056.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.84 ms /    24 runs   (    0.58 ms per token,  1734.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2911.69 ms /    24 runs   (  121.32 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2984.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.22 ms /    25 runs   (    0.57 ms per token,  1757.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3082.23 ms /    25 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3155.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.73 ms /    24 runs   (    0.57 ms per token,  1748.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2917.62 ms /    24 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2988.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.20 ms /    25 runs   (    0.57 ms per token,  1760.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3085.76 ms /    25 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3160.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.03 ms /    86 runs   (    0.58 ms per token,  1719.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10550.27 ms /    86 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10815.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.20 ms /    25 runs   (    0.57 ms per token,  1760.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3016.13 ms /    25 runs   (  120.65 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3089.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação à correspondência retiniana anômala, assinale a alternativa correta.\n",
      "a)É um fenômeno de adaptação sensorial monocular.\n",
      "b)É mais frequente nos desvios de pequeno ângulo.\n",
      "c)É considerada fator protetor de diplopia no pós-operatório de cirurgia de estrabismo.\n",
      "d)É considerada fator protetor de recidiva no pós-operatório de cirurgia de estrabismo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.03 ms /    81 runs   (    0.58 ms per token,  1722.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2126.33 ms /   126 tokens (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:        eval time =  9812.57 ms /    80 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12190.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.88 ms /    24 runs   (    0.58 ms per token,  1729.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2953.51 ms /    24 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3025.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.70 ms /    24 runs   (    0.57 ms per token,  1751.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2969.30 ms /    24 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3041.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3456.82 ms /    28 runs   (  123.46 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3540.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.90 ms /   128 runs   (    0.58 ms per token,  1732.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15696.83 ms /   128 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 16091.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1739.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3461.50 ms /    28 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3545.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.45 ms /    27 runs   (    0.57 ms per token,  1747.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3314.63 ms /    27 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3395.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.07 ms /    28 runs   (    0.57 ms per token,  1742.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3433.03 ms /    28 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3515.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3315.37 ms /    27 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3395.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 149: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following complications is most frequent after injection of botulinum toxin into the medial rectus muscle?\n",
      "a) Blepharoptosis.\n",
      "b) Retrobulbar hemorrhage.\n",
      "c) Mydriasis.\n",
      "d) Miosis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1736.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3382.62 ms /    27 runs   (  125.28 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  3463.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.57 ms /    25 runs   (    0.58 ms per token,  1716.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1344.72 ms /    70 tokens (   19.21 ms per token,    52.06 tokens per second)\n",
      "llama_print_timings:        eval time =  2931.85 ms /    24 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4351.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2947.07 ms /    24 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3019.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.75 ms /    17 runs   (    0.57 ms per token,  1744.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2040.42 ms /    17 runs   (  120.02 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  2090.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.69 ms /    24 runs   (    0.57 ms per token,  1753.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.88 ms /    24 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2986.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1745.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3391.81 ms /    28 runs   (  121.14 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3475.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.26 ms /    25 runs   (    0.57 ms per token,  1752.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3057.31 ms /    25 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3130.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.45 ms /    25 runs   (    0.58 ms per token,  1730.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3001.27 ms /    25 runs   (  120.05 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  3075.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.16 ms /    44 runs   (    0.57 ms per token,  1748.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5331.04 ms /    44 runs   (  121.16 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5462.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1750.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2876.54 ms /    24 runs   (  119.86 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =  2947.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.80 ms /    45 runs   (    0.57 ms per token,  1744.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5418.20 ms /    45 runs   (  120.40 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  5552.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das complicações abaixo é mais frequente após injeção de toxina botulínica no músculo reto medial?\n",
      "a)Blefaroptose.\n",
      "b)Hemorragia retrobulbar.\n",
      "c)Midríase.\n",
      "d)Miose.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.27 ms /    44 runs   (    0.57 ms per token,  1740.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1398.58 ms /    76 tokens (   18.40 ms per token,    54.34 tokens per second)\n",
      "llama_print_timings:        eval time =  5227.60 ms /    43 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  6759.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.85 ms /     7 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b} Hemorragia retrobulbar.'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.46 ms /    34 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4119.23 ms /    34 runs   (  121.15 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4220.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.34 ms /     7 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   873.69 ms /     7 runs   (  124.81 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =   893.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.65 ms /     7 runs   (  124.38 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.91 ms /    28 runs   (    0.57 ms per token,  1759.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3405.34 ms /    28 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3488.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.45 ms /    27 runs   (    0.57 ms per token,  1747.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3286.02 ms /    27 runs   (  121.70 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3365.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.65 ms /    43 runs   (    0.57 ms per token,  1744.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5221.48 ms /    43 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5349.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.04 ms /     7 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 150: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding exotropia caused by low monocular (sensory) visual acuity, mark the correct alternative.\n",
      "a) It represents approximately 2% of all cases of adult exotropia.\n",
      "b) Prescription of prisms is the treatment of choice.\n",
      "c) It is usually associated with normal stereopsis.\n",
      "d) It is common for the deviation to increase over time.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.79 ms /    67 runs   (    0.58 ms per token,  1727.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2100.90 ms /    89 tokens (   23.61 ms per token,    42.36 tokens per second)\n",
      "llama_print_timings:        eval time =  8042.74 ms /    66 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time = 10345.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.34 ms /    25 runs   (    0.57 ms per token,  1743.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3026.45 ms /    25 runs   (  121.06 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3100.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.91 ms /    54 runs   (    0.57 ms per token,  1747.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6573.81 ms /    54 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6736.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.64 ms /   163 runs   (    0.57 ms per token,  1740.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19965.99 ms /   163 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 20469.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    82.01 ms /   143 runs   (    0.57 ms per token,  1743.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17474.16 ms /   143 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 17912.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1750.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2922.66 ms /    24 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2995.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.74 ms /    71 runs   (    0.57 ms per token,  1742.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8663.45 ms /    71 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  8878.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.12 ms /    95 runs   (    0.57 ms per token,  1755.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11638.41 ms /    95 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 11925.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.23 ms /    51 runs   (    0.57 ms per token,  1745.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6182.35 ms /    51 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  6333.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   160.11 ms /   278 runs   (    0.58 ms per token,  1736.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 34368.82 ms /   278 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 35257.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação à exotropia causada por baixa acuidade visual monocular (sensorial), assinale a alternativa correta.\n",
      "a)Representa aproximadamente 2% de todos os casos de exotropia do adulto.\n",
      "b)Prescrição de prismas é o tratamento de escolha.\n",
      "c)Está associada, em geral, a estereopsia normal.\n",
      "d)É comum o aumento do desvio com o passar do tempo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.36 ms /   145 runs   (    0.58 ms per token,  1718.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2336.95 ms /   118 tokens (   19.80 ms per token,    50.49 tokens per second)\n",
      "llama_print_timings:        eval time = 17738.99 ms /   144 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 20528.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.49 ms /    20 runs   (    0.57 ms per token,  1740.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2434.26 ms /    20 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2494.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.77 ms /    88 runs   (    0.58 ms per token,  1733.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10822.29 ms /    88 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 11090.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.08 ms /    71 runs   (    0.58 ms per token,  1728.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8652.63 ms /    71 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  8867.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1732.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2487.23 ms /    20 runs   (  124.36 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  2546.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.87 ms /    83 runs   (    0.58 ms per token,  1733.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10153.67 ms /    83 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10405.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.87 ms /    17 runs   (    0.58 ms per token,  1722.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2146.92 ms /    17 runs   (  126.29 ms per token,     7.92 tokens per second)\n",
      "llama_print_timings:       total time =  2197.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   116.20 ms /   200 runs   (    0.58 ms per token,  1721.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24616.41 ms /   200 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 25266.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.46 ms /    91 runs   (    0.58 ms per token,  1734.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11228.24 ms /    91 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 11513.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.76 ms /     7 runs   (  120.82 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 151: \n",
      "Language: english\n",
      "Question: \n",
      "Vicious head positions to compensate for strabismus occur most frequently in which of the following deviations?\n",
      "a) Partially accommodative.\n",
      "b) Incomitants.\n",
      "c) Intermittent exotropia.\n",
      "d) Commanders.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.07 ms /    24 runs   (    0.59 ms per token,  1705.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1163.60 ms /    60 tokens (   19.39 ms per token,    51.56 tokens per second)\n",
      "llama_print_timings:        eval time =  2775.69 ms /    23 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  4013.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.99 ms /    24 runs   (    0.58 ms per token,  1715.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2900.48 ms /    24 runs   (  120.85 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2975.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.48 ms /    24 runs   (    0.60 ms per token,  1657.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2964.36 ms /    24 runs   (  123.51 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3039.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.33 ms /    24 runs   (    0.60 ms per token,  1674.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2944.00 ms /    24 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3019.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.69 ms /    24 runs   (    0.57 ms per token,  1752.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.21 ms /    24 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2999.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1731.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2883.70 ms /    24 runs   (  120.15 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  2955.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.80 ms /    17 runs   (    0.58 ms per token,  1734.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2077.93 ms /    17 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2128.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2945.93 ms /    24 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3018.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.49 ms /    28 runs   (    0.59 ms per token,  1697.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3396.12 ms /    28 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3481.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "As posições viciosas da cabeça para compensar os estrabismos ocorrem mais frequentemente em qual dos desvios abaixo?\n",
      "a)Parcialmente acomodativos.\n",
      "b)Incomitantes.\n",
      "c)Exotropia intermitente.\n",
      "d)Comitantes.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2910.47 ms /    24 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2981.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.89 ms /    27 runs   (    0.59 ms per token,  1699.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1447.67 ms /    76 tokens (   19.05 ms per token,    52.50 tokens per second)\n",
      "llama_print_timings:        eval time =  3161.71 ms /    26 runs   (  121.60 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4692.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.80 ms /    29 runs   (    0.58 ms per token,  1725.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3521.79 ms /    29 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3609.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Comitantes.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.36 ms /    32 runs   (    0.57 ms per token,  1743.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3867.51 ms /    32 runs   (  120.86 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3963.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd}Comitantes'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.07 ms /    28 runs   (    0.57 ms per token,  1742.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3398.74 ms /    28 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3482.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.38 ms /    32 runs   (    0.57 ms per token,  1741.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3929.20 ms /    32 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4024.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.95 ms /    33 runs   (    0.57 ms per token,  1741.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4078.99 ms /    33 runs   (  123.61 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4177.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.64 ms /    29 runs   (    0.57 ms per token,  1742.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3517.48 ms /    29 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3604.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Comitantes'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.51 ms /    32 runs   (    0.58 ms per token,  1729.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3870.66 ms /    32 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3965.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd}Comitantes'}\n",
      "Test #8: \n",
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.60 ms /    35 runs   (    0.59 ms per token,  1698.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4254.16 ms /    35 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4360.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.70 ms /    29 runs   (    0.58 ms per token,  1736.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3542.15 ms /    29 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3628.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Comitantes.'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 152: \n",
      "Language: english\n",
      "Question: \n",
      "During the Maddox test, Maddox cylinders were placed in front of the patient's eyes, the red one in front of the right eye and the colorless one in front of the left eye, both vertically oriented. The patient, upon observing a point of light, reported seeing the red line tilted counterclockwise (patient's perspective). It most likely features:\n",
      "a) Inciclotorsion of the right eye.\n",
      "b) Excyclotorsion of the right eye.\n",
      "c) Inciclotorsion of the left eye.\n",
      "d) Hyperfunction of the left superior oblique muscle.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.49 ms /    39 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2801.65 ms /   145 tokens (   19.32 ms per token,    51.76 tokens per second)\n",
      "llama_print_timings:        eval time =  4661.93 ms /    38 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  7581.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.89 ms /    40 runs   (    0.57 ms per token,  1747.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4869.56 ms /    40 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4989.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.67 ms /    36 runs   (    0.57 ms per token,  1741.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4442.87 ms /    36 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  4551.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.81 ms /    36 runs   (    0.58 ms per token,  1729.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4378.02 ms /    36 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4486.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.95 ms /    40 runs   (    0.57 ms per token,  1742.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4889.52 ms /    40 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5009.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.53 ms /    40 runs   (    0.59 ms per token,  1699.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4910.39 ms /    40 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5032.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.30 ms /    37 runs   (    0.58 ms per token,  1736.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4515.94 ms /    37 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4627.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.87 ms /    40 runs   (    0.57 ms per token,  1748.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4872.90 ms /    40 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4993.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.34 ms /    37 runs   (    0.58 ms per token,  1734.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4531.89 ms /    37 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4643.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.98 ms /    40 runs   (    0.57 ms per token,  1740.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4889.70 ms /    40 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5009.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Durante o teste de Maddox, colocou-se cilindros de Maddox diante dos olhos do paciente, sendo o vermelho diante do olho direito e o incolor diante do olho esquerdo, ambos orientados verticalmente. O paciente, ao observar um foco de luz puntiforme, informou ver a linha vermelha inclinada no sentido anti-horário (perspectiva do paciente). Ele apresenta mais provavelmente:\n",
      "a)Inciclotorção do olho direito.\n",
      "b)Exciclotorção do olho direito.\n",
      "c)Inciclotorção do olho esquerdo.\n",
      "d)Hiperfunção de músculo oblíquo superior esquerdo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1713.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3532.18 ms /   187 tokens (   18.89 ms per token,    52.94 tokens per second)\n",
      "llama_print_timings:        eval time =   743.32 ms /     6 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4296.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.85 ms /    19 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2380.27 ms /    19 runs   (  125.28 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  2436.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.88 ms /    19 runs   (    0.57 ms per token,  1746.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2372.06 ms /    19 runs   (  124.85 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  2428.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #3: \n",
      "{'response': 'a'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.88 ms /    19 runs   (    0.57 ms per token,  1746.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2339.56 ms /    19 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2396.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.90 ms /    19 runs   (    0.57 ms per token,  1742.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2344.71 ms /    19 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  2401.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.79 ms /    19 runs   (    0.57 ms per token,  1760.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2411.26 ms /    19 runs   (  126.91 ms per token,     7.88 tokens per second)\n",
      "llama_print_timings:       total time =  2467.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.41 ms /    19 runs   (    0.60 ms per token,  1664.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2350.54 ms /    19 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  2409.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1773.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   895.69 ms /     7 runs   (  127.96 ms per token,     7.82 tokens per second)\n",
      "llama_print_timings:       total time =   915.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.92 ms /    28 runs   (    0.57 ms per token,  1758.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3433.29 ms /    28 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3515.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.76 ms /    40 runs   (    0.57 ms per token,  1757.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4920.85 ms /    40 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5038.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 153: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding pleomorphic adenoma of the lacrimal gland, mark the correct alternative.\n",
      "a) Computed tomography scan shows heterogeneous and poorly delimited lesion.\n",
      "b) The most common condition is a rapidly progressive growth mass.\n",
      "c) On palpation, the tumor is generally painless.\n",
      "d) It is more common in women.\n",
      "Test #0: \n",
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.97 ms /    17 runs   (    0.59 ms per token,  1705.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2065.30 ms /    86 tokens (   24.02 ms per token,    41.64 tokens per second)\n",
      "llama_print_timings:        eval time =  1934.97 ms /    16 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4051.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.17 ms /    70 runs   (    0.57 ms per token,  1742.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8487.53 ms /    70 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  8696.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.71 ms /    17 runs   (    0.57 ms per token,  1749.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2082.91 ms /    17 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2132.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.60 ms /    50 runs   (    0.57 ms per token,  1748.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6072.95 ms /    50 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  6220.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.68 ms /    50 runs   (    0.57 ms per token,  1743.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6188.04 ms /    50 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6341.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1728.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2904.45 ms /    24 runs   (  121.02 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2977.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.87 ms /    50 runs   (    0.58 ms per token,  1731.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6160.67 ms /    50 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6315.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1750.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2955.56 ms /    24 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3027.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1740.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3044.05 ms /    25 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3119.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação ao adenoma pleomórfico de glândula lacrimal, assinale a alternativa correta.\n",
      "a)O exame de tomografia computadorizada mostra lesão heterogênea e mal delimitada.\n",
      "b)O quadro mais comum é de massa de crescimento rapidamente progressivo.\n",
      "c)À palpação, a tumoração é, em geral, indolor.\n",
      "d)É mais frequente em mulheres.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.62 ms /    67 runs   (    0.58 ms per token,  1735.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8191.06 ms /    67 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  8393.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.65 ms /    20 runs   (    0.58 ms per token,  1716.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2080.83 ms /   114 tokens (   18.25 ms per token,    54.79 tokens per second)\n",
      "llama_print_timings:        eval time =  2394.25 ms /    19 runs   (  126.01 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  4536.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.94 ms /    17 runs   (    0.58 ms per token,  1709.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2071.81 ms /    17 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2123.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.89 ms /    28 runs   (    0.57 ms per token,  1762.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3406.10 ms /    28 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3489.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1749.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.13 ms /     7 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   882.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3338.65 ms /    27 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3418.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.62 ms /    24 runs   (    0.57 ms per token,  1761.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2901.56 ms /    24 runs   (  120.90 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2972.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.46 ms /    51 runs   (    0.58 ms per token,  1730.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6280.26 ms /    51 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6434.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.91 ms /    57 runs   (    0.58 ms per token,  1731.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6957.70 ms /    57 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7131.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   140.92 ms /   244 runs   (    0.58 ms per token,  1731.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 30003.70 ms /   244 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 30775.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.54 ms /    57 runs   (    0.57 ms per token,  1751.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7047.72 ms /    57 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  7219.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 154: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding orbital involvement in leukemia, mark the correct alternative.\n",
      "a) The treatment is generally not sensitive to radiotherapy.\n",
      "b) The treatment is generally not sensitive to chemotherapy.\n",
      "c) Granulocytic sarcoma is the orbital infiltration most frequently associated with lymphoid leukemia.\n",
      "d) Imaging exams show an orbital mass that usually compromises the bone structure.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.18 ms /    64 runs   (    0.60 ms per token,  1676.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1850.97 ms /   101 tokens (   18.33 ms per token,    54.57 tokens per second)\n",
      "llama_print_timings:        eval time =  7699.35 ms /    63 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9747.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.43 ms /    25 runs   (    0.58 ms per token,  1732.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3049.98 ms /    25 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3125.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.72 ms /    24 runs   (    0.57 ms per token,  1749.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2969.45 ms /    24 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3040.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    25 runs   (    0.58 ms per token,  1727.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3019.91 ms /    25 runs   (  120.80 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3096.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.80 ms /    24 runs   (    0.58 ms per token,  1738.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.94 ms /    24 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2988.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.35 ms /    25 runs   (    0.57 ms per token,  1742.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3171.45 ms /    25 runs   (  126.86 ms per token,     7.88 tokens per second)\n",
      "llama_print_timings:       total time =  3247.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.44 ms /    24 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3001.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.83 ms /    24 runs   (    0.58 ms per token,  1734.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2887.56 ms /    24 runs   (  120.31 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2961.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2914.37 ms /    24 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2986.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação ao comprometimento orbitário na leucemia, assinale a alternativa correta.\n",
      "a)O tratamento geralmente não é sensível à radioterapia.\n",
      "b)O tratamento geralmente não é sensível à quimioterapia.\n",
      "c)O sarcoma granulocítico é a infiltração orbitária mais frequentemente associada a leucemia linfoide.\n",
      "d)Exames de imagem mostram massa orbitária que geralmente compromete a estrutura óssea.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.62 ms /    55 runs   (    0.57 ms per token,  1739.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6765.00 ms /    55 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6933.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.25 ms /    27 runs   (    0.60 ms per token,  1661.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2317.21 ms /   129 tokens (   17.96 ms per token,    55.67 tokens per second)\n",
      "llama_print_timings:        eval time =  3173.30 ms /    26 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5572.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    27 runs   (    0.58 ms per token,  1732.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3259.72 ms /    27 runs   (  120.73 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3340.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.07 ms /    66 runs   (    0.58 ms per token,  1733.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8064.10 ms /    66 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  8262.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.83 ms /     7 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.74 ms /    62 runs   (    0.58 ms per token,  1734.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7605.08 ms /    62 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  7792.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   881.86 ms /     7 runs   (  125.98 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =   902.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.10 ms /    65 runs   (    0.59 ms per token,  1706.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8160.97 ms /    65 runs   (  125.55 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  8359.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1749.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   886.69 ms /     7 runs   (  126.67 ms per token,     7.89 tokens per second)\n",
      "llama_print_timings:       total time =   906.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.61 ms /    66 runs   (    0.58 ms per token,  1709.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8153.04 ms /    66 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8355.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3412.36 ms /    28 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3498.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 155: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding plexiform orbital neurofibroma, mark the correct alternative:\n",
      "a) Its malignant degeneration is rare.\n",
      "b) It is rarely seen in patients with neurofibromatosis.\n",
      "c) It has a good prognosis, with a low rate of recurrence after surgery.\n",
      "d) It is avascular, and bleeding from the tumor during surgery is rare.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.69 ms /    69 runs   (    0.59 ms per token,  1695.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2298.40 ms /    99 tokens (   23.22 ms per token,    43.07 tokens per second)\n",
      "llama_print_timings:        eval time =  8324.57 ms /    68 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10838.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1764.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.18 ms /     7 runs   (  120.17 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.38 ms /    44 runs   (    0.58 ms per token,  1733.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5399.82 ms /    44 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5535.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.30 ms /    87 runs   (    0.58 ms per token,  1729.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10692.71 ms /    87 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10962.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.10 ms /    24 runs   (    0.59 ms per token,  1702.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2930.12 ms /    24 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3004.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.67 ms /    48 runs   (    0.58 ms per token,  1734.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5896.11 ms /    48 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6042.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.50 ms /    65 runs   (    0.58 ms per token,  1733.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8056.34 ms /    65 runs   (  123.94 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  8253.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.98 ms /    40 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4959.15 ms /    40 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  5079.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.17 ms /    44 runs   (    0.57 ms per token,  1748.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5418.65 ms /    44 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5551.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.91 ms /    59 runs   (    0.57 ms per token,  1739.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7173.83 ms /    59 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7352.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relação ao neurofibroma da órbita tipo plexiforme, assinale a alternativa correta:\n",
      "a)Sua degenerarão maligna é rara.\n",
      "b)É raramente observado em pacientes com neurofibromatose.\n",
      "c)Tem bom prognóstico, com baixa taxa de recorrência após a cirurgia.\n",
      "d)É avascular, sendo raro o sangramento do tumor durante a cirurgia.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.31 ms /     7 runs   (    0.62 ms per token,  1623.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2437.28 ms /   122 tokens (   19.98 ms per token,    50.06 tokens per second)\n",
      "llama_print_timings:        eval time =   762.14 ms /     6 runs   (  127.02 ms per token,     7.87 tokens per second)\n",
      "llama_print_timings:       total time =  3220.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1696.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.68 ms /     7 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   871.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "Error converting respose to json: {'response': 'A'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.71 ms /     7 runs   (  121.24 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.50 ms /     7 runs   (  121.36 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.72 ms /    27 runs   (    0.58 ms per token,  1717.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3385.66 ms /    27 runs   (  125.39 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  3467.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   945.05 ms /     7 runs   (  135.01 ms per token,     7.41 tokens per second)\n",
      "llama_print_timings:       total time =   965.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1772.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.17 ms /     7 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.42 ms /     7 runs   (  120.77 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   865.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.11 ms /   152 runs   (    0.61 ms per token,  1632.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18683.51 ms /   152 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 19169.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.62 ms /     7 runs   (    0.66 ms per token,  1514.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.49 ms /     7 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   882.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.59 ms /     7 runs   (    0.66 ms per token,  1525.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.37 ms /     7 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   888.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 156: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following malignant epithelial tumors of the conjunctiva most commonly occurs in the limbal region?\n",
      "a) Melanoma.\n",
      "b) Kaposi's sarcoma.\n",
      "c) squamous cell carcinoma.\n",
      "d) Basal cell carcinoma.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.54 ms /    33 runs   (    0.65 ms per token,  1531.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1736.01 ms /    72 tokens (   24.11 ms per token,    41.47 tokens per second)\n",
      "llama_print_timings:        eval time =  3880.99 ms /    32 runs   (  121.28 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5722.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.59 ms /    28 runs   (    0.66 ms per token,  1506.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3432.35 ms /    28 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3523.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.65 ms /    20 runs   (    0.58 ms per token,  1716.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2444.67 ms /    20 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2504.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.53 ms /    36 runs   (    0.57 ms per token,  1753.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4373.44 ms /    36 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4482.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.52 ms /    36 runs   (    0.57 ms per token,  1754.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4385.19 ms /    36 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4493.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.70 ms /    24 runs   (    0.57 ms per token,  1752.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2906.79 ms /    24 runs   (  121.12 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2979.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.32 ms /    37 runs   (    0.58 ms per token,  1735.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4466.20 ms /    37 runs   (  120.71 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  4577.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.81 ms /    27 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3383.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.90 ms /    24 runs   (    0.58 ms per token,  1726.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2934.85 ms /    24 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3006.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.80 ms /    33 runs   (    0.57 ms per token,  1755.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4077.79 ms /    33 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4177.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual é o tumor epitelial maligno de conjuntiva, dentre os abaixo, que mais comumente ocorre na região do limbo?\n",
      "a)Melanoma.\n",
      "b)Sarcoma de Káposi.\n",
      "c)Carcinoma espinocelular.\n",
      "d)Carcinoma de células basais.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    27 runs   (    0.58 ms per token,  1730.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2231.42 ms /    91 tokens (   24.52 ms per token,    40.78 tokens per second)\n",
      "llama_print_timings:        eval time =  3138.45 ms /    26 runs   (  120.71 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  5450.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.21 ms /    11 runs   (    0.56 ms per token,  1770.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1343.16 ms /    11 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  1375.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a) Melanoma'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.70 ms /    17 runs   (    0.57 ms per token,  1752.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2068.77 ms /    17 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2120.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.24 ms /    11 runs   (    0.57 ms per token,  1763.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1331.37 ms /    11 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  1364.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a) Melanoma'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.90 ms /    28 runs   (    0.57 ms per token,  1761.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3416.45 ms /    28 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3501.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.94 ms /     7 runs   (    0.56 ms per token,  1777.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.48 ms /     7 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.21 ms /    11 runs   (    0.56 ms per token,  1772.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1334.98 ms /    11 runs   (  121.36 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  1368.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.20 ms /    11 runs   (    0.56 ms per token,  1773.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1341.78 ms /    11 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1374.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.35 ms /    27 runs   (    0.57 ms per token,  1758.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3307.32 ms /    27 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3387.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 157: \n",
      "Language: english\n",
      "Question: \n",
      "Check the alternative that contains three factors associated with the development of cataracts.\n",
      "a) High myopia, prolonged use of vitamin C and alcohol consumption.\n",
      "b) Low-energy radiation, prolonged use of corticosteroids and exposure to blue light.\n",
      "c) Smoking, exposure to ultraviolet light and previous vitrectomy.\n",
      "d) Eye trauma, diabetes mellitus and high hyperopia.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1762.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.39 ms /     7 runs   (  121.77 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.81 ms /    72 runs   (    0.58 ms per token,  1722.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1824.28 ms /   108 tokens (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:        eval time =  8701.08 ms /    71 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 10744.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.78 ms /    57 runs   (    0.58 ms per token,  1738.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6960.15 ms /    57 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7132.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.40 ms /    56 runs   (    0.58 ms per token,  1728.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6843.82 ms /    56 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7012.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.71 ms /    57 runs   (    0.57 ms per token,  1742.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6940.15 ms /    57 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  7111.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3418.15 ms /    28 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3501.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.06 ms /    20 runs   (    0.60 ms per token,  1658.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2460.97 ms /    20 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2521.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3283.67 ms /    27 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3365.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.50 ms /    25 runs   (    0.58 ms per token,  1724.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3032.34 ms /    25 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3109.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.85 ms /    17 runs   (    0.58 ms per token,  1726.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2092.04 ms /    17 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2144.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que contém três fatores associados ao desenvolvimento de catarata.\n",
      "a)Alta miopia, uso prolongado de vitamina C e consumo de álcool.\n",
      "b)Radiação de baixa energia, uso prolongado de corticoide e exposição à luz azul.\n",
      "c)Tabagismo, exposição à luz ultravioleta e vitrectomia prévia.\n",
      "d)Traumatismo ocular, diabetes melito e alta hipermetropia.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.15 ms /    46 runs   (    0.59 ms per token,  1694.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5695.46 ms /    46 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  5836.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.14 ms /    17 runs   (    0.60 ms per token,  1676.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2853.10 ms /   131 tokens (   21.78 ms per token,    45.91 tokens per second)\n",
      "llama_print_timings:        eval time =  1928.31 ms /    16 runs   (  120.52 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  4832.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    86.27 ms /   150 runs   (    0.58 ms per token,  1738.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18456.64 ms /   150 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18916.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.73 ms /    17 runs   (    0.57 ms per token,  1747.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2155.68 ms /    17 runs   (  126.80 ms per token,     7.89 tokens per second)\n",
      "llama_print_timings:       total time =  2205.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.95 ms /    59 runs   (    0.58 ms per token,  1738.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7252.92 ms /    59 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  7430.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.37 ms /    61 runs   (    0.58 ms per token,  1724.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7493.98 ms /    61 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7676.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.40 ms /    51 runs   (    0.58 ms per token,  1734.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6275.15 ms /    51 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6427.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.34 ms /    58 runs   (    0.57 ms per token,  1739.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7077.26 ms /    58 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  7252.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.42 ms /    63 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7752.73 ms /    63 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  7943.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.35 ms /    58 runs   (    0.57 ms per token,  1739.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7152.93 ms /    58 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  7329.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1732.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2476.22 ms /    20 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  2537.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 158: \n",
      "Language: english\n",
      "Question: \n",
      "About congenital and infantile cataracts, judge the statements below as true (T) or false (F) and mark the correct alternative.\n",
      "\n",
      " I - When the opacity is bilateral and severe, the interval between surgery on the first and second eye should be minimal and generally does not exceed one week.\n",
      " II - In the case of total opacities, surgery should be performed as early as possible, preferably between three and four months of age.\n",
      " III - Congenital cataract is the most common cause of alteration of the red reflex test in maternity hospitals.\n",
      " IV - The normal red reflex at birth is sufficient for the early detection of congenital anomalies in the follow-up up to two years of age.\n",
      "a) I: True; II: False; III: True; IV: False.\n",
      "b) I: False; II: True; III: False; IV: True.\n",
      "c) I: False; II: False; III: True; IV: False.\n",
      "d) I: True; II: True; III: True; IV: True.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.04 ms /   119 runs   (    0.57 ms per token,  1749.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4074.65 ms /   248 tokens (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:        eval time = 14551.36 ms /   118 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 18998.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.02 ms /   119 runs   (    0.56 ms per token,  1775.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14739.37 ms /   119 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 15108.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.79 ms /   119 runs   (    0.57 ms per token,  1755.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14819.36 ms /   119 runs   (  124.53 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time = 15187.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.94 ms /   119 runs   (    0.56 ms per token,  1777.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14769.17 ms /   119 runs   (  124.11 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 15136.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.81 ms /   119 runs   (    0.56 ms per token,  1781.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14833.67 ms /   119 runs   (  124.65 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time = 15197.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.25 ms /   119 runs   (    0.57 ms per token,  1769.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14699.02 ms /   119 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 15062.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.79 ms /   119 runs   (    0.56 ms per token,  1781.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14635.88 ms /   119 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 14999.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.64 ms /   119 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14741.00 ms /   119 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 15103.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) I: True; II: True; III: True; IV: True.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.37 ms /   119 runs   (    0.56 ms per token,  1793.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14755.04 ms /   119 runs   (  123.99 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 15117.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.95 ms /   119 runs   (    0.56 ms per token,  1777.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14798.66 ms /   119 runs   (  124.36 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 15162.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre as cataratas congênitas e infantis, julgue as assertivas abaixo como verdadeiras (V) ou falsas (F) e assinale a alternativa correta.\n",
      "\n",
      " I - Quando a opacidade é bilateral e grave, o intervalo entre a cirurgia do primeiro e do segundo olho deve ser apenas o mínimo e geralmente não ultrapassa uma semana.\n",
      " II - No caso de opacidades totais deve-se realizar a cirurgia o mais precocemente possível, de preferência entre os três e os quatro meses de idade.\n",
      " III - A catarata congênita é a causa mais comum de alteração do teste do reflexo vermelho em maternidades.\n",
      " IV - O reflexo vermelho normal ao nascimento é suficiente para a detecção precoce das anomalias congênitas no acompanhamento até os dois anos de idade.\n",
      "a)I: Verdadeiro; II: Falso; III: Verdadeiro; IV: Falso.\n",
      "b)I: Falso; II: Verdadeiro; III: Falso; IV: Verdadeiro.\n",
      "c)I: Falso; II: Falso; III: Verdadeiro; IV: Falso.\n",
      "d)I: Verdadeiro; lI: Verdadeiro; III: Verdadeiro; IV: Verdadeiro.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.79 ms /    37 runs   (    0.56 ms per token,  1779.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4801.85 ms /   330 tokens (   14.55 ms per token,    68.72 tokens per second)\n",
      "llama_print_timings:        eval time =  4510.49 ms /    36 runs   (  125.29 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  9424.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.46 ms /    37 runs   (    0.55 ms per token,  1808.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4560.11 ms /    37 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4673.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.41 ms /    37 runs   (    0.55 ms per token,  1812.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4594.81 ms /    37 runs   (  124.18 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  4706.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'd be happy to help! Here's the answer in JSON format:\n",
      "\n",
      "{\"response\": \"c\")I: Falso; II: Falso;\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.54 ms /    37 runs   (    0.56 ms per token,  1801.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4586.33 ms /    37 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4700.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.15 ms /    37 runs   (    0.54 ms per token,  1836.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4657.68 ms /    37 runs   (  125.88 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  4769.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.33 ms /    37 runs   (    0.55 ms per token,  1820.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4593.64 ms /    37 runs   (  124.15 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  4706.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.13 ms /    37 runs   (    0.57 ms per token,  1750.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4682.90 ms /    37 runs   (  126.56 ms per token,     7.90 tokens per second)\n",
      "llama_print_timings:       total time =  4799.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to assist you! Here's my answer in JSON format:\n",
      "\n",
      "{\"response\": \"c\") I: Falso; II: Falso;\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.37 ms /    37 runs   (    0.55 ms per token,  1816.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4552.85 ms /    37 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4665.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to help! Here's my answer in JSON format:\n",
      "\n",
      "{\"response\": \"c\")I: Falso; II: Falso; III\n",
      "Generating new response...\n",
      "Error converting respose to json:  Sure, I'm ready to help! Here's my answer in JSON format:\n",
      "\n",
      "{\"response\": \"c\") I: Falso; II: Falso; III\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.33 ms /    37 runs   (    0.55 ms per token,  1819.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4596.57 ms /    37 runs   (  124.23 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  4708.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.32 ms /    37 runs   (    0.55 ms per token,  1820.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4572.64 ms /    37 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4682.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.50 ms /    37 runs   (    0.55 ms per token,  1805.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4571.40 ms /    37 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4683.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.27 ms /    37 runs   (    0.55 ms per token,  1825.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4570.13 ms /    37 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  4681.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.28 ms /    37 runs   (    0.55 ms per token,  1824.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4556.67 ms /    37 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4671.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.73 ms /    27 runs   (    0.55 ms per token,  1833.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3390.38 ms /    27 runs   (  125.57 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  3471.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 159: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding congenital anomalies and failures in the development of the lens, mark the correct alternative.\n",
      "a) The intermittent pupillary block observed in microspherophacy happens due to the touch of the iris in the medium periphery of the crystalline lens due to the increased side-to-side diameter.\n",
      "b) Lens subluxation in Marfan syndrome is most commonly superior and temporal and may induce amblyopia caused by refractive asymmetry.\n",
      "c) In galactosemia, a central shadow resembling an \"oil drop\" can be observed in the red reflex test, which does not occur in other diseases.\n",
      "d) In homocystinuria, lens displacement is usually bilateral, symmetrical and present at birth.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   105.99 ms /   182 runs   (    0.58 ms per token,  1717.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3743.77 ms /   185 tokens (   20.24 ms per token,    49.42 tokens per second)\n",
      "llama_print_timings:        eval time = 22302.50 ms /   181 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 26621.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.64 ms /   182 runs   (    0.59 ms per token,  1706.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22626.33 ms /   182 runs   (  124.32 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 23201.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   105.33 ms /   182 runs   (    0.58 ms per token,  1727.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22487.79 ms /   182 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 23060.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.44 ms /    98 runs   (    0.58 ms per token,  1736.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12025.77 ms /    98 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12323.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.55 ms /    24 runs   (    0.61 ms per token,  1649.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2970.45 ms /    24 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3043.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.51 ms /   182 runs   (    0.59 ms per token,  1708.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22613.23 ms /   182 runs   (  124.25 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 23186.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.59 ms /   182 runs   (    0.59 ms per token,  1707.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22403.14 ms /   182 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 22975.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   108.11 ms /   182 runs   (    0.59 ms per token,  1683.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22541.47 ms /   182 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 23118.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.48 ms /    66 runs   (    0.60 ms per token,  1671.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8173.17 ms /    66 runs   (  123.84 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  8375.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.88 ms /    66 runs   (    0.57 ms per token,  1742.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8059.18 ms /    66 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8257.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre as anomalias congênitas e falhas do desenvolvimento do cristalino, assinale a alternativa correta.\n",
      "a)O bloqueio pupilar intermitente observado na microesferofacia acontece devido ao toque da íris na média periferia do cristalino em razão do diâmetro látero-lateral aumentado.\n",
      "b)A subluxação do cristalino na síndrome de Marfan é mais comumente superior e temporal e pode induzir ambliopia causada pela assimetria refracional.\n",
      "c)Na galactosemia pode-se observar no teste do reflexo vermelho uma sombra central à semelhança de \"gota de óleo\", o que não ocorre em outras doenças.\n",
      "d)Na homocistinúria, o deslocamento do cristalino é geralmente bilateral, simétrico e presente ao nascimento.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.38 ms /     7 runs   (    0.63 ms per token,  1597.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4011.51 ms /   227 tokens (   17.67 ms per token,    56.59 tokens per second)\n",
      "llama_print_timings:        eval time =   751.15 ms /     6 runs   (  125.19 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  4783.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.20 ms /     7 runs   (    0.60 ms per token,  1665.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.09 ms /     7 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1686.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.01 ms /     7 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   871.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.42 ms /    87 runs   (    0.58 ms per token,  1725.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10716.56 ms /    87 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 10980.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.57 ms /     7 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.14 ms /     7 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.82 ms /    71 runs   (    0.57 ms per token,  1739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8747.01 ms /    71 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8960.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.75 ms /   140 runs   (    0.58 ms per token,  1733.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17277.25 ms /   140 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 17707.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.48 ms /   126 runs   (    0.63 ms per token,  1585.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15490.30 ms /   126 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 15898.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.02 ms /     7 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   883.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 160: \n",
      "Language: english\n",
      "Question: \n",
      "After retrobulbar block for phacoemulsification surgery, the patient evolved with progressive loss of consciousness, seizures and respiratory arrest five minutes after anesthetic injection. Check the alternative that correctly describes the most likely complication in this case and a possible preventive measure.\n",
      "a) Intraocular injection - observe the joint movement of the eyeball and the needle before injecting.\n",
      "b) Intravascular injection - suspend anticoagulants or antiplatelet agents before surgery.\n",
      "c) Injection into the subarachnoid space - insert the needle less than 30 mm in depth.\n",
      "d) Retrobulbar hemorrhage - aspirate and check for the presence of hematic content before injecting.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.27 ms /     7 runs   (    0.61 ms per token,  1638.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3466.36 ms /   177 tokens (   19.58 ms per token,    51.06 tokens per second)\n",
      "llama_print_timings:        eval time =   734.09 ms /     6 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4221.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.85 ms /    91 runs   (    0.58 ms per token,  1721.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11206.52 ms /    91 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11480.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.18 ms /   108 runs   (    0.58 ms per token,  1737.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13283.52 ms /   108 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 13614.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.00 ms /   124 runs   (    0.58 ms per token,  1722.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15378.13 ms /   124 runs   (  124.02 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 15766.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.45 ms /   126 runs   (    0.57 ms per token,  1739.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15614.50 ms /   126 runs   (  123.92 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 16004.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    78.54 ms /   136 runs   (    0.58 ms per token,  1731.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16799.17 ms /   136 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 17219.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.65 ms /     8 runs   (    0.58 ms per token,  1722.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   999.26 ms /     8 runs   (  124.91 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  1022.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    74.42 ms /   129 runs   (    0.58 ms per token,  1733.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15923.79 ms /   129 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 16321.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.92 ms /    88 runs   (    0.58 ms per token,  1728.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10750.55 ms /    88 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 11024.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    76.86 ms /   132 runs   (    0.58 ms per token,  1717.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16276.29 ms /   132 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16689.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Após bloqueio retrobulbar para realização de cirurgia de facoemulsificação, o paciente evolui com perda progressiva de consciência, convulsões e parada respiratória após cinco minutos da injeção do anestésico. Assinale a alternativa que descreve corretamente a complicação mais provável neste caso e uma possível medida preventiva.\n",
      "a)Injeção intraocular - observar a movimentação conjunta do globo ocular e da agulha antes de injetar.\n",
      "b)Injeção intravascular - suspender anticoagulantes ou antiagregantes plaquetários antes da cirurgia.\n",
      "c)Injeção no espaço subaracnoide - inserir a agulha menos do que 30 mm em profundidade.\n",
      "d)Hemorragia retrobulbar - aspirar e verificar a presença de conteúdo hemático antes de injetar.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.07 ms /   137 runs   (    0.58 ms per token,  1711.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3799.05 ms /   230 tokens (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:        eval time = 16775.20 ms /   136 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 20999.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.19 ms /   137 runs   (    0.58 ms per token,  1729.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16942.50 ms /   137 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 17365.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.80 ms /   137 runs   (    0.58 ms per token,  1716.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16956.83 ms /   137 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 17380.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.45 ms /   113 runs   (    0.58 ms per token,  1726.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14091.29 ms /   113 runs   (  124.70 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time = 14436.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  ####\n",
      "\n",
      "Response: A\n",
      "\n",
      "The correct answer is A, Injeção intraocular - observar a movimentação conjunta do globo ocular e da agulha antes de injetar.\n",
      "\n",
      "Explanation: The complication of inadvertent intravascular injection of local anesthetic is a possible consequence of retrobulbar block. To prevent this complication, it is essential to observe the movement of the globe and the needle before injecting the local anesthetic.\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.34 ms /   137 runs   (    0.58 ms per token,  1726.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17016.52 ms /   137 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 17441.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.81 ms /   137 runs   (    0.58 ms per token,  1716.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16828.07 ms /   137 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 17256.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.16 ms /   137 runs   (    0.58 ms per token,  1730.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16892.36 ms /   137 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 17317.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.26 ms /   137 runs   (    0.58 ms per token,  1728.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16853.94 ms /   137 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 17276.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    78.97 ms /   137 runs   (    0.58 ms per token,  1734.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16880.95 ms /   137 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 17306.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.10 ms /   137 runs   (    0.58 ms per token,  1731.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16885.44 ms /   137 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 17311.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.67 ms /   103 runs   (    0.58 ms per token,  1726.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12774.29 ms /   103 runs   (  124.02 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 13091.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 161: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding biometrics in eyes covered with silicone oil, it is correct to state:\n",
      "a) The axial length measured by ultrasound is falsely reduced in relation to the real value.\n",
      "b)Low coherence reflectometry cannot be used in this situation.\n",
      "c) The anterior chamber depth measurement must be performed in the supine position.\n",
      "d) Partial coherence interferometry is preferable to ultrasonography in these cases.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.90 ms /    25 runs   (    0.60 ms per token,  1678.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2014.88 ms /   106 tokens (   19.01 ms per token,    52.61 tokens per second)\n",
      "llama_print_timings:        eval time =  2964.78 ms /    24 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  5056.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.29 ms /    75 runs   (    0.58 ms per token,  1732.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9240.58 ms /    75 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9467.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.34 ms /    25 runs   (    0.57 ms per token,  1743.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3057.57 ms /    25 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3131.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2912.78 ms /    24 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2983.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    25 runs   (    0.58 ms per token,  1734.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3052.04 ms /    25 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3126.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.02 ms /    47 runs   (    0.57 ms per token,  1739.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5717.57 ms /    47 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5858.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n",
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.45 ms /    25 runs   (    0.58 ms per token,  1730.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3038.58 ms /    25 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3112.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1723.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3072.32 ms /    25 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3147.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.29 ms /    25 runs   (    0.57 ms per token,  1750.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3040.48 ms /    25 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3116.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3029.43 ms /    25 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3104.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a biometria em olhos tamponados por óleo de silicone é correto afirmar:\n",
      "a)O comprimento axial medido pelo ultrassom é falsamente reduzido em relação ao valor real.\n",
      "b)A reflectometria de baixa coerência não pode ser utilizada nessa situação.\n",
      "c)A medida da profundidade de câmara anterior deve ser realizada em posição supina.\n",
      "d)A interferometria de coerência parcial é preferível à ultrassonografia nesses casos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.88 ms /   115 runs   (    0.58 ms per token,  1719.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2483.94 ms /   138 tokens (   18.00 ms per token,    55.56 tokens per second)\n",
      "llama_print_timings:        eval time = 14022.39 ms /   114 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 16866.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.34 ms /    51 runs   (    0.58 ms per token,  1738.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6275.84 ms /    51 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6430.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.85 ms /   114 runs   (    0.58 ms per token,  1731.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13988.00 ms /   114 runs   (  122.70 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 14341.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.84 ms /   137 runs   (    0.58 ms per token,  1716.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16840.77 ms /   137 runs   (  122.93 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 17273.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.18 ms /     9 runs   (    0.58 ms per token,  1736.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1088.67 ms /     9 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1115.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.56 ms /   110 runs   (    0.58 ms per token,  1730.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13576.97 ms /   110 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13915.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.59 ms /    48 runs   (    0.57 ms per token,  1739.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5944.52 ms /    48 runs   (  123.84 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6091.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'a'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1755.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.28 ms /     7 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.32 ms /     7 runs   (  120.76 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   867.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.30 ms /    54 runs   (    0.58 ms per token,  1725.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6645.76 ms /    54 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6815.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 162: \n",
      "Language: english\n",
      "Question: \n",
      "Check the alternative that contains, respectively, a drug associated with the occurrence of flaccid iris syndrome in the perioperative period and an adequate intervention to restore mydriasis in these cases.\n",
      "a) Chlorpromazine - iris retractors.\n",
      "b) Doxasozine - Beehler dilator.\n",
      "c) Tamsulosin - sphincterectomies.\n",
      "d) Atropine - iris expander ring.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    24 runs   (    0.60 ms per token,  1669.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2504.60 ms /   109 tokens (   22.98 ms per token,    43.52 tokens per second)\n",
      "llama_print_timings:        eval time =  2803.10 ms /    23 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5380.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.47 ms /    28 runs   (    0.59 ms per token,  1699.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3396.99 ms /    28 runs   (  121.32 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3481.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.41 ms /   164 runs   (    0.59 ms per token,  1683.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20258.28 ms /   164 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 20775.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3296.28 ms /    27 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3376.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    28 runs   (    0.58 ms per token,  1717.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3436.14 ms /    28 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3519.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1725.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3402.95 ms /    28 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3486.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.42 ms /    27 runs   (    0.61 ms per token,  1643.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3332.61 ms /    27 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3415.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.03 ms /    38 runs   (    0.69 ms per token,  1459.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4630.64 ms /    38 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4753.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.80 ms /    29 runs   (    0.58 ms per token,  1726.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3520.30 ms /    29 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3607.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que contém, respectivamente, um medicamento associado à ocorrência da síndrome da íris flácida no peroperatório e uma intervenção adequada para restabelecimento da midríase nesses casos.\n",
      "a)Clorpromazina - retratores de íris.\n",
      "b)Doxasozina - dilatador de Beehler.\n",
      "c)Tamsulosina - esfincterectomias.\n",
      "d)Atropina - anel expansor de íris.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.57 ms /    93 runs   (    0.58 ms per token,  1736.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11338.03 ms /    93 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 11624.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.24 ms /     7 runs   (    0.61 ms per token,  1651.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2060.45 ms /   128 tokens (   16.10 ms per token,    62.12 tokens per second)\n",
      "llama_print_timings:        eval time =   730.90 ms /     6 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2812.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.87 ms /    81 runs   (    0.62 ms per token,  1624.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9995.27 ms /    81 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10343.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.46 ms /    27 runs   (    0.68 ms per token,  1462.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3287.52 ms /    27 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3476.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.90 ms /    80 runs   (    0.67 ms per token,  1484.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9817.52 ms /    80 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10380.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.13 ms /    90 runs   (    0.68 ms per token,  1472.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11018.75 ms /    90 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 11655.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.62 ms /     7 runs   (    0.66 ms per token,  1516.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.06 ms /     7 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   915.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.77 ms /     7 runs   (    0.68 ms per token,  1466.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.02 ms /     7 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   910.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.53 ms /    83 runs   (    0.68 ms per token,  1468.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10173.68 ms /    83 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 10756.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    81.91 ms /   123 runs   (    0.67 ms per token,  1501.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15122.52 ms /   123 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 15998.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.28 ms /    96 runs   (    0.61 ms per token,  1647.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11924.30 ms /    96 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 12322.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 163: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the prevention of endophthalmitis in cataract surgery, mark the correct alternative.\n",
      "a) In cases of contraindication to povidone-iodine, topical antibiotic eye drops should be used for five days before the procedure.\n",
      "b) The main risk factors include immunosuppression, diabetes, blepharitis, conjunctivitis, rupture of the posterior capsule and vitreous loss.\n",
      "c) The intracameral use of gentamicin should be adopted, especially in cases associated with previous vitrectomy.\n",
      "d) The most frequent etiological agents are bacteria from inadequate sterilization of surgical materials and intraocular lenses. \n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.15 ms /    17 runs   (    0.60 ms per token,  1674.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3413.91 ms /   169 tokens (   20.20 ms per token,    49.50 tokens per second)\n",
      "llama_print_timings:        eval time =  1973.12 ms /    16 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5437.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.26 ms /    28 runs   (    0.58 ms per token,  1722.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3411.60 ms /    28 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3495.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1739.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3114.79 ms /    25 runs   (  124.59 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3190.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.34 ms /    70 runs   (    0.58 ms per token,  1735.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8621.69 ms /    70 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8835.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.33 ms /    25 runs   (    0.57 ms per token,  1744.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3059.27 ms /    25 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3134.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.40 ms /    89 runs   (    0.58 ms per token,  1731.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11025.91 ms /    89 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 11298.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.20 ms /    25 runs   (    0.57 ms per token,  1761.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3060.46 ms /    25 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3136.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    24 runs   (    0.58 ms per token,  1725.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2950.85 ms /    24 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3023.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.07 ms /    92 runs   (    0.58 ms per token,  1733.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11355.77 ms /    92 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 11636.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.50 ms /    95 runs   (    0.57 ms per token,  1743.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11638.61 ms /    95 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 11925.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a prevenção de endoftalmite em cirurgia de catarata, assinale a alternativa correta.\n",
      "a)Em casos de contraindicação à iodopovidona, deve-se utilizar colírio de antibiótico tópico por cinco dias antes do procedimento.\n",
      "b)Os principais fatores de risco incluem imunossupressão, diabetes, blefarite, conjuntivite, rotura da cápsula posterior e perda vítrea.\n",
      "c)O uso intracameral de gentamicina deve ser adotado, principalmente nos casos associados a vitrectomia anterior.\n",
      "d)Os agentes etiológicos mais frequentes são bactérias provenientes da esterilização inadequada dos materiais cirúrgicos e lentes intraoculares.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.82 ms /    84 runs   (    0.58 ms per token,  1720.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3664.46 ms /   204 tokens (   17.96 ms per token,    55.67 tokens per second)\n",
      "llama_print_timings:        eval time = 10237.52 ms /    83 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 14158.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.13 ms /    85 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10543.71 ms /    85 runs   (  124.04 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 10805.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.33 ms /    11 runs   (    0.58 ms per token,  1737.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1360.21 ms /    11 runs   (  123.66 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  1392.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.99 ms /    78 runs   (    0.59 ms per token,  1696.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9657.70 ms /    78 runs   (  123.82 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  9942.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.76 ms /    82 runs   (    0.62 ms per token,  1615.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10155.01 ms /    82 runs   (  123.84 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 10582.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.59 ms /     7 runs   (  124.37 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.08 ms /     7 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   879.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.40 ms /    77 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9487.11 ms /    77 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9720.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.86 ms /    83 runs   (    0.58 ms per token,  1734.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10412.88 ms /    83 runs   (  125.46 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time = 10666.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.49 ms /    77 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9526.66 ms /    77 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  9760.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 164: \n",
      "Language: english\n",
      "Question: \n",
      "After performing the core fractures with the divide-and-conquer technique, a whitish portion and contraction of the tissue can be seen on the lateral portion of the corneal incision, with leakage of the irrigation solution through the gap formed. Among the alternatives below, which would be effective in preventing the occurrence of the described complication?\n",
      "a) Reduce the aspiration flow rate and make the incision narrower.\n",
      "b)Use larger diameter tips and smaller diameter coaxial irrigation sleeves.\n",
      "c) Keep the tip equidistant from the incision walls and use pulsed ultrasound.\n",
      "d) Fill the anterior chamber with cohesive viscoelastic and use continuous ultrasound.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.10 ms /   133 runs   (    0.58 ms per token,  1725.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2878.79 ms /   170 tokens (   16.93 ms per token,    59.05 tokens per second)\n",
      "llama_print_timings:        eval time = 16223.98 ms /   132 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 19514.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.06 ms /    98 runs   (    0.58 ms per token,  1717.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12150.53 ms /    98 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 12449.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.21 ms /    87 runs   (    0.58 ms per token,  1732.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10762.34 ms /    87 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 11032.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   114.28 ms /   197 runs   (    0.58 ms per token,  1723.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24206.04 ms /   197 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 24828.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.89 ms /   197 runs   (    0.58 ms per token,  1729.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24351.63 ms /   197 runs   (  123.61 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 24967.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   873.37 ms /     7 runs   (  124.77 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =   894.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.76 ms /    97 runs   (    0.57 ms per token,  1739.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11879.04 ms /    97 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12174.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.10 ms /   158 runs   (    0.58 ms per token,  1734.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19518.42 ms /   158 runs   (  123.53 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 20014.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    82.18 ms /   143 runs   (    0.57 ms per token,  1740.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17606.51 ms /   143 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 18047.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    94.91 ms /   157 runs   (    0.60 ms per token,  1654.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19374.69 ms /   157 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 19866.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Após realizar as fraturas do núcleo com a técnica de dividir e conquistar, nota-se uma porção esbranquiçada e contração do tecido na porção lateral da incisão da córnea, com vazamento da solução de irrigação pelo vão formado. Entre as alternativas abaixo, qual seria eficaz em prevenir a ocorrência da complicação descrita?\n",
      "a)Reduzir a taxa de fluxo de aspiração e fazer incisão mais estreita.\n",
      "b)Usar ponteiras de maior diâmetro e luvas de irrigação coaxial de menor diâmetro.\n",
      "c)Manter a ponteira equidistante das paredes da incisão e utilizar ultrassom pulsado.\n",
      "d)Preencher a câmara anterior com viscoelástico coesivo e utilizar ultrassom contínuo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1686.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4068.95 ms /   232 tokens (   17.54 ms per token,    57.02 tokens per second)\n",
      "llama_print_timings:        eval time =   721.26 ms /     6 runs   (  120.21 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  4811.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.50 ms /     7 runs   (  124.50 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   891.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.72 ms /     7 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.05 ms /    40 runs   (    0.58 ms per token,  1735.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4913.71 ms /    40 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5032.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.24 ms /    37 runs   (    0.57 ms per token,  1741.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4557.60 ms /    37 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4666.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.15 ms /     7 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.84 ms /   135 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16648.36 ms /   135 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 17062.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.96 ms /    37 runs   (    0.65 ms per token,  1543.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4573.78 ms /    37 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4694.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.43 ms /     7 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.96 ms /    37 runs   (    0.59 ms per token,  1684.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4658.40 ms /    37 runs   (  125.90 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  4774.73 ms\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation:\n",
    "llm_language_evaluation(path=PATH, model=MODEL, temperature=TEMPERATURE, n_repetitions=N_REPETITIONS, reasoning=REASONING, languages=LANGUAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc602206",
   "metadata": {},
   "source": [
    "#### See the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c7d08b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>test</th>\n",
       "      <th>theme</th>\n",
       "      <th>subtheme</th>\n",
       "      <th>portuguese</th>\n",
       "      <th>english</th>\n",
       "      <th>answer</th>\n",
       "      <th>responses_english_0</th>\n",
       "      <th>responses_english_1</th>\n",
       "      <th>...</th>\n",
       "      <th>responses_portuguese_0</th>\n",
       "      <th>responses_portuguese_1</th>\n",
       "      <th>responses_portuguese_2</th>\n",
       "      <th>responses_portuguese_3</th>\n",
       "      <th>responses_portuguese_4</th>\n",
       "      <th>responses_portuguese_5</th>\n",
       "      <th>responses_portuguese_6</th>\n",
       "      <th>responses_portuguese_7</th>\n",
       "      <th>responses_portuguese_8</th>\n",
       "      <th>responses_portuguese_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Teórica I</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>cornea</td>\n",
       "      <td>Em qual região ocular células caliciformes são...</td>\n",
       "      <td>In which ocular region are caliciform cells ph...</td>\n",
       "      <td>D</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>Teórica I</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>retina</td>\n",
       "      <td>Assinale a alternativa que melhor correlaciona...</td>\n",
       "      <td>Mark the alternative that best correlates the ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>Teórica I</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>cornea</td>\n",
       "      <td>Ordene as três denominações celulares encontra...</td>\n",
       "      <td>Order the three cell names found in the cornea...</td>\n",
       "      <td>A</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>Teórica I</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>cornea</td>\n",
       "      <td>Sobre a membrana de Descemet da córnea, é corr...</td>\n",
       "      <td>Regarding Descemet's membrane of the cornea, i...</td>\n",
       "      <td>C</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>Teórica I</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>cornea</td>\n",
       "      <td>Sobre a camada lipídica do filme lacrimal, ass...</td>\n",
       "      <td>About the lipidic layer of the lacrimal film, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>C</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>161</td>\n",
       "      <td>2022</td>\n",
       "      <td>Teórica II</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Após bloqueio retrobulbar para realização de c...</td>\n",
       "      <td>After retrobulbar block for phacoemulsificatio...</td>\n",
       "      <td>C</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>162</td>\n",
       "      <td>2022</td>\n",
       "      <td>Teórica II</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sobre a biometria em olhos tamponados por óleo...</td>\n",
       "      <td>Regarding biometrics in eyes covered with sili...</td>\n",
       "      <td>D</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>163</td>\n",
       "      <td>2022</td>\n",
       "      <td>Teórica II</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assinale a alternativa que contém, respectivam...</td>\n",
       "      <td>Check the alternative that contains, respectiv...</td>\n",
       "      <td>A</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>164</td>\n",
       "      <td>2022</td>\n",
       "      <td>Teórica II</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sobre a prevenção de endoftalmite em cirurgia ...</td>\n",
       "      <td>Regarding the prevention of endophthalmitis in...</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>165</td>\n",
       "      <td>2022</td>\n",
       "      <td>Teórica II</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Após realizar as fraturas do núcleo com a técn...</td>\n",
       "      <td>After performing the core fractures with the d...</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  year        test                theme subtheme  \\\n",
       "0      1  2022   Teórica I             Anatomia   cornea   \n",
       "1      2  2022   Teórica I             Anatomia   retina   \n",
       "2      3  2022   Teórica I             Anatomia   cornea   \n",
       "3      4  2022   Teórica I             Anatomia   cornea   \n",
       "4      5  2022   Teórica I             Anatomia   cornea   \n",
       "..   ...   ...         ...                  ...      ...   \n",
       "159  161  2022  Teórica II  Cristalino/Catarata      NaN   \n",
       "160  162  2022  Teórica II  Cristalino/Catarata      NaN   \n",
       "161  163  2022  Teórica II  Cristalino/Catarata      NaN   \n",
       "162  164  2022  Teórica II  Cristalino/Catarata      NaN   \n",
       "163  165  2022  Teórica II  Cristalino/Catarata      NaN   \n",
       "\n",
       "                                            portuguese  \\\n",
       "0    Em qual região ocular células caliciformes são...   \n",
       "1    Assinale a alternativa que melhor correlaciona...   \n",
       "2    Ordene as três denominações celulares encontra...   \n",
       "3    Sobre a membrana de Descemet da córnea, é corr...   \n",
       "4    Sobre a camada lipídica do filme lacrimal, ass...   \n",
       "..                                                 ...   \n",
       "159  Após bloqueio retrobulbar para realização de c...   \n",
       "160  Sobre a biometria em olhos tamponados por óleo...   \n",
       "161  Assinale a alternativa que contém, respectivam...   \n",
       "162  Sobre a prevenção de endoftalmite em cirurgia ...   \n",
       "163  Após realizar as fraturas do núcleo com a técn...   \n",
       "\n",
       "                                               english answer  \\\n",
       "0    In which ocular region are caliciform cells ph...      D   \n",
       "1    Mark the alternative that best correlates the ...      B   \n",
       "2    Order the three cell names found in the cornea...      A   \n",
       "3    Regarding Descemet's membrane of the cornea, i...      C   \n",
       "4    About the lipidic layer of the lacrimal film, ...      B   \n",
       "..                                                 ...    ...   \n",
       "159  After retrobulbar block for phacoemulsificatio...      C   \n",
       "160  Regarding biometrics in eyes covered with sili...      D   \n",
       "161  Check the alternative that contains, respectiv...      A   \n",
       "162  Regarding the prevention of endophthalmitis in...      B   \n",
       "163  After performing the core fractures with the d...      C   \n",
       "\n",
       "    responses_english_0 responses_english_1  ... responses_portuguese_0  \\\n",
       "0                     b                   b  ...                      a   \n",
       "1                     B                   B  ...                      B   \n",
       "2                     c                   c  ...                      b   \n",
       "3                     b                   b  ...                      b   \n",
       "4                     B                   B  ...                      c   \n",
       "..                  ...                 ...  ...                    ...   \n",
       "159                   b                   b  ...                      c   \n",
       "160                   b                   b  ...                      c   \n",
       "161                   b                   b  ...                      A   \n",
       "162                   b                   A  ...                      b   \n",
       "163                   c                   c  ...                      c   \n",
       "\n",
       "    responses_portuguese_1 responses_portuguese_2 responses_portuguese_3  \\\n",
       "0                        b                      a                      b   \n",
       "1                        B                      B                      A   \n",
       "2                        b                      a                      A   \n",
       "3                        b                      b                      b   \n",
       "4                        c                      c                      C   \n",
       "..                     ...                    ...                    ...   \n",
       "159                      c                      c                      c   \n",
       "160                      a                      c                      c   \n",
       "161                      b                      b                      b   \n",
       "162                      B                      b                      b   \n",
       "163                      c                      c                      c   \n",
       "\n",
       "    responses_portuguese_4 responses_portuguese_5 responses_portuguese_6  \\\n",
       "0                        b                      b                      b   \n",
       "1                        B                      B                      A   \n",
       "2                        a                      a                      b   \n",
       "3                        b                      b                      b   \n",
       "4                        b                      b                      c   \n",
       "..                     ...                    ...                    ...   \n",
       "159                      c                      c                      c   \n",
       "160                      a                      c                      c   \n",
       "161                      B                      B                      A   \n",
       "162                      b                      b                      B   \n",
       "163                      c                      c                      c   \n",
       "\n",
       "    responses_portuguese_7 responses_portuguese_8 responses_portuguese_9  \n",
       "0                        A                      a                      a  \n",
       "1                        A                      A                      B  \n",
       "2                        b                      a                      b  \n",
       "3                        b                      b                      b  \n",
       "4                        b                      B                      A  \n",
       "..                     ...                    ...                    ...  \n",
       "159                      c                      c                      c  \n",
       "160                      a                      a                      a  \n",
       "161                      b                      B                      b  \n",
       "162                      b                      b                      b  \n",
       "163                      c                      c                      c  \n",
       "\n",
       "[164 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if N_REPETITIONS > 1:\n",
    "    df = pd.read_csv(f\"responses/{MODEL}_Temperature{str(TEMPERATURE).replace('.', '_')}_{N_REPETITIONS}Repetitions.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(f\"responses/{MODEL}_Temperature{str(TEMPERATURE).replace('.', '_')}.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81336b09",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a81fc827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Anatomia              4                 5     21                 19.047619   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    23.809524  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Córnea              4                 1     10                      40.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                         10.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         theme  match_english  match_portuguese  Total  \\\n",
      "0  Embriologia              1                 1      2   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                      50.0                         50.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          theme  match_english  match_portuguese  Total  \\\n",
      "0  Farmacologia              5                 4      9   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                 55.555556                    44.444444  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Genética              0                 0      2                       0.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAIkCAYAAAA9JHCEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQ+0lEQVR4nO3deXxM9/7H8fckkUUiCRFJEbtLLK02looWtUXRUrtqxa69tZSqpS260FyUakureu9PULqEVktVa+miKCqofam11C4JQiSZ7+8Pj8w1EmQiqZPr9Xw85sF8z/ec8zmTk5l3zvmeMzZjjBEAAICFud3pAgAAAG6FwAIAACyPwAIAACyPwAIAACyPwAIAACyPwAIAACyPwAIAACyPwAIAACyPwAIAgAV9/fXXGj9+vFJTU+90KZZAYAEAC+vevbvKlCnzt6/34MGDstlseuutt/72dUP67bff1LlzZ1WoUEEFChTI1jyxsbGy2Ww6ePBg3hZ3hxBY8pk//vhD/fr1U7ly5eTt7S1/f3/Vq1dP77zzji5dunSny3PZjh079Oqrr+boF2zYsGGy2Wzq1KlT7hf2PyDjA+fah7+/v2rUqKGpU6cqPT0919bVvXt3+fn55drykDfKlCmTaZ/I6hEbG3unS70jFi1apMcee0whISHy9PRUkSJFVL9+fU2aNElJSUl/Wx0JCQnq2LGj/vWvf6ldu3aZpr/55ptauHDh31aPVdj4LqH845tvvlGHDh3k5eWlbt26qVq1arpy5Yp++eUXLViwQN27d9eMGTPudJkumT9/vjp06KAffvhBDRs2zPZ8xhiVKlVKHh4eOnHihE6cOKFChQrlXaH50MGDB1W2bFl16dJFLVq0kCQlJiZqyZIlWrJkiYYOHaqJEyfmyrq6d++u+fPn68KFC7myPPxXamqq7Ha7vLy8bntZCxcudPoZLVmyRJ988onefvttFS1a1NEeGRkpNzc3lS1bVhMnTtTQoUNve91WZrfb1atXL8XGxqp69epq166dwsLCdP78ea1du1ZfffWVIiMjtWLFir+lnh9//FH79+9Xz549s5zu5+en9u3bZwqW6enpSk1NlZeXl2w2299Q6d/MIF/Yv3+/8fPzM5UrVzbHjh3LNH3v3r1mypQpt70eu91ukpOTs5x26dIlk56eftvruFZcXJyRZH744QeX5lu5cqWRZFauXGkKFChgYmNjc7UuK0hNTTUpKSk5nv/AgQNGkpk4caJTu91uN7Vq1TLFixe/3RIdoqOjja+vb64tD3+PiRMnGknmwIEDmabdaP/5XxQTE2MkmcGDBxu73Z5p+rFjx8y//vWvO1BZ1nx9fU10dPSdLuNvxymhfGLChAm6cOGC/vOf/+iee+7JNL1ChQoaNGiQ43laWpreeOMNlS9fXl5eXipTpoxeeuklpaSkOM1XpkwZtWrVSt99951q1qwpHx8fffjhh/rxxx9ls9n06aef6pVXXlGJEiVUsGBBx2HRdevWqXnz5goICFDBggXVoEEDrV69OlNdR48eVa9evVS8eHF5eXmpbNmyevbZZ3XlyhXFxsaqQ4cOkqRHHnnEcTj6xx9/vOXrMXfuXFWpUkWPPPKImjRporlz52bqk7ENn3/+ucaNG6eSJUvK29tbjRs31r59+5z67t27V+3atVNoaKi8vb1VsmRJde7cWYmJiZKktm3b6oEHHnCa57HHHpPNZtPXX3/taFu3bp1sNpu+/fZbR1tCQoKef/55hYWFycvLSxUqVND48eNlt9sdfa4dLzBlyhTHz23Hjh2SpPfee09Vq1ZVwYIFVbhwYdWsWVPz5s275euUFZvNppCQEHl4eDjaoqOjVbRo0SwH9zVr1kyVKlXK0bqudejQIf3zn/9UpUqV5OPjo6CgIHXo0CHT6cCM8/CrV6/WkCFDFBwcLF9fXz3xxBM6deqUU1+73a5XX31VxYsXV8GCBfXII49ox44dKlOmjLp37+7o9+qrr2b5F2dW5/y/+uortWzZ0rHPli9fXm+88UaWp9CmTZumcuXKycfHR7Vr19aqVavUsGHDTEcLU1JSNGbMGFWoUEFeXl4KCwvTsGHDMv0+ZuX6MSzX7iszZsxw7Cu1atXShg0bbrm8nMjOenbt2qX27durSJEi8vb2Vs2aNZ1+N6T/vt6//PKLBg4cqODgYAUGBqpfv366cuWKEhIS1K1bNxUuXFiFCxfWsGHDZK47CWC32zVlyhRVrVpV3t7eCgkJUb9+/XTu3DmnfomJidq1a5fjd/hGkpOTNX78eFWtWlUTJ07Mcj+55557NHz48EztH3/8sSIiIuTj46MiRYqoc+fOOnLkiFOfhg0bqlq1atqxY4ceeeQRFSxYUCVKlNCECRMyLS87+4nNZtPFixc1a9Ysx3tmxr5+ozEs3377rRo0aKBChQrJ399ftWrVcnr/WLVqlTp06KBSpUo51jt48GDLDTPwuHUXWMGiRYtUrlw5RUZGZqt/7969NWvWLLVv314vvPCC1q1bp5iYGO3cuVNffvmlU9/du3erS5cu6tevn/r06eP04fTGG2/I09NTQ4cOVUpKijw9PbVy5Uo9+uijioiI0JgxY+Tm5qaZM2eqUaNGWrVqlWrXri1JOnbsmGrXrq2EhAT17dtXlStX1tGjRzV//nwlJyerfv36GjhwoN5991299NJLCg8PlyTHvzeSkpKiBQsW6IUXXpAkdenSRT169NDx48cVGhqaqf+//vUvubm5aejQoUpMTNSECRPUtWtXrVu3TpJ05coVRUVFKSUlRQMGDFBoaKiOHj2qxYsXKyEhQQEBAXr44Yf11VdfKSkpSf7+/jLGaPXq1XJzc9OqVav0+OOPS7r6i+/m5qZ69epJuvpm2KBBAx09elT9+vVTqVKltGbNGo0cOVJ//fWXpkyZ4lTrzJkzdfnyZfXt21deXl4qUqSIPvroIw0cOFDt27fXoEGDdPnyZf3+++9at26dnnzyyVvuC8nJyTp9+rQkKSkpSd9++62WLl2qkSNHOvo8/fTTmj17tr777ju1atXK0X78+HGtXLlSY8aMueV6bmXDhg1as2aNOnfurJIlS+rgwYP64IMP1LBhQ+3YsUMFCxZ06j9gwAAVLlxYY8aM0cGDBzVlyhT1799fn332maPPyJEjNWHCBD322GOKiorSli1bFBUVpcuXL+e4ztjYWPn5+WnIkCHy8/PTypUrNXr0aCUlJTmdQvvggw/Uv39/Pfzwwxo8eLAOHjyoNm3aqHDhwipZsqSjn91u1+OPP65ffvlFffv2VXh4uLZu3aq3335be/bsyfFYhHnz5un8+fPq16+fbDabJkyYoLZt22r//v3ZHqSZW+vZvn276tWrpxIlSmjEiBHy9fXV559/rjZt2mjBggV64oknnJaZ8Xv22muv6ddff9WMGTMUGBioNWvWqFSpUnrzzTe1ZMkSTZw4UdWqVVO3bt0c8/br10+xsbHq0aOHBg4cqAMHDmjq1KnatGmTVq9e7ajpyy+/VI8ePTRz5kyn8Hq9X375RQkJCRo6dKjc3d2z/bqMGzdOo0aNUseOHdW7d2+dOnVK7733nurXr69NmzYpMDDQ0ffcuXNq3ry52rZtq44dO2r+/PkaPny4qlevrkcffVRS9veTOXPmqHfv3qpdu7b69u0rSSpfvvwN64yNjVXPnj1VtWpVjRw5UoGBgdq0aZOWLl3qeP+Ii4tTcnKynn32WQUFBWn9+vV677339OeffyouLi7br0meu9OHeHBriYmJRpJp3bp1tvpv3rzZSDK9e/d2ah86dKjjNEqG0qVLG0lm6dKlTn1/+OEHI8mUK1fO6RSR3W43FStWNFFRUU6HTpOTk03ZsmVN06ZNHW3dunUzbm5uZsOGDZlqzJg3J6eE5s+fbySZvXv3GmOMSUpKMt7e3ubtt9/OchvCw8OdTq288847RpLZunWrMcaYTZs2GUkmLi7uhuvcsGGDkWSWLFlijDHm999/N5JMhw4dTJ06dRz9Hn/8cXP//fc7nr/xxhvG19fX7Nmzx2l5I0aMMO7u7ubw4cPGmP8efvf39zcnT5506tu6dWtTtWrV7L48DhnLzOrx7LPPOv380tPTTcmSJU2nTp2cljF58mRjs9nM/v37b7qu7JwSyupU49q1a40kM3v2bEfbzJkzjSTTpEkTpxoHDx5s3N3dTUJCgjHGmOPHjxsPDw/Tpk0bp2W++uqrRpLTIfMxY8aYrN7uMtZ17SmRrOrs16+fKViwoLl8+bIxxpiUlBQTFBRkatWqZVJTUx39YmNjjSTToEEDR9ucOXOMm5ubWbVqldMyp0+fbiSZ1atXZ1rftaKjo03p0qUdzzN+rkFBQebs2bOO9q+++spIMosWLbrp8q6VnVNC2VlP48aNTfXq1R2vjzFXf8cjIyNNxYoVHW0Zr/f17x9169Y1NpvNPPPMM462tLQ0U7JkSafXctWqVUaSmTt3rlOtS5cuzdSesa6ZM2fe9DXIeD9YuHChU3taWpo5deqU0yOj5oMHDxp3d3czbtw4p3m2bt1qPDw8nNobNGiQaR9PSUkxoaGhpl27do42V/aTG50Sun5/TkhIMIUKFTJ16tQxly5dcup7/fv39WJiYozNZjOHDh3KNO1O4ZRQPpBxGia7g0qXLFkiSRoyZIhTe8YRiW+++capvWzZsoqKispyWdHR0fLx8XE837x5s/bu3asnn3xSZ86c0enTp3X69GldvHhRjRs31s8//yy73S673a6FCxfqscceU82aNTMt93YGhM2dO1c1a9ZUhQoVJF19XVq2bJnlaSFJ6tGjhzw9PR3PH374YUnS/v37JUkBAQGSpO+++07JyclZLuP++++Xn5+ffv75Z0lXj6SULFlS3bp1U3x8vJKTk2WM0S+//OJYvnT1L5eHH35YhQsXdrxWp0+fVpMmTZSenu5YXoZ27dopODjYqS0wMFB//vlnjg/39+3bV8uWLdOyZcu0YMECPffcc/rwww+d9g83Nzd17dpVX3/9tc6fP+9onzt3riIjI1W2bNkcrfta1+5HqampOnPmjCpUqKDAwEDFx8dnWfe1+8nDDz+s9PR0HTp0SJK0YsUKpaWl6Z///KfTfAMGDMi1Os+fP6/Tp0/r4YcfVnJysnbt2iXp6iWnZ86cUZ8+fZxOrXXt2lWFCxd2Wl5cXJzCw8NVuXJlp32gUaNGkqQffvghR3V26tTJaV3X79e55VbrOXv2rFauXKmOHTs6Xq/Tp0/rzJkzioqK0t69e3X06FGnZfbq1cvpZ1unTh0ZY9SrVy9Hm7u7u2rWrOm0PXFxcQoICFDTpk2dXsuIiAj5+fk5vZbdu3eXMeamR1ek/76/Xn+V29atWxUcHOz0OHPmjCTpiy++kN1uV8eOHZ3qCA0NVcWKFTP9TP38/PTUU085nnt6eqp27dqZti2395Nly5bp/PnzGjFihLy9vZ2mXfv6X7vPX7x4UadPn1ZkZKSMMdq0aZPL680rnBLKB/z9/SXJ6YPkZg4dOiQ3NzfHB3qG0NBQBQYGOt7wM9zsw+j6aXv37pV0NcjcSGJioq5cuaKkpCRVq1YtWzVnV0JCgpYsWaL+/fs7jUOpV6+eFixYoD179ugf//iH0zylSpVyep7x5ptxzrts2bIaMmSIJk+erLlz5+rhhx/W448/rqeeesoRZtzd3VW3bl2tWrVK0tXA8vDDD+uhhx5Senq6fv31V4WEhOjs2bNOgWXv3r36/fffM4WQDCdPnnR6ntXPYvjw4Vq+fLlq166tChUqqFmzZnryyScdp51upWLFimrSpInjedu2bWWz2TRlyhT17NlT1atXlyR169ZN48eP15dffqlu3bpp9+7d2rhxo6ZPn56t9dzKpUuXFBMTo5kzZ+ro0aNOYxOyGmdwq59bxn58/X5epEiRTKHBFdu3b9crr7yilStXZrqUNaPOG63bw8Mj0z1T9u7dq507d2Z7H8iuW70+ueVW69m3b5+MMRo1apRGjRqV5TJOnjypEiVK3HCZGb9nYWFhmdqv3Z69e/cqMTFRxYoVu+F6XJXxh+D1V7hVqFBBy5YtkyTNnj1bc+bMcarDGKOKFStmuczrT8mVLFky0x9phQsX1u+//+60zNzeT/744w9JuuX78OHDhzV69Gh9/fXXWY4FsgoCSz7g7++v4sWLa9u2bS7Nl92jGNem61tNyxgoOnHiRNWoUSPLefz8/HT27NnsFemiuLg4paSkaNKkSZo0aVKm6XPnztVrr73m1Haj89LXfmBOmjRJ3bt311dffaXvv/9eAwcOVExMjH799VfHeISHHnpI48aN0+XLl7Vq1Sq9/PLLCgwMVLVq1bRq1SqFhIRIklNgsdvtatq0qYYNG5ZlDdeHq6x+FuHh4dq9e7cWL16spUuXasGCBXr//fc1evToTNuaXY0bN9bUqVP1888/OwJLlSpVFBERoY8//ljdunXTxx9/LE9PT3Xs2DFH67jegAEDNHPmTD3//POqW7euAgICZLPZ1LlzZ6cByBmy83PLrhv9Llw/kDYhIUENGjSQv7+/Xn/9dZUvX17e3t6Kj4/X8OHDs6zzVux2u6pXr67JkydnOf36D+nsys3X53bWk/GaDB069IZHaq8PdjdaZlbt126P3W5XsWLFbng09UYf9jdTuXJlSdK2bdvUunVrR7ufn58j6P/yyy9O89jtdsfg+qxqvv5oTXZ+Vnm1n9xKenq6mjZtqrNnz2r48OGqXLmyfH19dfToUXXv3j1H+3xeIbDkE61atdKMGTO0du1a1a1b96Z9S5cuLbvdrr179zoNYD1x4oQSEhJUunTpHNeRMbjL39/f6a/26wUHB8vf3/+WIcvVU0Nz585VtWrVshwE+uGHH2revHk5/hCvXr26qlevrldeeUVr1qxRvXr1NH36dI0dO1bS1SBy5coVffLJJzp69KgjmNSvX98RWP7xj384got09fW6cOHCTV+r7PD19VWnTp3UqVMnXblyRW3bttW4ceM0cuTITId6syMtLU1S5r8qu3XrpiFDhuivv/7SvHnz1LJly9s6WnGt+fPnKzo62iloXr58WQkJCTlaXsZ+vG/fPqcjU2fOnMn0V2LGNiQkJDgNhrz+aOOPP/6oM2fO6IsvvlD9+vUd7QcOHLjhuh955BFHe1pamg4ePKh7773X0Va+fHlt2bJFjRs3/p+8N0a5cuUkXT2qcLv7+a2UL19ey5cvV7169W76h5YrHn74YQUEBOjTTz/VyJEj5eZ265ES5cuXlzFGZcuWzfRHR065sp9kdz/KeL/etm1bptCYYevWrdqzZ49mzZrlNLg54+iSlTCGJZ8YNmyYfH191bt3b504cSLT9D/++EPvvPOOJDluEnb9FSgZyb1ly5Y5riMiIkLly5fXW2+9leVNwjIuO3Vzc1ObNm20aNEi/fbbb5n6Zfxl4evrK0nZ+tA6cuSIfv75Z3Xs2FHt27fP9OjRo4f27dvnuPonu5KSkhwf4BmqV68uNzc3p8sJ69SpowIFCmj8+PEqUqSIqlatKunqG96vv/6qn376yenoiiR17NhRa9eu1XfffZdpvQkJCZnWm5WM8+YZPD09VaVKFRljcvwdI4sWLZIk3XfffU7tXbp0kc1m06BBg7R//36n8+63y93dPdNf/++9916O77jbuHFjeXh46IMPPnBqnzp1aqa+GW/c144Zyrg09PoaJee/fK9cuaL333/fqV/NmjUVFBSkjz76yOlnOHfu3ExhqWPHjjp69Kg++uijTHVdunRJFy9evOl2Wl2xYsXUsGFDffjhh/rrr78yTb/+UvTb0bFjR6Wnp+uNN97INC0tLc3pfSS7lzUXLFhQw4YN07Zt2zRixIgsj1Bd39a2bVu5u7vrtddeyzTNGJPpdzY7XNlPfH19s/We2axZMxUqVEgxMTGZrpzLqDurfd4Y4/g8sRKOsOQT5cuX17x589SpUyeFh4c73el2zZo1iouLcwwuu++++xQdHa0ZM2Y4DnGvX79es2bNUps2bZz+InSVm5ub/v3vf+vRRx9V1apV1aNHD5UoUUJHjx7VDz/8IH9/f8eH4Ztvvqnvv/9eDRo0cFym99dffykuLk6//PKLAgMDVaNGDbm7u2v8+PFKTEyUl5eXGjVqlOU56nnz5skY47iE+HotWrSQh4eH5s6dqzp16mR7m1auXKn+/furQ4cO+sc//qG0tDTNmTNH7u7uTrfFLliwoCIiIvTrr7867sEiXT3CcvHiRV28eDFTYHnxxRf19ddfq1WrVurevbsiIiJ08eJFbd26VfPnz9fBgwed7jCalWbNmik0NFT16tVTSEiIdu7cqalTp6ply5bZGogdHx+vjz/+WNLVcVArVqzQggULFBkZqWbNmjn1DQ4OVvPmzRUXF6fAwECXwm1qaqrjaNS1ihQpon/+859q1aqV5syZo4CAAFWpUkVr167V8uXLFRQUlO11XCskJESDBg3SpEmT9Pjjj6t58+basmWLvv32WxUtWtTpr9BmzZqpVKlS6tWrl1588UW5u7vr//7v/xQcHKzDhw87+kVGRqpw4cKKjo7WwIEDZbPZNGfOnEwfSp6ennr11Vc1YMAANWrUSB07dtTBgwcVGxur8uXLO6376aef1ueff65nnnlGP/zwg+rVq6f09HTt2rVLn3/+ueMeSPnZtGnT9NBDD6l69erq06ePypUrpxMnTmjt2rX6888/tWXLllxZT4MGDdSvXz/FxMRo8+bNatasmQoUKKC9e/cqLi5O77zzjtq3by8p+5c1S9KIESO0c+dOTZw4Ud9//73atWunkiVL6ty5c4qPj1dcXJyKFSvmOJpZvnx5jR07ViNHjnRczl6oUCEdOHBAX375pfr27evy3YFd2U8iIiK0fPlyTZ48WcWLF1fZsmWzfM/z9/fX22+/rd69e6tWrVp68sknVbhwYW3ZskXJycmaNWuWKleurPLly2vo0KE6evSo/P39tWDBglwfC5Ur/qarkZBL9uzZY/r06WPKlCljPD09TaFChUy9evXMe++953RJYWpqqnnttddM2bJlTYECBUxYWJgZOXKkUx9jrl7W3LJly0zrybgk+EaX+m7atMm0bdvWBAUFGS8vL1O6dGnTsWNHs2LFCqd+hw4dMt26dTPBwcHGy8vLlCtXzjz33HNOlxl/9NFHply5csbd3f2mlzhXr17dlCpV6qavT8OGDU2xYsVMamrqDbch43LNjMsd9+/fb3r27GnKly9vvL29TZEiRcwjjzxili9fnmn5L774opFkxo8f79ReoUIFI8n88ccfmeY5f/68GTlypKlQoYLx9PQ0RYsWNZGRkeatt94yV65ccaopq7uKfvjhh6Z+/fqO17p8+fLmxRdfNImJiTd9LbK6rNnDw8OUK1fOvPjii+b8+fNZzvf5558bSaZv3743Xf61oqOjb3gJdfny5Y0xxpw7d8706NHDFC1a1Pj5+ZmoqCiza9cuU7p0aadLNDMuzbz+cviMn+e1+0daWpoZNWqUCQ0NNT4+PqZRo0Zm586dJigoyOkSWWOM2bhxo6lTp47x9PQ0pUqVMpMnT87ysubVq1ebBx980Pj4+JjixYubYcOGme+++y7LffPdd981pUuXNl5eXqZ27dpm9erVJiIiwjRv3typ35UrV8z48eNN1apVjZeXlylcuLCJiIgwr7322i1/jje6rDmrfUWSGTNmzE2Xd62c3uk2q/X88ccfplu3biY0NNQUKFDAlChRwrRq1crMnz/f0edGP9uMy85PnTrl1H6jy+VnzJhhIiIijI+PjylUqJCpXr26GTZsmNNdwLN7WfO1vvzyS9OiRQsTHBxsPDw8TGBgoHnooYfMxIkTHZfTX2vBggXmoYceMr6+vsbX19dUrlzZPPfcc2b37t2OPg0aNMjytgTX/1yNyf5+smvXLlO/fn3j4+PjdAl/VvuzMcZ8/fXXJjIy0vj4+Bh/f39Tu3Zt88knnzim79ixwzRp0sT4+fmZokWLmj59+pgtW7a4/PrlNb5LCICTr776Sm3atNHPP/+c6YhRfpCQkKDChQtr7Nixevnll//WddvtdgUHB6tt27ZZHtoHkHOMYQHg5KOPPlK5cuX00EMP3elSbimrW4dnjN1y5cs0c+Ly5cuZThXNnj1bZ8+ezfN1A3cjxrAAkCR9+umn+v333/XNN9/onXfeyRdXtHz22WeKjY1VixYt5Ofnp19++UWffPKJmjVrlu371OTUr7/+qsGDB6tDhw4KCgpSfHy8/vOf/6hatWqO78gCkHs4JQRA0tVLJf38/NSpUydNnz7d6Q6uVhUfH69hw4Zp8+bNSkpKUkhIiNq1a6exY8dmuhdGbjt48KAGDhyo9evX6+zZsypSpIhatGihf/3rXze8sRmAnCOwAAAAy2MMCwAAsDwCCwAAsDwCCwAAsDzrj6rLB+x2u44dO6ZChQrliysrAACwCmOMzp8/r+LFi9/0u5wILLng2LFjefZNmgAA3A2OHDmikiVL3nA6gSUXZHyfy5EjR+Tv73+HqwEAIP9ISkpSWFjYLb8bjcCSCzJOA/n7+xNYAADIgVsNqWDQLQAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsDwCCwAAsLx8F1imTZumMmXKyNvbW3Xq1NH69etv2j8uLk6VK1eWt7e3qlevriVLltyw7zPPPCObzaYpU6bkctUAAOB25KvA8tlnn2nIkCEaM2aM4uPjdd999ykqKkonT57Msv+aNWvUpUsX9erVS5s2bVKbNm3Upk0bbdu2LVPfL7/8Ur/++quKFy+e15sBAABclK8Cy+TJk9WnTx/16NFDVapU0fTp01WwYEH93//9X5b933nnHTVv3lwvvviiwsPD9cYbb+iBBx7Q1KlTnfodPXpUAwYM0Ny5c1WgQIG/Y1MAAIAL8k1guXLlijZu3KgmTZo42tzc3NSkSROtXbs2y3nWrl3r1F+SoqKinPrb7XY9/fTTevHFF1W1atW8KR4AANwWjztdQHadPn1a6enpCgkJcWoPCQnRrl27spzn+PHjWfY/fvy44/n48ePl4eGhgQMHZruWlJQUpaSkOJ4nJSVle14AAOC6fHOEJS9s3LhR77zzjmJjY2Wz2bI9X0xMjAICAhyPsLCwPKwSAADkm8BStGhRubu768SJE07tJ06cUGhoaJbzhIaG3rT/qlWrdPLkSZUqVUoeHh7y8PDQoUOH9MILL6hMmTI3rGXkyJFKTEx0PI4cOXJ7GwcAAG4q3wQWT09PRUREaMWKFY42u92uFStWqG7dulnOU7duXaf+krRs2TJH/6efflq///67Nm/e7HgUL15cL774or777rsb1uLl5SV/f3+nBwAAyDv5ZgyLJA0ZMkTR0dGqWbOmateurSlTpujixYvq0aOHJKlbt24qUaKEYmJiJEmDBg1SgwYNNGnSJLVs2VKffvqpfvvtN82YMUOSFBQUpKCgIKd1FChQQKGhoapUqdLfu3EAAOCG8lVg6dSpk06dOqXRo0fr+PHjqlGjhpYuXeoYWHv48GG5uf33oFFkZKTmzZunV155RS+99JIqVqyohQsXqlq1andqEwAAQA7YjDHmTheR3yUlJSkgIECJiYmcHgIAwAXZ/QzNN2NYAADA3YvAAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALI/AAgAALC/fBZZp06apTJky8vb2Vp06dbR+/fqb9o+Li1PlypXl7e2t6tWra8mSJY5pqampGj58uKpXry5fX18VL15c3bp107Fjx/J6MwAAgAvyVWD57LPPNGTIEI0ZM0bx8fG67777FBUVpZMnT2bZf82aNerSpYt69eqlTZs2qU2bNmrTpo22bdsmSUpOTlZ8fLxGjRql+Ph4ffHFF9q9e7cef/zxv3OzAADALdiMMeZOF5FdderUUa1atTR16lRJkt1uV1hYmAYMGKARI0Zk6t+pUyddvHhRixcvdrQ9+OCDqlGjhqZPn57lOjZs2KDatWvr0KFDKlWqVLbqSkpKUkBAgBITE+Xv75+DLQMA4O6U3c/QfHOE5cqVK9q4caOaNGniaHNzc1OTJk20du3aLOdZu3atU39JioqKumF/SUpMTJTNZlNgYGCu1A0AAG6fx50uILtOnz6t9PR0hYSEOLWHhIRo165dWc5z/PjxLPsfP348y/6XL1/W8OHD1aVLl5umvJSUFKWkpDieJyUlZXczAABADuSbIyx5LTU1VR07dpQxRh988MFN+8bExCggIMDxCAsL+5uqBADg7pRvAkvRokXl7u6uEydOOLWfOHFCoaGhWc4TGhqarf4ZYeXQoUNatmzZLcehjBw5UomJiY7HkSNHcrBFAAAgu/JNYPH09FRERIRWrFjhaLPb7VqxYoXq1q2b5Tx169Z16i9Jy5Ytc+qfEVb27t2r5cuXKygo6Ja1eHl5yd/f3+kBAADyTr4ZwyJJQ4YMUXR0tGrWrKnatWtrypQpunjxonr06CFJ6tatm0qUKKGYmBhJ0qBBg9SgQQNNmjRJLVu21KeffqrffvtNM2bMkHQ1rLRv317x8fFavHix0tPTHeNbihQpIk9PzzuzoQAAwEm+CiydOnXSqVOnNHr0aB0/flw1atTQ0qVLHQNrDx8+LDe3/x40ioyM1Lx58/TKK6/opZdeUsWKFbVw4UJVq1ZNknT06FF9/fXXkqQaNWo4reuHH35Qw4YN/5btAgAAN5ev7sNiVdyHBQCAnPmfuw8LAAC4exFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5bkcWOLj47V161bH86+++kpt2rTRSy+9pCtXruRqcQAAAFIOAku/fv20Z88eSdL+/fvVuXNnFSxYUHFxcRo2bFiuFwgAAOByYNmzZ49q1KghSYqLi1P9+vU1b948xcbGasGCBbldHwAAgOuBxRgju90uSVq+fLlatGghSQoLC9Pp06dztzoAAADlILDUrFlTY8eO1Zw5c/TTTz+pZcuWkqQDBw4oJCQk1wsEAABwObBMmTJF8fHx6t+/v15++WVVqFBBkjR//nxFRkbmeoEAAAAernROT09XQkKCfv75ZxUuXNhp2sSJE+Xu7p6rxQEAAEguHmFxd3dXs2bNlJCQkGmat7e3ChQokFt1AQAAOLh8SqhatWrav39/XtQCAACQJZcDy9ixYzV06FAtXrxYf/31l5KSkpweAAAAuc1mjDGuzODm9t+MY7PZHP83xshmsyk9PT33qssnkpKSFBAQoMTERPn7+9/pcgAAyDey+xnq0qBbSfrhhx9uqzAAAABXuRxYGjRokBd1AAAA3FCOvq151apVeuqppxQZGamjR49KkubMmaNffvklV4sDAACQchBYFixYoKioKPn4+Cg+Pl4pKSmSpMTERL355pu5XiAAAECOrhKaPn26PvroI6f7rtSrV0/x8fG5WhwAAICUg8Cye/du1a9fP1N7QEBAljeUAwAAuF0uB5bQ0FDt27cvU/svv/yicuXK5UpRAAAA13I5sPTp00eDBg3SunXrZLPZdOzYMc2dO1dDhw7Vs88+mxc1AgCAu5zLlzWPGDFCdrtdjRs3VnJysurXry8vLy8NHTpUAwYMyIsaAQDAXc7lO91muHLlivbt26cLFy6oSpUq8vPzy+3a8g3udAsAQM7k2Z1uV65cqcjISHl7e6tKlSq3VSQAAEB2uBxYHn/8caWlpalWrVpq2LChGjRooHr16snHxycv6gMAAHB90O25c+e0YsUKPfroo1q/fr2eeOIJBQYGql69enrllVfyokYAAHCXy/EYlgzbt2/XxIkTNXfuXNntdr6tmTEsAABkW56NYdmzZ49+/PFH/fjjj/rpp5+UkpKihx9+WG+99ZYaNmx4OzUDAABkyeXAUrlyZQUHB2vQoEEaMWKEqlevLpvNlhe1AQAASMrBGJaBAweqRIkSev311/XMM8/o5Zdf1vfff6/k5OS8qA8AACDnY1gSEhK0atUq/fTTT/rpp5+0fft23X///Vq9enVu12h5jGEBACBnsvsZ6vIRlgzp6elKTU1VSkqKLl++rJSUFO3evTuniwMAALihHJ0SuvfeexUSEqJ+/frp2LFj6tOnjzZt2qRTp07lRY0AAOAu5/Kg27/++kt9+/ZVw4YNVa1atbyoCQAAwInLgSUuLi4v6gAAALghl08JzZo1S998843j+bBhwxQYGKjIyEgdOnQoV4sDAACQchBY3nzzTcf3Bq1du1bTpk3ThAkTVLRoUQ0ePDjXCwQAAHD5lNCRI0dUoUIFSdLChQvVrl079e3bV/Xq1eNOtwAAIE+4fITFz89PZ86ckSR9//33atq0qSTJ29tbly5dyt3qAAAAlIMjLE2bNlXv3r11//33a8+ePWrRooWkq1+CWKZMmdyuDwAAwPUjLNOmTVPdunV16tQpLViwQEFBQZKkjRs3qkuXLrleIAAAQI5vzY//4tb8AADkTHY/Q10+JSRd/R6h9evX6+TJk7Lb7Y52m82mp59+OieLBAAAuCGXA8uiRYvUtWtXXbhwQf7+/rLZbI5pBBYAAJAXXB7D8sILL6hnz566cOGCEhISdO7cOcfj7NmzeVEjAAC4y7kcWI4ePaqBAweqYMGCeVEPAABAJi4HlqioKP322295UQsAAECWXB7D0rJlS7344ovasWOHqlevrgIFCjhNf/zxx3OtOAAAACkHlzW7ud34oIzNZlN6evptF5XfcFkzAAA5k2eXNV97GTMAAMDfweUxLDeSkJCgqVOn5tbiAAAAHG47sKxYsUJPPvmk7rnnHo0ZMyY3agIAAHCSo8By5MgRvf766ypbtqyaNWsmm82mL7/8UsePH8/t+jKZNm2aypQpI29vb9WpU0fr16+/af+4uDhVrlxZ3t7eql69upYsWeI03Rij0aNH65577pGPj4+aNGmivXv35uUmAAAAF2U7sKSmpiouLk5RUVGqVKmSNm/erIkTJ8rNzU0vv/yymjdvnumKodz22WefaciQIRozZozi4+N13333KSoqSidPnsyy/5o1a9SlSxf16tVLmzZtUps2bdSmTRtt27bN0WfChAl69913NX36dK1bt06+vr6KiorS5cuX83RbAABA9mX7KqFixYqpcuXKeuqpp9ShQwcVLlxYklSgQAFt2bJFVapUydNCJalOnTqqVauWY6yM3W5XWFiYBgwYoBEjRmTq36lTJ128eFGLFy92tD344IOqUaOGpk+fLmOMihcvrhdeeEFDhw6VJCUmJiokJESxsbHq3LlzturiKiEAAHImu5+h2T7CkpaWJpvNJpvNJnd391wp0hVXrlzRxo0b1aRJE0ebm5ubmjRporVr12Y5z9q1a536S1dvfJfR/8CBAzp+/LhTn4CAANWpU+eGywQAAH+/bAeWY8eOqW/fvvrkk08UGhqqdu3a6csvv3T68sO8dPr0aaWnpyskJMSpPSQk5IZjZ44fP37T/hn/urJMSUpJSVFSUpLTAwAA5J1sBxZvb2917dpVK1eu1NatWxUeHq6BAwcqLS1N48aN07Jly+6am8bFxMQoICDA8QgLC7vTJQEA8D8tR1cJlS9fXmPHjtWhQ4f0zTffKCUlRa1atcp0pCI3FS1aVO7u7jpx4oRT+4kTJxQaGprlPKGhoTftn/GvK8uUpJEjRyoxMdHxOHLkiMvbAwAAsu+27sPi5uamRx99VPPnz9eff/6pl156KbfqysTT01MRERFasWKFo81ut2vFihWqW7dulvPUrVvXqb8kLVu2zNG/bNmyCg0NdeqTlJSkdevW3XCZkuTl5SV/f3+nBwAAyDsu35r/RoKDgzVkyJDcWlyWhgwZoujoaNWsWVO1a9fWlClTdPHiRfXo0UOS1K1bN5UoUUIxMTGSpEGDBqlBgwaaNGmSWrZsqU8//VS//fabZsyYIenqdx89//zzGjt2rCpWrKiyZctq1KhRKl68uNq0aZOn2wIAALIv1wLL36FTp046deqURo8erePHj6tGjRpaunSp41TU4cOHnb6cMTIyUvPmzdMrr7yil156SRUrVtTChQtVrVo1R59hw4bp4sWL6tu3rxISEvTQQw9p6dKl8vb2/tu3DwAAZM3lb2tGZtyHBQCAnMn1+7AAAADcKS4Hltdff13JycmZ2i9duqTXX389V4oCAAC4lsunhNzd3fXXX3+pWLFiTu1nzpxRsWLF7pp7sVyLU0IAAORMnp0SMsZkeXfbLVu2qEiRIq4uDgAA4JayfZVQ4cKFHd8l9I9//MMptKSnp+vChQt65pln8qRIAABwd8t2YJkyZYqMMerZs6dee+01BQQEOKZ5enqqTJkyN73ZGgAAQE5lO7BER0dLunp32Hr16snDI1/dwgUAAORjLo9huXjxYqbb3UvSd999p2+//TZXigIAALiWy4FlxIgRWV4JZIzRiBEjcqUoAACAa7kcWPbu3asqVapkaq9cubL27duXK0UBAABcy+XAEhAQoP3792dq37dvn3x9fXOlKAAAgGu5HFhat26t559/Xn/88Yejbd++fXrhhRf0+OOP52pxAAAAUg4Cy4QJE+Tr66vKlSurbNmyKlu2rMLDwxUUFKS33norL2oEAAB3OZevTQ4ICNCaNWu0bNkybdmyRT4+Prr33ntVv379vKgPAADA9e8Sutbly5fl5eWV5a367yZ8lxAAADmTZ98lZLfb9cYbb6hEiRLy8/PTgQMHJEmjRo3Sf/7zn5xXDAAAcAMuB5axY8cqNjZWEyZMkKenp6O9WrVq+ve//52rxQEAAEg5CCyzZ8/WjBkz1LVrV7m7uzva77vvPu3atStXiwMAAJByEFiOHj2qChUqZGq32+1KTU3NlaIAAACu5XJgqVKlilatWpWpff78+br//vtzpSgAAIBruXxZ8+jRoxUdHa2jR4/Kbrfriy++0O7duzV79mwtXrw4L2oEAAB3uRzd6XbRokVavny5fH19NXr0aO3cuVOLFi1S06ZN86JGAABwl3PpCEtaWprefPNN9ezZU8uWLcurmgAAAJy4dITFw8NDEyZMUFpaWl7VAwAAkInLp4QaN26sn376KS9qAQAAyJLLg24fffRRjRgxQlu3blVERIR8fX2dpvONzQAAILe5/F1Cbm43Pihjs9mUnp5+20XlN3yXEAAAOZPdz1CXj7DY7fbbKgwAAMBVLo1hSU1NlYeHh7Zt25ZX9QAAAGTiUmApUKCASpUqdVee9gEAAHeOy1cJvfzyy3rppZd09uzZvKgHAAAgE5fHsEydOlX79u1T8eLFVbp06UxXCcXHx+dacQAAAFIOAkubNm3yoAwAAIAbc/myZmTGZc0AAORMnl3WnGHjxo3auXOnJKlq1aq6//77c7ooAACAm3I5sJw8eVKdO3fWjz/+qMDAQElSQkKCHnnkEX366acKDg7O7RoBAMBdzuWrhAYMGKDz589r+/btOnv2rM6ePatt27YpKSlJAwcOzIsaAQDAXc7lMSwBAQFavny5atWq5dS+fv16NWvWTAkJCblZX77AGBYAAHImu5+hLh9hsdvtKlCgQKb2AgUKcNt+AACQJ1wOLI0aNdKgQYN07NgxR9vRo0c1ePBgNW7cOFeLAwAAkHIQWKZOnaqkpCSVKVNG5cuXV/ny5VW2bFklJSXpvffey4saAQDAXc7lq4TCwsIUHx+v5cuXa9euXZKk8PBwNWnSJNeLAwAAkLhxXK5g0C0AADmT64NuV65cqSpVqigpKSnTtMTERFWtWlWrVq3KWbUAAAA3ke3AMmXKFPXp0yfL9BMQEKB+/fpp8uTJuVocAACA5EJg2bJli5o3b37D6c2aNdPGjRtzpSgAAIBrZTuwnDhxIsv7r2Tw8PDQqVOncqUoAACAa2U7sJQoUULbtm274fTff/9d99xzT64UBQAAcK1sB5YWLVpo1KhRunz5cqZply5d0pgxY9SqVatcLQ4AAEBy4bLmEydO6IEHHpC7u7v69++vSpUqSZJ27dqladOmKT09XfHx8QoJCcnTgq2Iy5oBAMiZ7H6GZvvGcSEhIVqzZo2effZZjRw5Uhk5x2azKSoqStOmTbsrwwoAAMh7Lt3ptnTp0lqyZInOnTunffv2yRijihUrqnDhwnlVHwAAgOu35pekwoULq1atWrldCwAAQJZc/vJDAACAvxuBBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWF6+CSxnz55V165d5e/vr8DAQPXq1UsXLly46TyXL1/Wc889p6CgIPn5+aldu3Y6ceKEY/qWLVvUpUsXhYWFycfHR+Hh4XrnnXfyelMAAICL8k1g6dq1q7Zv365ly5Zp8eLF+vnnn9W3b9+bzjN48GAtWrRIcXFx+umnn3Ts2DG1bdvWMX3jxo0qVqyYPv74Y23fvl0vv/yyRo4cqalTp+b15gAAABfYjDHmThdxKzt37lSVKlW0YcMG1axZU5K0dOlStWjRQn/++aeKFy+eaZ7ExEQFBwdr3rx5at++vSRp165dCg8P19q1a/Xggw9mua7nnntOO3fu1MqVK7NdX1JSkgICApSYmCh/f/8cbCEAAHen7H6G5osjLGvXrlVgYKAjrEhSkyZN5ObmpnXr1mU5z8aNG5WamqomTZo42ipXrqxSpUpp7dq1N1xXYmKiihQpknvFAwCA2+ZxpwvIjuPHj6tYsWJObR4eHipSpIiOHz9+w3k8PT0VGBjo1B4SEnLDedasWaPPPvtM33zzzU3rSUlJUUpKiuN5UlJSNrYCAADk1B09wjJixAjZbLabPnbt2vW31LJt2za1bt1aY8aMUbNmzW7aNyYmRgEBAY5HWFjY31IjAAB3qzt6hOWFF15Q9+7db9qnXLlyCg0N1cmTJ53a09LSdPbsWYWGhmY5X2hoqK5cuaKEhASnoywnTpzINM+OHTvUuHFj9e3bV6+88sot6x45cqSGDBnieJ6UlERoAQAgD93RwBIcHKzg4OBb9qtbt64SEhK0ceNGRURESJJWrlwpu92uOnXqZDlPRESEChQooBUrVqhdu3aSpN27d+vw4cOqW7euo9/27dvVqFEjRUdHa9y4cdmq28vLS15eXtnqCwAAbl++uEpIkh599FGdOHFC06dPV2pqqnr06KGaNWtq3rx5kqSjR4+qcePGmj17tmrXri1JevbZZ7VkyRLFxsbK399fAwYMkHR1rIp09TRQo0aNFBUVpYkTJzrW5e7unq0glYGrhAAAyJnsfobmi0G3kjR37lz1799fjRs3lpubm9q1a6d3333XMT01NVW7d+9WcnKyo+3tt9929E1JSVFUVJTef/99x/T58+fr1KlT+vjjj/Xxxx872kuXLq2DBw/+LdsFAABuLd8cYbEyjrAAAJAz/1P3YQEAAHc3AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALA8AgsAALC8fBNYzp49q65du8rf31+BgYHq1auXLly4cNN5Ll++rOeee05BQUHy8/NTu3btdOLEiSz7njlzRiVLlpTNZlNCQkIebAEAAMipfBNYunbtqu3bt2vZsmVavHixfv75Z/Xt2/em8wwePFiLFi1SXFycfvrpJx07dkxt27bNsm+vXr1077335kXpAADgNtmMMeZOF3ErO3fuVJUqVbRhwwbVrFlTkrR06VK1aNFCf/75p4oXL55pnsTERAUHB2vevHlq3769JGnXrl0KDw/X2rVr9eCDDzr6fvDBB/rss880evRoNW7cWOfOnVNgYGC260tKSlJAQIASExPl7+9/exsLAMBdJLufofniCMvatWsVGBjoCCuS1KRJE7m5uWndunVZzrNx40alpqaqSZMmjrbKlSurVKlSWrt2raNtx44dev311zV79my5ueWLlwMAgLuOx50uIDuOHz+uYsWKObV5eHioSJEiOn78+A3n8fT0zHSkJCQkxDFPSkqKunTpookTJ6pUqVLav39/tupJSUlRSkqK43lSUpILWwMAAFx1Rw8pjBgxQjab7aaPXbt25dn6R44cqfDwcD311FMuzRcTE6OAgADHIywsLI8qBAAA0h0+wvLCCy+oe/fuN+1Trlw5hYaG6uTJk07taWlpOnv2rEJDQ7OcLzQ0VFeuXFFCQoLTUZYTJ0445lm5cqW2bt2q+fPnS5IyhvMULVpUL7/8sl577bUslz1y5EgNGTLE8TwpKYnQAgBAHrqjgSU4OFjBwcG37Fe3bl0lJCRo48aNioiIkHQ1bNjtdtWpUyfLeSIiIlSgQAGtWLFC7dq1kyTt3r1bhw8fVt26dSVJCxYs0KVLlxzzbNiwQT179tSqVatUvnz5G9bj5eUlLy+vbG8nAAC4PfliDEt4eLiaN2+uPn36aPr06UpNTVX//v3VuXNnxxVCR48eVePGjTV79mzVrl1bAQEB6tWrl4YMGaIiRYrI399fAwYMUN26dR1XCF0fSk6fPu1YnytXCQEAgLyVLwKLJM2dO1f9+/dX48aN5ebmpnbt2undd991TE9NTdXu3buVnJzsaHv77bcdfVNSUhQVFaX333//TpQPAABuQ764D4vVcR8WAABy5n/qPiwAAODuRmABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACWR2ABAACW53GnC/hfYIyRJCUlJd3hSgAAyF8yPjszPktvhMCSC86fPy9JCgsLu8OVAACQP50/f14BAQE3nG4zt4o0uCW73a5jx46pUKFCstlsd7oc3IakpCSFhYXpyJEj8vf3v9PlAMgCv6f/W4wxOn/+vIoXLy43txuPVOEISy5wc3NTyZIl73QZyEX+/v68EQIWx+/p/46bHVnJwKBbAABgeQQWAABgeQQW4BpeXl4aM2aMvLy87nQpAG6A39O7E4NuAQCA5XGEBQAAWB6BBQAAWB6BBQAAWB6BBchC9+7d1aZNG8fzhg0b6vnnn8/WvK70BQBkDzeOA7Lhiy++UIECBe50GcD/jO7duyshIUELFy6806UgnyCwANlQpEiRO10C8D8hPT2drzBBjnBKCPmO3W5XTEyMypYtKx8fH913332aP3++JOnHH3+UzWbTihUrVLNmTRUsWFCRkZHavXu30zLGjh2rYsWKqVChQurdu7dGjBihGjVq3HCd15/mef/991WxYkV5e3srJCRE7du3z1TjsGHDVKRIEYWGhurVV1/Nrc0H/lYNGzZU//791b9/fwUEBKho0aIaNWqU45t1z507p27duqlw4cIqWLCgHn30Ue3du9cxf2xsrAIDA/X111+rSpUq8vLyUs+ePTVr1ix99dVXstlsstls+vHHHx2/vwkJCY75N2/eLJvNpoMHDzraPvroI4WFhalgwYJ64oknNHnyZAUGBjqmX39KV5Kef/55NWzY0PH8Zu8jGdvVtWtXBQcHy8fHRxUrVtTMmTMd048cOaKOHTsqMDBQRYoUUevWrZ1qRO4jsCDfiYmJ0ezZszV9+nRt375dgwcP1lNPPaWffvrJ0efll1/WpEmT9Ntvv8nDw0M9e/Z0TJs7d67GjRun8ePHa+PGjSpVqpQ++OCDbK//t99+08CBA/X6669r9+7dWrp0qerXr+/UZ9asWfL19dW6des0YcIEvf7661q2bNntbzxwB8yaNUseHh5av3693nnnHU2ePFn//ve/JV0NB7/99pu+/vprrV27VsYYtWjRQqmpqY75k5OTNX78eP373//W9u3b9e6776pjx45q3ry5/vrrL/3111+KjIzMVi2rV6/WM888o0GDBmnz5s1q2rSpxo0b5/I23ep9ZNSoUdqxY4e+/fZb7dy5Ux988IGKFi0qSUpNTVVUVJQKFSqkVatWafXq1fLz81Pz5s115coVl2tBNhkgH7l8+bIpWLCgWbNmjVN7r169TJcuXcwPP/xgJJnly5c7pn3zzTdGkrl06ZIxxpg6deqY5557zmn+evXqmfvuu8/xPDo62rRu3drxvEGDBmbQoEHGGGMWLFhg/P39TVJSUpY1NmjQwDz00ENObbVq1TLDhw93dXOBO65BgwYmPDzc2O12R9vw4cNNeHi42bNnj5FkVq9e7Zh2+vRp4+PjYz7//HNjjDEzZ840kszmzZudlnv975gxxvH7e+7cOUfbpk2bjCRz4MABY4wxnTp1Mi1btnSar2vXriYgIOCmyx40aJBp0KCBMebW7yPGGPPYY4+ZHj16ZPmazJkzx1SqVMnpNUlJSTE+Pj7mu+++y3Ie3D6OsCBf2bdvn5KTk9W0aVP5+fk5HrNnz9Yff/zh6Hfvvfc6/n/PPfdIkk6ePClJ2r17t2rXru203Ouf30zTpk1VunRplStXTk8//bTmzp2r5ORkpz7Xrj+jhoz1A/nNgw8+6DTupG7dutq7d6927NghDw8P1alTxzEtKChIlSpV0s6dOx1tnp6emX4ncup2f3+l7L2PPPvss/r0009Vo0YNDRs2TGvWrHHMv2XLFu3bt0+FChVyzFukSBFdvnzZ6X0IuYtBt8hXLly4IEn65ptvVKJECadpXl5ejjeLa6/oyXijtdvtuVJDoUKFFB8frx9//FHff/+9Ro8erVdffVUbNmxwnEe//ooim82Wa+sH8hsfH59sDbR1c7v6N7S55htjrj21lF1ubm5Oy7h+Obd6H5GkRx99VIcOHdKSJUu0bNkyNW7cWM8995zeeustXbhwQREREZo7d26mdQcHB7tcL7KHIyzIVzIG7R0+fFgVKlRweoSFhWVrGZUqVdKGDRuc2q5/fiseHh5q0qSJJkyYoN9//10HDx7UypUrXVoGkF+sW7fO6fmvv/6qihUrqkqVKkpLS3OafubMGe3evVtVqlS56TI9PT2Vnp7u1JbxYf/XX3852jZv3uzUJzu/v8HBwU7LuH452X0fCQ4OVnR0tD7++GNNmTJFM2bMkCQ98MAD2rt3r4oVK5Zp/oCAgJtuN3KOIyzIVwoVKqShQ4dq8ODBstvteuihh5SYmKjVq1fL399fpUuXvuUyBgwYoD59+qhmzZqKjIzUZ599pt9//13lypXLVg2LFy/W/v37Vb9+fRUuXFhLliyR3W5XpUqVbnfzAEs6fPiwhgwZon79+ik+Pl7vvfeeJk2apIoVK6p169bq06ePPvzwQxUqVEgjRoxQiRIl1Lp165sus0yZMvruu++0e/duBQUFKSAgwBEYXn31VY0bN0579uzRpEmTnOYbMGCA6tevr8mTJ+uxxx7TypUr9e233zodwWnUqJEmTpyo2bNnq27duvr444+1bds23X///ZJu/T4SHR2t0aNHKyIiQlWrVlVKSooWL16s8PBwSVLXrl01ceJEtW7dWq+//rpKliypQ4cO6YsvvtCwYcNUsmTJXP4JQOIIC/KhN954Q6NGjVJMTIzCw8PVvHlzffPNNypbtmy25u/atatGjhypoUOH6oEHHtCBAwfUvXt3eXt7Z2v+wMBAffHFF2rUqJHCw8M1ffp0ffLJJ6patertbBZgWd26ddOlS5dUu3ZtPffccxo0aJD69u0rSZo5c6YiIiLUqlUr1a1bV8YYLVmy5JY3WuzTp48qVaqkmjVrKjg4WKtXr1aBAgX0ySefaNeuXbr33ns1fvx4jR071mm+evXqafr06Zo8ebLuu+8+LV26VIMHD3b6/Y2KitKoUaM0bNgw1apVS+fPn1e3bt2clnOr9xFPT0+NHDlS9957r+rXry93d3d9+umnkqSCBQvq559/VqlSpdS2bVuFh4erV69eunz5svz9/W/79UbWbOb6E33AXahp06YKDQ3VnDlz7nQpgKU0bNhQNWrU0JQpU+50KTfUp08f7dq1S6tWrbrTpSAPcUoId53k5GRNnz5dUVFRcnd31yeffKLly5dznxQgn3jrrbfUtGlT+fr66ttvv9WsWbP0/vvv3+mykMcILLjr2Gw2LVmyROPGjdPly5dVqVIlLViwQE2aNLnTpQHIhvXr12vChAk6f/68ypUrp3fffVe9e/e+02Uhj3FKCAAAWB6DbgEAgOURWAAAgOURWAAAgOURWAAAgOURWAAAgOURWADkqe7du6tNmzZ3ugwA+RyBBQAAWB6BBcAdM3nyZFWvXl2+vr4KCwvTP//5T124cMExPTY2VoGBgfruu+8UHh4uPz8/NW/e3OmbeNPS0jRw4EAFBgYqKChIw4cPV3R0tNNRnTJlymS6tXyNGjX06quvZrsWSfroo48UFhamggUL6oknntDkyZMVGBjo1Oerr77SAw88IG9vb5UrV06vvfaa0tLSbvu1Au52BBYAd4ybm5veffddbd++XbNmzdLKlSs1bNgwpz7Jycl66623NGfOHP388886fPiwhg4d6pg+fvx4zZ07VzNnztTq1auVlJSkhQsX5notq1ev1jPPPKNBgwZp8+bNatq0qcaNG+e0jFWrVqlbt24aNGiQduzYoQ8//FCxsbGZ+gHIAQMAeSg6Otq0bt06W33j4uJMUFCQ4/nMmTONJLNv3z5H27Rp00xISIjjeUhIiJk4caLjeVpamilVqpTTOkuXLm3efvttp3Xdd999ZsyYMdmupVOnTqZly5ZOfbp27WoCAgIczxs3bmzefPNNpz5z5swx99xzzw3XAyB7+C4hAHfM8uXLFRMTo127dikpKUlpaWm6fPmykpOTVbBgQUlSwYIFVb58ecc899xzj06ePClJSkxM1IkTJ1S7dm3HdHd3d0VERMhut+dqLbt379YTTzzhNE/t2rW1ePFix/MtW7Zo9erVTkdU0tPTM20TANdxSgjAHXHw4EG1atVK9957rxYsWKCNGzdq2rRpkqQrV644+hUoUMBpPpvNJuPiV6C5ubllmic1NdXlWm7lwoULeu2117R582bHY+vWrdq7d6+8vb1dqhmAM46wALgjNm7cKLvdrkmTJsnN7erfTp9//rlLywgICFBISIg2bNig+vXrS7p6RCM+Pl41atRw9AsODnYaqJuUlKQDBw64VEulSpW0YcMGp7brnz/wwAPavXu3KlSo4NJ2ALg1AguAPJeYmKjNmzc7tRUtWlSpqal677339Nhjj2n16tWaPn26y8seMGCAYmJiVKFCBVWuXFnvvfeezp07J5vN5ujTqFEjxcbG6rHHHlNgYKBGjx4td3d3x/QKFSrcspYBAwaofv36mjx5sh577DGtXLlS3377rdN6Ro8erVatWqlUqVJq37693NzctGXLFm3btk1jx451edsAXONOD6IB8L8tOjraSMr06NWrl5k8ebK55557jI+Pj4mKijKzZ882ksy5c+eMMVcH3V47qNUYY7788ktz7VtXamqq6d+/v/H39zeFCxc2w4cPNx06dDCdO3d29ElMTDSdOnUy/v7+JiwszMTGxmYadHurWowxZsaMGaZEiRLGx8fHtGnTxowdO9aEhoY61bd06VITGRlpfHx8jL+/v6ldu7aZMWNGrr2ewN3KZoyLJ4MBwMLsdrvCw8PVsWNHvfHGG3m6rj59+mjXrl1atWpVnq4HAKeEAORzhw4d0vfff68GDRooJSVFU6dO1YEDB/Tkk0/m+rreeustNW3aVL6+vvr22281a9Ysvf/++7m+HgCZEVgA5Gtubm6KjY3V0KFDZYxRtWrVtHz5coWHh+f6utavX68JEybo/PnzKleunN5991317t0719cDIDNOCQEAAMvjPiwAAMDyCCwAAMDyCCwAAMDyCCwAAMDyCCwAAMDyCCwAAMDyCCwAAMDyCCwAAMDyCCwAAMDy/h+Tj4eRAyHn/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Glaucoma              3                 3      7                 42.857143   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    42.857143  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       theme  match_english  match_portuguese  Total  \\\n",
      "0  Oncologia              1                 0      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     100.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Refração              9                 8     31                 29.032258   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    25.806452  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Retina              6                 2     12                      50.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    16.666667  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAIjCAYAAACNoFiVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAABH9UlEQVR4nO3dd3hU1d728XuSQBISUoDQQwsIoWsoD0SK9A4WQMVDQAVUmnAQQaSDkSoqSPM8BJCigIhSFZAiRSmCCNKkyEGUmgQIBJJZ7x8+mZchYZOBxAn4/VzXXLDXXnuv30ym3LPb2IwxRgAAAHfg4e4CAABA1kZYAAAAlggLAADAEmEBAABYIiwAAABLhAUAAGCJsAAAACwRFgAAgCXCAgAAsERYAID71KlTJxUrVuxvH/fEiROy2WwaP3783z72wyzlcY2JiXF3KVkGYSET/Prrr+rWrZtKlCghHx8fBQQEKDIyUu+//76uXbvm7vJcduDAAQ0bNkwnTpxwedn+/fvLZrOpffv2GV/YQyDlTenWW0BAgCpXrqzJkycrOTk5w8bq1KmT/P39M2x9yBzFihVL9ZxI6/ZP+yCrW7eu0/339fVVxYoVNWnSJNnt9nta5/z58zVp0qSMLfQh5eXuAh42K1asUNu2beXt7a2OHTuqfPnyunHjhr777ju98cYb2r9/v2bMmOHuMl1y4MABDR8+XHXr1nXp25MxRgsWLFCxYsX01Vdf6fLly8qZM2fmFfoAe+6559SsWTNJUlxcnFauXKmePXvq5MmTGjdunJurw93MnDnznj+wbjdp0iRduXLFMb1y5UotWLBA7733nvLkyeNor1mzZoaM9yApXLiwoqOjJUnnz5/X/Pnz1adPH507d06jR492eX3z58/Xzz//rNdff92pvWjRorp27ZqyZcuWEWU/HAwyzLFjx4y/v78pU6aM+f3331PNP3LkiJk0adJ9j2O3201CQkKa865du2aSk5Pve4xbLVq0yEgy3377rUvLrV+/3kgy69evN9myZTMxMTEZWldWcPPmTZOYmHjPyx8/ftxIMuPGjXNqt9vtpmrVqqZgwYL3W6JDVFSU8fPzy7D14e8xbtw4I8kcP3481bw7PX8eRnXq1DHlypVzart27ZopWrSoyZkzp0lKSnJ5nc2bNzdFixbNoAofbuyGyEBjx47VlStX9J///EcFChRINb9kyZLq3bu3YzopKUkjR45UWFiYvL29VaxYMb311ltKTEx0Wq5YsWJq0aKF1qxZoypVqsjX11fTp0/Xhg0bZLPZtHDhQr399tsqVKiQcuTIofj4eEnS999/ryZNmigwMFA5cuRQnTp1tGXLllR1nT59Wi+99JIKFiwob29vFS9eXK+++qpu3LihmJgYtW3bVpL0xBNPODYBbtiw4a6Px7x581S2bFk98cQTatCggebNm5eqT8p9+OyzzzR69GgVLlxYPj4+ql+/vo4ePerU98iRI3r66aeVP39++fj4qHDhwnr22WcVFxcnSXrqqaf02GOPOS3TsmVL2Ww2ffnll46277//XjabTatWrXK0xcbG6vXXX1doaKi8vb1VsmRJjRkzxunb4q37hydNmuT4ux04cECS9OGHH6pcuXLKkSOHgoODVaVKFc2fP/+uj1NabDab8uXLJy+v/7/xLyoqSnny5NHNmzdT9W/UqJFKly59T2Pd6uTJk3rttddUunRp+fr6Knfu3Grbtm2qXVAxMTGy2WzasmWL+vbtq5CQEPn5+enJJ5/UuXPnnPra7XYNGzZMBQsWVI4cOfTEE0/owIEDKlasmDp16uToN2zYMNlstlQ1pYx1aw3Lli1T8+bNHc/ZsLAwjRw5Ms3dNlOmTFGJEiXk6+uratWqafPmzapbt67q1q3r1C8xMVFDhw5VyZIl5e3trdDQUPXv3z/V6zEttx+zcOtzZcaMGY7nStWqVbVjx467ru9epGecgwcP6plnnlGuXLnk4+OjKlWqOL02pP//eH/33Xfq1auXQkJCFBQUpG7duunGjRuKjY1Vx44dFRwcrODgYPXv31/mth8vttvtmjRpksqVKycfHx/ly5dP3bp106VLl5z6xcXF6eDBg47XsKt8fHxUtWpVXb58WWfPnnWa98knnygiIkK+vr7KlSuXnn32WZ06dcoxv27dulqxYoVOnjzpeF9L+RumdcxCym6806dPq02bNvL391dISIj69euX6nk3fvx41axZU7lz55avr68iIiK0ePHie7qPWQW7ITLQV199pRIlSqR78+DLL7+s2bNn65lnntG///1vff/994qOjtYvv/yipUuXOvU9dOiQnnvuOXXr1k1dunRx+mAYOXKksmfPrn79+ikxMVHZs2fX+vXr1bRpU0VERGjo0KHy8PDQrFmzVK9ePW3evFnVqlWTJP3++++qVq2aYmNj1bVrV5UpU0anT5/W4sWLlZCQoNq1a6tXr1764IMP9NZbbyk8PFySHP/eSWJiopYsWaJ///vfkv7azN65c2f98ccfyp8/f6r+7777rjw8PNSvXz/FxcVp7Nix6tChg77//ntJ0o0bN9S4cWMlJiaqZ8+eyp8/v06fPq3ly5crNjZWgYGBqlWrlpYtW6b4+HgFBATIGKMtW7bIw8NDmzdvVqtWrSRJmzdvloeHhyIjIyVJCQkJqlOnjk6fPq1u3bqpSJEi2rp1qwYOHKgzZ86k2qc5a9YsXb9+XV27dpW3t7dy5cqlmTNnqlevXnrmmWfUu3dvXb9+XT/99JO+//57Pf/883d9LiQkJOj8+fOSpPj4eK1atUqrV6/WwIEDHX3+9a9/ac6cOVqzZo1atGjhaP/jjz+0fv16DR069K7j3M2OHTu0detWPfvssypcuLBOnDihqVOnqm7dujpw4IBy5Mjh1L9nz54KDg7W0KFDdeLECU2aNEk9evTQp59+6ugzcOBAjR07Vi1btlTjxo21d+9eNW7cWNevX7/nOmNiYuTv76++ffvK399f69ev15AhQxQfH++022bq1Knq0aOHatWqpT59+ujEiRNq06aNgoODVbhwYUc/u92uVq1a6bvvvlPXrl0VHh6uffv26b333tPhw4f1xRdf3FOd8+fP1+XLl9WtWzfZbDaNHTtWTz31lI4dO5ahm7jTM87+/fsVGRmpQoUKacCAAfLz89Nnn32mNm3aaMmSJXryySed1pnyOhs+fLi2b9+uGTNmKCgoSFu3blWRIkX0zjvvaOXKlRo3bpzKly+vjh07Opbt1q2bYmJi1LlzZ/Xq1UvHjx/X5MmT9eOPP2rLli2OmpYuXarOnTtr1qxZTsHRFSkf7EFBQY620aNHa/DgwWrXrp1efvllnTt3Th9++KFq166tH3/8UUFBQRo0aJDi4uL03//+V++9954k3fWYnuTkZDVu3FjVq1fX+PHjtXbtWk2YMEFhYWF69dVXHf3ef/99tWrVSh06dNCNGze0cOFCtW3bVsuXL1fz5s3v6X66nbs3bTws4uLijCTTunXrdPXfs2ePkWRefvllp/Z+/fo5Nt2nKFq0qJFkVq9e7dT322+/NZJMiRIlnHZL2O12U6pUKdO4cWNjt9sd7QkJCaZ48eKmYcOGjraOHTsaDw8Ps2PHjlQ1pix7L7shFi9ebCSZI0eOGGOMiY+PNz4+Pua9995L8z6Eh4c7bc5///33jSSzb98+Y4wxP/74o5FkFi1adMcxd+zYYSSZlStXGmOM+emnn4wk07ZtW1O9enVHv1atWplHH33UMT1y5Ejj5+dnDh8+7LS+AQMGGE9PT/Pbb78ZY/7/Jt+AgABz9uxZp76tW7dOtYk0PVLWmdbt1Vdfdfr7JScnm8KFC5v27ds7rWPixInGZrOZY8eOWY6Vnt0Qae3e2rZtm5Fk5syZ42ibNWuWkWQaNGjgVGOfPn2Mp6eniY2NNcYY88cffxgvLy/Tpk0bp3UOGzbMSDJRUVGOtqFDh5q03pJSxrp1M3xadXbr1s3kyJHDXL9+3RhjTGJiosmdO7epWrWquXnzpqNfTEyMkWTq1KnjaJs7d67x8PAwmzdvdlrntGnTjCSzZcuWVOPdKioqymlzdsrfNXfu3ObixYuO9mXLlhlJ5quvvrJc363SsxsiPePUr1/fVKhQwfH4GPPXa7xmzZqmVKlSjraUx/v2948aNWoYm81mXnnlFUdbUlKSKVy4sNNjuXnzZiPJzJs3z6nW1atXp2pPGWvWrFl3fRzq1KljypQpY86dO2fOnTtnDh48aN544w0jyTRv3tzR78SJE8bT09OMHj3aafl9+/YZLy8vp/Y77YZIeVxvrSsqKspIMiNGjHDq++ijj5qIiAinttufnzdu3DDly5c39erVu+v9zKrYDZFBUjb9p/cAvpUrV0qS+vbt69Se8k18xYoVTu3FixdX48aN01xXVFSUfH19HdN79uzRkSNH9Pzzz+vChQs6f/68zp8/r6tXr6p+/fratGmT7Ha77Ha7vvjiC7Vs2VJVqlRJtd60Ngmn17x581SlShWVLFlS0l+PS/PmzdPcFSFJnTt3Vvbs2R3TtWrVkiQdO3ZMkhQYGChJWrNmjRISEtJcx6OPPip/f39t2rRJ0l9bEAoXLqyOHTtq9+7dSkhIkDFG3333nWP9krRo0SLVqlVLwcHBjsfq/PnzatCggZKTkx3rS/H0008rJCTEqS0oKEj//e9/73kTc9euXfXNN9/om2++0ZIlS9S9e3dNnz7d6fnh4eGhDh066Msvv9Tly5cd7fPmzVPNmjVVvHjxexr7Vrc+j27evKkLFy6oZMmSCgoK0u7du9Os+9bnSa1atZScnKyTJ09KktatW6ekpCS99tprTsv17Nkzw+q8fPmyzp8/r1q1aikhIUEHDx6UJO3cuVMXLlxQly5dnHbndOjQQcHBwU7rW7RokcLDw1WmTBmn50C9evUkSd9+++091dm+fXunsW5/XmeUu41z8eJFrV+/Xu3atXM8XufPn9eFCxfUuHFjHTlyRKdPn3Za50svveT0t61evbqMMXrppZccbZ6enqpSpYrT/Vm0aJECAwPVsGFDp8cyIiJC/v7+To9lp06dZIxJ91aFgwcPKiQkRCEhISpTpozGjRunVq1aOe0u+Pzzz2W329WuXTun8fPnz69SpUrd898yxSuvvOI0XatWrVR/z1ufn5cuXVJcXJxq1aqV5mvoQcFuiAwSEBAgSU5v4lZOnjwpDw8Px4dpivz58ysoKMjxZpvC6oPg9nlHjhyR9FeIuJO4uDjduHFD8fHxKl++fLpqTq/Y2FitXLlSPXr0cDruIDIyUkuWLNHhw4f1yCOPOC1TpEgRp+mUN76UfZzFixdX3759NXHiRM2bN0+1atVSq1at9MILLziChKenp2rUqKHNmzdL+iss1KpVS48//riSk5O1fft25cuXTxcvXnQKC0eOHNFPP/2UKgCkuH1faFp/izfffFNr165VtWrVVLJkSTVq1EjPP/+8Y1fH3ZQqVUoNGjRwTD/11FOy2WyaNGmSXnzxRVWoUEGS1LFjR40ZM0ZLly5Vx44ddejQIe3atUvTpk1L1zh3c+3aNUVHR2vWrFk6ffq0077otPYr3+3vlvI8vv15nitXrlQf2K7Yv3+/3n77ba1fv94R1G+v805je3l5pTqr58iRI/rll1/S/RxIr7s9PhnlbuMcPXpUxhgNHjxYgwcPTnMdZ8+eVaFChe64zpTXWWhoaKr2W+/PkSNHFBcXp7x5895xnHtVrFgxx5knv/76q0aPHq1z587Jx8fHaXxjjEqVKpXmOu5n94+Pj0+q50hwcHCqv+fy5cs1atQo7dmzx+mYl/v5AuZuhIUMEhAQoIIFC+rnn392abn0PnluTap3m5dyUN64ceNUuXLlNJfx9/fXxYsX01ekixYtWqTExERNmDBBEyZMSDV/3rx5Gj58uFObp6dnmuu69cNqwoQJ6tSpk5YtW6avv/5avXr1UnR0tLZv3+7Y//z4449r9OjRun79ujZv3qxBgwYpKChI5cuX1+bNm5UvXz5JcgoLdrtdDRs2VP/+/dOs4fZgk9bfIjw8XIcOHdLy5cu1evVqLVmyRB999JGGDBmS6r6mV/369TV58mRt2rTJERbKli2riIgIffLJJ+rYsaM++eQTZc+eXe3atbunMW7Xs2dPzZo1S6+//rpq1KihwMBA2Ww2Pfvss2meGpiev1t63em1cPvBY7GxsapTp44CAgI0YsQIhYWFycfHR7t379abb755T6cw2u12VahQQRMnTkxz/u0fkOmVkY/P/YyT8pj069fvjlsobw9Vd1pnWu233h+73a68efPecSvinQJZevj5+TmF6sjISD322GN666239MEHHzjGTzmAOa1a7+daI3d6TG6VcnxU7dq19dFHH6lAgQLKli2bZs2adc8HPGcFhIUM1KJFC82YMUPbtm1TjRo1LPsWLVpUdrtdR44ccTpY8M8//1RsbKyKFi16z3WEhYVJ+ivA3PrCul1ISIgCAgLuGnBcTcPz5s1T+fLl0zzgbvr06Zo/f/49f4BWqFBBFSpU0Ntvv62tW7cqMjJS06ZN06hRoyT9FQJu3LihBQsW6PTp045QULt2bUdYeOSRRxyhQfrr8bpy5YrlY5Uefn5+at++vdq3b68bN27oqaee0ujRozVw4ECnbz7plZSUJElO59xLf21d6Nu3r86cOaP58+erefPm9/Ut/VaLFy9WVFSUU8i7fv26YmNj72l9Kc/jo0ePOm2RuXDhQqpvYyn3ITY21ulgtdu3sm3YsEEXLlzQ559/rtq1azvajx8/fsexn3jiCUd7UlKSTpw4oYoVKzrawsLCtHfvXtWvX/+B/vZ3JyVKlJD017fq+32e301YWJjWrl2ryMhIyy85GaFixYp64YUXNH36dPXr109FihRRWFiYjDEqXrx4qqB/u8z4Wy9ZskQ+Pj5as2aNvL29He2zZs3K8LH+ThyzkIH69+8vPz8/vfzyy/rzzz9Tzf/111/1/vvvS5LjAjy3H2mf8s3mfo6YjYiIUFhYmMaPH5/qg0aS49Q2Dw8PtWnTRl999ZV27tyZql/KtwU/Pz9JStcHxqlTp7Rp0ya1a9dOzzzzTKpb586ddfToUcdZDukVHx/v+PBMUaFCBXl4eDht5qtevbqyZcumMWPGKFeuXCpXrpykv0LE9u3btXHjRqetCpLUrl07bdu2TWvWrEk1bmxsbKpx03LhwgWn6ezZs6ts2bIyxqR5qmN6fPXVV5KkSpUqObU/99xzstls6t27t44dO6YXXnjhntafFk9Pz1Tfej/88MN7vpJk/fr15eXlpalTpzq1T548OVXflJB76zEiV69e1ezZs1PVKDl/m71x44Y++ugjp35VqlRR7ty5NXPmTKe/4bx581IFlXbt2un06dOaOXNmqrquXbumq1evWt7PrC5v3ryqW7eupk+frjNnzqSaf/vprvejXbt2Sk5O1siRI1PNS0pKcnofud9TJ6W/3ndv3rzpeO986qmn5OnpqeHDh6d6LhtjnF6rfn5+9zV2Wjw9PWWz2ZxeMydOnLjnM2qyCrYsZKCwsDDNnz9f7du3V3h4uNMVHLdu3apFixY5DuSpVKmSoqKiNGPGDMdm1R9++EGzZ89WmzZtnL4JucrDw0Mff/yxmjZtqnLlyqlz584qVKiQTp8+rW+//VYBAQGOD6J33nlHX3/9terUqeM4ZezMmTNatGiRvvvuOwUFBaly5cry9PTUmDFjFBcXJ29vb9WrVy/NfZLz58+XMcZxmuLtmjVrJi8vL82bN0/Vq1dP931av369evToobZt2+qRRx5RUlKS5s6dK09PTz399NOOfjly5FBERIS2b9/uuMaC9NeWhatXr+rq1aupwsIbb7yhL7/8Ui1atFCnTp0UERGhq1evat++fVq8eLFOnDjhdOW8tDRq1Ej58+dXZGSk8uXLp19++UWTJ09W8+bN03XQ6+7du/XJJ59I+uu4l3Xr1mnJkiWqWbOmGjVq5NQ3JCRETZo00aJFixQUFORSsLx586ZjK8ytcuXKpddee00tWrTQ3LlzFRgYqLJly2rbtm1au3atcufOne4xbpUvXz717t1bEyZMUKtWrdSkSRPt3btXq1atUp48eZy+2TVq1EhFihTRSy+9pDfeeEOenp763//9X4WEhOi3335z9KtZs6aCg4MVFRWlXr16yWazae7cuak+GLJnz65hw4apZ8+eqlevntq1a6cTJ04oJiZGYWFhTmP/61//0meffaZXXnlF3377rSIjI5WcnKyDBw/qs88+c1zj5EE2ZcoUPf7446pQoYK6dOmiEiVK6M8//9S2bdv03//+V3v37s2QcerUqaNu3bopOjpae/bsUaNGjZQtWzYdOXJEixYt0vvvv69nnnlGUsacOlm2bFk1a9ZMH3/8sQYPHqywsDCNGjVKAwcOdJwqmzNnTh0/flxLly5V165d1a9fP0l/fbH69NNP1bdvX1WtWlX+/v5q2bLlfd3/5s2ba+LEiWrSpImef/55nT17VlOmTFHJkiX1008/3de63ervPfnin+Hw4cOmS5cuplixYiZ79uwmZ86cJjIy0nz44YdOpy3dvHnTDB8+3BQvXtxky5bNhIaGmoEDBzr1MeavUydvPTUoRcpph3c6nfDHH380Tz31lMmdO7fx9vY2RYsWNe3atTPr1q1z6nfy5EnTsWNHExISYry9vU2JEiVM9+7dnU5lnDlzpilRooTx9PS0PI2yQoUKpkiRIpaPT926dU3evHnNzZs373gfbj916dixY+bFF180YWFhxsfHx+TKlcs88cQTZu3atanWn3I61ZgxY5zaS5YsaSSZX3/9NdUyly9fNgMHDjQlS5Y02bNnN3ny5DE1a9Y048ePNzdu3HCqKa2r5U2fPt3Url3b8ViHhYWZN954w8TFxVk+FmmdOunl5WVKlChh3njjDXP58uU0l/vss8+MJNO1a1fL9d8q5dSvtG5hYWHGGGMuXbpkOnfubPLkyWP8/f1N48aNzcGDB03RokWdTnNMOeXt9lNuU/6etz4/kpKSzODBg03+/PmNr6+vqVevnvnll19M7ty5nU7DM8aYXbt2merVq5vs2bObIkWKmIkTJ6Z56uSWLVvM//zP/xhfX19TsGBB079/f7NmzZo0n5sffPCBKVq0qPH29jbVqlUzW7ZsMREREaZJkyZO/W7cuGHGjBljypUrZ7y9vU1wcLCJiIgww4cPv+vf8U6nTqb1XJFkhg4darm+W93rFRzTGufXX381HTt2NPnz5zfZsmUzhQoVMi1atDCLFy929LnT3zbl1NZz5845td/plNwZM2aYiIgI4+vra3LmzGkqVKhg+vfv73R1W1dPnbzT6ckbNmxIdX+XLFliHn/8cePn52f8/PxMmTJlTPfu3c2hQ4ccfa5cuWKef/55ExQUZCQ5/oZ3OnUyrfuZ1im///nPf0ypUqWMt7e3KVOmjJk1a9YdTw1+UNiMyeAjbQBkumXLlqlNmzbatGlTqi0lD4LY2FgFBwdr1KhRGjRo0N86tt1uV0hIiJ566qk0dzsASI1jFoAH0MyZM1WiRAk9/vjj7i7lrtL6pdWUY3Vuv+RyRrt+/Xqq3RNz5szRxYsXM31s4GHCMQvAA2ThwoX66aeftGLFCr3//vsPxJH7n376qWJiYtSsWTP5+/vru+++04IFC9SoUaN0X4fiXm3fvl19+vRR27ZtlTt3bu3evVv/+c9/VL58ecdvngC4O3ZDAA8Qm80mf39/tW/fXtOmTXO6MmFWtXv3bvXv31979uxRfHy88uXLp6efflqjRo26r3Pe0+PEiRPq1auXfvjhB128eFG5cuVSs2bN9O67797xokEAUiMsAAAASxyzAAAALBEWAACApay/w9OC3W7X77//rpw5cz4QB3oBAJBVGGN0+fJlFSxYUB4e1tsOHuiw8Pvvv9/zD7wAAIC/LtOf8mN8d/JAh4WUy+ieOnXK8RPRAADg7uLj4xUaGpquS9I/0GEhZddDQEAAYQEAgHuQnt34HOAIAAAsERYAAIAlwgIAALBEWAAAAJYICwAAwBJhAQAAWCIsAAAAS4QFAABgibAAAAAsERYAAIAlwgIAALBEWAAAAJYICwAAwBJhAQAAWCIsAAAAS24PC6dPn9YLL7yg3Llzy9fXVxUqVNDOnTvdXRYAAPg/Xu4c/NKlS4qMjNQTTzyhVatWKSQkREeOHFFwcLA7ywIAALdwa1gYM2aMQkNDNWvWLEdb8eLF3VgRAAC4nVt3Q3z55ZeqUqWK2rZtq7x58+rRRx/VzJkz79g/MTFR8fHxTjcAAJC53Lpl4dixY5o6dar69u2rt956Szt27FCvXr2UPXt2RUVFpeofHR2t4cOHZ3pdxQasyPQxgKzixLvN3V0CgCzOZowx7ho8e/bsqlKlirZu3epo69Wrl3bs2KFt27al6p+YmKjExETHdHx8vEJDQxUXF6eAgIAMq4uwgH8SwgLwzxQfH6/AwMB0fYa6dTdEgQIFVLZsWae28PBw/fbbb2n29/b2VkBAgNMNAABkLreGhcjISB06dMip7fDhwypatKibKgIAALdza1jo06ePtm/frnfeeUdHjx7V/PnzNWPGDHXv3t2dZQEAgFu4NSxUrVpVS5cu1YIFC1S+fHmNHDlSkyZNUocOHdxZFgAAuIVbz4aQpBYtWqhFixbuLgMAANyB2y/3DAAAsjbCAgAAsERYAAAAlggLAADAEmEBAABYIiwAAABLhAUAAGCJsAAAACwRFgAAgCXCAgAAsERYAAAAlggLAADAEmEBAABYIiwAAABLhAUAAGCJsAAAACwRFgAAgCXCAgAAsERYAAAAlggLAADAEmEBAABYIiwAAABLhAUAAGCJsAAAACwRFgAAgCXCAgAAsERYAAAAlggLAADAEmEBAABYIiwAAABLhAUAAGCJsAAAACwRFgAAgCXCAgAAsERYAAAAlggLAADAEmEBAABYIiwAAABLhAUAAGCJsAAAACwRFgAAgCXCAgAAsERYAAAAlggLAADAEmEBAABYIiwAAABLhAUAAGCJsAAAACwRFgAAgCXCAgAAsERYAAAAlggLAADAEmEBAABYIiwAAABLhAUAAGCJsAAAACwRFgAAgCXCAgAAsERYAAAAlggLAADAEmEBAABYIiwAAABLbg0Lw4YNk81mc7qVKVPGnSUBAIDbeLm7gHLlymnt2rWOaS8vt5cEAABu4fZPZi8vL+XPn9/dZQAAgDtw+zELR44cUcGCBVWiRAl16NBBv/322x37JiYmKj4+3ukGAAAyl1vDQvXq1RUTE6PVq1dr6tSpOn78uGrVqqXLly+n2T86OlqBgYGOW2ho6N9cMQAA/zw2Y4xxdxEpYmNjVbRoUU2cOFEvvfRSqvmJiYlKTEx0TMfHxys0NFRxcXEKCAjIsDqKDViRYesCsroT7zZ3dwkA3CA+Pl6BgYHp+gx1+zELtwoKCtIjjzyio0ePpjnf29tb3t7ef3NVAAD8s7n9mIVbXblyRb/++qsKFCjg7lIAAMD/cWtY6NevnzZu3KgTJ05o69atevLJJ+Xp6annnnvOnWUBAIBbuHU3xH//+18999xzunDhgkJCQvT4449r+/btCgkJcWdZAADgFm4NCwsXLnTn8AAAIB2y1DELAAAg6yEsAAAAS4QFAABgibAAAAAsERYAAIAlwgIAALBEWAAAAJYICwAAwBJhAQAAWCIsAAAAS4QFAABgibAAAAAsERYAAIAlwgIAALBEWAAAAJYICwAAwBJhAQAAWCIsAAAAS4QFAABgibAAAAAsERYAAIAlwgIAALBEWAAAAJYICwAAwBJhAQAAWCIsAAAAS4QFAABgibAAAAAsERYAAIAlwgIAALBEWAAAAJYICwAAwBJhAQAAWCIsAAAAS4QFAABgibAAAAAsERYAAIAlwgIAALBEWAAAAJYICwAAwBJhAQAAWCIsAAAAS4QFAABgibAAAAAsERYAAIAlwgIAALBEWAAAAJYICwAAwBJhAQAAWCIsAAAAS4QFAABgibAAAAAsERYAAIAlwgIAALBEWAAAAJYICwAAwBJhAQAAWCIsAAAAS4QFAABgibAAAAAsERYAAIAlwgIAALCUZcLCu+++K5vNptdff93dpQAAgFtkibCwY8cOTZ8+XRUrVnR3KQAA4DZuDwtXrlxRhw4dNHPmTAUHB7u7HAAAcBu3h4Xu3burefPmatCgwV37JiYmKj4+3ukGAAAyl5c7B1+4cKF2796tHTt2pKt/dHS0hg8fnslVAQCAW7lty8KpU6fUu3dvzZs3Tz4+PulaZuDAgYqLi3PcTp06lclVAgAAt21Z2LVrl86ePavHHnvM0ZacnKxNmzZp8uTJSkxMlKenp9My3t7e8vb2/rtLBQDgH81tYaF+/frat2+fU1vnzp1VpkwZvfnmm6mCAgAAcA+3hYWcOXOqfPnyTm1+fn7KnTt3qnYAAOA+bj8bAgAAZG1uPRvidhs2bHB3CQAA4DZsWQAAAJZcDgu7d+92OjBx2bJlatOmjd566y3duHEjQ4sDAADu53JY6Natmw4fPixJOnbsmJ599lnlyJFDixYtUv/+/TO8QAAA4F4uh4XDhw+rcuXKkqRFixapdu3amj9/vmJiYrRkyZKMrg8AALiZy2HBGCO73S5JWrt2rZo1ayZJCg0N1fnz5zO2OgAA4HYuh4UqVapo1KhRmjt3rjZu3KjmzZtLko4fP658+fJleIEAAMC9XA4LkyZN0u7du9WjRw8NGjRIJUuWlCQtXrxYNWvWzPACAQCAe7l0nYXk5GTFxsZq06ZNCg4Odpo3btw4LtEMAMBDyKUtC56enmrUqJFiY2NTzfPx8VG2bNkyqi4AAJBFuLwbonz58jp27Fhm1AIAALIgl8PCqFGj1K9fPy1fvlxnzpxRfHy80w0AADxcXP5tiJRTJVu1aiWbzeZoN8bIZrMpOTk546oDAABu53JY+PbbbzOjDgAAkEW5HBbq1KmTGXUAAIAs6p5+dXLz5s164YUXVLNmTZ0+fVqSNHfuXH333XcZWhwAAHA/l8PCkiVL1LhxY/n6+mr37t1KTEyUJMXFxemdd97J8AIBAIB73dPZENOmTdPMmTOdrqsQGRmp3bt3Z2hxAADA/VwOC4cOHVLt2rVTtQcGBqZ5sSYAAPBgczks5M+fX0ePHk3V/t1336lEiRIZUhQAAMg6XA4LXbp0Ue/evfX999/LZrPp999/17x589SvXz+9+uqrmVEjAABwI5dPnRwwYIDsdrvq16+vhIQE1a5dW97e3urXr5969uyZGTUCAAA3cjks2Gw2DRo0SG+88YaOHj2qK1euqGzZsvL398+M+gAAgJu5HBbWr1+vmjVrysfHR2XLls2MmgAAQBbiclho1aqVkpKSVLVqVdWtW1d16tRRZGSkfH19M6M+AADgZi4f4Hjp0iWtW7dOTZs21Q8//KAnn3xSQUFBioyM1Ntvv50ZNQIAADeyGWPM/axg//79GjdunObNmye73f63/upkfHy8AgMDFRcXp4CAgAxbb7EBKzJsXUBWd+Ld5u4uAYAbuPIZ6vJuiMOHD2vDhg3asGGDNm7cqMTERNWqVUvjx49X3bp177VmAACQRbkcFsqUKaOQkBD17t1bAwYMUIUKFWSz2TKjNgAAkAW4fMxCr169VKhQIY0YMUKvvPKKBg0apK+//loJCQmZUR8AAHAzl8PCpEmTtHv3bv3xxx8aOHCgbty4oUGDBilPnjyKjIzMjBoBAIAbuRwWUiQnJ+vmzZtKTEzU9evXlZiYqEOHDmVkbQAAIAu4p90QFStWVL58+dStWzf9/vvv6tKli3788UedO3cuM2oEAABu5PIBjmfOnFHXrl1Vt25dlS9fPjNqAgAAWYjLYWHRokWZUQcAAMiiXN4NMXv2bK1Y8f8vWtS/f38FBQWpZs2aOnnyZIYWBwAA3M/lsPDOO+84fgdi27ZtmjJlisaOHas8efKoT58+GV4gAABwL5d3Q5w6dUolS5aUJH3xxRd6+umn1bVrV0VGRnIFRwAAHkIub1nw9/fXhQsXJElff/21GjZsKEny8fHRtWvXMrY6AADgdi5vWWjYsKFefvllPfroozp8+LCaNWsm6a8flCpWrFhG1wcAANzM5S0LU6ZMUY0aNXTu3DktWbJEuXPnliTt2rVLzz33XIYXCAAA3MvlLQtBQUGaPHlyqvbhw4dnSEEAACBrcTksSFJsbKx++OEHnT17Vna73dFus9n0r3/9K8OKAwAA7udyWPjqq6/UoUMHXblyRQEBAU4/T01YAADg4ePyMQv//ve/9eKLL+rKlSuKjY3VpUuXHLeLFy9mRo0AAMCNXA4Lp0+fVq9evZQjR47MqAcAAGQxLoeFxo0ba+fOnZlRCwAAyIJcPmahefPmeuONN3TgwAFVqFBB2bJlc5rfqlWrDCsOAAC4n8thoUuXLpKkESNGpJpns9mUnJx8/1UBAIAsw+WwcOupkgAA4OHn8jELdxIbG5vmxZoAAMCD7b7Dwrp16/T888+rQIECGjp0aEbUBAAAspB7CgunTp3SiBEjVLx4cTVq1Eg2m01Lly7VH3/8kdH1AQAAN0t3WLh586YWLVqkxo0bq3Tp0tqzZ4/GjRsnDw8PDRo0SE2aNEl1ZgQAAHjwpfsAx0KFCqlMmTJ64YUXtHDhQgUHB0sSvzQJAMBDLt1bFpKSkmSz2WSz2eTp6ZmZNQEAgCwk3WHh999/V9euXbVgwQLlz59fTz/9tJYuXer0Q1IAAODhk+6w4OPjow4dOmj9+vXat2+fwsPD1atXLyUlJWn06NH65ptvuCATAAAPoXs6GyIsLEyjRo3SyZMntWLFCiUmJqpFixbKly9fRtcHAADczOUrON7Kw8NDTZs2VdOmTXXu3DnNnTs3o+oCAABZRIZdwTEkJER9+/bNqNUBAIAsIsPCAgAAeDgRFgAAgCXCAgAAsORyWBgxYoQSEhJStV+7dk0jRoxwaV1Tp05VxYoVFRAQoICAANWoUUOrVq1ytSQAAJCJXA4Lw4cP15UrV1K1JyQkaPjw4S6tq3Dhwnr33Xe1a9cu7dy5U/Xq1VPr1q21f/9+V8sCAACZxOVTJ40xaV61ce/evcqVK5dL62rZsqXT9OjRozV16lRt375d5cqVc7U0AACQCdIdFoKDgx2/DfHII484BYbk5GRduXJFr7zyyj0XkpycrEWLFunq1auqUaNGmn0SExOVmJjomI6Pj7/n8QAAQPqkOyxMmjRJxhi9+OKLGj58uAIDAx3zsmfPrmLFit3xQ97Kvn37VKNGDV2/fl3+/v5aunSpypYtm2bf6Ohol3d1AACA+2MzxhhXFti4caMiIyPl5XVfF390uHHjhn777TfFxcVp8eLF+vjjj7Vx48Y0A0NaWxZCQ0MVFxengICADKlHkooNWJFh6wKyuhPvNnd3CQDcID4+XoGBgen6DHX5AMerV69q3bp1qdrXrFlzT2cyZM+eXSVLllRERISio6NVqVIlvf/++2n29fb2dpw5kXIDAACZy+WwMGDAgDR/XdIYowEDBtx3QXa73WnrAQAAcC+X9yUcOXIkzV0EZcqU0dGjR11a18CBA9W0aVMVKVJEly9f1vz587VhwwatWbPG1bIAAEAmcTksBAYG6tixYypWrJhT+9GjR+Xn5+fSus6ePauOHTvqzJkzCgwMVMWKFbVmzRo1bNjQ1bIAAEAmcTkstG7dWq+//rqWLl2qsLAwSX8FhX//+99q1aqVS+v6z3/+4+rwAADgb+byMQtjx46Vn5+fypQpo+LFi6t48eIKDw9X7ty5NX78+MyoEQAAuNE97YbYunWrvvnmG+3du1e+vr6qWLGiateunRn1AQAAN7uniyXYbDY1atRItWvXlre3d5qXfwYAAA8Hl3dD2O12jRw5UoUKFZK/v7+OHz8uSRo8eDDHIAAA8BByOSyMGjVKMTExGjt2rLJnz+5oL1++vD7++OMMLQ4AALify2Fhzpw5mjFjhjp06CBPT09He6VKlXTw4MEMLQ4AALify2Hh9OnTKlmyZKp2u92umzdvZkhRAAAg63A5LJQtW1abN29O1b548WI9+uijGVIUAADIOlw+G2LIkCGKiorS6dOnZbfb9fnnn+vQoUOaM2eOli9fnhk1AgAAN3J5y0Lr1q311Vdfae3atfLz89OQIUP0yy+/6KuvvuIyzQAAPIRc2rKQlJSkd955Ry+++KK++eabzKoJAABkIS5tWfDy8tLYsWOVlJSUWfUAAIAsxuXdEPXr19fGjRszoxYAAJAFuXyAY9OmTTVgwADt27dPERERqX6W2tVfngQAAFmby2HhtddekyRNnDgx1Tybzabk5OT7rwoAAGQZLocFu92eGXUAAIAsyqVjFm7evCkvLy/9/PPPmVUPAADIYlwKC9myZVORIkXY1QAAwD+Iy2dDDBo0SG+99ZYuXryYGfUAAIAsxuVjFiZPnqyjR4+qYMGCKlq0aKqzIXbv3p1hxQEAAPdzOSy0adMmE8oAAABZlcthYejQoZlRBwAAyKJcDgspdu3apV9++UWSVK5cOX6eGgCAh5TLYeHs2bN69tlntWHDBgUFBUmSYmNj9cQTT2jhwoUKCQnJ6BoBAIAbuXw2RM+ePXX58mXt379fFy9e1MWLF/Xzzz8rPj5evXr1yowaAQCAG7m8ZWH16tVau3atwsPDHW1ly5bVlClT1KhRowwtDgAAuJ/LWxbsdruyZcuWqj1btmxcChoAgIeQy2GhXr166t27t37//XdH2+nTp9WnTx/Vr18/Q4sDAADu53JYmDx5suLj41WsWDGFhYUpLCxMxYsXV3x8vD788MPMqBEAALiRy8cshIaGavfu3Vq7dq0OHjwoSQoPD1eDBg0yvDgAAOB+93SdBZvNpoYNG6phw4YZXQ8AAMhi0r0bYv369Spbtqzi4+NTzYuLi1O5cuW0efPmDC0OAAC4X7rDwqRJk9SlSxcFBASkmhcYGKhu3bpp4sSJGVocAABwv3SHhb1796pJkyZ3nN+oUSPt2rUrQ4oCAABZR7rDwp9//pnm9RVSeHl56dy5cxlSFAAAyDrSHRYKFSqkn3/++Y7zf/rpJxUoUCBDigIAAFlHusNCs2bNNHjwYF2/fj3VvGvXrmno0KFq0aJFhhYHAADcL92nTr799tv6/PPP9cgjj6hHjx4qXbq0JOngwYOaMmWKkpOTNWjQoEwrFAAAuEe6w0K+fPm0detWvfrqqxo4cKCMMZL+uuZC48aNNWXKFOXLly/TCgUAAO7h0kWZihYtqpUrV+rSpUs6evSojDEqVaqUgoODM6s+AADgZvd0Bcfg4GBVrVo1o2sBAABZkMs/JAUAAP5ZCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYMmtYSE6OlpVq1ZVzpw5lTdvXrVp00aHDh1yZ0kAAOA2bg0LGzduVPfu3bV9+3Z98803unnzpho1aqSrV6+6sywAAHALL3cOvnr1aqfpmJgY5c2bV7t27VLt2rXdVBUAALiVW8PC7eLi4iRJuXLlSnN+YmKiEhMTHdPx8fF/S10AAPyTZZmwYLfb9frrrysyMlLly5dPs090dLSGDx/+N1cGIKsqNmCFu0sA/jYn3m3utrGzzNkQ3bt3188//6yFCxfesc/AgQMVFxfnuJ06depvrBAAgH+mLLFloUePHlq+fLk2bdqkwoUL37Gft7e3vL29/8bKAACAW8OCMUY9e/bU0qVLtWHDBhUvXtyd5QAAgDS4NSx0795d8+fP17Jly5QzZ0798ccfkqTAwED5+vq6szQAAPB/3HrMwtSpUxUXF6e6deuqQIECjtunn37qzrIAAMAt3L4bAgAAZG1Z5mwIAACQNREWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFhya1jYtGmTWrZsqYIFC8pms+mLL75wZzkAACANbg0LV69eVaVKlTRlyhR3lgEAACx4uXPwpk2bqmnTpu4sAQAA3IVbw4KrEhMTlZiY6JiOj493YzUAAPwzPFAHOEZHRyswMNBxCw0NdXdJAAA89B6osDBw4EDFxcU5bqdOnXJ3SQAAPPQeqN0Q3t7e8vb2dncZAAD8ozxQWxYAAMDfz61bFq5cuaKjR486po8fP649e/YoV65cKlKkiBsrAwAAKdwaFnbu3KknnnjCMd23b19JUlRUlGJiYtxUFQAAuJVbw0LdunVljHFnCQAA4C44ZgEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACWskRYmDJliooVKyYfHx9Vr15dP/zwg7tLAgAA/8ftYeHTTz9V3759NXToUO3evVuVKlVS48aNdfbsWXeXBgAAlAXCwsSJE9WlSxd17txZZcuW1bRp05QjRw797//+r7tLAwAAkrzcOfiNGze0a9cuDRw40NHm4eGhBg0aaNu2ban6JyYmKjEx0TEdFxcnSYqPj8/QuuyJCRm6PiAry+jXz9+J1yr+STL6tZqyPmPMXfu6NSycP39eycnJypcvn1N7vnz5dPDgwVT9o6OjNXz48FTtoaGhmVYj8LALnOTuCgCkR2a9Vi9fvqzAwEDLPm4NC64aOHCg+vbt65i22+26ePGicufOLZvN5sbKcL/i4+MVGhqqU6dOKSAgwN3lALgDXqsPD2OMLl++rIIFC961r1vDQp48eeTp6ak///zTqf3PP/9U/vz5U/X39vaWt7e3U1tQUFBmloi/WUBAAG9AwAOA1+rD4W5bFFK49QDH7NmzKyIiQuvWrXO02e12rVu3TjVq1HBjZQAAIIXbd0P07dtXUVFRqlKliqpVq6ZJkybp6tWr6ty5s7tLAwAAygJhoX379jp37pyGDBmiP/74Q5UrV9bq1atTHfSIh5u3t7eGDh2aajcTgKyF1+o/k82k55wJAADwj+X2izIBAICsjbAAAAAsERYAAIAlwgKynE6dOqlNmzaO6bp16+r1119P17Ku9AUApI/bz4YA7ubzzz9XtmzZ3F0G8NDo1KmTYmNj9cUXX7i7FDwgCAvI8nLlyuXuEoCHQnJyMpfGxz1hNwRcYrfbFR0dreLFi8vX11eVKlXS4sWLJUkbNmyQzWbTunXrVKVKFeXIkUM1a9bUoUOHnNYxatQo5c2bVzlz5tTLL7+sAQMGqHLlyncc8/ZdCx999JFKlSolHx8f5cuXT88880yqGvv3769cuXIpf/78GjZsWEbdfeBvVbduXfXo0UM9evRQYGCg8uTJo8GDBzt+JfDSpUvq2LGjgoODlSNHDjVt2lRHjhxxLB8TE6OgoCB9+eWXKlu2rLy9vfXiiy9q9uzZWrZsmWw2m2w2mzZs2OB4/cbGxjqW37Nnj2w2m06cOOFomzlzpkJDQ5UjRw49+eSTmjhxotNl92/fjShJr7/+uurWreuYtnofSblfHTp0UEhIiHx9fVWqVCnNmjXLMf/UqVNq166dgoKClCtXLrVu3dqpRmQ8wgJcEh0drTlz5mjatGnav3+/+vTpoxdeeEEbN2509Bk0aJAmTJignTt3ysvLSy+++KJj3rx58zR69GiNGTNGu3btUpEiRTR16tR0j79z50716tVLI0aM0KFDh7R69WrVrl3bqc/s2bPl5+en77//XmPHjtWIESP0zTff3P+dB9xg9uzZ8vLy0g8//KD3339fEydO1Mcffyzprw/mnTt36ssvv9S2bdtkjFGzZs108+ZNx/IJCQkaM2aMPv74Y+3fv18ffPCB2rVrpyZNmujMmTM6c+aMatasma5atmzZoldeeUW9e/fWnj171LBhQ40ePdrl+3S395HBgwfrwIEDWrVqlX755RdNnTpVefLkkSTdvHlTjRs3Vs6cObV582Zt2bJF/v7+atKkiW7cuOFyLUgnA6TT9evXTY4cOczWrVud2l966SXz3HPPmW+//dZIMmvXrnXMW7FihZFkrl27Zowxpnr16qZ79+5Oy0dGRppKlSo5pqOiokzr1q0d03Xq1DG9e/c2xhizZMkSExAQYOLj49OssU6dOubxxx93aqtatap58803Xb27gNvVqVPHhIeHG7vd7mh78803TXh4uDl8+LCRZLZs2eKYd/78eePr62s+++wzY4wxs2bNMpLMnj17nNZ7+2vMGON4/V66dMnR9uOPPxpJ5vjx48YYY9q3b2+aN2/utFyHDh1MYGCg5bp79+5t6tSpY4y5+/uIMca0bNnSdO7cOc3HZO7cuaZ06dJOj0liYqLx9fU1a9asSXMZ3D+2LCDdjh49qoSEBDVs2FD+/v6O25w5c/Trr786+lWsWNHx/wIFCkiSzp49K0k6dOiQqlWr5rTe26etNGzYUEWLFlWJEiX0r3/9S/PmzVNCQoJTn1vHT6khZXzgQfM///M/TscZ1KhRQ0eOHNGBAwfk5eWl6tWrO+blzp1bpUuX1i+//OJoy549e6rXxL2639evlL73kVdffVULFy5U5cqV1b9/f23dutWx/N69e3X06FHlzJnTsWyuXLl0/fp1p/chZCwOcES6XblyRZK0YsUKFSpUyGmet7e344V665kLKW9ydrs9Q2rImTOndu/erQ0bNujrr7/WkCFDNGzYMO3YscOx3/T2MydsNluGjQ88aHx9fdN1UKOHx1/fHc0tvwBw6+6M9PLw8HBax+3rudv7iCQ1bdpUJ0+e1MqVK/XNN9+ofv366t69u8aPH68rV64oIiJC8+bNSzV2SEiIy/UifdiygHRLOUDqt99+U8mSJZ1uoaGh6VpH6dKltWPHDqe226fvxsvLSw0aNNDYsWP1008/6cSJE1q/fr1L6wAeFN9//73T9Pbt21WqVCmVLVtWSUlJTvMvXLigQ4cOqWzZspbrzJ49u5KTk53aUj5oz5w542jbs2ePU5/0vH5DQkKc1nH7etL7PhISEqKoqCh98sknmjRpkmbMmCFJeuyxx3TkyBHlzZs31fKBgYGW9xv3ji0LSLecOXOqX79+6tOnj+x2ux5//HHFxcVpy5YtCggIUNGiRe+6jp49e6pLly6qUqWKatasqU8//VQ//fSTSpQoka4ali9frmPHjql27doKDg7WypUrZbfbVbp06fu9e0CW9Ntvv6lv377q1q2bdu/erQ8//FATJkxQqVKl1Lp1a3Xp0kXTp09Xzpw5NWDAABUqVEitW7e2XGexYsW0Zs0aHTp0SLlz51ZgYKDjw3rYsGEaPXq0Dh8+rAkTJjgt17NnT9WuXVsTJ05Uy5YttX79eq1atcppy0W9evU0btw4zZkzRzVq1NAnn3yin3/+WY8++qiku7+PREVFaciQIYqIiFC5cuWUmJio5cuXKzw8XJLUoUMHjRs3Tq1bt9aIESNUuHBhnTx5Up9//rn69++vwoULZ/BfABJbFuCikSNHavDgwYqOjlZ4eLiaNGmiFStWqHjx4ulavkOHDho4cKD69eunxx57TMePH1enTp3k4+OTruWDgoL0+eefq169egoPD9e0adO0YMEClStX7n7uFpBldezYUdeuXVO1atXUvXt39e7dW127dpUkzZo1SxEREWrRooVq1KghY4xWrlx514uYdenSRaVLl1aVKlUUEhKiLVu2KFu2bFqwYIEOHjyoihUrasyYMRo1apTTcpGRkZo2bZomTpyoSpUqafXq1erTp4/T67dx48YaPHiw+vfvr6pVq+ry5cvq2LGj03ru9j6SPXt2DRw4UBUrVlTt2rXl6emphQsXSpJy5MihTZs2qUiRInrqqacUHh6ul156SdevX1dAQMB9P95IGz9RDbdr2LCh8ufPr7lz57q7FCBLqVu3ripXrqxJkya5u5Q76tKliw4ePKjNmze7uxRkInZD4G+VkJCgadOmqXHjxvL09NSCBQu0du1aroMAPCDGjx+vhg0bys/PT6tWrdLs2bP10UcfubssZDLCAv5WNptNK1eu1OjRo3X9+nWVLl1aS5YsUYMGDdxdGoB0+OGHHzR27FhdvnxZJUqU0AcffKCXX37Z3WUhk7EbAgAAWOIARwAAYImwAAAALBEWAACAJcICAACwRFgAAACWCAsAAMASYQF4iHXq1Elt2rRxdxkAHnCEBQAAYImwAPxDTZw4URUqVJCfn59CQ0P12muv6cqVK475MTExCgoK0po1axQeHi5/f381adLE6eeHk5KS1KtXLwUFBSl37tx68803FRUV5bQ1o1ixYql+26By5coaNmxYumuRpJkzZyo0NFQ5cuTQk08+qYkTJyooKMipz7Jly/TYY4/Jx8dHJUqU0PDhw5WUlHTfjxXwT0dYAP6hPDw89MEHH2j//v2aPXu21q9fr/79+zv1SUhI0Pjx4zV37lxt2rRJv/32m/r16+eYP2bMGM2bN0+zZs3Sli1bFB8fry+++CLDa9myZYteeeUV9e7dW3v27FHDhg01evRop3Vs3rxZHTt2VO/evXXgwAFNnz5dMTExqfoBuAcGwEMrKirKtG7dOl19Fy1aZHLnzu2YnjVrlpFkjh496mibMmWKyZcvn2M6X758Zty4cY7ppKQkU6RIEacxixYtat577z2nsSpVqmSGDh2a7lrat29vmjdv7tSnQ4cOJjAw0DFdv35988477zj1mTt3rilQoMAdxwGQPvyQFPAPtXbtWkVHR+vgwYOKj49XUlKSrl+/roSEBOXIkUOSlCNHDoWFhTmWKVCggM6ePStJiouL059//qlq1ao55nt6eioiIkJ2uz1Dazl06JCefPJJp2WqVaum5cuXO6b37t2rLVu2OG1JSE5OTnWfALiO3RDAP9CJEyfUokULVaxYUUuWLNGuXbs0ZcoUSdKNGzcc/bJly+a0nM1mk3Hxt+c8PDxSLXPz5k2Xa7mbK1euaPjw4dqzZ4/jtm/fPh05ckQ+Pj4u1QzAGVsWgH+gXbt2yW63a8KECfLw+Os7w2effebSOgIDA5UvXz7t2LFDtWvXlvTXN/ndu3ercuXKjn4hISFOB0XGx8fr+PHjLtVSunRp7dixw6nt9unHHntMhw4dUsmSJV26HwDujrAAPOTi4uK0Z88ep7Y8efLo5s2b+vDDD9WyZUtt2bJF06ZNc3ndPXv2VHR0tEqWLKkyZcroww8/1KVLl2Sz2Rx96tWrp5iYGLVs2VJBQUEaMmSIPD09HfNLlix511p69uyp2rVra+LEiWrZsqXWr1+vVatWOY0zZMgQtWjRQkWKFNEzzzwjDw8P7d27Vz///LNGjRrl8n0DcAt3HzQBIPNERUUZSaluL730kpk4caIpUKCA8fX1NY0bNzZz5swxksylS5eMMX8d4HjrAYTGGLN06VJz69vGzZs3TY8ePUxAQIAJDg42b775pmnbtq159tlnHX3i4uJM+/btTUBAgAkNDTUxMTGpDnC8Wy3GGDNjxgxTqFAh4+vra9q0aWNGjRpl8ufP71Tf6tWrTc2aNY2vr68JCAgw1apVMzNmzMiwxxP4p7IZ4+IOSAC4A7vdrvDwcLVr104jR47M1LG6dOmigwcPavPmzZk6DgB2QwC4DydPntTXX3+tOnXqKDExUZMnT9bx48f1/PPPZ/hY48ePV8OGDeXn56dVq1Zp9uzZ+uijjzJ8HACpERYA3DMPDw/FxMSoX79+MsaofPnyWrt2rcLDwzN8rB9++EFjx47V5cuXVaJECX3wwQd6+eWXM3wcAKmxGwIAAFjiOgsAAMASYQEAAFgiLAAAAEuEBQAAYImwAAAALBEWAACAJcICAACwRFgAAACW/h93ABjLWhBxGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                theme  match_english  match_portuguese  Total  \\\n",
      "0  Cirurgia Refrativa              1                 1      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     100.0                        100.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 theme  match_english  match_portuguese  Total  \\\n",
      "0  Cirurgia Refrativva              0                 1      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                        100.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 theme  match_english  match_portuguese  Total  \\\n",
      "0  Cristalino/Catarata              3                 5      8   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                      37.5                         62.5  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Córnea              4                 1     10                      40.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                         10.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               theme  match_english  match_portuguese  Total  \\\n",
      "0  Córnea/Cristalino              1                 0      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     100.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        theme  match_english  match_portuguese  Total  \\\n",
      "0  Estrabismo              3                 3     11   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                 27.272727                    27.272727  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          theme  match_english  match_portuguese  Total  \\\n",
      "0  Farmacologia              5                 4      9   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                 55.555556                    44.444444  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   theme  match_english  match_portuguese  Total  \\\n",
      "0  Farmacologia/Glaucoma              0                 0      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Glaucoma              3                 3      7                 42.857143   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    42.857143  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       theme  match_english  match_portuguese  Total  \\\n",
      "0  Glaucoma               1                 0      2   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                      50.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             theme  match_english  match_portuguese  Total  \\\n",
      "0  Glaucoma/Uveíte              0                 0      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               theme  match_english  match_portuguese  Total  \\\n",
      "0  Lentes de Contato              0                 0      3   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              theme  match_english  match_portuguese  Total  \\\n",
      "0  Neuroftalmologia              0                 1      7   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                    14.285714  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       theme  match_english  match_portuguese  Total  \\\n",
      "0  Oncologia/Plástica Ocular              1                 0      3   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                 33.333333                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             theme  match_english  match_portuguese  Total  \\\n",
      "0  Plástica Ocular              3                 4     16   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     18.75                         25.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Refração              9                 8     31                 29.032258   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    25.806452  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      theme  match_english  match_portuguese  Total  \\\n",
      "0  Refração/Visão subnormal              0                 0      2   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Retina              6                 2     12                      50.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    16.666667  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              theme  match_english  match_portuguese  Total  \\\n",
      "0  Retina/Oncologia              0                 0      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Uveíte              4                 2      8                      50.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                         25.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             theme  match_english  match_portuguese  Total  \\\n",
      "0  Visão subnormal              1                 1      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     100.0                        100.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Óptica              0                 1      1                       0.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                        100.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             theme  match_english  match_portuguese  Total  \\\n",
      "0  Óptica/Refração              1                 1      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     100.0                        100.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEMPERATURE = str(TEMPERATURE).replace('.', '_')\n",
    "\n",
    "run_analysis(model=MODEL, temperature=TEMPERATURE, n_repetitions=N_REPETITIONS, languages=LANGUAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1743df60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>year</th>\n",
       "      <th>theme</th>\n",
       "      <th>match_english</th>\n",
       "      <th>match_portuguese</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teórica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teórica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Córnea</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Teórica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Embriologia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Teórica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Farmacologia</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Teórica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Genética</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Teórica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Teórica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Oncologia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Teórica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Refração</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Teórica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Retina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Cirurgia Refrativa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Cirurgia Refrativva</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Córnea</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Córnea/Cristalino</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Estrabismo</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Farmacologia</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Farmacologia/Glaucoma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Glaucoma/Uveíte</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Lentes de Contato</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Neuroftalmologia</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Oncologia/Plástica Ocular</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Plástica Ocular</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Refração</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Refração/Visão subnormal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Retina</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Retina/Oncologia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Uveíte</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Visão subnormal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Óptica</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Teórica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Óptica/Refração</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          test  year                      theme  match_english  \\\n",
       "0    Teórica I  2022                   Anatomia              4   \n",
       "1    Teórica I  2022                     Córnea              1   \n",
       "2    Teórica I  2022                Embriologia              1   \n",
       "3    Teórica I  2022               Farmacologia              2   \n",
       "4    Teórica I  2022                   Genética              0   \n",
       "5    Teórica I  2022                   Glaucoma              1   \n",
       "6    Teórica I  2022                  Oncologia              1   \n",
       "7    Teórica I  2022                   Refração              3   \n",
       "8    Teórica I  2022                     Retina              0   \n",
       "9   Teórica II  2022         Cirurgia Refrativa              1   \n",
       "10  Teórica II  2022        Cirurgia Refrativva              0   \n",
       "11  Teórica II  2022        Cristalino/Catarata              3   \n",
       "12  Teórica II  2022                     Córnea              3   \n",
       "13  Teórica II  2022          Córnea/Cristalino              1   \n",
       "14  Teórica II  2022                 Estrabismo              3   \n",
       "15  Teórica II  2022               Farmacologia              3   \n",
       "16  Teórica II  2022      Farmacologia/Glaucoma              0   \n",
       "17  Teórica II  2022                   Glaucoma              2   \n",
       "18  Teórica II  2022                  Glaucoma               1   \n",
       "19  Teórica II  2022            Glaucoma/Uveíte              0   \n",
       "20  Teórica II  2022          Lentes de Contato              0   \n",
       "21  Teórica II  2022           Neuroftalmologia              0   \n",
       "22  Teórica II  2022  Oncologia/Plástica Ocular              1   \n",
       "23  Teórica II  2022            Plástica Ocular              3   \n",
       "24  Teórica II  2022                   Refração              6   \n",
       "25  Teórica II  2022   Refração/Visão subnormal              0   \n",
       "26  Teórica II  2022                     Retina              6   \n",
       "27  Teórica II  2022           Retina/Oncologia              0   \n",
       "28  Teórica II  2022                     Uveíte              4   \n",
       "29  Teórica II  2022            Visão subnormal              1   \n",
       "30  Teórica II  2022                     Óptica              0   \n",
       "31  Teórica II  2022            Óptica/Refração              1   \n",
       "\n",
       "    match_portuguese  Total  \n",
       "0                  5     21  \n",
       "1                  1      1  \n",
       "2                  1      2  \n",
       "3                  2      3  \n",
       "4                  0      2  \n",
       "5                  0      1  \n",
       "6                  0      1  \n",
       "7                  0     12  \n",
       "8                  0      1  \n",
       "9                  1      1  \n",
       "10                 1      1  \n",
       "11                 5      8  \n",
       "12                 0      9  \n",
       "13                 0      1  \n",
       "14                 3     11  \n",
       "15                 2      6  \n",
       "16                 0      1  \n",
       "17                 3      6  \n",
       "18                 0      2  \n",
       "19                 0      1  \n",
       "20                 0      3  \n",
       "21                 1      7  \n",
       "22                 0      3  \n",
       "23                 4     16  \n",
       "24                 8     19  \n",
       "25                 0      2  \n",
       "26                 2     11  \n",
       "27                 0      1  \n",
       "28                 2      8  \n",
       "29                 1      1  \n",
       "30                 1      1  \n",
       "31                 1      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_REPETITIONS = 1 if N_REPETITIONS < 1 else N_REPETITIONS\n",
    "pd.read_csv(f'results/results_{MODEL}_Temperature{TEMPERATURE}_Repetitions{N_REPETITIONS}/matches_results_{MODEL}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025a628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_bias_vpython=3_8_15]",
   "language": "python",
   "name": "conda-env-nlp_bias_vpython_3_8_15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
