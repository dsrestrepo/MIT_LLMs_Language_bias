{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08cf9338",
   "metadata": {},
   "source": [
    "# Evaluate Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646d3e0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c3f67",
   "metadata": {},
   "source": [
    "#### Load the API key and libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5914d9f9",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from src.Language_Evaluation import llm_language_evaluation\n",
    "from src.data_analysis import run_analysis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6cc1c",
   "metadata": {
    "height": 30
   },
   "source": [
    "#### Load the Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee875ae",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "PATH = 'data/Portuguese.csv'\n",
    "MODEL = \"Llama-2-13b\"\n",
    "TEMPERATURE = 0.7\n",
    "N_REPETITIONS = 10\n",
    "REASONING = False\n",
    "LANGUAGES = ['english', 'portuguese']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded1020",
   "metadata": {},
   "source": [
    "#### Run The Experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa463d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The model file 'Models/Llama-2-13b.gguf' already exists. Do you want to overwrite it? (yes/no):  No\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model installation aborted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from Models/Llama-2-13b.gguf (version GGUF V2 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q8_0     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:             blk.15.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:             blk.15.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.2.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:            blk.2.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.2.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.2.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.2.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:              blk.2.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:         blk.2.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.2.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.2.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.3.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:            blk.3.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.3.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.3.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.3.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:              blk.3.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:         blk.3.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.3.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.3.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.4.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:            blk.4.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.4.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.4.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.4.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:              blk.4.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:         blk.4.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:              blk.4.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:              blk.4.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.5.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:            blk.5.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:            blk.5.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:              blk.5.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:            blk.5.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:              blk.5.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:         blk.5.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:              blk.5.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:              blk.5.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.6.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:            blk.6.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:            blk.6.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:              blk.6.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:            blk.6.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:              blk.6.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:         blk.6.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:              blk.6.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:              blk.6.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:           blk.7.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:            blk.7.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.7.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.7.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:            blk.7.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.7.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:         blk.7.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:              blk.7.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:              blk.7.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.8.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:            blk.8.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:            blk.8.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:              blk.8.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:            blk.8.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:              blk.8.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:         blk.8.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:              blk.8.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:              blk.8.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.9.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:            blk.9.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:            blk.9.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:              blk.9.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:            blk.9.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:              blk.9.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:         blk.9.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:              blk.9.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:              blk.9.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:          blk.15.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:           blk.15.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:        blk.15.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.15.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.16.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.16.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.16.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.16.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:          blk.17.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:           blk.17.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:           blk.17.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:        blk.17.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:             blk.17.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:             blk.17.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.18.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:        blk.18.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:             blk.18.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:             blk.18.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.19.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:        blk.19.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:             blk.19.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:             blk.19.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.20.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:        blk.20.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:             blk.20.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.20.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:          blk.21.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:           blk.21.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:           blk.21.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:             blk.21.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:        blk.21.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:             blk.21.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:             blk.21.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.22.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:        blk.22.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:             blk.22.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.23.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:        blk.23.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:             blk.23.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.24.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:        blk.24.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:             blk.24.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.25.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:        blk.25.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:             blk.25.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:          blk.26.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:           blk.26.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:             blk.26.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:        blk.26.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:             blk.26.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:           blk.27.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:             blk.27.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:        blk.27.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:             blk.27.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.28.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:             blk.28.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:        blk.28.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:             blk.28.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:           blk.29.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:             blk.29.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:        blk.29.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:             blk.29.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:                    output.weight q8_0     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:          blk.32.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  291:           blk.32.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  292:           blk.32.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  293:             blk.32.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  294:           blk.32.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  295:             blk.32.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  296:        blk.32.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  297:             blk.32.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  298:             blk.32.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  299:          blk.33.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  300:           blk.33.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  301:           blk.33.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  302:             blk.33.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  303:           blk.33.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  304:             blk.33.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  305:        blk.33.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  306:             blk.33.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  307:             blk.33.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  308:          blk.34.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  309:           blk.34.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  310:           blk.34.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  311:             blk.34.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  312:           blk.34.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  313:             blk.34.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  314:        blk.34.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  315:             blk.34.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  316:             blk.34.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  317:          blk.35.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  318:           blk.35.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  319:           blk.35.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  320:             blk.35.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  321:           blk.35.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  322:             blk.35.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  323:        blk.35.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  324:             blk.35.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  325:             blk.35.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  326:          blk.36.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  327:           blk.36.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  328:           blk.36.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  329:             blk.36.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  330:           blk.36.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  331:             blk.36.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  332:        blk.36.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  333:             blk.36.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  334:             blk.36.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  335:          blk.37.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  336:           blk.37.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  337:           blk.37.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  338:             blk.37.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  339:           blk.37.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  340:             blk.37.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  341:        blk.37.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  342:             blk.37.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  343:             blk.37.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  344:          blk.38.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  345:           blk.38.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  346:           blk.38.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  347:             blk.38.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  348:           blk.38.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  349:             blk.38.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  350:        blk.38.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  351:             blk.38.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  352:             blk.38.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  353:          blk.39.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  354:           blk.39.ffn_down.weight q8_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  355:           blk.39.ffn_gate.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  356:             blk.39.ffn_up.weight q8_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  357:           blk.39.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  358:             blk.39.attn_k.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  359:        blk.39.attn_output.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  360:             blk.39.attn_q.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  361:             blk.39.attn_v.weight q8_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  362:               output_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                          general.file_type u32     \n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  18:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q8_0:  282 tensors\n",
      "llm_load_print_meta: format           = GGUF V2 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = mostly Q8_0\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 12.88 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name   = LLaMA v2\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.12 MB\n",
      "llm_load_tensors: mem required  = 13189.98 MB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  =  400.00 MB\n",
      "llama_new_context_with_model: compute buffer total size = 80.88 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Question 1: \n",
      "Language: english\n",
      "Question: \n",
      "In which ocular region are caliciform cells physiologically found?\n",
      "a) Cornea.\n",
      "b) Corneoscleral limbus.\n",
      "c) Gray line.\n",
      "d) Semilunar fold.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    27 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3616.50 ms /   200 tokens (   18.08 ms per token,    55.30 tokens per second)\n",
      "llama_print_timings:        eval time =  3135.57 ms /    26 runs   (  120.60 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  6831.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.21 ms /    21 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2546.53 ms /    21 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2606.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.78 ms /    36 runs   (    0.58 ms per token,  1732.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4414.04 ms /    36 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4517.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3271.69 ms /    27 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3348.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.57 ms /     7 runs   (  120.37 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   861.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1727.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2914.70 ms /    24 runs   (  121.45 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2981.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.57 ms /    27 runs   (    0.58 ms per token,  1734.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3254.69 ms /    27 runs   (  120.54 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  3331.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   839.41 ms /     7 runs   (  119.92 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.36 ms /    25 runs   (    0.57 ms per token,  1740.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3032.74 ms /    25 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3103.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    27 runs   (    0.58 ms per token,  1730.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.00 ms /    27 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3375.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Em qual regio ocular clulas caliciformes so fisiologicamente encontradas?\n",
      "a)Crnea.\n",
      "b)Limbo corneoescleral.\n",
      "c)Linha cinzenta.\n",
      "d)Prega semilunar.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.29 ms /    12 runs   (    0.61 ms per token,  1645.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1588.30 ms /    63 tokens (   25.21 ms per token,    39.66 tokens per second)\n",
      "llama_print_timings:        eval time =  1333.49 ms /    11 runs   (  121.23 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2956.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.29 ms /     7 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   873.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.59 ms /     7 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   871.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.61 ms /    36 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4383.94 ms /    36 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4485.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.93 ms /     7 runs   (  123.99 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   886.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.09 ms /     7 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   884.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.46 ms /     7 runs   (  120.49 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   862.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.72 ms /    40 runs   (    0.57 ms per token,  1760.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4887.22 ms /    40 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4999.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.41 ms /    32 runs   (    0.58 ms per token,  1737.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3932.01 ms /    32 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4022.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.93 ms /    12 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1469.63 ms /    12 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1503.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 2: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the alternative that best correlates the histological characteristics with the respective ocular tissues:\n",
      "\n",
      "I. Monolayer of cells tightly joined together by junctional complexes.\n",
      "II. Parallel and regular striations observed under optical microscopy, perpendicular to the epithelium.\n",
      "III. It contains bipolar cells, amacrine cells, horizontal cells and Muller cells.\n",
      "IV. It contains magnocellular, parvocellular and coniocellular cells.\n",
      "\n",
      "A. Photoreceptors.\n",
      "B. Retinal pigmented epithelium.\n",
      "C. Retinal ganglionic layer.\n",
      "D. Inner nuclear layer.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.25 ms /    39 runs   (    0.57 ms per token,  1752.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2497.29 ms /   158 tokens (   15.81 ms per token,    63.27 tokens per second)\n",
      "llama_print_timings:        eval time =  4650.78 ms /    38 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7259.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.13 ms /    39 runs   (    0.57 ms per token,  1762.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4758.35 ms /    39 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4869.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.12 ms /    39 runs   (    0.57 ms per token,  1762.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4763.55 ms /    39 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4875.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    90.25 ms /   157 runs   (    0.57 ms per token,  1739.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19474.11 ms /   157 runs   (  124.04 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 19938.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.40 ms /    39 runs   (    0.57 ms per token,  1741.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4822.94 ms /    39 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4934.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.70 ms /   145 runs   (    0.58 ms per token,  1732.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17839.76 ms /   145 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18267.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n",
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.12 ms /    96 runs   (    0.58 ms per token,  1710.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11788.21 ms /    96 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 12068.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.61 ms /   107 runs   (    0.58 ms per token,  1736.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13165.58 ms /   107 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 13523.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.20 ms /    39 runs   (    0.57 ms per token,  1756.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4757.38 ms /    39 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4869.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.91 ms /    58 runs   (    0.58 ms per token,  1710.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7219.95 ms /    58 runs   (  124.48 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  7388.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que melhor correlaciona as caractersticas histolgicas com os respectivos tecidos oculares:\n",
      "\n",
      "I. Monocamada de clulas fortemente unidas por complexos juncionais.\n",
      "II. Estriaes paralelas e regulares observadas  microscopia ptica, perpendiculares ao epitlio.\n",
      "III. Contm clulas bipolares, clulas amcrinas, clulas horizontais e clulas de Muller.\n",
      "IV. Contm clulas magnocelulares, parvocelulares e coniocelulares.\n",
      "\n",
      "A. Fotorreceptores.\n",
      "B. Epitlio pigmentado da pigmentado da retina.\n",
      "C. Camada ganglionar retiniana.\n",
      "D. Camada nuclear interna.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.37 ms /    64 runs   (    0.58 ms per token,  1712.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3810.76 ms /   196 tokens (   19.44 ms per token,    51.43 tokens per second)\n",
      "llama_print_timings:        eval time =  7840.10 ms /    63 runs   (  124.45 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 11838.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.53 ms /     7 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    99.05 ms /   171 runs   (    0.58 ms per token,  1726.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21104.02 ms /   171 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 21617.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.37 ms /    11 runs   (    0.58 ms per token,  1727.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1346.01 ms /    11 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1377.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.84 ms /    94 runs   (    0.58 ms per token,  1713.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11621.04 ms /    94 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 11900.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.91 ms /   125 runs   (    0.58 ms per token,  1714.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15410.08 ms /   125 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 15782.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1729.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.08 ms /     7 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.48 ms /    41 runs   (    0.57 ms per token,  1746.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5012.41 ms /    41 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5129.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3474.30 ms /    28 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3554.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.60 ms /     7 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   876.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 3: \n",
      "Language: english\n",
      "Question: \n",
      "Order the three cell names found in the corneal epithelium, starting with the most superficial, followed by the intermediate and the deep.\n",
      "a) Flat, wing, basal.\n",
      "b) wing, basal, flat.\n",
      "c) Basal, flat, wing.\n",
      "d) wing, flat, basal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    25 runs   (    0.56 ms per token,  1797.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1570.68 ms /    79 tokens (   19.88 ms per token,    50.30 tokens per second)\n",
      "llama_print_timings:        eval time =  2926.28 ms /    24 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4569.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.98 ms /    73 runs   (    0.58 ms per token,  1738.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8837.59 ms /    73 runs   (  121.06 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  9051.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.54 ms /    68 runs   (    0.57 ms per token,  1764.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8282.72 ms /    68 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  8480.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.48 ms /    33 runs   (    0.56 ms per token,  1785.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4087.59 ms /    33 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4181.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    25 runs   (    0.55 ms per token,  1819.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3035.80 ms /    25 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3105.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.67 ms /    25 runs   (    0.55 ms per token,  1829.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3034.73 ms /    25 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3105.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.80 ms /    36 runs   (    0.55 ms per token,  1818.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4339.93 ms /    36 runs   (  120.55 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  4442.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.48 ms /    35 runs   (    0.56 ms per token,  1796.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4255.24 ms /    35 runs   (  121.58 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4354.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.54 ms /    25 runs   (    0.54 ms per token,  1846.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3064.23 ms /    25 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3133.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.40 ms /    35 runs   (    0.55 ms per token,  1804.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4340.52 ms /    35 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  4442.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Ordene as trs denominaes celulares encontradas no epitlio da crnea, iniciando pelo mais superficial, seguido do intermedirio e do profundo.\n",
      "a)Plana, alada, basal.\n",
      "b)Alada, basal, plana.\n",
      "c)Basal, plana, alada.\n",
      "d)Alada, plana, basal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.33 ms /    82 runs   (    0.58 ms per token,  1732.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1581.18 ms /    96 tokens (   16.47 ms per token,    60.71 tokens per second)\n",
      "llama_print_timings:        eval time =  9911.43 ms /    81 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 11733.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.90 ms /    37 runs   (    0.56 ms per token,  1770.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4457.60 ms /    37 runs   (  120.48 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  4562.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.86 ms /    28 runs   (    0.57 ms per token,  1765.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3393.68 ms /    28 runs   (  121.20 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3473.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.21 ms /    20 runs   (    0.56 ms per token,  1783.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2453.50 ms /    20 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2509.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.01 ms /    30 runs   (    0.57 ms per token,  1763.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3660.43 ms /    30 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3744.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.42 ms /    36 runs   (    0.57 ms per token,  1762.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4434.41 ms /    36 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4537.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.77 ms /    94 runs   (    0.57 ms per token,  1748.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11485.01 ms /    94 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 11756.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.36 ms /    20 runs   (    0.57 ms per token,  1761.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2452.06 ms /    20 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2508.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.56 ms /    29 runs   (    0.57 ms per token,  1751.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3527.72 ms /    29 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3609.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   125.03 ms /   217 runs   (    0.58 ms per token,  1735.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26535.61 ms /   217 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 27188.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 4: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding Descemet's membrane of the cornea, it is correct to state:\n",
      "a) Endothelial cells do not participate in its formation.\n",
      "b) Its thickness in the adult is about 30 m.\n",
      "c) Its most anterior portion is of embryonic origin.\n",
      "d) Its thickness reduces with age.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.43 ms /    24 runs   (    0.60 ms per token,  1663.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1910.71 ms /    83 tokens (   23.02 ms per token,    43.44 tokens per second)\n",
      "llama_print_timings:        eval time =  2801.20 ms /    23 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4782.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.02 ms /    40 runs   (    0.58 ms per token,  1737.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4846.27 ms /    40 runs   (  121.16 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4960.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.95 ms /    68 runs   (    0.57 ms per token,  1745.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8226.88 ms /    68 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  8423.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.35 ms /    25 runs   (    0.57 ms per token,  1742.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3064.12 ms /    25 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3135.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.49 ms /    48 runs   (    0.57 ms per token,  1745.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5834.93 ms /    48 runs   (  121.56 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5971.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.83 ms /    17 runs   (    0.58 ms per token,  1729.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2071.06 ms /    17 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2119.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.63 ms /    29 runs   (    0.57 ms per token,  1744.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3533.33 ms /    29 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3615.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.77 ms /    24 runs   (    0.57 ms per token,  1743.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2898.96 ms /    24 runs   (  120.79 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2967.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.43 ms /    48 runs   (    0.57 ms per token,  1749.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5887.82 ms /    48 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6024.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.02 ms /    40 runs   (    0.58 ms per token,  1737.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4855.83 ms /    40 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4970.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a membrana de Descemet da crnea,  correto afirmar:\n",
      "a)As clulas endoteliais no participam da sua formao.\n",
      "b)Sua espessura no adulto  de cerca de 30 m.\n",
      "c)Sua poro mais anterior  de origem embrionria.\n",
      "d)Sua espessura reduz-se com a idade.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.46 ms /     6 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1845.33 ms /   103 tokens (   17.92 ms per token,    55.82 tokens per second)\n",
      "llama_print_timings:        eval time =   660.78 ms /     5 runs   (  132.16 ms per token,     7.57 tokens per second)\n",
      "llama_print_timings:       total time =  2523.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {:response:\"A\"}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.63 ms /    58 runs   (    0.58 ms per token,  1724.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7099.03 ms /    58 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7269.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.94 ms /     7 runs   (    0.56 ms per token,  1774.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.96 ms /     7 runs   (  120.28 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   861.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   122.16 ms /   211 runs   (    0.58 ms per token,  1727.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25872.20 ms /   211 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 26513.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.92 ms /     7 runs   (    0.56 ms per token,  1787.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.08 ms /     7 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   871.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1765.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.96 ms /     7 runs   (  119.85 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.90 ms /     7 runs   (    0.56 ms per token,  1794.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.55 ms /     7 runs   (  119.79 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =   857.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.91 ms /     7 runs   (    0.56 ms per token,  1791.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.36 ms /     7 runs   (  121.34 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.87 ms /     7 runs   (    0.55 ms per token,  1806.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.68 ms /     7 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   875.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.89 ms /     7 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.26 ms /     7 runs   (  120.75 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   864.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.04 ms /    59 runs   (    0.58 ms per token,  1733.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7162.53 ms /    59 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  7332.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 5: \n",
      "Language: english\n",
      "Question: \n",
      "About the lipidic layer of the lacrimal film, choose the right answer. a) its purpose is to stabilize the lacrimal film secreted by the meibomian and manz glans b) Cholesterol esters are within its components, and one of the functions is to delay the lacrimal film evaporation c) In meibomian gland dysfunction, the fusion point decrease, leading to stagnation d) can be evaluated by the lacrimal film break up time, keeping intact less than five seconds in healthy eyes.\n",
      "Test #0: \n",
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.05 ms /    64 runs   (    0.58 ms per token,  1727.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2549.81 ms /   129 tokens (   19.77 ms per token,    50.59 tokens per second)\n",
      "llama_print_timings:        eval time =  7778.50 ms /    63 runs   (  123.47 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10514.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.87 ms /    64 runs   (    0.58 ms per token,  1735.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7789.21 ms /    64 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7973.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.51 ms /    77 runs   (    0.64 ms per token,  1555.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9542.95 ms /    77 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  9776.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.22 ms /    60 runs   (    0.64 ms per token,  1569.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7390.86 ms /    60 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7573.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.80 ms /    61 runs   (    0.67 ms per token,  1495.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7435.95 ms /    61 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  7624.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.20 ms /    61 runs   (    0.68 ms per token,  1480.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7424.91 ms /    61 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7619.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.67 ms /   107 runs   (    0.60 ms per token,  1654.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13093.62 ms /   107 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 13417.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n",
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.33 ms /    61 runs   (    0.58 ms per token,  1726.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7512.68 ms /    61 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7688.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.84 ms /    17 runs   (    0.58 ms per token,  1727.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2082.93 ms /    17 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2132.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.22 ms /    61 runs   (    0.58 ms per token,  1731.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7493.10 ms /    61 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7671.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a camada lipdica do filme lacrimal, assinale a alternativa correta. a)Tem por propsito bsico estabilizar o filme e  secretada pelas glndulas de Meibomius e de Manz.  b)steres de colesterol esto entre seus componentes e uma de suas funes  retardar a evaporao do filme lacrimal. c)Na disfuno das glndulas de Meibomius, o ponto de fuso de sua secreo diminui, colaborando para a estagnao dessas substncias. d)Pode ser avaliada pelo tempo de ruptura do filme lacrimal, permanecendo intacta por menos de cinco segundos em olhos saudveis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.16 ms /     7 runs   (    0.59 ms per token,  1681.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3175.39 ms /   183 tokens (   17.35 ms per token,    57.63 tokens per second)\n",
      "llama_print_timings:        eval time =   733.49 ms /     6 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3929.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.94 ms /    31 runs   (    0.58 ms per token,  1728.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3815.52 ms /    31 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3905.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1699.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.29 ms /     7 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   876.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1701.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.69 ms /     7 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   878.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.06 ms /     7 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   885.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    99.79 ms /   165 runs   (    0.60 ms per token,  1653.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20399.58 ms /   165 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 21102.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.51 ms /     7 runs   (    0.64 ms per token,  1550.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.19 ms /     7 runs   (  120.60 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   891.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.40 ms /     7 runs   (    0.63 ms per token,  1590.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.49 ms /     7 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   901.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   119.55 ms /   184 runs   (    0.65 ms per token,  1539.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22588.27 ms /   184 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 23874.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 6: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the external ocular muscles, choose the correct answer. a) in the Hering's law, the innervation is equally distributed to the agosist and antagonist muscles, for a given ocular version. b) The persecutory movements will automatically occur, slowly, with the displacement of the fixation point c) In the sherrington's law, the contraction stimulus is distributed between the agonists of both eyes, so that it occur symmetrically. d) Saccadic movements are characterized by abrupq, uncoordinated, reflex movments.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.49 ms /     7 runs   (    0.64 ms per token,  1559.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.96 ms /     7 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   897.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   149.36 ms /   230 runs   (    0.65 ms per token,  1539.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2621.36 ms /   137 tokens (   19.13 ms per token,    52.26 tokens per second)\n",
      "llama_print_timings:        eval time = 28294.96 ms /   229 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 32550.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.74 ms /    80 runs   (    0.66 ms per token,  1516.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9755.98 ms /    80 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 10301.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.09 ms /   111 runs   (    0.66 ms per token,  1518.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13669.01 ms /   111 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 14430.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.80 ms /    78 runs   (    0.65 ms per token,  1535.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9609.65 ms /    78 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 10139.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.68 ms /    24 runs   (    0.65 ms per token,  1531.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2929.95 ms /    24 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3090.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    71.19 ms /   109 runs   (    0.65 ms per token,  1531.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13429.68 ms /   109 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 14176.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.26 ms /    70 runs   (    0.58 ms per token,  1738.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8634.25 ms /    70 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  8836.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.01 ms /    83 runs   (    0.58 ms per token,  1728.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10253.03 ms /    83 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10497.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.48 ms /    70 runs   (    0.58 ms per token,  1729.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8662.86 ms /    70 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  8870.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.11 ms /    66 runs   (    0.58 ms per token,  1731.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8137.51 ms /    66 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  8329.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre os msculos oculares externos, assinale a alternativa correta.\n",
      "a)Na lei de Hering, a inervao se distribui igualmente para os msculos agonista e antagonista, para determinada verso.\n",
      "b)Os movimentos persecutrios se do automaticamente, de maneira lenta, ao deslocamento do ponto de fixao.\n",
      "c)Na lei de Sherrington, o estmulo de contrao  distribudo entre os agonistas de ambos os olhos, para que ela ocorra simetricamente.\n",
      "d)Os movimentos sacdicos so caracterizados por movimentos bruscos, descoordenados, de natureza totalmente reflexa.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.18 ms /     7 runs   (    0.60 ms per token,  1673.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3749.31 ms /   178 tokens (   21.06 ms per token,    47.48 tokens per second)\n",
      "llama_print_timings:        eval time =   733.47 ms /     6 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4503.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.12 ms /    47 runs   (    0.58 ms per token,  1733.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5802.17 ms /    47 runs   (  123.45 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  5938.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.55 ms /    79 runs   (    0.58 ms per token,  1734.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9760.49 ms /    79 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  9990.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.69 ms /    75 runs   (    0.58 ms per token,  1716.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9216.05 ms /    75 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  9433.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.81 ms /    64 runs   (    0.58 ms per token,  1738.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7867.78 ms /    64 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8052.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Os movimentos sacdicos so caracterizados por movimentos bruscos, descoordenados, de natureza totalmente reflexa.'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.58 ms /    67 runs   (    0.58 ms per token,  1736.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8314.18 ms /    67 runs   (  124.09 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  8508.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.18 ms /    47 runs   (    0.58 ms per token,  1729.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5971.68 ms /    47 runs   (  127.06 ms per token,     7.87 tokens per second)\n",
      "llama_print_timings:       total time =  6109.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.33 ms /   134 runs   (    0.58 ms per token,  1732.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16516.48 ms /   134 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16917.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.93 ms /    60 runs   (    0.58 ms per token,  1717.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7458.84 ms /    60 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  7634.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.09 ms /    76 runs   (    0.58 ms per token,  1723.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9423.94 ms /    76 runs   (  124.00 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  9647.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 7: \n",
      "Language: english\n",
      "Question: \n",
      "About the cornea, it is correct to state. a) The arrangement of corneal collagen fibrils is unrelated to its transparency. b) Pleomorphism of endothelial cells is characterized by the variation in the size of these cells. c) anterior stroma have a large number of mitochondria, responsible for the production of energy that supplies the endothelial pump. d) The endothelium behaves as a permeable non-selective barrier between the aqueous humor and the substantia propria.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.36 ms /    64 runs   (    0.58 ms per token,  1713.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2195.79 ms /   127 tokens (   17.29 ms per token,    57.84 tokens per second)\n",
      "llama_print_timings:        eval time =  7805.51 ms /    63 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 10191.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    96.07 ms /   166 runs   (    0.58 ms per token,  1727.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20475.54 ms /   166 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 20977.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.14 ms /    71 runs   (    0.58 ms per token,  1725.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8649.83 ms /    71 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  8856.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.20 ms /    71 runs   (    0.58 ms per token,  1723.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8787.49 ms /    71 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  8994.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.73 ms /   114 runs   (    0.58 ms per token,  1734.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14059.90 ms /   114 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 14399.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.17 ms /    49 runs   (    0.57 ms per token,  1739.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5977.31 ms /    49 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  6116.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.77 ms /   114 runs   (    0.58 ms per token,  1733.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14132.52 ms /   114 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 14462.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.44 ms /    80 runs   (    0.58 ms per token,  1722.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9852.26 ms /    80 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 10083.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.74 ms /    67 runs   (    0.58 ms per token,  1729.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8181.00 ms /    67 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8373.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.52 ms /    48 runs   (    0.59 ms per token,  1682.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5894.02 ms /    48 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6032.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a crnea,  correto afirmar:\n",
      "a)A disposio das fibrilas de colgeno corneanas no tem relao com a sua transparncia.\n",
      "b)Pleomorfismo das clulas endoteliais  caracterizado pela variao do tamanho dessas clulas.\n",
      "c)As clulas do estroma anterior possuem grande quantidade de mitocndrias, responsveis pela produo de energia que supre a bomba endotelial.\n",
      "d)O endotlio comporta-se como uma barreira permevel no-seletiva entre o humor aquoso e a substncia prpria.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.17 ms /     7 runs   (    0.60 ms per token,  1678.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3194.99 ms /   162 tokens (   19.72 ms per token,    50.70 tokens per second)\n",
      "llama_print_timings:        eval time =   724.85 ms /     6 runs   (  120.81 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3939.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.37 ms /    11 runs   (    0.58 ms per token,  1728.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1362.66 ms /    11 runs   (  123.88 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  1393.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.31 ms /    59 runs   (    0.58 ms per token,  1719.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7284.00 ms /    59 runs   (  123.46 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  7455.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.04 ms /    71 runs   (    0.61 ms per token,  1649.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8736.65 ms /    71 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8943.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.85 ms /   205 runs   (    0.58 ms per token,  1724.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25335.50 ms /   205 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 25947.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.67 ms /    27 runs   (    0.58 ms per token,  1722.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3308.67 ms /    27 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3385.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1722.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.38 ms /     7 runs   (  121.77 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1716.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.49 ms /     7 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.37 ms /     7 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.39 ms /    56 runs   (    0.60 ms per token,  1677.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6933.32 ms /    56 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  7096.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 8: \n",
      "Language: english\n",
      "Question: \n",
      "Choose the alternative that correctly fills in the gaps. Levocycloversion corresponds to ____________ of the right eye and ________ of the left eye and is triggered when the head is tilted towards the shoulder___________.\n",
      "a) Excicloduction / incicloduction / left.\n",
      "b) Incicloduction / excicloduction / left.\n",
      "c) Excicloduction / incicloduction / law.\n",
      "d) Incicloduction / excicloduction / right.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.32 ms /    24 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2296.37 ms /   126 tokens (   18.23 ms per token,    54.87 tokens per second)\n",
      "llama_print_timings:        eval time =  2796.27 ms /    23 runs   (  121.58 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5161.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.44 ms /   106 runs   (    0.57 ms per token,  1753.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13097.26 ms /   106 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 13406.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.17 ms /    24 runs   (    0.55 ms per token,  1822.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2935.57 ms /    24 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3003.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.27 ms /    24 runs   (    0.55 ms per token,  1808.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2947.81 ms /    24 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3015.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.62 ms /    81 runs   (    0.56 ms per token,  1775.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9945.26 ms /    81 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10178.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.85 ms /    29 runs   (    0.55 ms per token,  1829.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3622.06 ms /    29 runs   (  124.90 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3703.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.00 ms /    77 runs   (    0.57 ms per token,  1750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9527.89 ms /    77 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  9751.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.16 ms /    24 runs   (    0.55 ms per token,  1824.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2913.62 ms /    24 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2980.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.48 ms /    82 runs   (    0.57 ms per token,  1764.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10204.14 ms /    82 runs   (  124.44 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 10439.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.22 ms /    24 runs   (    0.55 ms per token,  1815.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2935.60 ms /    24 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3002.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que preenche corretamente as lacunas. A levocicloverso corresponde a ____________ do olho direito e ________ do olho esquerdo e  desencadeada quando se inclina a cabea para o ombro___________.\n",
      "a)Excicloduo / incicloduo / esquerdo.\n",
      "b)Incicloduo / excicloduo / esquerdo.\n",
      "c)Excicloduo / incicloduo / direito.\n",
      "d)Incicloduo / excicloduo / direito.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.45 ms /    27 runs   (    0.57 ms per token,  1747.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3044.48 ms /   149 tokens (   20.43 ms per token,    48.94 tokens per second)\n",
      "llama_print_timings:        eval time =  3210.35 ms /    26 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6331.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.12 ms /    27 runs   (    0.56 ms per token,  1785.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3334.43 ms /    27 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3410.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.38 ms /   146 runs   (    0.57 ms per token,  1750.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18098.22 ms /   146 runs   (  123.96 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 18528.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.13 ms /    27 runs   (    0.56 ms per token,  1784.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3307.43 ms /    27 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3384.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.36 ms /    24 runs   (    0.56 ms per token,  1796.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2960.15 ms /    24 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3027.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.51 ms /    73 runs   (    0.57 ms per token,  1758.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9002.82 ms /    73 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9212.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.26 ms /    52 runs   (    0.56 ms per token,  1777.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6385.12 ms /    52 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6533.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.77 ms /    28 runs   (    0.56 ms per token,  1775.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3488.17 ms /    28 runs   (  124.58 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3567.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.28 ms /    24 runs   (    0.55 ms per token,  1806.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2967.98 ms /    24 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3034.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.17 ms /    27 runs   (    0.56 ms per token,  1779.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3329.31 ms /    27 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3405.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 9: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the vitreous body cells, mark the correct alternative.\n",
      "a) They are more numerous in the adult than in the embryonic vitreous.\n",
      "b) They are mainly represented by lymphocytes and mature neutrophils.\n",
      "c) They are abundant in the region of the vitreous base.\n",
      "d) They are absent in the newborn.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.53 ms /    25 runs   (    0.58 ms per token,  1720.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1685.17 ms /    87 tokens (   19.37 ms per token,    51.63 tokens per second)\n",
      "llama_print_timings:        eval time =  2929.94 ms /    24 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4686.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.88 ms /    17 runs   (    0.58 ms per token,  1720.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2089.15 ms /    17 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2136.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1742.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2936.98 ms /    24 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3004.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.98 ms /    24 runs   (    0.58 ms per token,  1716.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2970.94 ms /    24 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3039.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.91 ms /    68 runs   (    0.60 ms per token,  1662.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8363.16 ms /    68 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8563.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2926.64 ms /    24 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2994.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.21 ms /    25 runs   (    0.69 ms per token,  1452.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3072.85 ms /    25 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3149.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1733.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2940.45 ms /    24 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3007.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.26 ms /    70 runs   (    0.58 ms per token,  1738.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8608.95 ms /    70 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8809.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1740.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3029.39 ms /    25 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3099.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao s clulas do corpo vtreo, assinale a alternativa correta.\n",
      "a)So mais numerosos no adulto, comparativamente s do vtreo embrionrio.\n",
      "b)So representadas principalmente por linfcitos e neutrfilos maduros.\n",
      "c)So abundantes na regio da base vtrea.\n",
      "d)Esto ausentes no recm-nascido.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.30 ms /    39 runs   (    0.57 ms per token,  1749.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2273.65 ms /   108 tokens (   21.05 ms per token,    47.50 tokens per second)\n",
      "llama_print_timings:        eval time =  4643.97 ms /    38 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7029.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.43 ms /    46 runs   (    0.57 ms per token,  1740.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5672.74 ms /    46 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5803.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.71 ms /    71 runs   (    0.57 ms per token,  1743.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8766.15 ms /    71 runs   (  123.47 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8974.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.73 ms /    55 runs   (    0.58 ms per token,  1733.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6757.21 ms /    55 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6916.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.38 ms /    39 runs   (    0.57 ms per token,  1742.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4810.59 ms /    39 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4921.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.68 ms /     7 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.83 ms /    19 runs   (    0.57 ms per token,  1755.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2322.25 ms /    19 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2375.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.50 ms /     7 runs   (  124.36 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   889.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.95 ms /    40 runs   (    0.57 ms per token,  1742.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4900.92 ms /    40 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5014.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.55 ms /     7 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   873.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 10: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the physiology of the oculomotor muscles, mark the correct alternative.\n",
      "a) Muscle contraction is independent of calcium availability.\n",
      "b) The muscle fiber is a multinucleated cell.\n",
      "c) Each muscle contraction is the result of a unique cycle of formation and destruction of actin-myosin bridges.\n",
      "d) Muscle relaxation rely mainly on sodium availability.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.85 ms /   108 runs   (    0.58 ms per token,  1718.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2470.22 ms /   102 tokens (   24.22 ms per token,    41.29 tokens per second)\n",
      "llama_print_timings:        eval time = 13088.83 ms /   107 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 15879.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.96 ms /    24 runs   (    0.58 ms per token,  1719.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2935.44 ms /    24 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3003.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.08 ms /    28 runs   (    0.57 ms per token,  1741.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3416.99 ms /    28 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3496.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1724.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3508.98 ms /    28 runs   (  125.32 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  3590.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.46 ms /    24 runs   (    0.60 ms per token,  1659.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2963.82 ms /    24 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3034.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.62 ms /    27 runs   (    0.58 ms per token,  1728.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3307.06 ms /    27 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3385.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.76 ms /    95 runs   (    0.58 ms per token,  1734.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11606.88 ms /    95 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 11883.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   130.76 ms /   227 runs   (    0.58 ms per token,  1736.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27911.05 ms /   227 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 28606.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.62 ms /    27 runs   (    0.58 ms per token,  1728.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3322.58 ms /    27 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3399.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1733.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3262.30 ms /    27 runs   (  120.83 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3338.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao  fisiologia dos msculos oculomotores, assinale a alternativa correta.\n",
      "a)A contrao muscular independe da disponibilidade de clcio.\n",
      "b)A fibra muscular  uma clula multinucleada.\n",
      "c)Cada contrao muscular  resultado de um ciclo nico de formao e destruio de pontes de actina-miosina.\n",
      "d)O relaxamento muscular depende principalmente da disponibilidade de sdio.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.05 ms /   151 runs   (    0.60 ms per token,  1658.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2680.24 ms /   123 tokens (   21.79 ms per token,    45.89 tokens per second)\n",
      "llama_print_timings:        eval time = 18594.87 ms /   150 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 21742.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.19 ms /    28 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3426.08 ms /    28 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3506.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.62 ms /    51 runs   (    0.58 ms per token,  1721.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6211.57 ms /    51 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6360.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.46 ms /    20 runs   (    0.57 ms per token,  1745.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2463.20 ms /    20 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2521.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.27 ms /    68 runs   (    0.58 ms per token,  1731.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8428.59 ms /    68 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  8629.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.85 ms /    55 runs   (    0.58 ms per token,  1726.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6783.64 ms /    55 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  6946.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1735.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3444.84 ms /    28 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3525.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.35 ms /    58 runs   (    0.58 ms per token,  1739.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7254.94 ms /    58 runs   (  125.09 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  7423.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.73 ms /    27 runs   (    0.58 ms per token,  1716.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3336.78 ms /    27 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3415.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.45 ms /    58 runs   (    0.58 ms per token,  1733.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7150.27 ms /    58 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  7317.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 11: \n",
      "Language: english\n",
      "Question: \n",
      "With regard to the lens, mark the correct alternative.\n",
      "a) Although its volume increases with age, its weight remains constant.\n",
      "b) The proteolysis of its fibers is the main mechanism of its cellular growth.\n",
      "c) The synthesis of its proteins takes place during the differentiation of the cell into fiber.\n",
      "d) Its protein synthesis is continuous throughout life, maintaining stable plasticity and elasticity from childhood to aging.\n",
      " \n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.60 ms /    27 runs   (    0.61 ms per token,  1626.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2194.06 ms /   107 tokens (   20.51 ms per token,    48.77 tokens per second)\n",
      "llama_print_timings:        eval time =  3274.80 ms /    26 runs   (  125.95 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  5549.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.12 ms /    24 runs   (    0.59 ms per token,  1699.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2920.42 ms /    24 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2989.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.00 ms /    62 runs   (    0.58 ms per token,  1722.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7567.03 ms /    62 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7748.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.52 ms /    25 runs   (    0.58 ms per token,  1721.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3019.69 ms /    25 runs   (  120.79 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3091.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.96 ms /    51 runs   (    0.59 ms per token,  1702.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6322.56 ms /    51 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6473.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Its protein synthesis is continuous throughout life, maintaining stable plasticity and elasticity from childhood to aging.'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.44 ms /    49 runs   (    0.58 ms per token,  1722.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6064.98 ms /    49 runs   (  123.78 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6209.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1734.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3445.85 ms /    28 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3526.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.62 ms /    62 runs   (    0.57 ms per token,  1740.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7558.84 ms /    62 runs   (  121.92 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  7739.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3416.80 ms /    28 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3497.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.35 ms /    49 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6022.40 ms /    49 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6166.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao ao cristalino, assinale a alternativa correta.\n",
      "a)Embora seu volume aumente com a idade, seu peso mantm-se constante.\n",
      "b)A protelise de suas fibras  o principal mecanismo de seu crescimento celular.\n",
      "c)A sntese de suas protenas processa-se durante a diferenciao da clula em fibra.\n",
      "d)Sua sntese proteica  continua ao longo da vida, mantendo plasticidade e elasticidade estveis da infncia ao envelhecimento.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.33 ms /    27 runs   (    0.60 ms per token,  1653.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2402.68 ms /   141 tokens (   17.04 ms per token,    58.68 tokens per second)\n",
      "llama_print_timings:        eval time =  3232.61 ms /    26 runs   (  124.33 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  5718.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1664.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.56 ms /     7 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.78 ms /    27 runs   (    0.58 ms per token,  1711.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3309.92 ms /    27 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3388.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.96 ms /   145 runs   (    0.58 ms per token,  1727.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17837.79 ms /   145 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18275.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.67 ms /    53 runs   (    0.58 ms per token,  1727.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6508.33 ms /    53 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6661.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.06 ms /    33 runs   (    0.58 ms per token,  1731.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4029.23 ms /    33 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4123.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1741.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3389.38 ms /    27 runs   (  125.53 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  3466.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   130.55 ms /   226 runs   (    0.58 ms per token,  1731.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27929.94 ms /   226 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 28617.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.62 ms /    70 runs   (    0.58 ms per token,  1723.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8634.03 ms /    70 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  8835.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.94 ms /    55 runs   (    0.58 ms per token,  1721.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6724.74 ms /    55 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  6881.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 12: \n",
      "Language: english\n",
      "Question: \n",
      "A patient with arthrosis has been using high doses of chloroquine for years. It is believed that this drug can cause malfunction of the retinal pigment epithelium, since:\n",
      "a) It hinders the synthesis of melanin.\n",
      "b) It hinders phagocytosis of the disks of the photoreceptor outer segments.\n",
      "c) It hinders the transport of intracellular ions.\n",
      "d) It favors intense heat exchange between the photoreceptors and the choroid.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.62 ms /    25 runs   (    0.58 ms per token,  1710.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2732.51 ms /   130 tokens (   21.02 ms per token,    47.58 tokens per second)\n",
      "llama_print_timings:        eval time =  2976.83 ms /    24 runs   (  124.03 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  5781.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.61 ms /    25 runs   (    0.58 ms per token,  1711.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3043.66 ms /    25 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3115.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.28 ms /    28 runs   (    0.58 ms per token,  1719.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3419.61 ms /    28 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3499.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    76.27 ms /   132 runs   (    0.58 ms per token,  1730.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16284.15 ms /   132 runs   (  123.36 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16670.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.12 ms /    97 runs   (    0.58 ms per token,  1728.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11959.31 ms /    97 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 12240.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.94 ms /    24 runs   (    0.58 ms per token,  1721.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2946.55 ms /    24 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3014.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   102.19 ms /   170 runs   (    0.60 ms per token,  1663.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20860.53 ms /   170 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 21373.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.58 ms /    50 runs   (    0.57 ms per token,  1749.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6093.06 ms /    50 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6234.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.80 ms /    24 runs   (    0.58 ms per token,  1738.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2950.30 ms /    24 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3018.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.29 ms /    80 runs   (    0.58 ms per token,  1728.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9752.26 ms /    80 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  9982.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente com artrose faz uso de altas doses de cloroquina h anos. Acredita-se que essa droga pode causar mau funcionamento do epitlio pigmentar retiniano, uma vez que:\n",
      "a)Impede a sntese de melanina.\n",
      "b)Impede a fagocitose dos discos dos segmentos externos dos fotorreceptores.\n",
      "c)Impede o transporte de ons intracelulares.\n",
      "d)Favorece a intensa troca de calor entre os fotorreceptores e a coroide.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    70.21 ms /   120 runs   (    0.59 ms per token,  1709.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2651.00 ms /   143 tokens (   18.54 ms per token,    53.94 tokens per second)\n",
      "llama_print_timings:        eval time = 14661.60 ms /   119 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 17668.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.79 ms /   144 runs   (    0.58 ms per token,  1718.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17783.50 ms /   144 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 18213.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.31 ms /   116 runs   (    0.59 ms per token,  1698.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14396.72 ms /   116 runs   (  124.11 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 14741.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.05 ms /   113 runs   (    0.58 ms per token,  1737.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13906.52 ms /   113 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 14237.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.36 ms /     7 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.28 ms /     7 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   874.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.41 ms /   113 runs   (    0.58 ms per token,  1727.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14007.31 ms /   113 runs   (  123.96 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 14346.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.68 ms /    86 runs   (    0.58 ms per token,  1731.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10566.23 ms /    86 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10815.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   111.82 ms /   193 runs   (    0.58 ms per token,  1725.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23788.81 ms /   193 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 24371.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    70.19 ms /   121 runs   (    0.58 ms per token,  1723.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14833.27 ms /   121 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 15193.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 13: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the blood flow in the choroid, it is possible to state:\n",
      "a) It is responsible for all nutrition of the retina.\n",
      "b) It is responsible for 95% of the glucose consumed in the inner part of the retina.\n",
      "c)Participates in the thermal regulation of photoreceptors.\n",
      "d) The pre-capillary sphincters prevent the hyperflow of blood in noble areas such as the macula.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.24 ms /    24 runs   (    0.59 ms per token,  1685.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2294.83 ms /   110 tokens (   20.86 ms per token,    47.93 tokens per second)\n",
      "llama_print_timings:        eval time =  2815.82 ms /    23 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5180.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1725.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3525.06 ms /    28 runs   (  125.90 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  3605.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.49 ms /    32 runs   (    0.58 ms per token,  1730.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3927.81 ms /    32 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4019.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1727.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2948.10 ms /    24 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3016.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.46 ms /    25 runs   (    0.58 ms per token,  1728.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3079.36 ms /    25 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3151.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.99 ms /    24 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2941.59 ms /    24 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3010.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1723.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3030.35 ms /    25 runs   (  121.21 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3101.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    24 runs   (    0.58 ms per token,  1725.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2932.06 ms /    24 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3000.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.97 ms /    24 runs   (    0.58 ms per token,  1718.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2932.26 ms /    24 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3000.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao ao fluxo sanguneo na coroide, podemos afirmar:\n",
      "a) responsvel por toda nutrio da retina.\n",
      "b) responsvel por 95% da glicose consumida na parte interna da retina.\n",
      "c)Participa da regulao trmica dos fotorreceptores.\n",
      "d)Os esfncteres pr-capilares previnem o hiperfluxo de sangue em reas nobres como a mcula.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1722.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3052.40 ms /    25 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3123.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1687.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2284.93 ms /   124 tokens (   18.43 ms per token,    54.27 tokens per second)\n",
      "llama_print_timings:        eval time =   748.43 ms /     6 runs   (  124.74 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3053.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.23 ms /     9 runs   (    0.58 ms per token,  1720.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1121.82 ms /     9 runs   (  124.65 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  1147.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.28 ms /    28 runs   (    0.58 ms per token,  1719.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3440.82 ms /    28 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3520.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.66 ms /    47 runs   (    0.61 ms per token,  1640.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5761.17 ms /    47 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5899.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    86.70 ms /   126 runs   (    0.69 ms per token,  1453.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15397.24 ms /   126 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 15810.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.64 ms /    28 runs   (    0.63 ms per token,  1587.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3431.34 ms /    28 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3515.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.50 ms /    24 runs   (    0.60 ms per token,  1655.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2977.50 ms /    24 runs   (  124.06 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3047.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.10 ms /    24 runs   (    0.59 ms per token,  1702.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.08 ms /    24 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2984.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.86 ms /    27 runs   (    0.59 ms per token,  1702.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3273.69 ms /    27 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3352.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.96 ms /    27 runs   (    0.59 ms per token,  1691.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3285.72 ms /    27 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3363.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 14: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the embryology of the choroid, it is correct to state:\n",
      "a) The choriocapillaris is the first to be formed, with subsequent formation of the great vessels.\n",
      "b) The basal lamina originate the Bruch's membrane, which lies between the choriocapillaris and Sattler's layer.\n",
      "c) The intermediate vascular layer is the last to form and develops from the ciliary body towards the equator.\n",
      "d) The choroidal stroma is essentially produced from mesoderm cells.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.33 ms /    54 runs   (    0.60 ms per token,  1670.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2417.78 ms /   133 tokens (   18.18 ms per token,    55.01 tokens per second)\n",
      "llama_print_timings:        eval time =  6539.78 ms /    53 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  9116.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1699.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.92 ms /     7 runs   (  120.42 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   862.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    27 runs   (    0.58 ms per token,  1731.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3259.45 ms /    27 runs   (  120.72 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3336.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.57 ms /    54 runs   (    0.58 ms per token,  1710.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6642.54 ms /    54 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6800.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.61 ms /    25 runs   (    0.58 ms per token,  1710.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3105.36 ms /    25 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3178.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.28 ms /    28 runs   (    0.58 ms per token,  1720.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3401.31 ms /    28 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3482.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.77 ms /    53 runs   (    0.58 ms per token,  1722.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6475.50 ms /    53 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  6628.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.19 ms /    28 runs   (    0.58 ms per token,  1729.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3448.92 ms /    28 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3530.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.66 ms /    28 runs   (    0.60 ms per token,  1680.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3534.16 ms /    28 runs   (  126.22 ms per token,     7.92 tokens per second)\n",
      "llama_print_timings:       total time =  3615.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.94 ms /    17 runs   (    0.58 ms per token,  1710.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2089.68 ms /    17 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2138.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a embriologia da coroide,  correto afirmar:\n",
      "a)A coriocapilar  a primeira a se formar, com posterior formao dos grandes vasos.\n",
      "b)A lmina basal d origem  membrana de Bruch que se situa entre o coriocapilar e a camada de Sattler.\n",
      "c)A camada vascular intermediria  a ltima a se formar e desenvolve-se do corpo ciliar em direo ao equador.\n",
      "d)O estroma da coroide  essencialmente produzido a partir de clulas do mesoderma.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.36 ms /    67 runs   (    0.60 ms per token,  1660.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2795.00 ms /   154 tokens (   18.15 ms per token,    55.10 tokens per second)\n",
      "llama_print_timings:        eval time =  8137.95 ms /    66 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 11131.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.17 ms /   106 runs   (    0.58 ms per token,  1732.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13089.72 ms /   106 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13401.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.98 ms /     7 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   882.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "Error converting respose to json: {:response:\"b\"}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.43 ms /     6 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   724.04 ms /     6 runs   (  120.67 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   740.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.49 ms /     7 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   877.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1752.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.42 ms /     7 runs   (  124.20 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   889.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.43 ms /     7 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   876.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.47 ms /    86 runs   (    0.58 ms per token,  1738.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10567.49 ms /    86 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10820.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.15 ms /    90 runs   (    0.58 ms per token,  1725.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11055.19 ms /    90 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11319.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.71 ms /    41 runs   (    0.58 ms per token,  1728.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5067.22 ms /    41 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5185.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.13 ms /    98 runs   (    0.58 ms per token,  1715.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12137.01 ms /    98 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 12424.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 15: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding ocular embryology, it is correct to state:\n",
      "a) Corneal epithelium arises from neural crest cells.\n",
      "b) At birth, the cornea and sclera have curvature radius.\n",
      "c) Bowman's layer appears between the first and second month of pregnancy.\n",
      "d) The cornea develops from the ectodermal surface and neural crest cells.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.08 ms /    24 runs   (    0.59 ms per token,  1705.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1971.08 ms /    97 tokens (   20.32 ms per token,    49.21 tokens per second)\n",
      "llama_print_timings:        eval time =  2812.16 ms /    23 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4852.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.94 ms /    45 runs   (    0.58 ms per token,  1735.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5512.66 ms /    45 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5642.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n",
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.87 ms /    19 runs   (    0.57 ms per token,  1748.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2320.63 ms /    19 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2375.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.28 ms /    37 runs   (    0.58 ms per token,  1738.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4546.38 ms /    37 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4652.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.01 ms /    47 runs   (    0.57 ms per token,  1740.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5784.16 ms /    47 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5920.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n",
      "{'response': 'd) The cornea develops from the ectodermal surface and neural crest cells.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.02 ms /    37 runs   (    0.60 ms per token,  1680.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4586.24 ms /    37 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4694.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.15 ms /    47 runs   (    0.58 ms per token,  1731.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5742.84 ms /    47 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5878.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} The cornea develops from the ectodermal surface and neural crest cells.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.25 ms /    37 runs   (    0.57 ms per token,  1740.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4513.94 ms /    37 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4621.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.86 ms /    47 runs   (    0.57 ms per token,  1750.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5757.38 ms /    47 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5893.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.53 ms /    36 runs   (    0.57 ms per token,  1753.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4452.15 ms /    36 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4555.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao  embriologia ocular,  correto afirmar:\n",
      "a)O epitlio da crnea origina-se a partir das clulas da crista neural.\n",
      "b)Ao nascimento, crnea e esclera apresentam o mesmo raio de curvatura.\n",
      "c)A camada de Bowman surge entre o primeiro e o segundo ms de gestao.\n",
      "d)A crnea desenvolve-se a partir da superfcie ectodrmica e das clulas da crista neural.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.89 ms /    38 runs   (    0.63 ms per token,  1590.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2549.22 ms /   130 tokens (   19.61 ms per token,    51.00 tokens per second)\n",
      "llama_print_timings:        eval time =  4511.35 ms /    37 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  7181.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.46 ms /    63 runs   (    0.58 ms per token,  1727.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7867.66 ms /    63 runs   (  124.88 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  8051.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) A crnea desenvolve-se a partir da superfcie ectodrmica e das clulas da crista neural.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.08 ms /    59 runs   (    0.58 ms per token,  1731.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7244.19 ms /    59 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7415.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) A crnea desenvolve-se a partir da superfcie ectodrmica e das clulas da crista neural.'}\n",
      "Test #3: \n",
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.15 ms /    61 runs   (    0.58 ms per token,  1735.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7496.10 ms /    61 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7674.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.31 ms /    63 runs   (    0.58 ms per token,  1735.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7723.11 ms /    63 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  7906.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.52 ms /    38 runs   (    0.57 ms per token,  1765.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4661.83 ms /    38 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4771.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} A crnea desenvolve-se a partir da superfcie ectodrmica e das clulas da crista neural.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.37 ms /    58 runs   (    0.58 ms per token,  1737.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7102.67 ms /    58 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7269.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.87 ms /     7 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   868.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.46 ms /    58 runs   (    0.58 ms per token,  1733.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7101.06 ms /    58 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7268.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.93 ms /    31 runs   (    0.58 ms per token,  1729.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3811.15 ms /    31 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3900.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 16: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the autosomal dominant inheritance diseases, it is correct to state:\n",
      "a) In general, they are observed in several gestations.\n",
      "b) Men tend to be more affected than women.\n",
      "c) The severity of the disease is always the same among affected people from the same family.\n",
      "d) Only females transmit the mutation.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.92 ms /    24 runs   (    0.58 ms per token,  1723.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1902.38 ms /    80 tokens (   23.78 ms per token,    42.05 tokens per second)\n",
      "llama_print_timings:        eval time =  2804.45 ms /    23 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4776.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1731.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3008.12 ms /    24 runs   (  125.34 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  3077.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.62 ms /   100 runs   (    0.58 ms per token,  1735.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12316.82 ms /   100 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 12615.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1736.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3041.37 ms /    25 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3113.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.81 ms /    17 runs   (    0.58 ms per token,  1732.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2060.65 ms /    17 runs   (  121.21 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2108.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.94 ms /    24 runs   (    0.58 ms per token,  1721.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.13 ms /    24 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2985.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.80 ms /    17 runs   (    0.58 ms per token,  1735.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2090.65 ms /    17 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2140.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.81 ms /    17 runs   (    0.58 ms per token,  1732.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2069.31 ms /    17 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2117.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.79 ms /    17 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2064.78 ms /    17 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2113.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.82 ms /    17 runs   (    0.58 ms per token,  1730.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2077.53 ms /    17 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2126.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre as doenas de herana autossmica dominante,  correto afirmar:\n",
      "a)Em geral, so observadas em vrias gestaes.\n",
      "b)Os homens costumam ser mais afetados do que as mulheres.\n",
      "c)A gravidade da doena  sempre a mesma entre as pessoas afetadas da mesma famlia.\n",
      "d)Apenas as mulheres transmitem a mutao.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.38 ms /    76 runs   (    0.58 ms per token,  1712.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1984.10 ms /   109 tokens (   18.20 ms per token,    54.94 tokens per second)\n",
      "llama_print_timings:        eval time =  9172.88 ms /    75 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 11384.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.66 ms /    34 runs   (    0.58 ms per token,  1729.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4128.87 ms /    34 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4228.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.52 ms /    48 runs   (    0.57 ms per token,  1744.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5934.59 ms /    48 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  6074.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.28 ms /    49 runs   (    0.58 ms per token,  1732.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6010.16 ms /    49 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6156.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   909.59 ms /     7 runs   (  129.94 ms per token,     7.70 tokens per second)\n",
      "llama_print_timings:       total time =   930.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   876.67 ms /     7 runs   (  125.24 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =   897.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {'response': 'c'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   145.06 ms /   252 runs   (    0.58 ms per token,  1737.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 31120.25 ms /   252 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 31898.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.49 ms /    52 runs   (    0.59 ms per token,  1705.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6389.61 ms /    52 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6542.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.06 ms /     7 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   879.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.62 ms /    48 runs   (    0.58 ms per token,  1737.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5854.89 ms /    48 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5994.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)} A gravidade da doena  sempre a mesma entre as pessoas afetadas da mesma famlia.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3310.26 ms /    27 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3388.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 17: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding mitochondrial inheritance diseases, it is correct to state:\n",
      "a) Daltonism is an example of a disease linked to mitochondrial DNA.\n",
      "b) Inheritance occurs only through maternal lineage.\n",
      "c) Male patients assisted by the disease will transmit the phenotype to all offspring.\n",
      "d) Leber's hereditary optic neuropathy is an example of a disease linked to mitochondrial DNA, it usually causes congenital blindness and affects patients of both sexes in the same proportion.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.92 ms /    17 runs   (    0.58 ms per token,  1714.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2786.39 ms /   127 tokens (   21.94 ms per token,    45.58 tokens per second)\n",
      "llama_print_timings:        eval time =  1963.84 ms /    16 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4799.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n",
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   139.22 ms /   240 runs   (    0.58 ms per token,  1723.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 29656.74 ms /   240 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 30400.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.98 ms /    70 runs   (    0.59 ms per token,  1708.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8740.96 ms /    70 runs   (  124.87 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  8946.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1738.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2084.73 ms /    17 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2133.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.60 ms /    20 runs   (    0.58 ms per token,  1723.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2445.96 ms /    20 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2503.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.35 ms /    17 runs   (    0.61 ms per token,  1642.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2131.63 ms /    17 runs   (  125.39 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  2181.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.37 ms /    73 runs   (    0.58 ms per token,  1723.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8950.89 ms /    73 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  9164.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.22 ms /    17 runs   (    0.60 ms per token,  1662.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2067.89 ms /    17 runs   (  121.64 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2116.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1727.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.29 ms /    24 runs   (  121.47 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2984.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2932.54 ms /    24 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3001.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre as doenas de padro de herana mitocondrial,  correto afirmar:\n",
      "a)Daltonismo  um exemplo de doena ligada ao DNA mitocondrial.\n",
      "b)A herana ocorre apenas pela linhagem materna.\n",
      "c)Pacientes do sexo masculino afetados pela doena, transmitiro o fentipo para toda a prole.\n",
      "d)A neuropatia ptica hereditria de Leber  um exemplo de doena ligada ao DNA mitocondrial, causa geralmente cegueira congnita e afeta na mesma proporo pacientes de ambos os sexos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1702.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3223.15 ms /   164 tokens (   19.65 ms per token,    50.88 tokens per second)\n",
      "llama_print_timings:        eval time =   745.21 ms /     6 runs   (  124.20 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3988.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1697.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.17 ms /     7 runs   (  121.02 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   867.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1708.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.89 ms /     7 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.44 ms /     7 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.18 ms /     7 runs   (    0.60 ms per token,  1675.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.04 ms /     7 runs   (  124.43 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1701.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.47 ms /     7 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.39 ms /     7 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   117.62 ms /   203 runs   (    0.58 ms per token,  1725.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25088.76 ms /   203 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 25709.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n",
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.01 ms /     7 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   871.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.07 ms /     7 runs   (  121.01 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   867.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 18: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the lenses below best corrects simple myopic astigmatism?\n",
      "a)-3.00 spherical diopter + 1.00 cylindrical diopter X 90.\n",
      "b) +1.00 spherical diopter -1.00 cylindrical diopter X 90.\n",
      "c)-3.00 spherical diopter + 3.00 cylindrical diopter X 180.\n",
      "d) 0.00 spherical diopter +1.00 cylindrical diopter X 180.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.71 ms /    50 runs   (    0.55 ms per token,  1804.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2462.53 ms /   138 tokens (   17.84 ms per token,    56.04 tokens per second)\n",
      "llama_print_timings:        eval time =  6029.50 ms /    49 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8638.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.82 ms /    52 runs   (    0.55 ms per token,  1804.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6406.75 ms /    52 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6557.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.11 ms /    28 runs   (    0.54 ms per token,  1853.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3438.32 ms /    28 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3518.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.71 ms /    50 runs   (    0.55 ms per token,  1804.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6231.80 ms /    50 runs   (  124.64 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  6376.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.77 ms /    52 runs   (    0.55 ms per token,  1807.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6420.77 ms /    52 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6570.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    27 runs   (    0.53 ms per token,  1873.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3296.31 ms /    27 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3372.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.76 ms /    53 runs   (    0.58 ms per token,  1722.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6490.41 ms /    53 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6648.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.28 ms /    27 runs   (    0.60 ms per token,  1658.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3361.54 ms /    27 runs   (  124.50 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3444.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.89 ms /    52 runs   (    0.56 ms per token,  1800.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6408.29 ms /    52 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  6561.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.87 ms /    52 runs   (    0.56 ms per token,  1801.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6402.96 ms /    52 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6557.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das lentes abaixo melhor corrige um astigmatismo mipico simples?\n",
      "a)-3,00 dioptria esfrica + 1,00 dioptria cilindrica X 90.\n",
      "b)+1,00 dioptria esfrica -1,00 dioptria cilindrica X 90.\n",
      "c)-3,00 dioptria esfrica + 3,00 dioptria cilindrica X 180.\n",
      "d)0,00 dioptria esfrica +1,00 dioptria cilindrica X 180.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.10 ms /    20 runs   (    0.60 ms per token,  1653.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2424.67 ms /   157 tokens (   15.44 ms per token,    64.75 tokens per second)\n",
      "llama_print_timings:        eval time =  2311.49 ms /    19 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4796.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.17 ms /     9 runs   (    0.57 ms per token,  1739.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1119.54 ms /     9 runs   (  124.39 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  1145.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.11 ms /    65 runs   (    0.57 ms per token,  1751.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7962.16 ms /    65 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8153.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.76 ms /    47 runs   (    0.57 ms per token,  1756.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5741.40 ms /    47 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5877.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)-3,00 dioptria esfrica + 3,00 dioptria cilindrica X 180'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1816.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.14 ms /     7 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.66 ms /    37 runs   (    0.56 ms per token,  1790.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4516.88 ms /    37 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4623.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)-3,00 dioptria esfrica + 3,00 dioptria cilindrica X 180'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.61 ms /    24 runs   (    0.57 ms per token,  1763.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2979.51 ms /    24 runs   (  124.15 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3049.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.03 ms /   126 runs   (    0.58 ms per token,  1725.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15539.46 ms /   126 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 15919.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.77 ms /    63 runs   (    0.57 ms per token,  1761.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7795.76 ms /    63 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  7981.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.76 ms /    29 runs   (    0.58 ms per token,  1730.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3553.21 ms /    29 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3638.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 19: \n",
      "Language: english\n",
      "Question: \n",
      "What is the focal length of the circle of least confusion on Sturm's conoid of a +1.00 OD +2.00 DC X 180 spherocylindrical lens?\n",
      "a) 0 m.\n",
      "b) 0.5 m.\n",
      "c) 1 m.\n",
      "d) 2 m.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.16 ms /    27 runs   (    0.56 ms per token,  1781.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1961.77 ms /    84 tokens (   23.35 ms per token,    42.82 tokens per second)\n",
      "llama_print_timings:        eval time =  3182.51 ms /    26 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5223.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.95 ms /    29 runs   (    0.55 ms per token,  1818.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3571.28 ms /    29 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3655.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.28 ms /    12 runs   (    0.52 ms per token,  1912.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1442.13 ms /    12 runs   (  120.18 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  1476.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.85 ms /    29 runs   (    0.55 ms per token,  1829.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3545.28 ms /    29 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3628.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.55 ms /    30 runs   (    0.55 ms per token,  1812.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3675.36 ms /    30 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3762.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.25 ms /    30 runs   (    0.54 ms per token,  1845.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3665.15 ms /    30 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3751.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.68 ms /     7 runs   (    0.53 ms per token,  1903.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.01 ms /     7 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.94 ms /    29 runs   (    0.55 ms per token,  1819.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3544.31 ms /    29 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3627.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.51 ms /    30 runs   (    0.55 ms per token,  1817.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3646.14 ms /    30 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3732.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.01 ms /    34 runs   (    0.56 ms per token,  1788.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4232.66 ms /    34 runs   (  124.49 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  4332.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual  a distncia focal do crculo de menor confuso no conoide de Sturm de uma lente esferocilndrica de +1,00 DE +2,00 DC X 180?\n",
      "a)0 metros.\n",
      "b)0,5 metros.\n",
      "c)1 metros.\n",
      "d)2 metros.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.64 ms /    10 runs   (    0.56 ms per token,  1773.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2181.16 ms /    87 tokens (   25.07 ms per token,    39.89 tokens per second)\n",
      "llama_print_timings:        eval time =  1104.78 ms /     9 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3315.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {:response:\"c\")1 metros.\"}\n",
      "Generating new response...\n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.23 ms /    22 runs   (    0.56 ms per token,  1799.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2678.25 ms /    22 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2742.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.19 ms /    79 runs   (    0.57 ms per token,  1748.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9673.60 ms /    79 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  9907.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.22 ms /    33 runs   (    0.55 ms per token,  1811.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4038.91 ms /    33 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4134.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.54 ms /    12 runs   (    0.55 ms per token,  1834.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1485.67 ms /    12 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  1520.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.50 ms /    12 runs   (    0.54 ms per token,  1845.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1488.14 ms /    12 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  1522.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.87 ms /     7 runs   (    0.55 ms per token,  1806.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.05 ms /     7 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.37 ms /    29 runs   (    0.53 ms per token,  1886.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3552.27 ms /    29 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3636.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.50 ms /    12 runs   (    0.54 ms per token,  1846.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1463.83 ms /    12 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1497.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.88 ms /     7 runs   (    0.55 ms per token,  1804.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   877.93 ms /     7 runs   (  125.42 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =   897.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.55 ms /    12 runs   (    0.55 ms per token,  1830.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1458.99 ms /    12 runs   (  121.58 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  1493.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 20: \n",
      "Language: english\n",
      "Question: \n",
      "What is the focal length of the circle of least confusion on Sturm's conoid of a +1.00 OD +2.00 DC X 180 spherocylindrical lens?\n",
      "a) 0 meters.\n",
      "b) 0.5 meters.\n",
      "c) 1 meters.\n",
      "d) 2 meters.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.64 ms /     7 runs   (    0.52 ms per token,  1922.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2083.86 ms /    84 tokens (   24.81 ms per token,    40.31 tokens per second)\n",
      "llama_print_timings:        eval time =   739.57 ms /     6 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  2843.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.78 ms /    29 runs   (    0.54 ms per token,  1838.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3529.26 ms /    29 runs   (  121.70 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3613.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.31 ms /    33 runs   (    0.55 ms per token,  1802.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4037.85 ms /    33 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4133.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    29 runs   (    0.54 ms per token,  1858.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3628.25 ms /    29 runs   (  125.11 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  3711.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.80 ms /    27 runs   (    0.55 ms per token,  1824.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3321.00 ms /    27 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3398.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.55 ms /    32 runs   (    0.55 ms per token,  1823.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3891.39 ms /    32 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3983.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.03 ms /    24 runs   (    0.54 ms per token,  1842.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2946.69 ms /    24 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3015.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    30 runs   (    0.54 ms per token,  1851.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3702.65 ms /    30 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3788.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.42 ms /    12 runs   (    0.53 ms per token,  1869.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1468.02 ms /    12 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1501.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.28 ms /    12 runs   (    0.52 ms per token,  1910.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1469.46 ms /    12 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1502.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um ponto objetivo situado a dois metros de uma lente convexa de 2 DE forma um ponto imagem a que distncia da lente?\n",
      "a)2,0 m.\n",
      "b)1,5 m.\n",
      "c)0,67 m.\n",
      "d)0,4 m.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.97 ms /    33 runs   (    0.57 ms per token,  1739.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1347.45 ms /    74 tokens (   18.21 ms per token,    54.92 tokens per second)\n",
      "llama_print_timings:        eval time =  3912.33 ms /    32 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5356.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.56 ms /    20 runs   (    0.58 ms per token,  1729.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2496.71 ms /    20 runs   (  124.84 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  2555.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.18 ms /    32 runs   (    0.57 ms per token,  1760.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3922.46 ms /    32 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4015.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.54 ms /    22 runs   (    0.57 ms per token,  1754.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2684.88 ms /    22 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2748.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.52 ms /    20 runs   (    0.58 ms per token,  1736.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2399.11 ms /    20 runs   (  119.96 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =  2456.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.71 ms /     7 runs   (  120.24 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.48 ms /    20 runs   (    0.57 ms per token,  1742.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2433.59 ms /    20 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2491.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.93 ms /    23 runs   (    0.56 ms per token,  1778.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2834.21 ms /    23 runs   (  123.23 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2900.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.50 ms /    13 runs   (    0.58 ms per token,  1733.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1639.67 ms /    13 runs   (  126.13 ms per token,     7.93 tokens per second)\n",
      "llama_print_timings:       total time =  1677.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.59 ms /    24 runs   (    0.57 ms per token,  1766.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2924.98 ms /    24 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2993.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 21: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following values in decimal logarithm (logMAR) corresponds to normal visual acuity (1.0)?\n",
      "to 1.\n",
      "b)0.\n",
      "c)1.\n",
      "d)2.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.98 ms /    24 runs   (    0.58 ms per token,  1716.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1300.50 ms /    56 tokens (   23.22 ms per token,    43.06 tokens per second)\n",
      "llama_print_timings:        eval time =  2778.92 ms /    23 runs   (  120.82 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  4150.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.72 ms /    28 runs   (    0.56 ms per token,  1780.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3446.54 ms /    28 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3527.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.23 ms /    30 runs   (    0.57 ms per token,  1741.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3650.62 ms /    30 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3737.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.48 ms /    27 runs   (    0.57 ms per token,  1744.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3296.76 ms /    27 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3375.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.44 ms /    27 runs   (    0.57 ms per token,  1748.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3287.53 ms /    27 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3366.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1758.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   836.24 ms /     7 runs   (  119.46 ms per token,     8.37 tokens per second)\n",
      "llama_print_timings:       total time =   856.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.47 ms /    31 runs   (    0.56 ms per token,  1774.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3748.65 ms /    31 runs   (  120.92 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3837.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.33 ms /    27 runs   (    0.57 ms per token,  1760.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3316.84 ms /    27 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3394.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.74 ms /    28 runs   (    0.56 ms per token,  1779.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3418.46 ms /    28 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3499.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.62 ms /    28 runs   (    0.56 ms per token,  1792.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3462.21 ms /    28 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3542.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual dos valores abaixo em logaritmo decimal (logMAR) corresponde a acuidade visual normal (1,0)?\n",
      "a)-1.\n",
      "b)0.\n",
      "c)1.\n",
      "d)2.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.29 ms /    30 runs   (    0.58 ms per token,  1735.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1414.52 ms /    60 tokens (   23.58 ms per token,    42.42 tokens per second)\n",
      "llama_print_timings:        eval time =  3542.32 ms /    29 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5045.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    28 runs   (    0.57 ms per token,  1749.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3376.73 ms /    28 runs   (  120.60 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3458.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.28 ms /    23 runs   (    0.58 ms per token,  1731.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2838.37 ms /    23 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  2905.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1757.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.41 ms /     7 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   874.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3293.51 ms /    27 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3370.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.99 ms /    28 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3393.35 ms /    28 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3474.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.69 ms /    24 runs   (    0.57 ms per token,  1753.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2907.91 ms /    24 runs   (  121.16 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2978.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.25 ms /    27 runs   (    0.56 ms per token,  1770.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3320.72 ms /    27 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3398.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1767.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.53 ms /     7 runs   (  123.08 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   880.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.74 ms /    28 runs   (    0.56 ms per token,  1778.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3412.62 ms /    28 runs   (  121.88 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3493.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 22: \n",
      "Language: english\n",
      "Question: \n",
      "What is the optical effect resulting from the interpolation of two polaroid filters perpendicular to each other?\n",
      "a) Transmission is reduced by 50%.\n",
      "b) Transmission is increased by 50%.\n",
      "c) Absence of light transmission.\n",
      "d)No loss of light energy.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.65 ms /    53 runs   (    0.58 ms per token,  1729.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1679.52 ms /    69 tokens (   24.34 ms per token,    41.08 tokens per second)\n",
      "llama_print_timings:        eval time =  6321.90 ms /    52 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  8158.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.40 ms /    27 runs   (    0.57 ms per token,  1753.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3269.12 ms /    27 runs   (  121.08 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3347.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.48 ms /    34 runs   (    0.57 ms per token,  1745.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4124.45 ms /    34 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4224.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.86 ms /    34 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4130.85 ms /    34 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4230.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.03 ms /    28 runs   (    0.57 ms per token,  1746.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3460.33 ms /    28 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3542.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.04 ms /    31 runs   (    0.58 ms per token,  1718.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3759.76 ms /    31 runs   (  121.28 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3850.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.87 ms /    31 runs   (    0.58 ms per token,  1734.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3809.56 ms /    31 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3899.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c} Absence of light transmission.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.64 ms /    42 runs   (    0.56 ms per token,  1776.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5104.50 ms /    42 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5227.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.88 ms /    28 runs   (    0.57 ms per token,  1762.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3490.23 ms /    28 runs   (  124.65 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3571.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.61 ms /    31 runs   (    0.57 ms per token,  1759.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3830.26 ms /    31 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3919.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c} Absence of light transmission.'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual o efeito ptico decorrente da interpolao de dois filtros polaroides perpendiculares entre si?\n",
      "a)Transmisso reduzida em 50%.\n",
      "b)Transmisso ampliada em 50%.\n",
      "c)Ausncia de transmisso luminosa.\n",
      "d)Nenhuma perda de energia luminosa.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.29 ms /    45 runs   (    0.58 ms per token,  1711.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2020.58 ms /    94 tokens (   21.50 ms per token,    46.52 tokens per second)\n",
      "llama_print_timings:        eval time =  5347.26 ms /    44 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  7500.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.17 ms /    46 runs   (    0.57 ms per token,  1757.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5652.79 ms /    46 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5786.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.15 ms /    32 runs   (    0.57 ms per token,  1762.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3864.37 ms /    32 runs   (  120.76 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3957.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.73 ms /    19 runs   (    0.56 ms per token,  1770.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2320.34 ms /    19 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2374.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.34 ms /    20 runs   (    0.57 ms per token,  1764.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2449.59 ms /    20 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2507.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n",
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.71 ms /    19 runs   (    0.56 ms per token,  1773.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2296.67 ms /    19 runs   (  120.88 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2351.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.94 ms /     7 runs   (    0.56 ms per token,  1776.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.27 ms /     7 runs   (  121.04 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   866.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'c} Ausncia de transmisso luminosa.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.05 ms /    18 runs   (    0.56 ms per token,  1790.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2243.47 ms /    18 runs   (  124.64 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  2295.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.55 ms /    83 runs   (    0.57 ms per token,  1745.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10142.74 ms /    83 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 10388.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.12 ms /    18 runs   (    0.56 ms per token,  1778.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2244.83 ms /    18 runs   (  124.71 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  2296.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 23: \n",
      "Language: english\n",
      "Question: \n",
      "In which of the materials is the speed of light the lowest?\n",
      "a) Air.\n",
      "b) Diamond.\n",
      "c) Glass.\n",
      "d) The speed of light is constant regardless of the medium.\n",
      "Test #0: \n",
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    24 runs   (    0.60 ms per token,  1670.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1173.62 ms /    50 tokens (   23.47 ms per token,    42.60 tokens per second)\n",
      "llama_print_timings:        eval time =  2815.44 ms /    23 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4060.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.50 ms /    27 runs   (    0.57 ms per token,  1741.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3276.11 ms /    27 runs   (  121.34 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3354.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.47 ms /    27 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.25 ms /    27 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3379.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3321.24 ms /    27 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3399.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n",
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.74 ms /    17 runs   (    0.57 ms per token,  1745.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2044.72 ms /    17 runs   (  120.28 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2093.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.55 ms /    24 runs   (    0.56 ms per token,  1770.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2889.61 ms /    24 runs   (  120.40 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2959.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.39 ms /    27 runs   (    0.57 ms per token,  1754.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3293.19 ms /    27 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3371.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.20 ms /    24 runs   (    0.59 ms per token,  1689.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2911.85 ms /    24 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2981.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.29 ms /    28 runs   (    0.62 ms per token,  1619.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3438.92 ms /    28 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3524.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.44 ms /    27 runs   (    0.76 ms per token,  1321.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3264.05 ms /    27 runs   (  120.89 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3363.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Em qual dos materiais abaixo a velocidade da luz  a menor?\n",
      "a)Ar.\n",
      "b)Diamante.\n",
      "c)Vidro.\n",
      "d)A velocidade da luz  constante independente do meio.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.56 ms /    27 runs   (    0.69 ms per token,  1454.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1481.29 ms /    63 tokens (   23.51 ms per token,    42.53 tokens per second)\n",
      "llama_print_timings:        eval time =  3158.42 ms /    26 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4730.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.33 ms /    28 runs   (    0.73 ms per token,  1377.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3384.37 ms /    28 runs   (  120.87 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3475.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.17 ms /    28 runs   (    0.76 ms per token,  1322.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3393.56 ms /    28 runs   (  121.20 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3490.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.27 ms /    27 runs   (    0.57 ms per token,  1768.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3291.63 ms /    27 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3370.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.34 ms /    27 runs   (    0.57 ms per token,  1760.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.24 ms /    27 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3379.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.28 ms /    27 runs   (    0.57 ms per token,  1767.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3277.98 ms /    27 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3356.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.92 ms /    42 runs   (    0.57 ms per token,  1755.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5152.80 ms /    42 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5276.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.55 ms /    41 runs   (    0.57 ms per token,  1741.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5033.16 ms /    41 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5154.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.26 ms /    27 runs   (    0.57 ms per token,  1768.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3350.07 ms /    27 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3427.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n",
      "{'response': 'C'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 24: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the alternative that corresponds to a reflection from a convex mirror.\n",
      "a) Keratoscopy with Placido disc.\n",
      "b) Shaving mirror.\n",
      "c) Dentist's mirror.\n",
      "d) Reflector headlamp.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.95 ms /    42 runs   (    0.57 ms per token,  1753.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5094.01 ms /    42 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5214.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.62 ms /    72 runs   (    0.58 ms per token,  1729.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1396.44 ms /    58 tokens (   24.08 ms per token,    41.53 tokens per second)\n",
      "llama_print_timings:        eval time =  8654.61 ms /    71 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 10262.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.11 ms /    42 runs   (    0.57 ms per token,  1742.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5116.44 ms /    42 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5236.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1768.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   840.85 ms /     7 runs   (  120.12 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   861.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.47 ms /    20 runs   (    0.57 ms per token,  1744.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2412.73 ms /    20 runs   (  120.64 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2469.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.23 ms /    32 runs   (    0.57 ms per token,  1755.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3911.88 ms /    32 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4003.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.91 ms /    33 runs   (    0.57 ms per token,  1744.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3954.08 ms /    33 runs   (  119.82 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =  4049.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.54 ms /    29 runs   (    0.57 ms per token,  1753.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3593.09 ms /    29 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3675.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.65 ms /    22 runs   (    0.57 ms per token,  1739.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2694.92 ms /    22 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2758.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.15 ms /    33 runs   (    0.58 ms per token,  1722.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3991.33 ms /    33 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4086.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que corresponde a uma reflexo de um espelho convexo.\n",
      "a)Ceratoscopia com disco de Plcido.\n",
      "b)Espelho de barbear.\n",
      "c)Espelho do dentista.\n",
      "d)Farol refletor.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.23 ms /    30 runs   (    0.57 ms per token,  1741.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3607.61 ms /    30 runs   (  120.25 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  3693.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.43 ms /    60 runs   (    0.57 ms per token,  1742.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1824.20 ms /    75 tokens (   24.32 ms per token,    41.11 tokens per second)\n",
      "llama_print_timings:        eval time =  7259.25 ms /    59 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  9261.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.53 ms /    43 runs   (    0.57 ms per token,  1752.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5231.91 ms /    43 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5356.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.38 ms /    43 runs   (    0.57 ms per token,  1763.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5225.49 ms /    43 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5348.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.82 ms /     7 runs   (    0.55 ms per token,  1831.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.57 ms /     7 runs   (  120.37 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.90 ms /     7 runs   (    0.56 ms per token,  1793.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.75 ms /     7 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   884.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.83 ms /    42 runs   (    0.57 ms per token,  1762.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5159.92 ms /    42 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5282.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.84 ms /    42 runs   (    0.57 ms per token,  1761.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5089.88 ms /    42 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5211.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.84 ms /    42 runs   (    0.57 ms per token,  1761.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5168.46 ms /    42 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5291.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.01 ms /    25 runs   (    0.56 ms per token,  1784.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3067.21 ms /    25 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3139.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.90 ms /     7 runs   (    0.56 ms per token,  1793.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.21 ms /     7 runs   (  120.74 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   864.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 25: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "A converging lens focuses light from a source 1 m away at a distance of 50 cm. How powerful is this lens?\n",
      "a) + 1 diopter.\n",
      "b) + 2 diopter.\n",
      "c) + 3 diopter.\n",
      "d) + 4 diopter.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.70 ms /    32 runs   (    0.55 ms per token,  1807.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2022.58 ms /    75 tokens (   26.97 ms per token,    37.08 tokens per second)\n",
      "llama_print_timings:        eval time =  3784.85 ms /    31 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5900.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   125.64 ms /   221 runs   (    0.57 ms per token,  1758.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27247.50 ms /   221 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 27926.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.18 ms /    31 runs   (    0.55 ms per token,  1803.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3832.02 ms /    31 runs   (  123.61 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3920.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.48 ms /    33 runs   (    0.56 ms per token,  1785.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4087.98 ms /    33 runs   (  123.88 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4183.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) + 2 diopter'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.01 ms /   116 runs   (    0.57 ms per token,  1757.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14252.84 ms /   116 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 14596.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.05 ms /    34 runs   (    0.62 ms per token,  1615.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4159.20 ms /    34 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4263.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.86 ms /   131 runs   (    0.58 ms per token,  1726.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16114.37 ms /   131 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 16513.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.11 ms /   131 runs   (    0.57 ms per token,  1744.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16054.66 ms /   131 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 16447.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.56 ms /   186 runs   (    0.57 ms per token,  1745.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22856.15 ms /   186 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 23423.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.03 ms /    34 runs   (    0.56 ms per token,  1786.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4120.27 ms /    34 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4218.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Uma lente convergente foca a luz proveniente de uma fonte situada a 1 m a uma distncia de 50 cm. Qual o poder desta lente?\n",
      "a)+ 1 dioptria.\n",
      "b)+ 2 dioptria.\n",
      "c)+ 3 dioptria.\n",
      "d)+ 4 dioptria.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.53 ms /    15 runs   (    0.57 ms per token,  1757.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2035.81 ms /    86 tokens (   23.67 ms per token,    42.24 tokens per second)\n",
      "llama_print_timings:        eval time =  1697.83 ms /    14 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3777.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.27 ms /    32 runs   (    0.57 ms per token,  1751.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3932.69 ms /    32 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4026.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.78 ms /    27 runs   (    0.55 ms per token,  1827.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3306.22 ms /    27 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3385.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.00 ms /    27 runs   (    0.56 ms per token,  1799.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.13 ms /    27 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3382.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)+ 2 dioptria'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.03 ms /    36 runs   (    0.56 ms per token,  1797.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4408.79 ms /    36 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4513.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a) + 1 dioptria.'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.80 ms /    34 runs   (    0.55 ms per token,  1808.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4174.06 ms /    34 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4273.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a)'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.38 ms /    35 runs   (    0.55 ms per token,  1806.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4288.30 ms /    35 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4389.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a)'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    30 runs   (    0.54 ms per token,  1840.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3732.37 ms /    30 runs   (  124.41 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3818.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.38 ms /    33 runs   (    0.56 ms per token,  1795.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4050.62 ms /    33 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4145.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a) 1 dioptria'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.63 ms /    31 runs   (    0.54 ms per token,  1864.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3785.51 ms /    31 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3873.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 26: \n",
      "Language: english\n",
      "Question: \n",
      "If we were to measure the focal power of the image of the posterior surface of the cornea after its removal from the eyeball, we would have a value around (consider the anterior curvature of the cornea 7.7 mm; the posterior curvature of the cornea 6.8 mm; the index of corneal stroma refraction 1.376 and the refractive index of air 1.00):\n",
      "a) + 5.00 Dioptres.\n",
      "b) 0.00 Dioptres.\n",
      "c)- 5.00 Dioptres.\n",
      "d)- 55.00 Dioptres.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.28 ms /    40 runs   (    0.56 ms per token,  1795.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3619.23 ms /   158 tokens (   22.91 ms per token,    43.66 tokens per second)\n",
      "llama_print_timings:        eval time =  4815.68 ms /    39 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8551.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.26 ms /    40 runs   (    0.56 ms per token,  1797.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4905.15 ms /    40 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5021.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.55 ms /    39 runs   (    0.55 ms per token,  1810.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4768.41 ms /    39 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4882.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.29 ms /    39 runs   (    0.57 ms per token,  1749.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4824.87 ms /    39 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4941.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.66 ms /    34 runs   (    0.55 ms per token,  1822.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4176.18 ms /    34 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4276.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   119.42 ms /   209 runs   (    0.57 ms per token,  1750.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26017.82 ms /   209 runs   (  124.49 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time = 26670.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.94 ms /   209 runs   (    0.57 ms per token,  1757.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25874.75 ms /   209 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 26523.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.67 ms /    43 runs   (    0.55 ms per token,  1816.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5315.45 ms /    43 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5441.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.96 ms /    40 runs   (    0.55 ms per token,  1821.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5020.14 ms /    40 runs   (  125.50 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  5137.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.76 ms /    36 runs   (    0.55 ms per token,  1821.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4400.24 ms /    36 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4504.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Se fossemos medir o poder focal imagem da face posterior da crnea aps sua retirada do globo ocular, teramos um valor ao redor de (considere a curvatura anterior da crnea 7,7 mm; a curvatura posterior da crnea 6,8 mm; o ndice de refrao do estroma corneano 1,376 e o ndice de refrao do ar 1,00):\n",
      "a)+ 5,00 Dioptrias.\n",
      "b)0,00 Dioptrias.\n",
      "c)- 5,00 Dioptrias.\n",
      "d)- 55,00 Dioptrias.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.45 ms /    34 runs   (    0.54 ms per token,  1842.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3035.76 ms /   165 tokens (   18.40 ms per token,    54.35 tokens per second)\n",
      "llama_print_timings:        eval time =  4063.92 ms /    33 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7199.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.86 ms /    36 runs   (    0.52 ms per token,  1908.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4411.43 ms /    36 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4516.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.44 ms /    41 runs   (    0.55 ms per token,  1826.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5045.32 ms /    41 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5165.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.04 ms /    18 runs   (    0.50 ms per token,  1991.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2200.27 ms /    18 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2252.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.20 ms /    18 runs   (    0.51 ms per token,  1956.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2187.25 ms /    18 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2239.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.32 ms /    38 runs   (    0.53 ms per token,  1870.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4697.02 ms /    38 runs   (  123.61 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4809.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a) 5,00 Dioptrias'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.26 ms /    18 runs   (    0.51 ms per token,  1943.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2204.49 ms /    18 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2256.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.15 ms /    39 runs   (    0.54 ms per token,  1844.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4795.32 ms /    39 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4909.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.88 ms /    37 runs   (    0.54 ms per token,  1861.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4550.02 ms /    37 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4658.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.37 ms /    38 runs   (    0.54 ms per token,  1865.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4645.96 ms /    38 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4757.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 27: \n",
      "Language: english\n",
      "Question: \n",
      "When reducing the cylinder prescription in a patient who did not adapt to his glasses with the following prescription -1.50 spherical diopter < > -3.50 cylindrical diopter X 180, a possible prescription maintaining the spherical equivalent is:\n",
      "a)- 2.50 spherical diopter < > -2.50 cylindrical diopter X 180.\n",
      "b) +1.50 spherical diopter < > -2.50 cylindrical diopter X 180.\n",
      "c) -4.50 spherical diopter < > +2.50 cylindrical diopter X 90.\n",
      "d) -2.50 spherical diopter < > +3.00 cylindrical diopter X 90.a)- 2.50 spherical diopter < > -2.50 cylindrical diopter X 180.\n",
      "b) +1.50 spherical diopter < > -2.50 cylindrical diopter X 180.\n",
      "c) -4.50 spherical diopter < > +2.50 cylindrical diopter X 90.\n",
      "d) -2.50 spherical diopter < > +3.00 cylindrical diopter X 90.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.51 ms /    55 runs   (    0.57 ms per token,  1745.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =  5475.88 ms /   312 tokens (   17.55 ms per token,    56.98 tokens per second)\n",
      "llama_print_timings:        eval time =  6673.86 ms /    54 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 12314.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.10 ms /    55 runs   (    0.57 ms per token,  1768.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6862.75 ms /    55 runs   (  124.78 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  7024.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.27 ms /    55 runs   (    0.57 ms per token,  1758.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6841.79 ms /    55 runs   (  124.40 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  7005.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a)- 2.50 spherical diopter < > -2.50 cylindrical diopter X 180'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.94 ms /    55 runs   (    0.56 ms per token,  1777.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6851.32 ms /    55 runs   (  124.57 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  7014.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a)- 2.50 spherical diopter < > -2.50 cylindrical diopter X 180'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.83 ms /    55 runs   (    0.56 ms per token,  1784.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6803.94 ms /    55 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6966.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'Answer option'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.88 ms /    32 runs   (    0.56 ms per token,  1789.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3975.47 ms /    32 runs   (  124.23 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  4068.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.70 ms /    49 runs   (    0.57 ms per token,  1769.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6024.73 ms /    49 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6168.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.07 ms /    55 runs   (    0.56 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6849.20 ms /    55 runs   (  124.53 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  7012.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "Error converting respose to json:  Sure, I'm ready to assist you! Here's my response in JSON format:\n",
      "\n",
      "{\"response\": \"b\") +1.50 spherical diopter < > -2.50 cylindrical diopter X 180.\"\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.22 ms /    55 runs   (    0.57 ms per token,  1761.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6788.20 ms /    55 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6950.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.34 ms /    54 runs   (    0.56 ms per token,  1779.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6646.68 ms /    54 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6805.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.44 ms /    55 runs   (    0.57 ms per token,  1749.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6817.41 ms /    55 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6979.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to assist you! Please provide the medical query in English or Portuguese with the appropriate delimiters (i.e., ####). I will respond with the answer in JSON format as requested.\n",
      "\n",
      "Here is the correct answer to the sample question\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.15 ms /    55 runs   (    0.57 ms per token,  1765.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6808.78 ms /    55 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6970.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to assist you! Here's the answer to your medical query in JSON format:\n",
      "\n",
      "{\"response\": \"a\") -2.50 spherical diopter < > -2.50 cylindrical diopter X 1\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.99 ms /    55 runs   (    0.56 ms per token,  1774.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6811.73 ms /    55 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6971.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to assist you! Please provide the medical query in English or Portuguese, delimited with #### characters, and I will provide the answer in JSON format with the key \"response\".\n",
      "\n",
      "Here is the correct answer for your first question:\n",
      "\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.07 ms /    29 runs   (    0.59 ms per token,  1698.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3574.83 ms /    29 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3662.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to assist you! Please provide the medical query with the four possible answer options delimited with #### characters.\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.91 ms /    54 runs   (    0.65 ms per token,  1546.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6690.05 ms /    54 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6856.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Ao reduzirmos a prescrio do cilindro em um paciente que no se adaptou a seus culos com a seguinte prescrio -1,50 Diotria esferica < > -3,50 dioptria cilindrica X 180, uma possvel prescrio mantendo o equivalente esfrico :\n",
      "a)- 2,50 dioptria esferica < > -2,50 dioptria cilindrica X 180.\n",
      "b)+1,50 dioptria esferica < > -2,50 dioptria cilindrica X 180.\n",
      "c)-4,50 dioptria esferica < > +2,50 dioptria cilindrica X 90.\n",
      "d)-2,50 dioptria esferica < > +3,00 dioptria cilindrica X 90.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3762.66 ms /   225 tokens (   16.72 ms per token,    59.80 tokens per second)\n",
      "llama_print_timings:        eval time =   725.83 ms /     6 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4508.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.31 ms /    27 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3379.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    81.54 ms /   142 runs   (    0.57 ms per token,  1741.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17624.71 ms /   142 runs   (  124.12 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 18049.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.04 ms /     9 runs   (    0.56 ms per token,  1785.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1106.18 ms /     9 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  1132.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.41 ms /     7 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.41 ms /    20 runs   (    0.57 ms per token,  1752.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2479.41 ms /    20 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2536.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.94 ms /     7 runs   (    0.56 ms per token,  1778.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.48 ms /     7 runs   (  124.07 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.43 ms /     7 runs   (  120.92 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.49 ms /     7 runs   (  123.78 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   886.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1761.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.15 ms /     7 runs   (  121.45 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   869.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 28: \n",
      "Language: english\n",
      "Question: \n",
      "A light ray is deviated by 20 mm from the visual axis at a distance of 50 cm from a prism. What is the power of the prism in diopters-prismatics?\n",
      "a) 0.4.\n",
      "b)2.5.\n",
      "c)4.\n",
      "d) 10.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.96 ms /    29 runs   (    0.58 ms per token,  1709.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1922.31 ms /    78 tokens (   24.64 ms per token,    40.58 tokens per second)\n",
      "llama_print_timings:        eval time =  3410.60 ms /    28 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5418.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.84 ms /    24 runs   (    0.58 ms per token,  1733.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2932.00 ms /    24 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3001.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2906.08 ms /    24 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2976.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.95 ms /    26 runs   (    0.58 ms per token,  1738.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3150.94 ms /    26 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3226.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.02 ms /    28 runs   (    0.57 ms per token,  1748.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3487.86 ms /    28 runs   (  124.57 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3571.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.77 ms /    24 runs   (    0.57 ms per token,  1742.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2883.59 ms /    24 runs   (  120.15 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  2952.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.94 ms /    28 runs   (    0.57 ms per token,  1757.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3408.85 ms /    28 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3489.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.34 ms /    29 runs   (    0.56 ms per token,  1774.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3558.81 ms /    29 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3642.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.72 ms /    24 runs   (    0.57 ms per token,  1748.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.45 ms /    24 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2985.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1738.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2925.80 ms /    24 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2996.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um raio de luz sofre desvio de 20 mm do eixo visual a uma distncia de 50 cm de um prima. Qual  o poder do prisma em dioptrias-prismticas?\n",
      "a)0,4.\n",
      "b)2,5.\n",
      "c)4.\n",
      "d)10.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.33 ms /    12 runs   (    0.61 ms per token,  1636.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2062.66 ms /    83 tokens (   24.85 ms per token,    40.24 tokens per second)\n",
      "llama_print_timings:        eval time =  1357.47 ms /    11 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3456.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.66 ms /    29 runs   (    0.57 ms per token,  1740.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3539.55 ms /    29 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3624.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.04 ms /    27 runs   (    0.56 ms per token,  1795.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3304.68 ms /    27 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3383.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.58 ms /    31 runs   (    0.57 ms per token,  1763.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3769.31 ms /    31 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3859.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1762.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   834.28 ms /     7 runs   (  119.18 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =   853.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    95.79 ms /   168 runs   (    0.57 ms per token,  1753.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20593.88 ms /   168 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 21112.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.26 ms /    25 runs   (    0.57 ms per token,  1753.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3024.44 ms /    25 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3097.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.58 ms /    31 runs   (    0.57 ms per token,  1763.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3782.19 ms /    31 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3873.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.55 ms /    31 runs   (    0.57 ms per token,  1765.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3786.29 ms /    31 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3876.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.68 ms /    26 runs   (    0.56 ms per token,  1771.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3197.62 ms /    26 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3272.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 29: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Considering Gullstrand's schematic eye, what is the characteristic of the image formed on the retina?\n",
      "a) Real, inverted.\n",
      "b) Virtual, inverted.\n",
      "c) Real, direct.\n",
      "d) Virtual, direct.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.75 ms /    22 runs   (    0.58 ms per token,  1725.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1501.64 ms /    64 tokens (   23.46 ms per token,    42.62 tokens per second)\n",
      "llama_print_timings:        eval time =  2562.80 ms /    21 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4129.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.05 ms /    23 runs   (    0.57 ms per token,  1762.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2796.12 ms /    23 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2864.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.41 ms /    22 runs   (    0.56 ms per token,  1772.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2670.70 ms /    22 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2735.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.92 ms /    23 runs   (    0.56 ms per token,  1780.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2849.94 ms /    23 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2916.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.86 ms /    23 runs   (    0.56 ms per token,  1787.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2820.32 ms /    23 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2886.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.87 ms /    23 runs   (    0.56 ms per token,  1786.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2792.51 ms /    23 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2860.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.81 ms /    23 runs   (    0.56 ms per token,  1795.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2809.04 ms /    23 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2876.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.84 ms /    51 runs   (    0.57 ms per token,  1768.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6237.91 ms /    51 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  6389.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.68 ms /    32 runs   (    0.58 ms per token,  1713.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3895.21 ms /    32 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3991.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Considerando o olho esquemtico de Gullstrand, qual a caracterstica da imagem formada na retina?\n",
      "a)Real, invertida.\n",
      "b)Virtual, invertida.\n",
      "c)Real, direta.\n",
      "d)Virtual, direta.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.09 ms /    30 runs   (    0.57 ms per token,  1755.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3648.80 ms /    30 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3737.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.56 ms /    32 runs   (    0.58 ms per token,  1723.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1242.33 ms /    67 tokens (   18.54 ms per token,    53.93 tokens per second)\n",
      "llama_print_timings:        eval time =  3832.49 ms /    31 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5171.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.00 ms /    23 runs   (    0.57 ms per token,  1769.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2775.37 ms /    23 runs   (  120.67 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2842.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c} Real, direta.'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.07 ms /    32 runs   (    0.56 ms per token,  1770.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3880.81 ms /    32 runs   (  121.28 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3975.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.75 ms /    33 runs   (    0.57 ms per token,  1759.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4033.75 ms /    33 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4130.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.12 ms /    30 runs   (    0.57 ms per token,  1752.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3654.56 ms /    30 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3743.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.47 ms /    22 runs   (    0.57 ms per token,  1764.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2669.61 ms /    22 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2733.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.17 ms /    32 runs   (    0.57 ms per token,  1761.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3876.05 ms /    32 runs   (  121.13 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3970.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.72 ms /    26 runs   (    0.57 ms per token,  1766.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3172.12 ms /    26 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3247.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.16 ms /    25 runs   (    0.57 ms per token,  1766.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3059.15 ms /    25 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3132.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.74 ms /    12 runs   (    0.56 ms per token,  1781.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1458.79 ms /    12 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  1493.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 30: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the alternative that correctly correlates the classes of antibacterials to their respective main sites of action.\n",
      "\n",
      "I- Cephalosporins\n",
      "II- Tetracyclines\n",
      "III- Quinolones\n",
      "IV- Macrolides\n",
      "\n",
      "A- Protein synthesis (30s inhibitor)\n",
      "B- Protein synthesis (50s inhibitor)\n",
      "C DNA gyrase\n",
      "D- Cell wall synthesis\n",
      "\n",
      "a) I: A; II: D; III: D; IV: b.\n",
      "b)I:D; II: A; III: C; IV: b.\n",
      "c) I: A; II: D; III: B; IV: c.\n",
      "d)I:D; II: B; III: A; IV: c.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    76.95 ms /   133 runs   (    0.58 ms per token,  1728.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3974.68 ms /   180 tokens (   22.08 ms per token,    45.29 tokens per second)\n",
      "llama_print_timings:        eval time = 16294.69 ms /   132 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 20675.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.91 ms /    27 runs   (    0.55 ms per token,  1810.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3293.78 ms /    27 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3372.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.92 ms /   136 runs   (    0.57 ms per token,  1745.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16913.89 ms /   136 runs   (  124.37 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 17329.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.09 ms /   170 runs   (    0.57 ms per token,  1750.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21063.23 ms /   170 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 21587.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.55 ms /   187 runs   (    0.57 ms per token,  1755.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22906.42 ms /   187 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 23480.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    82.80 ms /   145 runs   (    0.57 ms per token,  1751.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17789.22 ms /   145 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 18229.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.80 ms /    61 runs   (    0.57 ms per token,  1752.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7650.55 ms /    61 runs   (  125.42 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  7832.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.39 ms /   155 runs   (    0.57 ms per token,  1753.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18972.51 ms /   155 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 19446.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.35 ms /   187 runs   (    0.57 ms per token,  1758.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22964.04 ms /   187 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 23537.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.75 ms /   165 runs   (    0.57 ms per token,  1760.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20431.35 ms /   165 runs   (  123.83 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 20936.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que correlaciona corretamente as classes de antibacterianos aos seus respectivos principais stios de ao.\n",
      "\n",
      "I- Cefalosporinas\n",
      "II- Tetraciclnicas\n",
      "III- Quinolonas\n",
      "IV- Macroldeos\n",
      "\n",
      "A- Sntese proteica (inibidor 30s)\n",
      "B- Sntese proteica (inibidor 50s)\n",
      "C- DNA girase\n",
      "D- Sntese de parede celular\n",
      "\n",
      "a)I: A; II: D; III: D; IV: B.\n",
      "b)I: D; II: A; III: C; IV: B.\n",
      "c)I: A; II: D; III: B; IV: C.\n",
      "d)I: D; II: B; III: A; IV: C.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.44 ms /    44 runs   (    0.58 ms per token,  1729.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3809.11 ms /   206 tokens (   18.49 ms per token,    54.08 tokens per second)\n",
      "llama_print_timings:        eval time =  5328.22 ms /    43 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  9270.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.40 ms /     7 runs   (    0.49 ms per token,  2056.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.88 ms /     7 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.01 ms /    43 runs   (    0.56 ms per token,  1791.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5275.78 ms /    43 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5402.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.21 ms /    44 runs   (    0.55 ms per token,  1817.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5387.96 ms /    44 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5516.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.41 ms /     7 runs   (    0.49 ms per token,  2051.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.26 ms /     7 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   877.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.31 ms /    44 runs   (    0.55 ms per token,  1809.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5437.81 ms /    44 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5568.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.26 ms /    44 runs   (    0.55 ms per token,  1813.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5401.53 ms /    44 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5531.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.43 ms /     7 runs   (    0.49 ms per token,  2038.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.11 ms /     7 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.91 ms /   161 runs   (    0.57 ms per token,  1751.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20014.24 ms /   161 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 20508.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    95.67 ms /   161 runs   (    0.59 ms per token,  1682.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19908.96 ms /   161 runs   (  123.66 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 20412.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 31: \n",
      "Language: english\n",
      "Question: \n",
      "A patient with Sjogren's syndrome started to have improvements in his oral symptoms (increased salivation) after the non-ophthalmologist prescribed:\n",
      "a) Brimonidine, however, evolved with punctiform miosis and low vision.\n",
      "b) Tetracaine, however, evolved with traditional retinal detachment.\n",
      "c) Atropine, however, evolved with medium medriasis and accommodation difficulties.\n",
      "d) Pilocarpine, however, evolved with accommodative spasm.\n",
      "Test #0: \n",
      "{'response': 'd) Pilocarpine'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.45 ms /    32 runs   (    0.58 ms per token,  1734.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2666.97 ms /   127 tokens (   21.00 ms per token,    47.62 tokens per second)\n",
      "llama_print_timings:        eval time =  3769.51 ms /    31 runs   (  121.60 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  6531.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.30 ms /    44 runs   (    0.58 ms per token,  1738.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5407.67 ms /    44 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5538.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine, however, evolved with accommodative spasm.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.55 ms /    14 runs   (    0.61 ms per token,  1637.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1713.76 ms /    14 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1757.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.87 ms /    30 runs   (    0.73 ms per token,  1371.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3620.84 ms /    30 runs   (  120.69 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3723.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine'}\n",
      "Test #4: \n",
      "{'response': 'd) Pilocarpine, however, evolved with accommodative spasm.'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.70 ms /    40 runs   (    0.57 ms per token,  1762.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4877.26 ms /    40 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4996.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.67 ms /    33 runs   (    0.57 ms per token,  1767.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4040.41 ms /    33 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4137.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.07 ms /    41 runs   (    0.56 ms per token,  1777.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5052.03 ms /    41 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5173.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine, however, evolved with accommodative spasm.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.02 ms /    41 runs   (    0.56 ms per token,  1781.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5082.93 ms /    41 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  5204.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine, however, evolved with accommodative spasm.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.85 ms /    30 runs   (    0.56 ms per token,  1780.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3719.93 ms /    30 runs   (  124.00 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3809.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.91 ms /    37 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4623.64 ms /    37 runs   (  124.96 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  4733.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpine, however, evolved with accommodative spasm.'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente com sndrome Sjogren passou a ter melhoras dos seus sintomas orais (aumento da salivao) aps o mdico no-oftalmologista prescrever:\n",
      "a)Brimonidina, todavia, evoluiu com miose puntiforme e baixa de viso.\n",
      "b)Tetracana, todavia, evoluiu com descolamento de retina tradicional.\n",
      "c)Atropina, todavia, evoluiu com mdia medrase e dificuldades de acomodao.\n",
      "d)Pilocarpina, todavia, evoluiu com espasmo acomodativo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.93 ms /    48 runs   (    0.58 ms per token,  1718.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3761.16 ms /   159 tokens (   23.66 ms per token,    42.27 tokens per second)\n",
      "llama_print_timings:        eval time =  5861.08 ms /    47 runs   (  124.70 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  9766.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.53 ms /    48 runs   (    0.59 ms per token,  1682.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5941.88 ms /    48 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6087.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.62 ms /    48 runs   (    0.58 ms per token,  1737.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5892.21 ms /    48 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6035.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   880.23 ms /     7 runs   (  125.75 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =   901.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.45 ms /    11 runs   (    0.59 ms per token,  1704.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1344.19 ms /    11 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  1376.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.44 ms /     7 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   889.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1739.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3471.38 ms /    28 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3554.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.61 ms /    48 runs   (    0.58 ms per token,  1738.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5979.25 ms /    48 runs   (  124.57 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  6123.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.68 ms /   115 runs   (    0.58 ms per token,  1724.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14101.88 ms /   115 runs   (  122.62 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 14450.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.55 ms /    49 runs   (    0.58 ms per token,  1716.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6068.83 ms /    49 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6215.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Pilocarpina, todavia, evoluiu com espasmo acomodativo.'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 32: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the use of tissue plasminogen activating factor, it is correct to state:\n",
      "a) This medication in the intracameral space is proscribed.\n",
      "b) Activation of plasmin into plaminogen helps in the degradation of blood.\n",
      "c) Activation of plasminogen to plasmin helps in the degradation of blood.\n",
      "d) Its main indication is in bleeding in the vitreous space.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.61 ms /    25 runs   (    0.58 ms per token,  1711.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2512.99 ms /   107 tokens (   23.49 ms per token,    42.58 tokens per second)\n",
      "llama_print_timings:        eval time =  2915.81 ms /    24 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5503.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.95 ms /   101 runs   (    0.58 ms per token,  1713.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12391.15 ms /   101 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12702.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.97 ms /    25 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3054.23 ms /    25 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3129.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.79 ms /    24 runs   (    0.57 ms per token,  1740.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2926.67 ms /    24 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2996.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.29 ms /    46 runs   (    0.57 ms per token,  1749.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5623.35 ms /    46 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5760.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1723.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3055.07 ms /    25 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3128.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1739.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3054.06 ms /    25 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3127.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.88 ms /    24 runs   (    0.58 ms per token,  1729.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2951.93 ms /    24 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3022.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.50 ms /    25 runs   (    0.58 ms per token,  1724.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3041.58 ms /    25 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3114.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.12 ms /    44 runs   (    0.57 ms per token,  1751.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5339.76 ms /    44 runs   (  121.36 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5469.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao ao uso de fator ativador do plasminognio tecidual,  correto afirmar:\n",
      "a)Essa medicao no espao intracameral  proscrita.\n",
      "b)A ativao da plasmina em plaminognio ajuda na degradao do sangue.\n",
      "c)A ativao do plasminognio em plasmina ajuda na degradao do sangue.\n",
      "d)Sua maior indicao  em sangramentos no espao vtreo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.23 ms /     7 runs   (    0.60 ms per token,  1654.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3205.29 ms /   135 tokens (   23.74 ms per token,    42.12 tokens per second)\n",
      "llama_print_timings:        eval time =   725.56 ms /     6 runs   (  120.93 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3952.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.73 ms /    27 runs   (    0.58 ms per token,  1716.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3287.59 ms /    27 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3367.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.30 ms /    62 runs   (    0.59 ms per token,  1707.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7666.27 ms /    62 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  7855.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1741.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2930.63 ms /    24 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3001.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.17 ms /    35 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4352.24 ms /    35 runs   (  124.35 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  4455.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  ####\n",
      "\n",
      "Resposta: c) A ativao do plasminognio em plasmina ajuda na degradao do sangue.\n",
      "Generating new response...\n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   877.50 ms /     7 runs   (  125.36 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =   897.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.35 ms /    25 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3033.87 ms /    25 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3107.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1741.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2939.06 ms /    24 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3009.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3426.76 ms /    28 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3509.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    28 runs   (    0.58 ms per token,  1732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3526.96 ms /    28 runs   (  125.96 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  3609.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.46 ms /     7 runs   (  126.49 ms per token,     7.91 tokens per second)\n",
      "llama_print_timings:       total time =   906.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 33: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the use of mitomycin-C in trabeculectomy, it is correct to state:\n",
      "a) Because it is a pyrimidine analogue, its action stems from the blockage of thymine synthesis, preventing the production of DNA/RNA.\n",
      "b) Scleral thinning, avascular bleb, postoperative pain and corneal edema are complications related to its use.\n",
      "c) In pregnant women, the concentration should be increased due to a greater tendency to fibrosis.\n",
      "d) It should not be used in melanodermic patients.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.72 ms /   100 runs   (    0.58 ms per token,  1732.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3172.82 ms /   143 tokens (   22.19 ms per token,    45.07 tokens per second)\n",
      "llama_print_timings:        eval time = 12159.51 ms /    99 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 15634.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.73 ms /   131 runs   (    0.58 ms per token,  1729.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16184.64 ms /   131 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 16585.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   129.34 ms /   224 runs   (    0.58 ms per token,  1731.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27673.44 ms /   224 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 28377.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.90 ms /    62 runs   (    0.58 ms per token,  1727.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7617.52 ms /    62 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7802.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.14 ms /    63 runs   (    0.57 ms per token,  1743.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7773.22 ms /    63 runs   (  123.38 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  7961.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.70 ms /    55 runs   (    0.58 ms per token,  1734.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6747.28 ms /    55 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6909.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.20 ms /     9 runs   (    0.58 ms per token,  1731.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1101.11 ms /     9 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1127.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.17 ms /   109 runs   (    0.58 ms per token,  1725.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13441.26 ms /   109 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 13770.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.04 ms /    97 runs   (    0.58 ms per token,  1730.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11900.74 ms /    97 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12192.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.29 ms /   101 runs   (    0.58 ms per token,  1732.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12323.41 ms /   101 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 12630.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao ao uso de mitomicina-C na trabeculectomia,  correto afirmar:\n",
      "a)Por ser um anlogo da pirimidina, sua ao decorre do bloqueio da sntese de timina, evitando a produo de DNA/RNA.\n",
      "b)Afinamento escleral, bolha avascular, dor ps-operatria e edema de crnea so complicaes relacionadas ao seu uso.\n",
      "c)Nas gestantes, a concentrao deve ser aumentada pela maior tendncia  fibrose.\n",
      "d)No deve ser usada em pacientes melanodrmicos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   120.14 ms /   206 runs   (    0.58 ms per token,  1714.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3271.46 ms /   161 tokens (   20.32 ms per token,    49.21 tokens per second)\n",
      "llama_print_timings:        eval time = 25475.78 ms /   205 runs   (  124.27 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 29395.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.57 ms /    81 runs   (    0.57 ms per token,  1739.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9956.42 ms /    81 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10198.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.24 ms /    82 runs   (    0.58 ms per token,  1735.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10132.37 ms /    82 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 10378.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.46 ms /    82 runs   (    0.58 ms per token,  1727.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10048.75 ms /    82 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 10293.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.02 ms /    31 runs   (    0.58 ms per token,  1720.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3780.82 ms /    31 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3874.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.42 ms /     7 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.86 ms /   100 runs   (    0.58 ms per token,  1728.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12353.92 ms /   100 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 12659.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.46 ms /   103 runs   (    0.58 ms per token,  1732.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12720.52 ms /   103 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13037.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.35 ms /     7 runs   (  121.05 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.64 ms /    17 runs   (    0.57 ms per token,  1764.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2091.38 ms /    17 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2144.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 34: \n",
      "Language: english\n",
      "Question: \n",
      "Patients with proliferative diabetic retinopathy will complement their treatment with intravitreal anti-VEGF. We can state that:\n",
      "a) Priority should be given to the inhibition of the B isoforms of VEGF, since they are the main new vessel formers.\n",
      "b)Ranibizumab inhibits all VEGF-B isoforms, but not VEGF-A.\n",
      "c) Bevacizumab does not allow VEGF-A isoforms to bind to their receptors.\n",
      "d) The use of pegaptanib is no longer used, as the drug does not penetrate the retinal layers.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.23 ms /   179 runs   (    0.59 ms per token,  1685.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2586.40 ms /   162 tokens (   15.97 ms per token,    62.64 tokens per second)\n",
      "llama_print_timings:        eval time = 21993.05 ms /   178 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 25147.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3403.79 ms /    28 runs   (  121.56 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3486.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   119.07 ms /   205 runs   (    0.58 ms per token,  1721.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25261.60 ms /   205 runs   (  123.23 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 25903.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    98.13 ms /   170 runs   (    0.58 ms per token,  1732.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21050.83 ms /   170 runs   (  123.83 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 21572.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.31 ms /    56 runs   (    0.58 ms per token,  1732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6790.17 ms /    56 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  6955.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.42 ms /    65 runs   (    0.58 ms per token,  1736.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7989.05 ms /    65 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  8184.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.53 ms /    20 runs   (    0.58 ms per token,  1734.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2491.76 ms /    20 runs   (  124.59 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  2552.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.06 ms /    17 runs   (    0.59 ms per token,  1689.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2207.55 ms /    17 runs   (  129.86 ms per token,     7.70 tokens per second)\n",
      "llama_print_timings:       total time =  2261.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3423.94 ms /    28 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3507.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.69 ms /   205 runs   (    0.58 ms per token,  1727.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25307.35 ms /   205 runs   (  123.45 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 25964.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente com retinopatia diabtica proliferativa complementar seu tratamento com anti-VEGF intravtreo. Podemos afirmar que:\n",
      "a)Deve-se priorizar a inibio das isoformas B do VEGF, uma vez que so as principais formadoras de neovasos.\n",
      "b)O ranibizumabe inibe todas as isoformas do VEGF-B, mas no as de VEGF-A.\n",
      "c)O bevacizumabe no permite que as isoformas de VEFG-A se liguem aos seus receptores.\n",
      "d)O uso de pegaptanibe no  mais utilizado, pois a droga no penetra nas camadas da retina.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.02 ms /    86 runs   (    0.59 ms per token,  1685.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3719.99 ms /   186 tokens (   20.00 ms per token,    50.00 tokens per second)\n",
      "llama_print_timings:        eval time = 10417.25 ms /    85 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 14411.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.93 ms /   119 runs   (    0.58 ms per token,  1726.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14707.55 ms /   119 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15076.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.40 ms /   133 runs   (    0.58 ms per token,  1718.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16435.44 ms /   133 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 16841.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   104.22 ms /   181 runs   (    0.58 ms per token,  1736.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22403.46 ms /   181 runs   (  123.78 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 22965.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.12 ms /     7 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.61 ms /    20 runs   (    0.58 ms per token,  1722.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2519.74 ms /    20 runs   (  125.99 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  2578.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   105.73 ms /   181 runs   (    0.58 ms per token,  1711.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22313.09 ms /   181 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 22884.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   104.56 ms /   181 runs   (    0.58 ms per token,  1731.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22414.40 ms /   181 runs   (  123.84 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 22979.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.37 ms /     7 runs   (  120.20 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3497.59 ms /    28 runs   (  124.91 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3580.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 35: \n",
      "Language: english\n",
      "Question: \n",
      "Considering conjunctival tumors, the presence of which parameter below is used to differentiate between conjunctival dysplasia and invasive carcinoma?\n",
      "a) Cellular atypia.\n",
      "b) Involvement of the epithelial full thickness.\n",
      "c)Increase in the number of atypical nucleoli.\n",
      "d) Invasion of the basement membrane.\n",
      " \n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.00 ms /    36 runs   (    0.58 ms per token,  1714.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2265.33 ms /    95 tokens (   23.85 ms per token,    41.94 tokens per second)\n",
      "llama_print_timings:        eval time =  4263.10 ms /    35 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6637.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.20 ms /    35 runs   (    0.58 ms per token,  1732.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4300.58 ms /    35 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4405.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Invasion of the basement membrane.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.14 ms /    71 runs   (    0.58 ms per token,  1725.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8663.00 ms /    71 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  8880.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.46 ms /    79 runs   (    0.58 ms per token,  1737.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9686.67 ms /    79 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  9927.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.80 ms /    64 runs   (    0.57 ms per token,  1739.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7793.61 ms /    64 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  7985.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.43 ms /    77 runs   (    0.58 ms per token,  1733.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9424.11 ms /    77 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  9655.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.85 ms /    36 runs   (    0.61 ms per token,  1647.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4396.46 ms /    36 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4551.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    25 runs   (    0.65 ms per token,  1547.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3056.07 ms /    25 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3228.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.67 ms /    36 runs   (    0.66 ms per token,  1521.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4486.33 ms /    36 runs   (  124.62 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  4733.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.55 ms /   143 runs   (    0.60 ms per token,  1671.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17593.09 ms /   143 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18203.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Considerando os tumores conjuntivais, a presena de qual parmetro abaixo  utilizado para a diferenciao entre displasia da conjuntiva e carcinoma invasivo?\n",
      "a)Atipia celular.\n",
      "b)Envolvimento da espessura total epitelial.\n",
      "c)Aumento do nmero de nucleolos atpicos.\n",
      "d)Invaso da membrana basal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.35 ms /    91 runs   (    0.59 ms per token,  1705.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2552.97 ms /   104 tokens (   24.55 ms per token,    40.74 tokens per second)\n",
      "llama_print_timings:        eval time = 11074.84 ms /    90 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 13908.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.67 ms /    41 runs   (    0.58 ms per token,  1732.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5003.86 ms /    41 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5124.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3326.14 ms /    27 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3405.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3311.26 ms /    27 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3391.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.87 ms /    50 runs   (    0.58 ms per token,  1731.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6221.58 ms /    50 runs   (  124.43 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  6371.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   882.52 ms /     7 runs   (  126.07 ms per token,     7.93 tokens per second)\n",
      "llama_print_timings:       total time =   903.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.16 ms /    40 runs   (    0.58 ms per token,  1727.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4885.04 ms /    40 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5005.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    28 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3472.39 ms /    28 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3556.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.67 ms /    99 runs   (    0.58 ms per token,  1716.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12167.58 ms /    99 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 12469.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.93 ms /    27 runs   (    0.59 ms per token,  1694.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3319.61 ms /    27 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3400.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 36: \n",
      "Language: english\n",
      "Question: \n",
      "Fluorescein-labelled monoclonal antibodies (FITC) directed against the outer membrane cell wall protein are a better diagnostic method for which of the agents listed below?\n",
      "a) C. trachomatis.\n",
      "b) Acanthamoeba sp.\n",
      "c)Cryptococcus sp.\n",
      "d) Neisseria meningitidis.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.06 ms /    24 runs   (    0.59 ms per token,  1706.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2270.78 ms /    93 tokens (   24.42 ms per token,    40.96 tokens per second)\n",
      "llama_print_timings:        eval time =  2794.46 ms /    23 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5137.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2954.90 ms /    24 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3026.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.01 ms /    24 runs   (    0.58 ms per token,  1712.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2971.03 ms /    24 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3042.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.92 ms /    24 runs   (    0.58 ms per token,  1724.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2984.90 ms /    24 runs   (  124.37 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3056.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2922.22 ms /    24 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2993.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1727.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2952.30 ms /    24 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3024.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.64 ms /    27 runs   (    0.58 ms per token,  1726.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3329.75 ms /    27 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3410.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.73 ms /    24 runs   (    0.57 ms per token,  1747.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2940.57 ms /    24 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3011.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.48 ms /    25 runs   (    0.58 ms per token,  1726.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3025.42 ms /    25 runs   (  121.02 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3099.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    27 runs   (    0.58 ms per token,  1732.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3292.40 ms /    27 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3372.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Anticorpos monoclonais marcados com fluorescena (FITC) e dirigidos contra a membrana externa proteica da parede celular so um mtodo diagnstico mais bem indicado para qual dos agentes listados abaixo?\n",
      "a)C. tracomatis.\n",
      "b)Acanthamoeba sp.\n",
      "c)Cryptococcus sp.\n",
      "d)Neisseria meningitidis.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.28 ms /    28 runs   (    0.58 ms per token,  1720.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2231.53 ms /   109 tokens (   20.47 ms per token,    48.85 tokens per second)\n",
      "llama_print_timings:        eval time =  3294.90 ms /    27 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5610.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.87 ms /    27 runs   (    0.59 ms per token,  1701.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3330.14 ms /    27 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3412.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3286.73 ms /    27 runs   (  121.73 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3367.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.45 ms /    25 runs   (    0.58 ms per token,  1730.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3058.92 ms /    25 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3132.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3282.49 ms /    27 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3362.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.80 ms /    24 runs   (    0.57 ms per token,  1739.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2910.43 ms /    24 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2983.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3312.14 ms /    27 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3392.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3409.37 ms /    28 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3493.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.07 ms /    28 runs   (    0.57 ms per token,  1741.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3473.51 ms /    28 runs   (  124.05 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3557.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.65 ms /    36 runs   (    0.57 ms per token,  1743.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4378.60 ms /    36 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4486.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 37: \n",
      "Language: english\n",
      "Question: \n",
      "The innervation of the cornea is mainly done by which ciliary nerves?\n",
      "a) Short anterior.\n",
      "b) Short posterior.\n",
      "c) Long anterior.\n",
      "d) Long posterior.\n",
      "\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.29 ms /    39 runs   (    0.57 ms per token,  1749.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   762.98 ms /    50 tokens (   15.26 ms per token,    65.53 tokens per second)\n",
      "llama_print_timings:        eval time =  4702.99 ms /    38 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  5584.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    28 runs   (    0.57 ms per token,  1750.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3397.02 ms /    28 runs   (  121.32 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3480.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.85 ms /    28 runs   (    0.57 ms per token,  1766.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3386.84 ms /    28 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3469.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.75 ms /    31 runs   (    0.57 ms per token,  1746.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3739.85 ms /    31 runs   (  120.64 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3832.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.90 ms /    21 runs   (    0.57 ms per token,  1764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2563.43 ms /    21 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2624.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.85 ms /    12 runs   (    0.57 ms per token,  1751.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1454.11 ms /    12 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  1488.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) Short posterior'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.03 ms /    28 runs   (    0.57 ms per token,  1746.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3436.17 ms /    28 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3520.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.41 ms /    27 runs   (    0.57 ms per token,  1752.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3308.63 ms /    27 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3389.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.84 ms /    28 runs   (    0.57 ms per token,  1768.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3380.22 ms /    28 runs   (  120.72 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3463.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c} Long anterior.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.24 ms /    11 runs   (    0.57 ms per token,  1762.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1399.09 ms /    11 runs   (  127.19 ms per token,     7.86 tokens per second)\n",
      "llama_print_timings:       total time =  1431.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A inervao da crnea  feita, principalmente, por quais nervos ciliares?\n",
      "a)Anteriores curtos.\n",
      "b)Posteriores curtos.\n",
      "c)Anteriores longos.\n",
      "d)Posteriores longos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1736.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1709.00 ms /    69 tokens (   24.77 ms per token,    40.37 tokens per second)\n",
      "llama_print_timings:        eval time =  3293.05 ms /    27 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5086.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.71 ms /    28 runs   (    0.56 ms per token,  1782.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3418.98 ms /    28 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3502.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.29 ms /    24 runs   (    0.55 ms per token,  1806.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2905.13 ms /    24 runs   (  121.05 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2976.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.90 ms /    25 runs   (    0.56 ms per token,  1798.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3033.26 ms /    25 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3107.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.14 ms /    27 runs   (    0.56 ms per token,  1783.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3275.28 ms /    27 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3354.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.70 ms /    28 runs   (    0.56 ms per token,  1783.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3432.64 ms /    28 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3515.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.77 ms /    28 runs   (    0.56 ms per token,  1775.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3409.12 ms /    28 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3493.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.43 ms /    24 runs   (    0.56 ms per token,  1786.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2905.73 ms /    24 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2976.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1766.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.37 ms /     7 runs   (  120.62 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.08 ms /    28 runs   (    0.57 ms per token,  1741.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3411.12 ms /    28 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3494.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 38: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following extrinsic ocular muscles is innervated by the superior division of the oculomotor nerve?\n",
      "a) Superior oblique.\n",
      "b) Inferior rectum.\n",
      "c) medial rectus\n",
      "d) Superior rectum.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.64 ms /    25 runs   (    0.59 ms per token,  1707.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1639.82 ms /    66 tokens (   24.85 ms per token,    40.25 tokens per second)\n",
      "llama_print_timings:        eval time =  2883.88 ms /    24 runs   (  120.16 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  4598.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3391.32 ms /    28 runs   (  121.12 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3474.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.65 ms /    29 runs   (    0.57 ms per token,  1741.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3508.76 ms /    29 runs   (  120.99 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3595.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.79 ms /    24 runs   (    0.57 ms per token,  1740.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2910.49 ms /    24 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2981.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3264.57 ms /    27 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3344.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.87 ms /    33 runs   (    0.57 ms per token,  1749.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4030.33 ms /    33 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4129.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.22 ms /    30 runs   (    0.57 ms per token,  1742.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3705.87 ms /    30 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3795.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.75 ms /    24 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2996.76 ms /    24 runs   (  124.87 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3068.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.14 ms /    60 runs   (    0.57 ms per token,  1757.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7300.32 ms /    60 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7480.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.42 ms /    60 runs   (    0.57 ms per token,  1743.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7308.32 ms /    60 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  7489.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual dos msculos oculares extrnsecos abaixo  inervado pela diviso superior do nervo oculomotor?\n",
      "a)Oblquo superior.\n",
      "b)Reto inferior.\n",
      "c)Reto medial\n",
      "d)Reto superior.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.23 ms /    43 runs   (    0.59 ms per token,  1703.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1698.07 ms /    71 tokens (   23.92 ms per token,    41.81 tokens per second)\n",
      "llama_print_timings:        eval time =  5095.03 ms /    42 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  6921.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.41 ms /    43 runs   (    0.57 ms per token,  1761.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5236.72 ms /    43 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5362.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.38 ms /     7 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   887.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3380.67 ms /    28 runs   (  120.74 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3463.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1720.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.45 ms /     7 runs   (  120.64 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1754.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.51 ms /     7 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   885.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.08 ms /    42 runs   (    0.57 ms per token,  1744.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5095.21 ms /    42 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5219.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.96 ms /     7 runs   (  124.42 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.11 ms /    42 runs   (    0.57 ms per token,  1741.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5100.80 ms /    42 runs   (  121.45 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5226.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 39: \n",
      "Language: english\n",
      "Question: \n",
      "Based on anatomical knowledge, choose the most likely alternative.\n",
      "a) Fracture of the ethmoid bone can cause orbital emphysema.\n",
      "b) Fracture of the lateral part of the orbit can cause intraorbital hemorrhage, due to rupture of the anterior and posterior ethmoidal arteries.\n",
      "c) Fracture of the orbital floor can cause impairment of masticatory movements, due to damage to the maxillary nerve, a branch of the trigeminal nerve.\n",
      "d) Fracture of the lacrimal bone may decrease tear excretion by the main lacrimal gland, by compromising the lacrimal nerve.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.01 ms /    42 runs   (    0.64 ms per token,  1554.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5114.43 ms /    42 runs   (  121.77 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5246.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.00 ms /    24 runs   (    0.58 ms per token,  1714.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3612.94 ms /   165 tokens (   21.90 ms per token,    45.67 tokens per second)\n",
      "llama_print_timings:        eval time =  2899.34 ms /    23 runs   (  126.06 ms per token,     7.93 tokens per second)\n",
      "llama_print_timings:       total time =  6584.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.51 ms /    24 runs   (    0.69 ms per token,  1453.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2984.98 ms /    24 runs   (  124.37 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3062.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n",
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.41 ms /    25 runs   (    0.66 ms per token,  1523.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3102.28 ms /    25 runs   (  124.09 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3181.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.91 ms /    28 runs   (    0.60 ms per token,  1655.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3475.59 ms /    28 runs   (  124.13 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3560.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1740.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3077.14 ms /    25 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3150.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    28 runs   (    0.58 ms per token,  1728.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3443.44 ms /    28 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3527.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2952.87 ms /    24 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3024.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.27 ms /     7 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1725.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3088.47 ms /    25 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3162.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1734.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3428.34 ms /    28 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3510.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com base em conhecimentos anatmicos, escolha a alternativa mais provvel.\n",
      "a)Fratura do osso etmoidal pode causar enfisema orbitrio.\n",
      "b)Fratura da parte lateral da rbita pode causar hemorragia intraorbital, por ruptura das artrias etmoidais anteriores e posteriores.\n",
      "c)Fratura do assoalho da rbita pode causar comprometimento dos movimentos mastigatrios, por leso no nervo maxilar, ramo do nervo trigmeo.\n",
      "d)Fratura do osso lacrimal pode diminuir a excreo de lgrima pela glndula lacrimal principal, por comprometimento do nervo lacrimal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.31 ms /    28 runs   (    0.58 ms per token,  1716.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3234.90 ms /   183 tokens (   17.68 ms per token,    56.57 tokens per second)\n",
      "llama_print_timings:        eval time =  3412.01 ms /    27 runs   (  126.37 ms per token,     7.91 tokens per second)\n",
      "llama_print_timings:       total time =  6730.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.41 ms /   134 runs   (    0.58 ms per token,  1731.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16400.88 ms /   134 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 16808.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1723.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3125.24 ms /    25 runs   (  125.01 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  3199.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.41 ms /    65 runs   (    0.58 ms per token,  1737.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8101.13 ms /    65 runs   (  124.63 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  8296.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.48 ms /   134 runs   (    0.58 ms per token,  1729.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16435.12 ms /   134 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 16843.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.64 ms /     7 runs   (  123.23 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   883.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.74 ms /    17 runs   (    0.57 ms per token,  1745.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2087.73 ms /    17 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2137.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.49 ms /    27 runs   (    0.57 ms per token,  1743.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3356.97 ms /    27 runs   (  124.33 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3436.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.18 ms /    75 runs   (    0.58 ms per token,  1737.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9236.45 ms /    75 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9461.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.83 ms /    24 runs   (    0.58 ms per token,  1735.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2934.86 ms /    24 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3005.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 40: \n",
      "Language: english\n",
      "Question: \n",
      "There are many factors that contribute to the transparency of the cornea, but the main one is:\n",
      "a) Absence of adhesion proteoglycans, increasing the loose interfibrillar space and allowing free passage of light.\n",
      "b) Low metabolic demand, which allows nutrition by a reticular mesh of extremely fine stromal capillaries.\n",
      "c) Hyperosmotic characteristic of Descemet's membrane, which reduces stromal hydration.\n",
      "d) Organization of collagen fibrils in a regular, uniform and parallel way to each other.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.17 ms /    19 runs   (    0.59 ms per token,  1700.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2887.99 ms /   137 tokens (   21.08 ms per token,    47.44 tokens per second)\n",
      "llama_print_timings:        eval time =  2219.12 ms /    18 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5164.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.56 ms /    25 runs   (    0.58 ms per token,  1716.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3067.06 ms /    25 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3141.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3469.85 ms /    28 runs   (  123.92 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3552.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.80 ms /    17 runs   (    0.58 ms per token,  1735.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2088.86 ms /    17 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2138.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.02 ms /    24 runs   (    0.58 ms per token,  1712.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2916.01 ms /    24 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2987.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2449.04 ms /    20 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2507.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1737.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3055.10 ms /    25 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3129.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.55 ms /    20 runs   (    0.58 ms per token,  1731.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2448.86 ms /    20 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2508.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.78 ms /    29 runs   (    0.58 ms per token,  1728.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3516.47 ms /    29 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3602.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.15 ms /    21 runs   (    0.58 ms per token,  1728.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2575.55 ms /    21 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2637.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Muitos so os fatores que contribuem para a transparncia da crnea, mas o principal deles :\n",
      "a)Ausncia de proteoglicanos de adeso, aumentando o espao interfibrilar frouxo e permitindo a passagem livre da luz.\n",
      "b)Baixa demanda metablica, que permite a nutrio por uma malha reticular de capilares estromais extremamente finos.\n",
      "c)Caracterstica hiperosmtica da membrana de Descemet, que reduz a hidratao estromal.\n",
      "d)Organizao das fibrilas de colgeno de forma regular, uniforme e paralela umas s outras.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1694.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3339.48 ms /   173 tokens (   19.30 ms per token,    51.80 tokens per second)\n",
      "llama_print_timings:        eval time =   728.51 ms /     6 runs   (  121.42 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4088.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.72 ms /    20 runs   (    0.59 ms per token,  1706.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2495.45 ms /    20 runs   (  124.77 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  2555.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    27 runs   (    0.59 ms per token,  1682.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3317.72 ms /    27 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3400.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1738.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3444.36 ms /    28 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3527.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.52 ms /    27 runs   (    0.57 ms per token,  1739.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3335.28 ms /    27 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3415.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1745.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3395.29 ms /    28 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3478.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   873.42 ms /     7 runs   (  124.77 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =   893.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.50 ms /    20 runs   (    0.57 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2501.96 ms /    20 runs   (  125.10 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  2561.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1749.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.72 ms /     7 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3458.85 ms /    28 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3543.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 41: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding the anatomy of the posterior segment of the eye.\n",
      "a) The emergence of the two long ciliary nerves at the equator of the eye, approximately at twelve and six o'clock, explains greater sensitivity to pain in these quadrants during panphotocoagulation.\n",
      "b) The subretinal vorticose arteries give the lacy \"tiger\" appearance in the ophthalmoscopic examination of people with diffuse atrophy of the retinal pigment epithelium.\n",
      "c) In the ora serrata, there are small radial meridional folds next to the dentate processes, with, eventually, a small atrophic retinal hole at its base, which does not need to be blocked.\n",
      "d) The foveola, area of greater metabolic activity due to the high concentration of photoreceptors, presents an intense vascular network formed by anastomoses of the superior and inferior temporal arcades.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.50 ms /    78 runs   (    0.58 ms per token,  1714.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3700.39 ms /   230 tokens (   16.09 ms per token,    62.16 tokens per second)\n",
      "llama_print_timings:        eval time =  9507.78 ms /    77 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13447.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.86 ms /    76 runs   (    0.58 ms per token,  1732.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9359.43 ms /    76 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9592.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.47 ms /    79 runs   (    0.58 ms per token,  1737.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9745.00 ms /    79 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9984.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.33 ms /    84 runs   (    0.58 ms per token,  1738.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10367.48 ms /    84 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10621.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1702.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   872.09 ms /     7 runs   (  124.58 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   893.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.95 ms /    77 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9495.13 ms /    77 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9728.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.59 ms /    93 runs   (    0.58 ms per token,  1735.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11472.06 ms /    93 runs   (  123.36 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 11751.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.79 ms /    76 runs   (    0.58 ms per token,  1735.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9386.38 ms /    76 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  9615.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.67 ms /    90 runs   (    0.57 ms per token,  1741.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11088.00 ms /    90 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11361.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.59 ms /    83 runs   (    0.57 ms per token,  1744.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10221.70 ms /    83 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 10473.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Marque a alternativa correta quanto  anatomia do segmento posterior do olho.\n",
      "a)A emergncia dos dois nervos ciliares longos no equador do olho, aproximadamente s doze e seis horas, explica maior sensibilidade  dor nesses quadrantes durante a panfotocoagulao.\n",
      "b)As artrias vorticosas sub-retinianas conferem o aspecto rendilhado \"em tigre\" no exame oftalmoscpico de pessoas com atrofia difusa do epitlio pigmentado da retina.\n",
      "c)Na ora serrata encontram-se pequenas pregas meridionais radiais junto aos processos denteados com, eventualmente pequeno buraco retiniano atrfico na sua base, que no necessita ser bloqueado.\n",
      "d)A fovola, rea de maior atividade metablica devido a alta concentrao de fotorreceptores, apresenta intensa rede vascular formada por anastomoses das arcadas temporais superiores e inferiores.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.97 ms /    20 runs   (    0.60 ms per token,  1670.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4591.80 ms /   263 tokens (   17.46 ms per token,    57.28 tokens per second)\n",
      "llama_print_timings:        eval time =  2340.18 ms /    19 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6992.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1715.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.92 ms /     7 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   876.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.69 ms /    97 runs   (    0.60 ms per token,  1652.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12022.96 ms /    97 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 12322.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.17 ms /   104 runs   (    0.61 ms per token,  1646.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12792.16 ms /   104 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 13116.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1728.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   887.23 ms /     7 runs   (  126.75 ms per token,     7.89 tokens per second)\n",
      "llama_print_timings:       total time =   909.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.21 ms /    20 runs   (    0.66 ms per token,  1514.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2505.18 ms /    20 runs   (  125.26 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  2567.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1735.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3527.54 ms /    28 runs   (  125.98 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  3612.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.83 ms /     7 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   885.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.21 ms /    64 runs   (    0.58 ms per token,  1720.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7998.94 ms /    64 runs   (  124.98 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  8193.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.44 ms /    91 runs   (    0.58 ms per token,  1735.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11201.50 ms /    91 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11476.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 42: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding the anatomy of the camerular sinus.\n",
      "a) Schwalbe's line corresponds to the gonioscopic projection of the scleral spur.\n",
      "b) The ciliary body band usually cannot be seen by gonioscopy.\n",
      "c) pectineal iris processes reaching Schwalbe's line are not present in normal eyes; and when found, they are indicative of previous iridocyclitis.\n",
      "d) The drainage flow of aqueous humor occurs mainly in the posterior portion of the trabecular meshwork, which is more pigmented.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.56 ms /   167 runs   (    0.58 ms per token,  1711.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3193.28 ms /   143 tokens (   22.33 ms per token,    44.78 tokens per second)\n",
      "llama_print_timings:        eval time = 20528.94 ms /   166 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 24241.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    89.01 ms /   154 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18969.33 ms /   154 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 19444.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   128.07 ms /   221 runs   (    0.58 ms per token,  1725.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27272.72 ms /   221 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 27967.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.86 ms /    67 runs   (    0.58 ms per token,  1724.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8284.37 ms /    67 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  8486.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.25 ms /    73 runs   (    0.58 ms per token,  1727.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8989.52 ms /    73 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9216.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.04 ms /    24 runs   (    0.58 ms per token,  1709.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2935.05 ms /    24 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3009.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   104.12 ms /   177 runs   (    0.59 ms per token,  1700.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21779.16 ms /   177 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 22343.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.59 ms /    67 runs   (    0.58 ms per token,  1736.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8194.16 ms /    67 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  8392.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.75 ms /    67 runs   (    0.58 ms per token,  1729.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8256.02 ms /    67 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8454.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   115.15 ms /   199 runs   (    0.58 ms per token,  1728.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24528.27 ms /   199 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 25151.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa correta quanto  anatomia do seio camerular.\n",
      "a)A linha de Schwalbe corresponde  projeo gonioscpica do esporo escleral.\n",
      "b)A banda do corpo ciliar geralmente no pode ser observada pela gonioscopia.\n",
      "c)Processos irianos pectneos que alcanam a linha de Schwalbe no esto presentes em olhos normais; e quando encontrados so indicativos de iridociclite prvia.\n",
      "d)O fluxo de drenagem do humor aquoso ocorre principalmente na poro posterior da malha trabecular, que  mais pigmentada.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.50 ms /    17 runs   (    0.62 ms per token,  1619.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2944.86 ms /   172 tokens (   17.12 ms per token,    58.41 tokens per second)\n",
      "llama_print_timings:        eval time =  1976.75 ms /    16 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4973.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.59 ms /    69 runs   (    0.59 ms per token,  1700.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8527.50 ms /    69 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  8737.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.85 ms /     7 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.52 ms /     7 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    27 runs   (    0.58 ms per token,  1732.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3294.31 ms /    27 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3374.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.77 ms /     7 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.52 ms /    20 runs   (    0.58 ms per token,  1735.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2446.98 ms /    20 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2506.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1695.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.31 ms /     7 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.87 ms /    90 runs   (    0.59 ms per token,  1702.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11135.12 ms /    90 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 11407.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.65 ms /    91 runs   (    0.58 ms per token,  1728.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11189.17 ms /    91 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 11464.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 43: \n",
      "Language: english\n",
      "Question: \n",
      "The sentences below refer to which structure of the human eye?\n",
      "\n",
      "1- Most anterior extension of the uveal tract.\n",
      "2- Formed by blood vessels, connective tissue and malanocytes.\n",
      "3- Presents pigmented epithelium whose basal end of the cells is facing the posterior chamber.\n",
      "4- It has smooth muscle fibers of sympathetic innervation.\n",
      "\n",
      "a) ciliary body.\n",
      "b) iris.\n",
      "c) Camerular sinus.\n",
      "d) Choroidal tract of ora serrata.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.74 ms /    34 runs   (    0.58 ms per token,  1722.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2448.32 ms /   130 tokens (   18.83 ms per token,    53.10 tokens per second)\n",
      "llama_print_timings:        eval time =  4038.33 ms /    33 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6589.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.44 ms /    13 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1602.59 ms /    13 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  1642.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.12 ms /    30 runs   (    0.57 ms per token,  1752.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3705.25 ms /    30 runs   (  123.51 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3793.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.22 ms /    32 runs   (    0.57 ms per token,  1756.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3943.29 ms /    32 runs   (  123.23 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4037.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #4: \n",
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.19 ms /    32 runs   (    0.57 ms per token,  1759.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3873.03 ms /    32 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3967.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.41 ms /    48 runs   (    0.57 ms per token,  1751.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5905.31 ms /    48 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6048.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.43 ms /    25 runs   (    0.58 ms per token,  1732.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3049.65 ms /    25 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3124.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.80 ms /    33 runs   (    0.57 ms per token,  1755.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4116.59 ms /    33 runs   (  124.75 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  4214.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.40 ms /    29 runs   (    0.57 ms per token,  1768.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3566.72 ms /    29 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3652.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.57 ms /    31 runs   (    0.57 ms per token,  1764.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3765.96 ms /    31 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3857.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "As sentenas abaixo dizem respeito a qual estrutura do olho humano?\n",
      "\n",
      "1- Extenso mais anterior do trato uveal.\n",
      "2- Formada por vasos sanguneos, tecido conjuntivo e malancitos.\n",
      "3- Apresenta epitlio pigmentado cuja extremidade basal das clulas est voltada para a cmara posterior.\n",
      "4- Possui fibras musculares lisas de inervao simptica.\n",
      "\n",
      "a)Corpo ciliar.\n",
      "b)ris.\n",
      "c)Seio camerular.\n",
      "d)Trato coroidal da ora serrata.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.67 ms /    13 runs   (    0.59 ms per token,  1695.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3754.38 ms /   165 tokens (   22.75 ms per token,    43.95 tokens per second)\n",
      "llama_print_timings:        eval time =  1467.54 ms /    12 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5260.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.45 ms /    14 runs   (    0.60 ms per token,  1656.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1735.64 ms /    14 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  1778.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.28 ms /    14 runs   (    0.59 ms per token,  1691.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1748.95 ms /    14 runs   (  124.92 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  1791.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.41 ms /    49 runs   (    0.58 ms per token,  1724.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6056.88 ms /    49 runs   (  123.61 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  6204.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.05 ms /    14 runs   (    0.57 ms per token,  1739.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1693.84 ms /    14 runs   (  120.99 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1735.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.11 ms /    14 runs   (    0.58 ms per token,  1726.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1720.68 ms /    14 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  1761.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.02 ms /    14 runs   (    0.57 ms per token,  1744.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1722.55 ms /    14 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  1763.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.07 ms /    14 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1702.23 ms /    14 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  1743.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.09 ms /    14 runs   (    0.58 ms per token,  1731.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1708.22 ms /    14 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1748.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.11 ms /    14 runs   (    0.58 ms per token,  1726.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1730.93 ms /    14 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  1773.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 44: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the anatomy of the retina, choose the alternative that contains the correct correlation between the two columns below:\n",
      "\n",
      "I - outer plexiform layer\n",
      "II - External limit\n",
      "III - inner nuclear layer\n",
      "IV - Internal limit\n",
      "V - Nerve fiber layer\n",
      "\n",
      "A- It is in contact with the vitreous\n",
      "B- It is between the photoreceptors and the bipolar cells\n",
      "C- Contains amacrine and horizontal cells\n",
      "D - Muller cell processes\n",
      "E- Contains axons of ganglion cells\n",
      "\n",
      "a) A: II; B: III; C: I; D: V; I: IV.\n",
      "b) A: IV; B: I; C: III; D: II; E: V.\n",
      "c) A: IV; B: V; C: III; D: I; I: II.\n",
      "d) A: V; B:II; C: III; D: IV; E:I.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.97 ms /   148 runs   (    0.57 ms per token,  1741.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3862.27 ms /   219 tokens (   17.64 ms per token,    56.70 tokens per second)\n",
      "llama_print_timings:        eval time = 18133.86 ms /   147 runs   (  123.36 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 22453.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.70 ms /   148 runs   (    0.57 ms per token,  1747.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18174.22 ms /   148 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 18629.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.01 ms /    41 runs   (    0.56 ms per token,  1781.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5139.14 ms /    41 runs   (  125.34 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  5260.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A: II; B: III; C: I; D: V'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.38 ms /   148 runs   (    0.57 ms per token,  1754.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18141.16 ms /   148 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 18593.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.08 ms /    48 runs   (    0.56 ms per token,  1772.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5956.69 ms /    48 runs   (  124.10 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  6100.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.71 ms /    93 runs   (    0.57 ms per token,  1764.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11521.12 ms /    93 runs   (  123.88 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 11803.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.49 ms /   148 runs   (    0.57 ms per token,  1751.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18175.09 ms /   148 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 18631.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.22 ms /    48 runs   (    0.59 ms per token,  1700.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5983.69 ms /    48 runs   (  124.66 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  6131.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    74.95 ms /   132 runs   (    0.57 ms per token,  1761.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16276.40 ms /   132 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16683.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A respeito da anatomia da retina, escolha a alternativa que contenha a correlao correta entre as duas colunas abaixo:\n",
      "\n",
      "I- Camada plexiforme externa\n",
      "II- Limitante externa\n",
      "III- Camada nuclear interna\n",
      "IV- Limitante interna\n",
      "V- Camada de fibras nervosas\n",
      "\n",
      "A- Est em contato com o vtreo\n",
      "B- Est entre os fotorreceptores e as clulas bipolares\n",
      "C- Contm clulas amcrinas e horizontais\n",
      "D- So processos das clulas de Muller\n",
      "E- Contm axnios de clulas ganglionares\n",
      "\n",
      "a)A: II; B: III; C: I; D: V; E: IV.\n",
      "b)A: IV; B: I; C: III; D: II; E: V.\n",
      "c)A: IV; B: V; C: III; D: I; E: II.\n",
      "d)A: V; B: II; C: III; D: IV; E: I.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.70 ms /    39 runs   (    0.56 ms per token,  1797.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4792.61 ms /    39 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4909.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.75 ms /    49 runs   (    0.57 ms per token,  1765.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4158.56 ms /   260 tokens (   15.99 ms per token,    62.52 tokens per second)\n",
      "llama_print_timings:        eval time =  6017.80 ms /    48 runs   (  125.37 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time = 10325.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.19 ms /    49 runs   (    0.58 ms per token,  1738.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6051.39 ms /    49 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6199.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.63 ms /    28 runs   (    0.52 ms per token,  1914.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3449.77 ms /    28 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3532.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.86 ms /   107 runs   (    0.57 ms per token,  1758.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13201.89 ms /   107 runs   (  123.38 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13528.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.77 ms /     7 runs   (    0.54 ms per token,  1855.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   913.46 ms /     7 runs   (  130.49 ms per token,     7.66 tokens per second)\n",
      "llama_print_timings:       total time =   933.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.47 ms /   107 runs   (    0.57 ms per token,  1769.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13338.57 ms /   107 runs   (  124.66 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time = 13664.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.88 ms /   107 runs   (    0.57 ms per token,  1757.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13220.70 ms /   107 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 13547.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.96 ms /    28 runs   (    0.53 ms per token,  1872.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3447.47 ms /    28 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3529.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.84 ms /     7 runs   (    0.55 ms per token,  1821.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.89 ms /     7 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.09 ms /    28 runs   (    0.54 ms per token,  1855.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3488.52 ms /    28 runs   (  124.59 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3572.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 45: \n",
      "Language: english\n",
      "Question: \n",
      "Phakic patient evolved with a significant increase in intraocular pressure and athalamia 15 hours after a trabeculectomy. It is correct to say that:\n",
      "a) This severe ocular condition is more prevalent in aphakic patients.\n",
      "b) The use of topical cycloplegic during the immediate postoperative period is a risk factor for this condition.\n",
      "c) If there is a pervious iridotomy, this would not occur.\n",
      "d) Typically, this condition occurs in eyes with an anteroposterior diameter smaller than those of the general population.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.67 ms /    82 runs   (    0.58 ms per token,  1720.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2498.43 ms /   140 tokens (   17.85 ms per token,    56.04 tokens per second)\n",
      "llama_print_timings:        eval time = 10024.71 ms /    81 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 12774.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.96 ms /    50 runs   (    0.58 ms per token,  1726.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6153.74 ms /    50 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6304.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.22 ms /   106 runs   (    0.58 ms per token,  1731.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13075.50 ms /   106 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 13401.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   127.11 ms /   220 runs   (    0.58 ms per token,  1730.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27088.85 ms /   220 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 27786.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.92 ms /    79 runs   (    0.59 ms per token,  1683.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9717.58 ms /    79 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  9962.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.34 ms /    25 runs   (    0.57 ms per token,  1743.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3029.71 ms /    25 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3102.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.56 ms /    84 runs   (    0.58 ms per token,  1729.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10211.05 ms /    84 runs   (  121.56 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time = 10463.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1737.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3115.18 ms /    25 runs   (  124.61 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3190.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.88 ms /    78 runs   (    0.58 ms per token,  1738.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9690.74 ms /    78 runs   (  124.24 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  9925.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.18 ms /    82 runs   (    0.58 ms per token,  1738.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10067.52 ms /    82 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10317.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente fcico evoluiu com quadro de aumento importante da presso intraocular e atalamia 15 horas aps uma trabeculectomia.  correto afirmar que:\n",
      "a)Esse quadro ocular grave  mais prevalente em pacientes afcicos.\n",
      "b)O uso de cicloplgico tpico durante o ps-operatrio imediato  fator de risco para esse quadro.\n",
      "c)Se h iridotomia prvia, esse quadro no ocorre.\n",
      "d)Tipicamente, esse quadro ocorre em olhos com dimetro anteroposterior menor que os da populao em geral.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.38 ms /    28 runs   (    0.58 ms per token,  1709.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3335.18 ms /   174 tokens (   19.17 ms per token,    52.17 tokens per second)\n",
      "llama_print_timings:        eval time =  3322.26 ms /    27 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6740.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.67 ms /   115 runs   (    0.58 ms per token,  1724.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14182.52 ms /   115 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 14537.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    87.03 ms /   149 runs   (    0.58 ms per token,  1712.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18422.14 ms /   149 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 18889.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.02 ms /    59 runs   (    0.61 ms per token,  1638.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7178.29 ms /    59 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7358.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.70 ms /     7 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.67 ms /     7 runs   (    0.67 ms per token,  1498.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.31 ms /     7 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   880.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.03 ms /   193 runs   (    0.61 ms per token,  1635.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23791.89 ms /   193 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 24414.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1739.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.45 ms /     7 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.75 ms /     7 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.82 ms /     7 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 46: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding cortisonic glaucoma, it is correct to state that:\n",
      "a) Occurs at all ages.\n",
      "b) Corticosteroids in low concentrations do not increase intraocular pressure.\n",
      "c) Glaucoma is typically angle-closure.\n",
      "d) It is more frequent due to the use of oral corticosteroids than in the form of eye drops.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.57 ms /    28 runs   (    0.59 ms per token,  1690.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2259.23 ms /    93 tokens (   24.29 ms per token,    41.16 tokens per second)\n",
      "llama_print_timings:        eval time =  3271.29 ms /    27 runs   (  121.16 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5615.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.35 ms /    44 runs   (    0.58 ms per token,  1735.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5426.48 ms /    44 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5557.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.45 ms /    25 runs   (    0.58 ms per token,  1730.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3063.52 ms /    25 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3137.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.93 ms /    24 runs   (    0.58 ms per token,  1723.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2931.44 ms /    24 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3003.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.43 ms /    25 runs   (    0.58 ms per token,  1732.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3032.51 ms /    25 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3106.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.27 ms /    24 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2998.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.01 ms /    24 runs   (    0.58 ms per token,  1712.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2972.37 ms /    24 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3045.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.20 ms /    54 runs   (    0.58 ms per token,  1730.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6569.09 ms /    54 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  6735.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1725.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3126.13 ms /    25 runs   (  125.05 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  3203.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.70 ms /   107 runs   (    0.58 ms per token,  1734.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13197.50 ms /   107 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 13528.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre o glaucoma cortisnico,  correto afirmar que:\n",
      "a)Ocorre em todas as idades.\n",
      "b)Os corticoides em concentraes baixas no elevam a presso intraocular.\n",
      "c)O glaucoma  tipicamente de ngulo fechado.\n",
      "d) mais frequente por uso de corticoide via oral do que na forma de colrio.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.17 ms /     7 runs   (    0.60 ms per token,  1679.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1641.52 ms /   107 tokens (   15.34 ms per token,    65.18 tokens per second)\n",
      "llama_print_timings:        eval time =   719.98 ms /     6 runs   (  120.00 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  2382.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.09 ms /   115 runs   (    0.58 ms per token,  1714.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14247.34 ms /   115 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 14601.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   147.40 ms /   254 runs   (    0.58 ms per token,  1723.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 31222.37 ms /   254 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 32036.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   145.93 ms /   253 runs   (    0.58 ms per token,  1733.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 31125.86 ms /   253 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 31935.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.77 ms /    41 runs   (    0.58 ms per token,  1725.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5055.45 ms /    41 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5177.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   150.33 ms /   260 runs   (    0.58 ms per token,  1729.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 32016.10 ms /   260 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 32841.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.48 ms /     7 runs   (  120.50 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1709.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.23 ms /     7 runs   (  120.46 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   863.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.14 ms /     7 runs   (    0.59 ms per token,  1692.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.09 ms /     7 runs   (  120.73 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.92 ms /    42 runs   (    0.59 ms per token,  1685.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5163.26 ms /    42 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5289.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 47: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the visual field defects below best correlates with localized loss of the peripapillary nerve fiber layer (Hoyt's sign) in the inferior temporal sector?\n",
      "a) Inferior temporal cecal center.\n",
      "b) Upper nasal.\n",
      "c) Wedge-shaped upper temporal.\n",
      "d) Lower vertical.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1842.03 ms /    83 tokens (   22.19 ms per token,    45.06 tokens per second)\n",
      "llama_print_timings:        eval time =   727.62 ms /     6 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2590.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    25 runs   (    0.58 ms per token,  1727.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3058.50 ms /    25 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3132.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1733.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2911.91 ms /    24 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2982.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.53 ms /    33 runs   (    0.59 ms per token,  1689.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4060.28 ms /    33 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4159.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.79 ms /    24 runs   (    0.57 ms per token,  1740.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.08 ms /    24 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2999.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.73 ms /    16 runs   (    0.61 ms per token,  1644.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1975.16 ms /    16 runs   (  123.45 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  2024.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.43 ms /    34 runs   (    0.57 ms per token,  1750.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4127.82 ms /    34 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4229.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.87 ms /    33 runs   (    0.57 ms per token,  1748.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4059.24 ms /    33 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4156.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1762.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   877.49 ms /     7 runs   (  125.36 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =   898.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.25 ms /     7 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual dos defeitos de campo visual abaixo melhor se correlaciona com perda localizada da camada de fibras nervosas peripapilar (sinal de Hoyt) no setor temporal inferior?\n",
      "a)Centro-cecal temporal inferior.\n",
      "b)Nasal superior.\n",
      "c)Temporal superior em cunha.\n",
      "d)Vertical inferior.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.17 ms /    36 runs   (    0.59 ms per token,  1700.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1971.90 ms /    89 tokens (   22.16 ms per token,    45.13 tokens per second)\n",
      "llama_print_timings:        eval time =  4298.86 ms /    35 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6379.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.63 ms /     7 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.30 ms /    37 runs   (    0.58 ms per token,  1737.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4519.79 ms /    37 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4630.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1744.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3369.85 ms /    28 runs   (  120.35 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  3452.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.08 ms /    35 runs   (    0.57 ms per token,  1743.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4268.55 ms /    35 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4373.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.38 ms /     7 runs   (  120.34 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1744.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3428.87 ms /    28 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3513.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.73 ms /    24 runs   (    0.57 ms per token,  1748.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2927.26 ms /    24 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2997.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.01 ms /    35 runs   (    0.57 ms per token,  1748.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4353.54 ms /    35 runs   (  124.39 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  4459.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3302.08 ms /    27 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3383.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 48: \n",
      "Language: english\n",
      "Question: \n",
      "Hemosiderotic glaucoma is caused by: a) Accumulation of macrophages in the trabecular meshwork. b) Accumulation of blood cells incapable of diapedesis in the trabecular meshwork. c) Accumulation of iron present in hemoglobin in the trabecular meshwork. d) Clogging of the trabecular meshwork by fresh red blood cells, fibrin and plasma.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.33 ms /    45 runs   (    0.59 ms per token,  1708.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2193.08 ms /   103 tokens (   21.29 ms per token,    46.97 tokens per second)\n",
      "llama_print_timings:        eval time =  5367.95 ms /    44 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  7699.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.62 ms /    44 runs   (    0.58 ms per token,  1717.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5361.11 ms /    44 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5493.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.13 ms /    37 runs   (    0.60 ms per token,  1672.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4562.53 ms /    37 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4673.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.93 ms /    45 runs   (    0.58 ms per token,  1735.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5520.67 ms /    45 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5655.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.14 ms /    45 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5551.87 ms /    45 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5686.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.48 ms /    44 runs   (    0.58 ms per token,  1726.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5341.14 ms /    44 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5472.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.48 ms /    44 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5400.19 ms /    44 runs   (  122.73 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5531.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.97 ms /    45 runs   (    0.58 ms per token,  1732.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5490.09 ms /    45 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5624.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.19 ms /    37 runs   (    0.65 ms per token,  1529.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4548.95 ms /    37 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4666.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "O glaucoma hemossidertico  causado por: a) Acmulo de macrfagos na malha trabecular. b) Acmulo de clulas sanguneas incapazes de diapedese na malha trabecular.  c) Acmulo de ferro presente na hemoglobina na malha trabecular. d) Entupimento da malha trabecular por hemcias frescas, fibrina e plasma.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.68 ms /    25 runs   (    0.79 ms per token,  1270.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3073.53 ms /    25 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3161.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.97 ms /    24 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2498.17 ms /   116 tokens (   21.54 ms per token,    46.43 tokens per second)\n",
      "llama_print_timings:        eval time =  2804.43 ms /    23 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5375.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.11 ms /    47 runs   (    0.58 ms per token,  1733.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5724.69 ms /    47 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5865.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.44 ms /    20 runs   (    0.57 ms per token,  1747.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2475.38 ms /    20 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  2533.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.56 ms /    27 runs   (    0.58 ms per token,  1734.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3305.66 ms /    27 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3385.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.62 ms /     7 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   880.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.30 ms /    44 runs   (    0.58 ms per token,  1739.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5401.17 ms /    44 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5533.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3350.08 ms /    27 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3432.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.12 ms /    52 runs   (    0.58 ms per token,  1726.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6420.82 ms /    52 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6583.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1738.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2060.95 ms /    17 runs   (  121.23 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2112.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1741.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2958.99 ms /    24 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3033.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 49: \n",
      "Language: english\n",
      "Question: \n",
      "The classic risk factors for the development of primary open-angle glaucoma are: a) Asians, positive family history, young people. b) Elevated intraocular pressure, Caucasian race, age between 25 and 45 years. c) Elevated intraocular pressure, black race, positive family history. d) Female gender, increased corneal thickness, intraocular pressure with wide fluctuation.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.05 ms /    25 runs   (    0.60 ms per token,  1661.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2578.64 ms /   108 tokens (   23.88 ms per token,    41.88 tokens per second)\n",
      "llama_print_timings:        eval time =  2916.82 ms /    24 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5573.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.45 ms /    54 runs   (    0.58 ms per token,  1716.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6594.32 ms /    54 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6763.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.72 ms /    20 runs   (    0.59 ms per token,  1706.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2432.95 ms /    20 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2495.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.51 ms /    20 runs   (    0.58 ms per token,  1738.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2438.73 ms /    20 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2500.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.51 ms /    20 runs   (    0.58 ms per token,  1737.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2456.29 ms /    20 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2518.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3452.95 ms /    28 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3540.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.53 ms /    25 runs   (    0.58 ms per token,  1720.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3025.04 ms /    25 runs   (  121.00 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3101.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.48 ms /    25 runs   (    0.58 ms per token,  1726.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3032.79 ms /    25 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3108.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.48 ms /    25 runs   (    0.58 ms per token,  1726.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3036.50 ms /    25 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3113.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "So fatores de risco clssicos para o desenvolvimento de glaucoma primrio de ngulo aberto: a) Asiticos, histria familiar positiva, jovens. b) Presso intraocular elevada, raa caucasiana, idade entre 25 e 45 anos. c) Presso intraocular elevada, raa negra, histria familiar positiva. d) Sexo feminino, espessura corneal elevada, presso intraocular com ampla flutuao.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.21 ms /    21 runs   (    0.58 ms per token,  1719.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2528.27 ms /    21 runs   (  120.39 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2593.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.17 ms /    28 runs   (    0.61 ms per token,  1630.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2183.89 ms /   134 tokens (   16.30 ms per token,    61.36 tokens per second)\n",
      "llama_print_timings:        eval time =  3300.05 ms /    27 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5574.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.21 ms /     9 runs   (    0.58 ms per token,  1728.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1091.73 ms /     9 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  1119.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.88 ms /     7 runs   (  120.70 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   867.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.50 ms /     7 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.20 ms /     9 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1103.88 ms /     9 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  1131.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   872.42 ms /     7 runs   (  124.63 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =   893.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.08 ms /    28 runs   (    0.57 ms per token,  1741.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3386.29 ms /    28 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3471.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.17 ms /     7 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.20 ms /    20 runs   (    0.61 ms per token,  1639.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2504.34 ms /    20 runs   (  125.22 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  2568.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.34 ms /     7 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   868.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 50: \n",
      "Language: english\n",
      "Question: \n",
      "Male patient, 25 years old, with recurrent ocular hypertension (between 40 and 60 mmHg), painless, unilateral and of short duration, without loss of vision. Which are the most probable diagnostics? a) Fuchs heterochromic uveitis. b) Attack of acute glaucoma with bomb iris. c) Attack of acute glaucoma with plateau iris. d) Glaucomatocyclic crisis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.86 ms /    64 runs   (    0.61 ms per token,  1646.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2538.25 ms /   118 tokens (   21.51 ms per token,    46.49 tokens per second)\n",
      "llama_print_timings:        eval time =  7689.64 ms /    63 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 10430.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.56 ms /    27 runs   (    0.58 ms per token,  1734.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3306.30 ms /    27 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3387.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.10 ms /    28 runs   (    0.57 ms per token,  1739.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3453.57 ms /    28 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3536.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.45 ms /    27 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3382.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.35 ms /     7 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1744.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3407.45 ms /    28 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3489.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.07 ms /    99 runs   (    0.58 ms per token,  1734.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12191.91 ms /    99 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 12492.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1736.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3296.03 ms /    27 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3376.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1738.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3398.39 ms /    28 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3481.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.12 ms /     7 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente masculino, 25 anos, com quadros reincidentes de hipertenso ocular (entre 40 e 60 mmHg), indolor, unilateral e de curta durao, sem baixa de viso. Qual o diagnstico mais provvel? a) Uvete heterocrmica de Fuchs. b) Crise de glaucoma agudo com ris bomb. c) Crise de glaucoma agudo com ris em plateau. d) Crise glaucomatocclica.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.78 ms /    69 runs   (    0.58 ms per token,  1734.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2349.34 ms /   138 tokens (   17.02 ms per token,    58.74 tokens per second)\n",
      "llama_print_timings:        eval time =  8400.17 ms /    68 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10959.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.58 ms /    28 runs   (    0.59 ms per token,  1688.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3456.30 ms /    28 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3541.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.33 ms /    27 runs   (    0.57 ms per token,  1761.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3302.69 ms /    27 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3382.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.73 ms /    40 runs   (    0.57 ms per token,  1759.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4911.46 ms /    40 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5028.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.38 ms /    27 runs   (    0.57 ms per token,  1755.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3289.20 ms /    27 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3368.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.82 ms /    28 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3395.28 ms /    28 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3478.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.59 ms /    62 runs   (    0.57 ms per token,  1742.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7650.46 ms /    62 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  7836.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.10 ms /    49 runs   (    0.57 ms per token,  1743.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5999.76 ms /    49 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6148.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.91 ms /     7 runs   (    0.56 ms per token,  1789.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.90 ms /     7 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1818.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.29 ms /     7 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 51: \n",
      "Language: english\n",
      "Question: \n",
      "A 60-year-old diabetic patient complains of pain and low visual acuity in the right eye. On ophthalmological examination, visual acuity was 0.1, intraocular pressure 45 mmHg, corneal edema, iris neovascularization, open angle in all quadrants on gonioscopy, cup/disc ratio 0.3, and proliferative diabetic retinopathy. After initiating hypotensive clinical treatment, the patient had a good response. Among the options below, which is the most appropriate course of action to follow? a) Cyclophotocoagulation. b) Drainage implant. c) Panretinal photocoagulation. d) Trabeculectomy with mitomycin C.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    94.06 ms /   162 runs   (    0.58 ms per token,  1722.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3049.17 ms /   189 tokens (   16.13 ms per token,    61.98 tokens per second)\n",
      "llama_print_timings:        eval time = 19870.23 ms /   161 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 23425.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.18 ms /    34 runs   (    0.59 ms per token,  1684.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4161.57 ms /    34 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4263.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.82 ms /   169 runs   (    0.58 ms per token,  1727.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20892.59 ms /   169 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 21419.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.67 ms /     7 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.24 ms /    16 runs   (    0.58 ms per token,  1730.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1953.50 ms /    16 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2001.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.77 ms /     7 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.89 ms /    36 runs   (    0.58 ms per token,  1723.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4461.45 ms /    36 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4569.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   103.58 ms /   178 runs   (    0.58 ms per token,  1718.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21945.66 ms /   178 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 22503.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.76 ms /   125 runs   (    0.58 ms per token,  1718.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15447.26 ms /   125 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15840.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.07 ms /    33 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4068.43 ms /    33 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4166.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente diabtico com 60 anos queixa-se de dor e baixa de acuidade visual no olho direito. Ao exame oftalmolgico apresenta acuidade visual 0,1, presso intraocular 45 mmHg, edema de cornea, neovascularizao de ris, ngulo aberto em todos os quadrantes na gonioscopia, relao escavao/disco 0,3 e retinopatia diabtica proliferativa. Aps iniciar tratamento clnico hipotensor, apresentou boa resposta. Dentre as opes abaixo, qual  a conduta mais adequada a seguir? a) Ciclofotocoagulao. b) Implante de drenagem. c) Panfotocoagulao retiniana. d) Trabeculectomia com mitomicina C.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    19 runs   (    0.61 ms per token,  1647.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4200.43 ms /   216 tokens (   19.45 ms per token,    51.42 tokens per second)\n",
      "llama_print_timings:        eval time =  2234.62 ms /    18 runs   (  124.15 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  6493.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.84 ms /    19 runs   (    0.62 ms per token,  1605.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2354.24 ms /    19 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2414.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.25 ms /    19 runs   (    0.59 ms per token,  1689.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2352.81 ms /    19 runs   (  123.83 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  2411.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #3: \n",
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.97 ms /    19 runs   (    0.58 ms per token,  1731.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2320.69 ms /    19 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2378.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1732.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2477.49 ms /    20 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2537.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.75 ms /    20 runs   (    0.59 ms per token,  1702.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2471.82 ms /    20 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  2532.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.12 ms /    19 runs   (    0.59 ms per token,  1708.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2322.72 ms /    19 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2379.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.20 ms /    19 runs   (    0.59 ms per token,  1696.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2336.35 ms /    19 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2393.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.53 ms /    20 runs   (    0.58 ms per token,  1735.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2449.27 ms /    20 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2509.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.00 ms /    19 runs   (    0.58 ms per token,  1728.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2332.18 ms /    19 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2388.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Trabecuectomia com mitomicina C'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 52: \n",
      "Language: english\n",
      "Question: \n",
      "Among the options below, which would be the most suggestive finding of glaucoma? a) Cupping asymmetry of 0.2 between the eyes. b) Peripapillary atrophy with alpha zone in the temporal region of the nerve. c) Bilateral excavation/disk ratio of 0.5. d) Optic nerve cup/disk ratio of 0.4 with the presence of an inferior temporal notch.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    28 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2115.01 ms /   105 tokens (   20.14 ms per token,    49.65 tokens per second)\n",
      "llama_print_timings:        eval time =  3302.58 ms /    27 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5501.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1729.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3343.72 ms /    27 runs   (  123.84 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3424.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.92 ms /     7 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.11 ms /     7 runs   (  119.73 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =   858.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.02 ms /    28 runs   (    0.57 ms per token,  1748.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3406.55 ms /    28 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3489.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.56 ms /    27 runs   (    0.58 ms per token,  1735.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3277.91 ms /    27 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3358.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    28 runs   (    0.58 ms per token,  1717.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3410.95 ms /    28 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3494.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   103.70 ms /   181 runs   (    0.57 ms per token,  1745.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22301.49 ms /   181 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 22861.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.66 ms /    24 runs   (    0.57 ms per token,  1756.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2929.53 ms /    24 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2999.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.21 ms /    51 runs   (    0.57 ms per token,  1745.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6260.07 ms /    51 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6412.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.60 ms /    74 runs   (    0.58 ms per token,  1737.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9025.51 ms /    74 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  9248.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Dentre as opes abaixo, qual seria o achado mais sugestivo de glaucoma? a) Assimetria de escavao de 0,2 entre os olhos. b) Atrofia peripapilar com zona alfa na regio temporal do nervo. c) Relao escavao/disco bilateral de 0,5. d) Relao escavao/disco do nervo ptico de 0,4 com a presena de um notch temporal inferior.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.02 ms /    56 runs   (    0.59 ms per token,  1695.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2484.84 ms /   124 tokens (   20.04 ms per token,    49.90 tokens per second)\n",
      "llama_print_timings:        eval time =  6749.38 ms /    55 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  9406.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.63 ms /     8 runs   (    0.58 ms per token,  1726.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   963.47 ms /     8 runs   (  120.43 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   987.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd)'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.00 ms /    52 runs   (    0.58 ms per token,  1733.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6423.14 ms /    52 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6579.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.87 ms /    38 runs   (    0.58 ms per token,  1737.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4640.11 ms /    38 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4752.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd)'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.30 ms /    39 runs   (    0.57 ms per token,  1748.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4788.12 ms /    39 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4903.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.56 ms /    39 runs   (    0.58 ms per token,  1728.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4745.58 ms /    39 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4861.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.55 ms /    60 runs   (    0.58 ms per token,  1736.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7287.55 ms /    60 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  7466.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.48 ms /    39 runs   (    0.58 ms per token,  1734.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4766.19 ms /    39 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4882.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.96 ms /    59 runs   (    0.58 ms per token,  1737.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7216.06 ms /    59 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7396.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.34 ms /    60 runs   (    0.59 ms per token,  1697.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7347.54 ms /    60 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7528.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 53: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Topical use of alpha-2-agonist eye drops, such as brimonidine tartrate, should be avoided in which of the following situations? a) Children under two years old. b) Renal lithiasis. c) Asthma. d) Sickle cell anemia.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.19 ms /     7 runs   (    0.60 ms per token,  1671.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1354.81 ms /    73 tokens (   18.56 ms per token,    53.88 tokens per second)\n",
      "llama_print_timings:        eval time =   719.52 ms /     6 runs   (  119.92 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =  2095.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.57 ms /    32 runs   (    0.58 ms per token,  1722.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3845.97 ms /    32 runs   (  120.19 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  3941.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.14 ms /    36 runs   (    0.59 ms per token,  1702.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4435.75 ms /    36 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4542.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.53 ms /    25 runs   (    0.58 ms per token,  1720.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3040.69 ms /    25 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3113.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.84 ms /    17 runs   (    0.58 ms per token,  1727.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2037.94 ms /    17 runs   (  119.88 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =  2087.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.98 ms /    78 runs   (    0.58 ms per token,  1733.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9484.96 ms /    78 runs   (  121.60 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  9718.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.07 ms /   168 runs   (    0.58 ms per token,  1730.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20477.54 ms /   168 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 20994.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.71 ms /    25 runs   (    0.59 ms per token,  1699.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3071.53 ms /    25 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3146.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.82 ms /    17 runs   (    0.58 ms per token,  1730.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2045.84 ms /    17 runs   (  120.34 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2094.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.83 ms /    17 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2081.84 ms /    17 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2131.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "O uso tpico de colrio de alfa-2-agonista, como tartarato de brimonidina, deve ser evitado em qual situao, dentre as abaixo? a) Crianas abaixo de dois anos. b) Litase renal. c) Asma. d) Anemia falciforme.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1716.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2190.22 ms /    88 tokens (   24.89 ms per token,    40.18 tokens per second)\n",
      "llama_print_timings:        eval time =   729.24 ms /     6 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2939.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.63 ms /    69 runs   (    0.63 ms per token,  1581.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8454.17 ms /    69 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8669.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.48 ms /    69 runs   (    0.64 ms per token,  1551.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8458.26 ms /    69 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8677.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.55 ms /     7 runs   (    0.79 ms per token,  1262.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.12 ms /     7 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   872.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.38 ms /    72 runs   (    0.67 ms per token,  1488.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8808.80 ms /    72 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  9045.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.94 ms /    31 runs   (    0.71 ms per token,  1413.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3809.47 ms /    31 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3911.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1762.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.52 ms /     7 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   892.12 ms /     7 runs   (  127.45 ms per token,     7.85 tokens per second)\n",
      "llama_print_timings:       total time =   912.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.97 ms /    71 runs   (    0.58 ms per token,  1732.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8657.17 ms /    71 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  8873.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 54: \n",
      "Language: english\n",
      "Question: \n",
      "Which finding is most commonly associated with primary congenital glaucoma? a) Optic nerve edema. b) Ruptures in Descemet's membrane. c) Dislocation of the lens. d) Tent-like peripheral anterior synechiae.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1755.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.94 ms /     7 runs   (  120.42 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   863.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.87 ms /    39 runs   (    0.59 ms per token,  1705.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1668.71 ms /    69 tokens (   24.18 ms per token,    41.35 tokens per second)\n",
      "llama_print_timings:        eval time =  4592.09 ms /    38 runs   (  120.84 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  6376.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #1: \n",
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.54 ms /    39 runs   (    0.58 ms per token,  1730.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4783.20 ms /    39 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4900.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.41 ms /    38 runs   (    0.59 ms per token,  1695.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4662.92 ms /    38 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4778.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.95 ms /    38 runs   (    0.58 ms per token,  1731.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4629.27 ms /    38 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4742.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #4: \n",
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.50 ms /    39 runs   (    0.58 ms per token,  1733.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4834.32 ms /    39 runs   (  123.96 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4948.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.57 ms /    39 runs   (    0.58 ms per token,  1728.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4751.12 ms /    39 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4867.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.15 ms /    21 runs   (    0.58 ms per token,  1728.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2574.15 ms /    21 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2636.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.60 ms /    25 runs   (    0.58 ms per token,  1712.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3025.09 ms /    25 runs   (  121.00 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3098.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.57 ms /    39 runs   (    0.58 ms per token,  1728.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4746.65 ms /    39 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4862.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.97 ms /    38 runs   (    0.58 ms per token,  1729.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4626.62 ms /    38 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4738.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tent-like peripheral anterior synechiae.'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual achado  mais comumente associado ao glaucoma congnito primrio? a) Edema de nervo ptico. b) Rupturas na membrana de Descemet. c) Luxao do cristalino. d) Sinquias anteriores perifricas em tenda.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.11 ms /    38 runs   (    0.58 ms per token,  1719.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2036.10 ms /    78 tokens (   26.10 ms per token,    38.31 tokens per second)\n",
      "llama_print_timings:        eval time =  4526.57 ms /    37 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6674.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.63 ms /     7 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1731.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3384.26 ms /    28 runs   (  120.87 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3465.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.10 ms /    28 runs   (    0.65 ms per token,  1546.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3420.32 ms /    28 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3508.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.19 ms /    28 runs   (    0.65 ms per token,  1539.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3388.78 ms /    28 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3475.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.03 ms /    44 runs   (    0.59 ms per token,  1690.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5403.71 ms /    44 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5537.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.61 ms /    20 runs   (    0.58 ms per token,  1722.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2430.48 ms /    20 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2491.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3382.95 ms /    28 runs   (  120.82 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3468.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3319.84 ms /    27 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3402.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.54 ms /    25 runs   (    0.58 ms per token,  1719.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3039.77 ms /    25 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3115.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 55: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the pinhole test, it is correct to state: a) If the patient's visual acuity does not improve, it is a case of amblyopia. b) Decrease the depth of focus, due to the reduction of the pupil. c) Reduces diffusion circles on the retina. d) The size of the pinhole hole should be between 4 and 5 mm.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.12 ms /    20 runs   (    0.61 ms per token,  1650.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2503.49 ms /    93 tokens (   26.92 ms per token,    37.15 tokens per second)\n",
      "llama_print_timings:        eval time =  2314.09 ms /    19 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4879.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.51 ms /    28 runs   (    0.59 ms per token,  1696.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3432.48 ms /    28 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3520.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.53 ms /    20 runs   (    0.58 ms per token,  1734.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2449.26 ms /    20 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2510.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1724.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3436.18 ms /    28 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3522.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.58 ms /    20 runs   (    0.58 ms per token,  1727.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2467.03 ms /    20 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  2527.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.03 ms /    28 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3407.33 ms /    28 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3492.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.52 ms /    27 runs   (    0.57 ms per token,  1739.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3297.18 ms /    27 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3378.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3526.55 ms /    28 runs   (  125.95 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  3608.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1745.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3402.18 ms /    28 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3484.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.81 ms /    17 runs   (    0.58 ms per token,  1733.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2095.44 ms /    17 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  2145.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre o teste do buraco estenopeico,  correto afirmar: a) Se a acuidade visual do paciente no melhorar, trata-se de um caso de ambliopia. b) Diminui a profundidade de foco, por haver reduo da pupila. c) Reduz os crculos de difuso na retina. d) O tamanho do buraco estenopeico deve ser entre 4 e 5 mm.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1663.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1896.90 ms /   116 tokens (   16.35 ms per token,    61.15 tokens per second)\n",
      "llama_print_timings:        eval time =   722.15 ms /     6 runs   (  120.36 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2640.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.41 ms /    23 runs   (    0.58 ms per token,  1714.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2811.68 ms /    23 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2880.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.78 ms /     7 runs   (  126.54 ms per token,     7.90 tokens per second)\n",
      "llama_print_timings:       total time =   906.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.50 ms /     7 runs   (  120.36 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.78 ms /     7 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.80 ms /    17 runs   (    0.58 ms per token,  1734.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2069.37 ms /    17 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2119.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.10 ms /     7 runs   (  120.16 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.48 ms /     7 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   882.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.24 ms /     7 runs   (  124.46 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   891.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1695.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   890.75 ms /     7 runs   (  127.25 ms per token,     7.86 tokens per second)\n",
      "llama_print_timings:       total time =   911.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 56: \n",
      "Language: english\n",
      "Question: \n",
      "With regard to the Snellen chart, it is correct to state: a) A visual acuity of 0.05 in one eye allows for a professional D driver's license. b) Facectomy with implantation of an intraocular lens is necessary in phakic patients with visual acuity of 1.5 with the best fix. c) The patient with a visual acuity of 0.25 has a visual angle of 0.5 minutes. d) The patient with a visual acuity of 0.2 has subnormal vision.\n",
      "Test #0: \n",
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   136.62 ms /   235 runs   (    0.58 ms per token,  1720.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2911.62 ms /   132 tokens (   22.06 ms per token,    45.34 tokens per second)\n",
      "llama_print_timings:        eval time = 28757.73 ms /   234 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 32414.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.50 ms /    46 runs   (    0.58 ms per token,  1735.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5598.81 ms /    46 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5738.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.88 ms /   136 runs   (    0.57 ms per token,  1746.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16727.90 ms /   136 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 17144.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n",
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.92 ms /    82 runs   (    0.57 ms per token,  1747.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10083.81 ms /    82 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 10329.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.85 ms /   120 runs   (    0.57 ms per token,  1742.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14751.22 ms /   120 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 15116.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n",
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.98 ms /    28 runs   (    0.57 ms per token,  1752.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3421.45 ms /    28 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3504.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.52 ms /    53 runs   (    0.58 ms per token,  1736.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6513.61 ms /    53 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6671.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.70 ms /    24 runs   (    0.57 ms per token,  1751.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2909.81 ms /    24 runs   (  121.24 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2981.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.08 ms /    58 runs   (    0.57 ms per token,  1753.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7128.57 ms /    58 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7301.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.02 ms /    28 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3430.18 ms /    28 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3514.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao  tabela de Snellen,  correto afirmar: a) A acuidade visual de 0,05 em um olho permite a carteira profissional de direo letra D. b)  necessria a facectomia com implante de lente intraocular em pacientes fcicos com acuidades visuais de 1,5 com a melhor correo. c) O paciente com acuidade visual de 0,25 tem um ngulo visual de 0,5 minuto. d) O paciente com acuidade visual de 0,2 tem viso subnormal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1708.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2980.35 ms /   152 tokens (   19.61 ms per token,    51.00 tokens per second)\n",
      "llama_print_timings:        eval time =   737.96 ms /     6 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3738.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   124.33 ms /   215 runs   (    0.58 ms per token,  1729.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26571.31 ms /   215 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 27256.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) O paciente com acuidade visual de 0,2 tem viso subnormal.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.87 ms /     7 runs   (  124.12 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   890.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   102.71 ms /   180 runs   (    0.57 ms per token,  1752.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22222.92 ms /   180 runs   (  123.46 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 22785.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   124.05 ms /   215 runs   (    0.58 ms per token,  1733.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26565.50 ms /   215 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 27244.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.22 ms /    86 runs   (    0.57 ms per token,  1747.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10600.17 ms /    86 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 10857.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.11 ms /    84 runs   (    0.57 ms per token,  1746.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10312.81 ms /    84 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10564.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.86 ms /     7 runs   (    0.55 ms per token,  1811.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   893.83 ms /     7 runs   (  127.69 ms per token,     7.83 tokens per second)\n",
      "llama_print_timings:       total time =   913.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   123.89 ms /   215 runs   (    0.58 ms per token,  1735.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26548.40 ms /   215 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 27220.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.36 ms /    45 runs   (    0.56 ms per token,  1774.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5508.45 ms /    45 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5642.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 57: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the materials below has the highest Abbe index? a) CR-39 resin b) Trivex. c) High index resin. d) Polycarbonate.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1738.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1097.01 ms /    46 tokens (   23.85 ms per token,    41.93 tokens per second)\n",
      "llama_print_timings:        eval time =  2801.28 ms /    23 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3969.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.35 ms /    25 runs   (    0.57 ms per token,  1742.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3014.41 ms /    25 runs   (  120.58 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3089.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.09 ms /    61 runs   (    0.58 ms per token,  1738.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7429.48 ms /    61 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  7612.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.75 ms /    28 runs   (    0.60 ms per token,  1672.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3382.08 ms /    28 runs   (  120.79 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3466.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.56 ms /     7 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.22 ms /    25 runs   (    0.57 ms per token,  1758.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3001.14 ms /    25 runs   (  120.05 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  3075.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.93 ms /     7 runs   (    0.56 ms per token,  1779.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.75 ms /     7 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.77 ms /    54 runs   (    0.59 ms per token,  1699.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6598.00 ms /    54 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  6761.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n",
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2896.70 ms /    24 runs   (  120.70 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2968.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.90 ms /     7 runs   (    0.56 ms per token,  1793.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.06 ms /     7 runs   (  120.58 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual dos materiais abaixo apresenta maior ndice Abbe? a) Resina CR-39 b) Trivex. c) Resina de alto ndice. d) Policarbonato.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.97 ms /    24 runs   (    0.58 ms per token,  1718.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1378.11 ms /    56 tokens (   24.61 ms per token,    40.64 tokens per second)\n",
      "llama_print_timings:        eval time =  2800.46 ms /    23 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4250.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1723.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   904.61 ms /     7 runs   (  129.23 ms per token,     7.74 tokens per second)\n",
      "llama_print_timings:       total time =   925.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.22 ms /     7 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1755.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.57 ms /     7 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.04 ms /     7 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   886.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.82 ms /     7 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.11 ms /    25 runs   (    0.56 ms per token,  1771.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3100.53 ms /    25 runs   (  124.02 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3174.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.13 ms /     7 runs   (  121.73 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.21 ms /    16 runs   (    0.58 ms per token,  1737.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1972.37 ms /    16 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  2018.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.20 ms /     7 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 58: \n",
      "Language: english\n",
      "Question: \n",
      "A 65-year-old patient, myopic to -1.00 spherical diopters in both eyes, can read at 66 cm without lens correction. What is his accommodative range and what eyeglasses are sufficient for him to read at 33 cm, respectively? a) 0.50 spherical diopters; +1.00 spherical diopters. b) 0.50 spherical diopters; +1.50 spherical diopters. c) 1.00 spherical diopters; +1.50 spherical diopters. d) 1.00 spherical diopters; +2.00 spherical diopters.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   110.97 ms /   198 runs   (    0.56 ms per token,  1784.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4085.70 ms /   169 tokens (   24.18 ms per token,    41.36 tokens per second)\n",
      "llama_print_timings:        eval time = 24462.31 ms /   197 runs   (  124.17 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 29161.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   109.04 ms /   193 runs   (    0.56 ms per token,  1770.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23816.58 ms /   193 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 24421.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.17 ms /   198 runs   (    0.57 ms per token,  1765.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24428.66 ms /   198 runs   (  123.38 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 25046.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.00 ms /   198 runs   (    0.57 ms per token,  1752.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24538.80 ms /   198 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 25163.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.06 ms /   198 runs   (    0.57 ms per token,  1751.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24494.36 ms /   198 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 25108.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.82 ms /   198 runs   (    0.57 ms per token,  1754.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24457.27 ms /   198 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 25069.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.12 ms /   198 runs   (    0.57 ms per token,  1765.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24502.37 ms /   198 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 25122.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.34 ms /    48 runs   (    0.53 ms per token,  1894.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5903.91 ms /    48 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6044.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.89 ms /    51 runs   (    0.55 ms per token,  1828.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6269.71 ms /    51 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6420.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.09 ms /    50 runs   (    0.54 ms per token,  1845.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6086.41 ms /    50 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  6233.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente de 65 anos, mope de -1,00 dioptrias esfericas em ambos olhos, consegue ler a 66 cm, sem correo de lentes. Qual a sua amplitude acomodativa e qual grau de culos  suficiente para ele ler a 33 cm, respectivamente? a) 0,50 dioptrias esfericas; +1,00 dioptrias esfericas. b) 0,50 dioptrias esfericas; +1,50 dioptrias esfericas. c) 1,00 dioptrias esfericas; +1,50 dioptrias esfericas. d) 1,00 dioptrias esfericas; +2,00 dioptrias esfericas.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.69 ms /     7 runs   (    0.53 ms per token,  1895.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3398.21 ms /   188 tokens (   18.08 ms per token,    55.32 tokens per second)\n",
      "llama_print_timings:        eval time =   727.08 ms /     6 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4145.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.51 ms /     7 runs   (    0.50 ms per token,  1992.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.76 ms /     7 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.49 ms /     7 runs   (    0.50 ms per token,  2007.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.22 ms /     7 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.47 ms /     7 runs   (    0.50 ms per token,  2015.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.77 ms /     7 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   878.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.48 ms /     7 runs   (    0.50 ms per token,  2014.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.38 ms /     7 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.49 ms /     7 runs   (    0.50 ms per token,  2008.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.20 ms /     7 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   869.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.47 ms /     7 runs   (    0.50 ms per token,  2017.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.36 ms /     7 runs   (  126.48 ms per token,     7.91 tokens per second)\n",
      "llama_print_timings:       total time =   905.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.54 ms /     7 runs   (    0.51 ms per token,  1980.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.50 ms /     7 runs   (  124.07 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.52 ms /     7 runs   (    0.50 ms per token,  1990.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.01 ms /     7 runs   (  124.29 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   890.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.48 ms /     7 runs   (    0.50 ms per token,  2011.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.89 ms /     7 runs   (  121.56 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 59: \n",
      "Language: english\n",
      "Question: \n",
      "What range of accommodation is expected for a 30-year-old? a) 1.00 spherical diopters. b) 4.00 spherical diopters. c) 7.00 spherical diopters. d) 12.00 spherical diopters.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.52 ms /    36 runs   (    0.54 ms per token,  1843.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1863.36 ms /    76 tokens (   24.52 ms per token,    40.79 tokens per second)\n",
      "llama_print_timings:        eval time =  4237.63 ms /    35 runs   (  121.08 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  6207.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.37 ms /    39 runs   (    0.55 ms per token,  1825.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4791.48 ms /    39 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4906.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.20 ms /    28 runs   (    0.54 ms per token,  1841.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3413.21 ms /    28 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3494.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.58 ms /    27 runs   (    0.54 ms per token,  1851.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3258.98 ms /    27 runs   (  120.70 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3336.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.81 ms /    89 runs   (    0.59 ms per token,  1685.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10922.07 ms /    89 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 11197.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.86 ms /    36 runs   (    0.55 ms per token,  1812.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4395.40 ms /    36 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4502.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.43 ms /    39 runs   (    0.55 ms per token,  1819.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4815.89 ms /    39 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  4929.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.17 ms /    40 runs   (    0.55 ms per token,  1804.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4864.71 ms /    40 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4982.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.06 ms /    40 runs   (    0.55 ms per token,  1813.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4880.13 ms /    40 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4999.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.06 ms /    37 runs   (    0.54 ms per token,  1844.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4495.18 ms /    37 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4606.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual amplitude de acomodao esperada para uma pessoa de 30 anos de idade? a) 1,00 dioptria esferica. b) 4,00 dioptria esferica. c) 7,00 dioptria esferica. d) 12,00 dioptria esferica.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.62 ms /     7 runs   (    0.52 ms per token,  1933.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2065.73 ms /    85 tokens (   24.30 ms per token,    41.15 tokens per second)\n",
      "llama_print_timings:        eval time =   722.59 ms /     6 runs   (  120.43 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2808.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.91 ms /    65 runs   (    0.57 ms per token,  1761.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7962.61 ms /    65 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8163.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    30 runs   (    0.52 ms per token,  1924.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3646.61 ms /    30 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3736.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.21 ms /    20 runs   (    0.51 ms per token,  1957.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2479.39 ms /    20 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2536.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.09 ms /    85 runs   (    0.57 ms per token,  1767.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10436.65 ms /    85 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10694.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.32 ms /    33 runs   (    0.52 ms per token,  1905.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4034.09 ms /    33 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4132.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.41 ms /    37 runs   (    0.55 ms per token,  1812.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4500.59 ms /    37 runs   (  121.64 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4610.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.98 ms /    20 runs   (    0.50 ms per token,  2004.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2424.37 ms /    20 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2483.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.46 ms /    41 runs   (    0.55 ms per token,  1825.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4968.57 ms /    41 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5091.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.44 ms /    20 runs   (    0.52 ms per token,  1916.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2445.92 ms /    20 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2505.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 60: \n",
      "Language: english\n",
      "Question: \n",
      "An electronics technician performs, without correction, an accommodative effort of 6.00 DE when working at 20 cm. Which alternative best represents this patient's refraction? a) +1.50 spherical diopters -2.00 cylindrical diopters x 180. b) +1.50 spherical diopters -3.00 cylindrical diopters x 90. c) +2.50 spherical diopters -3.00 cylindrical diopters x 180. d) +3.50 spherical diopters -3.00 cylindrical diopters x 90.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    71.71 ms /   126 runs   (    0.57 ms per token,  1757.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3106.58 ms /   164 tokens (   18.94 ms per token,    52.79 tokens per second)\n",
      "llama_print_timings:        eval time = 15355.10 ms /   125 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 18854.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.89 ms /    99 runs   (    0.56 ms per token,  1771.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12245.07 ms /    99 runs   (  123.69 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 12548.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.15 ms /    56 runs   (    0.56 ms per token,  1797.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6839.00 ms /    56 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7006.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.55 ms /    56 runs   (    0.56 ms per token,  1774.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6877.99 ms /    56 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7045.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.32 ms /    51 runs   (    0.56 ms per token,  1800.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6214.16 ms /    51 runs   (  121.85 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6365.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.66 ms /    55 runs   (    0.56 ms per token,  1793.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6806.16 ms /    55 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6969.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.25 ms /    35 runs   (    0.52 ms per token,  1917.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4325.61 ms /    35 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4426.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.20 ms /    55 runs   (    0.59 ms per token,  1707.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6728.06 ms /    55 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6892.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.48 ms /    55 runs   (    0.55 ms per token,  1804.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6734.31 ms /    55 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6896.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.20 ms /    55 runs   (    0.57 ms per token,  1762.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6802.53 ms /    55 runs   (  123.68 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  6966.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um tcnico em eletrnica realiza, sem correo, esforo acomodativo de 6,00 DE quando trabalha a 20 cm. Qual alternativa melhor representa a refrao deste paciente? a) +1,50 dioptrias esfericas -2,00 dioptrias cilindricas x 180. b) +1,50 dioptrias esfericas -3,00 dioptrias cilindricas x 90. c) +2,50 dioptrias esfericas -3,00 dioptrias cilindricas x 180. d) +3,50 dioptrias esfericas -3,00 dioptrias cilindricas x 90.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.84 ms /     7 runs   (    0.55 ms per token,  1822.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3297.02 ms /   189 tokens (   17.44 ms per token,    57.32 tokens per second)\n",
      "llama_print_timings:        eval time =   741.81 ms /     6 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4058.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.44 ms /    38 runs   (    0.56 ms per token,  1772.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4704.93 ms /    38 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4817.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.80 ms /    59 runs   (    0.57 ms per token,  1745.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7309.28 ms /    59 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  7486.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.83 ms /     7 runs   (    0.55 ms per token,  1827.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.42 ms /     7 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.84 ms /     7 runs   (    0.55 ms per token,  1821.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.68 ms /     7 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.15 ms /    38 runs   (    0.56 ms per token,  1796.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4682.11 ms /    38 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4794.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.31 ms /    38 runs   (    0.56 ms per token,  1783.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4646.74 ms /    38 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4759.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.28 ms /    38 runs   (    0.56 ms per token,  1785.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4640.50 ms /    38 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4753.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.45 ms /    88 runs   (    0.58 ms per token,  1710.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10817.72 ms /    88 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 11087.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.19 ms /    38 runs   (    0.56 ms per token,  1793.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4687.99 ms /    38 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4801.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 61: \n",
      "Language: english\n",
      "Question: \n",
      "A three-year-old child has an esotropia of 70 prismatic diopters (uncorrected), an accommodative convergence/accommodation ratio of 6, and refraction under cycloplegia of +3.50 spherical diopters in both eyes. After prescription of refraction, it is more likely that the deviation with the use of glasses, in prismatic diopters, is approximately: a) Zero. b) 20. c) 50. d) 70.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.22 ms /    21 runs   (    0.58 ms per token,  1718.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2923.88 ms /   124 tokens (   23.58 ms per token,    42.41 tokens per second)\n",
      "llama_print_timings:        eval time =  2451.91 ms /    20 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5438.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   140.49 ms /   243 runs   (    0.58 ms per token,  1729.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 29830.00 ms /   243 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 30600.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.19 ms /    28 runs   (    0.58 ms per token,  1729.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3412.23 ms /    28 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3496.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) 70'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.41 ms /   113 runs   (    0.58 ms per token,  1727.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13816.41 ms /   113 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 14170.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1725.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3425.41 ms /    28 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3512.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) 70'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3428.02 ms /    28 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3513.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.00 ms /    99 runs   (    0.58 ms per token,  1736.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12079.24 ms /    99 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 12392.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.96 ms /    24 runs   (    0.58 ms per token,  1719.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3013.12 ms /    24 runs   (  125.55 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  3089.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1735.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3445.33 ms /    28 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3531.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Criana de trs anos apresenta esotropia de 70 dioptrias prismticas (sem correo), relao convergncia acomodativa/acomodao de 6, e refrao sob cicloplegia de +3.50 dioptrias esfericas em ambos os olhos. Aps a prescrio da refrao,  mais provvel que o desvio com o uso dos culos, em dioptrias prismticas, seja de aproximadamente: a) Zero. b) 20. c) 50. d) 70.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    89.93 ms /   153 runs   (    0.59 ms per token,  1701.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18862.47 ms /   153 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 19359.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.84 ms /    70 runs   (    0.58 ms per token,  1714.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2220.64 ms /   143 tokens (   15.53 ms per token,    64.40 tokens per second)\n",
      "llama_print_timings:        eval time =  8560.33 ms /    69 runs   (  124.06 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 11004.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.78 ms /     7 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.73 ms /     7 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.58 ms /     7 runs   (  121.23 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.59 ms /   134 runs   (    0.58 ms per token,  1727.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16522.56 ms /   134 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16948.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.43 ms /    32 runs   (    0.58 ms per token,  1736.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3902.79 ms /    32 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4001.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1706.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.31 ms /     7 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    86.17 ms /   149 runs   (    0.58 ms per token,  1729.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18355.43 ms /   149 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 18825.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.34 ms /    11 runs   (    0.58 ms per token,  1735.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1345.72 ms /    11 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1378.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   124.19 ms /   215 runs   (    0.58 ms per token,  1731.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26607.64 ms /   215 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 27280.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 62: \n",
      "Language: english\n",
      "Question: \n",
      "The measurement of the amplitude of fusional convergence is made by placing prisms in front of the eyes. Which of the alternatives below best represents the proper position of the prisms, considering a patient without strabismus? a) Temporal base in the eye with better visual acuity and nasal base in the other eye. b) Temporal base in the right eye. c) Nasal base in the eye with better visual acuity and temporal base in the other eye. d) Nasal base in the left eye.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.00 ms /    45 runs   (    0.58 ms per token,  1730.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2334.09 ms /   117 tokens (   19.95 ms per token,    50.13 tokens per second)\n",
      "llama_print_timings:        eval time =  5382.59 ms /    44 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7850.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.50 ms /    45 runs   (    0.57 ms per token,  1764.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5523.95 ms /    45 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5656.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.59 ms /    24 runs   (    0.57 ms per token,  1765.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2972.60 ms /    24 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3043.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.70 ms /    24 runs   (    0.57 ms per token,  1752.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2929.76 ms /    24 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3000.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.50 ms /     7 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.85 ms /    59 runs   (    0.57 ms per token,  1743.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7203.41 ms /    59 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7383.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.69 ms /    24 runs   (    0.57 ms per token,  1752.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2933.51 ms /    24 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3005.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.44 ms /    46 runs   (    0.57 ms per token,  1740.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5646.21 ms /    46 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5784.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.03 ms /    46 runs   (    0.57 ms per token,  1767.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5644.01 ms /    46 runs   (  122.70 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5782.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A medida da amplitude de convergncia fusional  feita pela colocao de prismas diante dos olhos. Qual das alternativas abaixo melhor representa a posio adequada dos prismas, considerando um paciente sem estrabismo? a) Base temporal no olho de melhor acuidade visual e base nasal no outro olho. b) Base temporal no olho direito. c) Base nasal no olho de melhor acuidade visual e base temporal no outro olho. d) Base nasal no olho esquerdo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.16 ms /    27 runs   (    0.56 ms per token,  1780.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3340.92 ms /    27 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3421.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1708.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2654.56 ms /   134 tokens (   19.81 ms per token,    50.48 tokens per second)\n",
      "llama_print_timings:        eval time =   751.80 ms /     6 runs   (  125.30 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  3427.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.79 ms /    28 runs   (    0.60 ms per token,  1668.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3399.29 ms /    28 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3486.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   873.59 ms /     7 runs   (  124.80 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =   894.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.36 ms /    27 runs   (    0.57 ms per token,  1757.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.90 ms /    27 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3381.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.38 ms /    27 runs   (    0.57 ms per token,  1754.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3318.07 ms /    27 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3399.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.67 ms /     7 runs   (  120.24 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1735.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3518.71 ms /    28 runs   (  125.67 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  3603.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.97 ms /    38 runs   (    0.58 ms per token,  1729.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4685.44 ms /    38 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4800.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.52 ms /     7 runs   (  120.50 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3337.91 ms /    27 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3419.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 63: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding atropine 1% eye drops, mark the correct alternative. a) It is contraindicated for the treatment of amblyopia b) It causes good cycloplegia, but mild mydriasis. c) It causes prolonged cycloplegia, with an effect that lasts for up to 15 days after instillation. d) Its maximum action occurs four hours after instillation.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    86.73 ms /   150 runs   (    0.58 ms per token,  1729.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2444.61 ms /    98 tokens (   24.94 ms per token,    40.09 tokens per second)\n",
      "llama_print_timings:        eval time = 18315.78 ms /   149 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 21226.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.37 ms /    60 runs   (    0.57 ms per token,  1745.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7290.01 ms /    60 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  7468.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.56 ms /    20 runs   (    0.58 ms per token,  1729.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2461.70 ms /    20 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2520.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1733.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2404.92 ms /    20 runs   (  120.25 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  2463.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.64 ms /    64 runs   (    0.57 ms per token,  1746.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7794.08 ms /    64 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  7986.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2899.10 ms /    24 runs   (  120.80 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2970.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.52 ms /   143 runs   (    0.58 ms per token,  1712.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17559.19 ms /   143 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 18020.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.58 ms /    25 runs   (    0.58 ms per token,  1714.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3056.89 ms /    25 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3135.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.65 ms /    48 runs   (    0.58 ms per token,  1735.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5889.21 ms /    48 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6035.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   108.08 ms /   185 runs   (    0.58 ms per token,  1711.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22824.05 ms /   185 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 23408.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao ao colrio de atropina 1%, assinale a alternativa correta. a)  contraindicado para tratamento de ambliopia b) Provoca boa cicloplegia, mas midrase discreta. c) Provoca cicloplegia prolongada, com efeito que se estende por, at, 15 dias aps a instilao. d) Sua ao mxima ocorre quatro horas aps a instilao.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.59 ms /    28 runs   (    0.59 ms per token,  1687.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1867.99 ms /   118 tokens (   15.83 ms per token,    63.17 tokens per second)\n",
      "llama_print_timings:        eval time =  3306.03 ms /    27 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5259.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.69 ms /    74 runs   (    0.58 ms per token,  1733.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9033.42 ms /    74 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  9260.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.80 ms /    20 runs   (    0.59 ms per token,  1694.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2437.44 ms /    20 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2496.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.20 ms /     9 runs   (    0.58 ms per token,  1729.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1087.01 ms /     9 runs   (  120.78 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  1113.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.56 ms /    53 runs   (    0.58 ms per token,  1734.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6556.74 ms /    53 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6716.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.15 ms /   130 runs   (    0.58 ms per token,  1729.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16068.35 ms /   130 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 16472.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.10 ms /    71 runs   (    0.58 ms per token,  1727.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8715.95 ms /    71 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  8932.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.59 ms /    20 runs   (    0.58 ms per token,  1725.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2447.54 ms /    20 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2506.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.45 ms /    17 runs   (    0.61 ms per token,  1627.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2132.38 ms /    17 runs   (  125.43 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  2184.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 64: \n",
      "Language: english\n",
      "Question: \n",
      "A 6-year-old emmetropic child has an exophoria of 6 prismatic diopters (PD). After placement of minus lenses of -2.00 spherical diopters, he presented esophoria of 2 SD. Its accommodative convergence/accommodation ratio is: a) 2. b) 4. c) 6. d) 8.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3400.44 ms /    28 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3484.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.43 ms /    31 runs   (    0.59 ms per token,  1682.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2248.97 ms /    98 tokens (   22.95 ms per token,    43.58 tokens per second)\n",
      "llama_print_timings:        eval time =  3661.16 ms /    30 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6004.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.58 ms /    32 runs   (    0.58 ms per token,  1722.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3895.93 ms /    32 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3992.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.96 ms /    31 runs   (    0.58 ms per token,  1726.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3819.51 ms /    31 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3912.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.22 ms /    23 runs   (    0.57 ms per token,  1740.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2789.87 ms /    23 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2858.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.86 ms /    31 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3787.91 ms /    31 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3880.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.44 ms /    27 runs   (    0.57 ms per token,  1748.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3297.61 ms /    27 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3378.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.55 ms /    20 runs   (    0.58 ms per token,  1732.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2514.61 ms /    20 runs   (  125.73 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =  2574.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.15 ms /    23 runs   (    0.57 ms per token,  1748.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2782.63 ms /    23 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2850.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    81.52 ms /   141 runs   (    0.58 ms per token,  1729.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17295.48 ms /   141 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 17733.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.87 ms /    31 runs   (    0.58 ms per token,  1734.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3770.02 ms /    31 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3863.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Criana de 6 anos de idade, emtrope, apresenta exoforia de 6 dioptrias prismticas (DP). Aps colocao de lentes negativas de -2,00 dioptrias esfricas, apresentou esoforia de 2 DP. Sua relao convergncia acomodativa/acomodao : a) 2. b) 4. c) 6. d) 8.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.03 ms /   114 runs   (    0.58 ms per token,  1726.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2054.13 ms /   112 tokens (   18.34 ms per token,    54.52 tokens per second)\n",
      "llama_print_timings:        eval time = 13859.62 ms /   113 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 16268.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   120.71 ms /   210 runs   (    0.57 ms per token,  1739.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25749.31 ms /   210 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 26412.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.78 ms /   112 runs   (    0.58 ms per token,  1728.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13715.77 ms /   112 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 14059.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    70.70 ms /   123 runs   (    0.57 ms per token,  1739.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15046.90 ms /   123 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 15423.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1735.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3424.71 ms /    28 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3509.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.19 ms /    23 runs   (    0.57 ms per token,  1743.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2826.78 ms /    23 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2895.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.55 ms /   126 runs   (    0.58 ms per token,  1713.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15440.34 ms /   126 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 15832.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3509.47 ms /    28 runs   (  125.34 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  3592.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.91 ms /   118 runs   (    0.58 ms per token,  1737.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14522.98 ms /   118 runs   (  123.08 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 14885.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.43 ms /   162 runs   (    0.58 ms per token,  1733.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19919.94 ms /   162 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 20424.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 65: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding Fresnel prisms, mark the correct alternative. a) Those with high values are associated with reduced visual acuity. b) Are obtained from prisms of equal power joined by their bases. c) They are obtained from prisms of equal power joined by their apexes. d) They are little used, mainly due to the discomfort caused by their high weight.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2145.24 ms /    89 tokens (   24.10 ms per token,    41.49 tokens per second)\n",
      "llama_print_timings:        eval time =  2765.18 ms /    23 runs   (  120.23 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  4982.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1737.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2083.57 ms /    17 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2135.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.86 ms /    17 runs   (    0.58 ms per token,  1723.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2081.33 ms /    17 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2132.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.72 ms /    17 runs   (    0.57 ms per token,  1748.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2077.47 ms /    17 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2128.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.77 ms /    24 runs   (    0.57 ms per token,  1743.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.93 ms /    24 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3000.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.79 ms /    17 runs   (    0.58 ms per token,  1737.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2066.92 ms /    17 runs   (  121.58 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2118.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.03 ms /    28 runs   (    0.57 ms per token,  1747.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3414.87 ms /    28 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3499.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.42 ms /    27 runs   (    0.57 ms per token,  1750.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3372.02 ms /    27 runs   (  124.89 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3452.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.72 ms /    17 runs   (    0.57 ms per token,  1748.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2048.10 ms /    17 runs   (  120.48 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2098.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.53 ms /     7 runs   (    0.65 ms per token,  1546.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.33 ms /     7 runs   (  120.19 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   863.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao aos prismas de Fresnel, assinale a alternativa correta. a) Os de altos valores so associados  reduo da acuidade visual. b) So obtidos a partir de prismas de igual poder unidos por suas bases. c) So obtidos a partir de prismas de igual poder unidos por seus pices.d) So pouco usados, principalmente pelo desconforto causado pelo seu alto peso.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.14 ms /     7 runs   (    0.59 ms per token,  1690.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2271.70 ms /   110 tokens (   20.65 ms per token,    48.42 tokens per second)\n",
      "llama_print_timings:        eval time =   734.09 ms /     6 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3026.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3415.12 ms /    28 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3500.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.66 ms /    24 runs   (    0.57 ms per token,  1756.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2937.17 ms /    24 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3008.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1729.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.54 ms /    27 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3381.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.75 ms /    17 runs   (    0.57 ms per token,  1742.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2065.55 ms /    17 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2116.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.65 ms /    17 runs   (    0.57 ms per token,  1762.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2113.04 ms /    17 runs   (  124.30 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  2163.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.24 ms /    25 runs   (    0.57 ms per token,  1755.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3097.51 ms /    25 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3172.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3430.33 ms /    28 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3514.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.41 ms /    58 runs   (    0.58 ms per token,  1736.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7251.07 ms /    58 runs   (  125.02 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  7425.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3292.23 ms /    27 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3372.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 66: \n",
      "Language: english\n",
      "Question: \n",
      "A 45-year-old +1.00 spherical diopter hyperopic patient no longer has accommodative tolerance. Therefore, to carry out an activity at 25 cm, which correction below will you need? a) +1.00 spherical diopters. b) +2.00 spherical diopters. c) +4.00 spherical diopters. d) +5.00 spherical diopters.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.77 ms /   163 runs   (    0.58 ms per token,  1738.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2186.34 ms /   107 tokens (   20.43 ms per token,    48.94 tokens per second)\n",
      "llama_print_timings:        eval time = 19905.02 ms /   162 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 22605.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.63 ms /    39 runs   (    0.55 ms per token,  1802.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4741.56 ms /    39 runs   (  121.58 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4858.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.47 ms /    40 runs   (    0.56 ms per token,  1780.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4849.55 ms /    40 runs   (  121.24 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4971.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.16 ms /    36 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4364.93 ms /    36 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4474.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    29 runs   (    0.54 ms per token,  1848.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3548.66 ms /    29 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3635.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.02 ms /    39 runs   (    0.56 ms per token,  1771.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4780.32 ms /    39 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4897.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.39 ms /    38 runs   (    0.56 ms per token,  1776.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4634.18 ms /    38 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4747.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.91 ms /    31 runs   (    0.55 ms per token,  1833.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3847.61 ms /    31 runs   (  124.12 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3938.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.52 ms /    39 runs   (    0.58 ms per token,  1731.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4835.22 ms /    39 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4951.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.91 ms /    39 runs   (    0.56 ms per token,  1779.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4775.47 ms /    39 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4890.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente hipermtrope de +1,00 dioptrias esfericas de 45 anos no possui mais tolerncia acomodativa. Logo, para exercer uma atividade a 25 cm necessitar de qual correo abaixo? a) +1,00 Dioptrias esfericas. b) +2,00 dioptrias esfericas. c) +4,00 dioptrias esfericas. d) +5,00 dioptrias esfericas.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1817.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2552.01 ms /   127 tokens (   20.09 ms per token,    49.76 tokens per second)\n",
      "llama_print_timings:        eval time =   732.15 ms /     6 runs   (  122.03 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3304.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.60 ms /    41 runs   (    0.55 ms per token,  1814.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4985.06 ms /    41 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5107.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    92.48 ms /   162 runs   (    0.57 ms per token,  1751.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19914.13 ms /   162 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 20422.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.74 ms /     7 runs   (    0.53 ms per token,  1873.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.02 ms /     7 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   887.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.42 ms /    32 runs   (    0.54 ms per token,  1836.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3899.77 ms /    32 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3995.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.67 ms /     7 runs   (    0.52 ms per token,  1908.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.36 ms /     7 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.30 ms /    35 runs   (    0.55 ms per token,  1813.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4299.96 ms /    35 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4404.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.68 ms /   128 runs   (    0.58 ms per token,  1737.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15669.32 ms /   128 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 16068.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.69 ms /     7 runs   (    0.53 ms per token,  1898.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.61 ms /     7 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.77 ms /     7 runs   (    0.54 ms per token,  1856.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   872.18 ms /     7 runs   (  124.60 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   893.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 67: \n",
      "Language: english\n",
      "Question: \n",
      "A six-year-old child with a learning disability has a static refraction of +2.00 spherical diopters in both eyes, achieving a visual acuity of 1.0. No ocular deviation. What is the best course of action in this case? a) It is not necessary to prescribe glasses. b) Full prescription. c) Prescription of +1.00 pherical diopters in both eyes. d) Prescription of reading glasses.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.43 ms /    28 runs   (    0.59 ms per token,  1704.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2171.15 ms /   114 tokens (   19.05 ms per token,    52.51 tokens per second)\n",
      "llama_print_timings:        eval time =  3272.14 ms /    27 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5528.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    25 runs   (    0.58 ms per token,  1734.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3119.70 ms /    25 runs   (  124.79 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3194.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.99 ms /   107 runs   (    0.58 ms per token,  1726.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13188.34 ms /   107 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 13513.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1740.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3033.66 ms /    25 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3107.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2911.96 ms /    24 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2983.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.53 ms /     7 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.40 ms /    25 runs   (    0.58 ms per token,  1736.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3085.20 ms /    25 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3159.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.66 ms /    34 runs   (    0.58 ms per token,  1728.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4154.30 ms /    34 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4257.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3478.09 ms /    28 runs   (  124.22 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3562.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.27 ms /     7 runs   (    0.61 ms per token,  1637.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.94 ms /     7 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   886.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Uma criana de seis anos de idade com dificuldade de aprendizado, apresenta refrao esttica de +2,00 DE em ambos os olhos, alcanando acuidade visual 1,0. No apresenta desvio ocular. Qual a melhor conduta neste caso? a) No  necessria a prescrio de culos. b) Prescrio total. c) Prescrio de +1,00 dioptrias esfericas em ambos os olhos. d) Prescrio de culos de leitura.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    69.92 ms /   120 runs   (    0.58 ms per token,  1716.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2216.96 ms /   138 tokens (   16.06 ms per token,    62.25 tokens per second)\n",
      "llama_print_timings:        eval time = 14641.05 ms /   119 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 17236.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.49 ms /    46 runs   (    0.58 ms per token,  1736.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5724.43 ms /    46 runs   (  124.44 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  5865.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.38 ms /   146 runs   (    0.58 ms per token,  1730.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17983.30 ms /   146 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 18444.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   114.39 ms /   198 runs   (    0.58 ms per token,  1730.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24342.38 ms /   198 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 24973.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   101.77 ms /   176 runs   (    0.58 ms per token,  1729.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21590.30 ms /   176 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 22151.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.04 ms /    50 runs   (    0.58 ms per token,  1721.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6120.72 ms /    50 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6275.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.45 ms /     7 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   874.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.36 ms /     7 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.74 ms /   153 runs   (    0.58 ms per token,  1724.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18838.55 ms /   153 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 19320.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 68: \n",
      "Language: english\n",
      "Question: \n",
      "What is the anisometropia of the patient who uses -3.00 spherical diopters in the right eye and +1.00 spherical diopters -2.00 cylindrical diopters x 90 in the left eye? a) 0 DE. b) 1 spherical diopters. c) 2 spherical diopters. d) 3 spherical diopters.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   927.96 ms /     7 runs   (  132.57 ms per token,     7.54 tokens per second)\n",
      "llama_print_timings:       total time =   948.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.27 ms /    32 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2457.70 ms /   101 tokens (   24.33 ms per token,    41.10 tokens per second)\n",
      "llama_print_timings:        eval time =  3749.64 ms /    31 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  6305.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   131.70 ms /   230 runs   (    0.57 ms per token,  1746.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28290.51 ms /   230 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 29020.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   150.65 ms /   266 runs   (    0.57 ms per token,  1765.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 32715.79 ms /   266 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 33560.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.31 ms /    32 runs   (    0.57 ms per token,  1747.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3959.61 ms /    32 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4055.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.11 ms /    34 runs   (    0.65 ms per token,  1537.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4121.36 ms /    34 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4228.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   139.01 ms /   242 runs   (    0.57 ms per token,  1740.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 29708.92 ms /   242 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 30484.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.63 ms /    33 runs   (    0.56 ms per token,  1771.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4098.86 ms /    33 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  4198.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   141.78 ms /   252 runs   (    0.56 ms per token,  1777.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 30929.88 ms /   252 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 31735.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   121.43 ms /   214 runs   (    0.57 ms per token,  1762.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26425.04 ms /   214 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 27097.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    99.99 ms /   175 runs   (    0.57 ms per token,  1750.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21500.21 ms /   175 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 22046.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual a anisometropia do paciente que usa -3,00 dioptrias esfericas no olho direito e +1,00 dioptrias esfericas -2,00 dioptrias cilindricas x 90 no olho esquerdo? a) 0 DE. b) 1 dioptrias esfericas. c) 2 dioptrias esfericas. d) 3 dioptrias esfericas.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.80 ms /    36 runs   (    0.58 ms per token,  1730.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2556.14 ms /   111 tokens (   23.03 ms per token,    43.42 tokens per second)\n",
      "llama_print_timings:        eval time =  4257.02 ms /    35 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  6922.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.62 ms /    36 runs   (    0.57 ms per token,  1745.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4399.71 ms /    36 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4508.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.93 ms /    16 runs   (    0.56 ms per token,  1791.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1935.96 ms /    16 runs   (  121.00 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  1983.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.52 ms /    34 runs   (    0.57 ms per token,  1741.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4151.80 ms /    34 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4254.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.92 ms /    16 runs   (    0.56 ms per token,  1794.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1988.33 ms /    16 runs   (  124.27 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  2036.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.29 ms /    34 runs   (    0.57 ms per token,  1762.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4190.29 ms /    34 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4292.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.16 ms /    35 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4239.55 ms /    35 runs   (  121.13 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4343.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.59 ms /    17 runs   (    0.56 ms per token,  1772.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2111.94 ms /    17 runs   (  124.23 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  2162.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.57 ms /    41 runs   (    0.57 ms per token,  1739.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5007.07 ms /    41 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5130.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.48 ms /    36 runs   (    0.57 ms per token,  1757.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4370.15 ms /    36 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4476.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 69: \n",
      "Language: english\n",
      "Question: \n",
      "An examiner located 0.67 m from the examined eye uses a retinoscope and scans the horizontal meridian (vertical axis), observing a movement in favor. After adding plus lenses, the flare is neutralized with +1.50 diopter. With this lens, when sweeping the vertical meridian (horizontal axis), a movement in favor is observed. Which of the following could be a prescription for the patient? a) +1.00 spherical diopter - 1.00 x 90. b) +1.00 spherical diopter - 1.00 x 180. c) -1.00 spherical diopter + 1.00 X 90. d) -1.00 spherical diopter + 1.00 X 180.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.85 ms /    49 runs   (    0.57 ms per token,  1759.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3386.05 ms /   197 tokens (   17.19 ms per token,    58.18 tokens per second)\n",
      "llama_print_timings:        eval time =  5959.28 ms /    48 runs   (  124.15 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  9494.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.96 ms /   130 runs   (    0.57 ms per token,  1757.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16137.36 ms /   130 runs   (  124.13 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 16537.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.44 ms /    49 runs   (    0.56 ms per token,  1786.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6071.70 ms /    49 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6218.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.31 ms /    49 runs   (    0.56 ms per token,  1794.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6053.10 ms /    49 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6200.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.24 ms /    49 runs   (    0.56 ms per token,  1798.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6155.98 ms /    49 runs   (  125.63 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  6303.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.66 ms /    27 runs   (    0.54 ms per token,  1842.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3338.74 ms /    27 runs   (  123.66 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3419.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    76.94 ms /   135 runs   (    0.57 ms per token,  1754.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16590.71 ms /   135 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 17011.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.75 ms /    48 runs   (    0.56 ms per token,  1794.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5896.19 ms /    48 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6040.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.92 ms /    50 runs   (    0.56 ms per token,  1791.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6128.01 ms /    50 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6276.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.07 ms /    49 runs   (    0.55 ms per token,  1809.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6090.45 ms /    49 runs   (  124.29 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  6235.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um examinador localizado a 0,67 m do olho examinado utiliza um retinoscpio e varre o meridiano horizontal (eixo vertical), observando um movimento a favor. Aps adicionar lentes positivas, o reflexo  neutralizado com +1,50 dioptria. Com esta lente, ao varrer o meridiano vertical (eixo horizontal), observa-se um movimento a favor. Qual das alternativas abaixo pode ser uma prescrio para o paciente? a) +1,00 dioptria esferica - 1,00 x 90. b) +1,00 dioptria esferica - 1,00 x 180. c) -1,00 dioptria esferica + 1,00 X 90. d) -1,00 dioptria esferica + 1,00 X 180.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.91 ms /     7 runs   (    0.56 ms per token,  1789.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4698.79 ms /   232 tokens (   20.25 ms per token,    49.37 tokens per second)\n",
      "llama_print_timings:        eval time =   736.61 ms /     6 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5456.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    30 runs   (    0.54 ms per token,  1855.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3698.05 ms /    30 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3789.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n",
      "Error converting respose to json: {: response: 'a'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.36 ms /     8 runs   (    0.54 ms per token,  1835.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   999.02 ms /     8 runs   (  124.88 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  1022.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.73 ms /     7 runs   (    0.53 ms per token,  1878.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.24 ms /     7 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.67 ms /    31 runs   (    0.54 ms per token,  1860.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3850.70 ms /    31 runs   (  124.22 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3945.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.92 ms /    30 runs   (    0.53 ms per token,  1884.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3737.95 ms /    30 runs   (  124.60 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3829.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.77 ms /     7 runs   (    0.54 ms per token,  1857.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   874.49 ms /     7 runs   (  124.93 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =   895.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.64 ms /   135 runs   (    0.58 ms per token,  1738.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16694.14 ms /   135 runs   (  123.66 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 17118.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.80 ms /     7 runs   (    0.54 ms per token,  1841.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.55 ms /     7 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   886.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.34 ms /    52 runs   (    0.56 ms per token,  1772.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6474.23 ms /    52 runs   (  124.50 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  6632.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    30 runs   (    0.53 ms per token,  1869.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3677.31 ms /    30 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3768.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 70: \n",
      "Language: english\n",
      "Question: \n",
      "A previously emmetropic 40-year-old patient with a history of epilepsy reports sudden onset blurred vision in both eyes. He has myopia of -4.50 spherical diopters in both eyes, reaching normal visual acuity. What is the likely cause? a) Stroke. b) Use of topiramate. c) Ectopia lentis. d) Cataract.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1699.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2254.97 ms /   103 tokens (   21.89 ms per token,    45.68 tokens per second)\n",
      "llama_print_timings:        eval time =   726.21 ms /     6 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3002.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.23 ms /    25 runs   (    0.73 ms per token,  1371.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3016.20 ms /    25 runs   (  120.65 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3101.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.48 ms /   125 runs   (    0.68 ms per token,  1462.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15276.55 ms /   125 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 15705.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.48 ms /     7 runs   (  120.93 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.68 ms /    84 runs   (    0.63 ms per token,  1594.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10307.37 ms /    84 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10573.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    24 runs   (    0.60 ms per token,  1658.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2910.03 ms /    24 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2981.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.97 ms /    24 runs   (    0.58 ms per token,  1717.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2956.92 ms /    24 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3027.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1739.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2042.92 ms /    17 runs   (  120.17 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  2092.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.36 ms /    25 runs   (    0.57 ms per token,  1741.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3041.29 ms /    25 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3114.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.36 ms /    70 runs   (    0.58 ms per token,  1734.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8546.52 ms /    70 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8755.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente previamente emtrope de 40 anos de idade com histrico de epilepsia refere viso embaada para longe de aparecimento sbito em ambos os olhos. Apresenta miopia de -4,50 dioptrias esfericas em ambos os olhos atingindo acuidade visual normal. Qual a provvel causa? a) Acidente vascular cerebral. b) Uso de topiramato. c) Ectopia lentis. d) Catarata.\n",
      "Test #0: \n",
      "{'response': 'd) Catarata.'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.48 ms /    73 runs   (    0.58 ms per token,  1718.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2747.83 ms /   133 tokens (   20.66 ms per token,    48.40 tokens per second)\n",
      "llama_print_timings:        eval time =  8771.43 ms /    72 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time = 11740.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1725.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.90 ms /     7 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.64 ms /    72 runs   (    0.58 ms per token,  1729.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8830.83 ms /    72 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  9047.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.23 ms /     9 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1114.61 ms /     9 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  1140.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.48 ms /     7 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    82.67 ms /   143 runs   (    0.58 ms per token,  1729.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17476.85 ms /   143 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 17916.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Catarata.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1718.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   836.11 ms /     7 runs   (  119.44 ms per token,     8.37 tokens per second)\n",
      "llama_print_timings:       total time =   856.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.20 ms /   168 runs   (    0.58 ms per token,  1728.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20698.62 ms /   168 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 21221.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.96 ms /    12 runs   (    0.58 ms per token,  1722.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1494.45 ms /    12 runs   (  124.54 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  1530.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Catarata.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.26 ms /    16 runs   (    0.58 ms per token,  1727.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1953.23 ms /    16 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2002.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 71: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the alternative that correctly correlates the columns. I - Compound hypermetropic astigmatism in favor of the rule. II - Compound myopic astigmatism against the rule. III- Astigmatic anisometropia. IV - Antimetropic anisometropia. A - Right eye: -1.00 spherical diopters -1.50 cylindrical diopters x 90 Left eye: -1.00 spherical diopters -1.50 cylindrical diopters x 90. B - Right eye: +5.00 spherical diopters Left eye: -1.00 spherical diopters. C - right eye: +5.00 spherical diopters -5.00 cylindrical diopters x 90 left eye: +1.00 spherical diopters -1.00 cylindrical diopters x 90. D - right eye: +5.00 spherical diopters +2.50 cylindrical diopters x 90 left eye: +5.00 spherical diopters +2.50 cylindrical diopters x 90.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.28 ms /    82 runs   (    0.61 ms per token,  1630.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4937.72 ms /   285 tokens (   17.33 ms per token,    57.72 tokens per second)\n",
      "llama_print_timings:        eval time = 10096.24 ms /    81 runs   (  124.64 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time = 15292.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.05 ms /    82 runs   (    0.56 ms per token,  1780.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10085.98 ms /    82 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 10334.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.24 ms /    82 runs   (    0.58 ms per token,  1735.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10177.94 ms /    82 runs   (  124.12 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 10430.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.68 ms /    82 runs   (    0.57 ms per token,  1756.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10120.14 ms /    82 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10366.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.66 ms /    82 runs   (    0.61 ms per token,  1651.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10080.22 ms /    82 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 10337.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.55 ms /    82 runs   (    0.63 ms per token,  1590.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10175.65 ms /    82 runs   (  124.09 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 10440.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.27 ms /    82 runs   (    0.63 ms per token,  1599.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10123.23 ms /    82 runs   (  123.45 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10385.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.84 ms /    27 runs   (    0.55 ms per token,  1819.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3338.35 ms /    27 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3418.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n",
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.42 ms /    82 runs   (    0.57 ms per token,  1766.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10108.77 ms /    82 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 10357.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.21 ms /    82 runs   (    0.56 ms per token,  1774.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10239.68 ms /    82 runs   (  124.87 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time = 10486.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que correlaciona corretamente as colunas. I - Astigmatismo hipermetrpico composto a favor da regra. II - Astigmatismo mipico composto contra a regra. III- Anisometropia astigmtica. IV - Anisometropia antimetrpica. A - Olho direito: -1,00 dioptrias esfericas -1,50 dioptrias cilindricas x 90 Olho esquerdo: -1,00 dioptrias esfericas -1,50 dioptrias cilindricas x 90. B - Olho direito: +5,00 dioptrias esfericas Olho esquerdo: -1,00 dioptrias esfericas. C - olho direito: +5,00 dioptrias esfericas -5,00 dioptrais cilindricas x 90 olho esquerdo: +1,00 dioptrias esfericas -1,00 dioptrias cilindricas x 90.  D - olho direito: +5,00 dioptrias esfericas +2,50 dioptrias cilindricas x 90 olho esquerdo: +5,00 dioptrias esfericas +2,50 dioptrias cilindricas x 90.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.30 ms /     7 runs   (    0.61 ms per token,  1629.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  5067.91 ms /   337 tokens (   15.04 ms per token,    66.50 tokens per second)\n",
      "llama_print_timings:        eval time =   731.45 ms /     6 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5821.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.57 ms /    27 runs   (    0.58 ms per token,  1734.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3327.19 ms /    27 runs   (  123.23 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3409.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.45 ms /    27 runs   (    0.57 ms per token,  1747.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3353.83 ms /    27 runs   (  124.22 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3436.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.20 ms /     7 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   876.58 ms /     7 runs   (  125.23 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   898.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #5: \n",
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.29 ms /    11 runs   (    0.57 ms per token,  1747.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1382.62 ms /    11 runs   (  125.69 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  1415.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3335.59 ms /    27 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3416.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n",
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.14 ms /     7 runs   (  124.45 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   892.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.36 ms /    27 runs   (    0.57 ms per token,  1758.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3354.75 ms /    27 runs   (  124.25 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3436.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.56 ms /    28 runs   (    0.59 ms per token,  1691.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3490.03 ms /    28 runs   (  124.64 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3576.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 72: \n",
      "Language: english\n",
      "Question: \n",
      "Classify the astigmatisms below according to the central keratometry. Consider insignificant internal astigmatism.\n",
      "\n",
      "I- 44.00 @ 90 x 42.00 @ 180.\n",
      "II- 44.00 @ 180 x 42.00 @ 90.\n",
      "III- 44.00 @ 45 x 42.00 @ 135.\n",
      "\n",
      "A- Astigmatism in favor of the rule.\n",
      "B- Astigmatism against the rule.\n",
      "C- Oblique astigmatism.\n",
      "\n",
      "a) I: A, II: B, III: C.\n",
      "b) I: A, II: C, III: B.\n",
      "c) I: B, II: A, III: C.\n",
      "d) I: B, II: C, III: A.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.80 ms /    91 runs   (    0.57 ms per token,  1756.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3790.71 ms /   214 tokens (   17.71 ms per token,    56.45 tokens per second)\n",
      "llama_print_timings:        eval time = 11128.85 ms /    90 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15202.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.38 ms /   153 runs   (    0.56 ms per token,  1791.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19010.41 ms /   153 runs   (  124.25 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 19486.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.11 ms /   126 runs   (    0.57 ms per token,  1747.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15500.29 ms /   126 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 15892.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.74 ms /    27 runs   (    0.55 ms per token,  1832.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3287.09 ms /    27 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3367.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.73 ms /   130 runs   (    0.57 ms per token,  1763.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16040.89 ms /   130 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 16440.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.27 ms /    66 runs   (    0.56 ms per token,  1771.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8166.25 ms /    66 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  8367.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.54 ms /    20 runs   (    0.53 ms per token,  1897.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2477.22 ms /    20 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2535.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.41 ms /    89 runs   (    0.57 ms per token,  1765.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10934.79 ms /    89 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11203.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    87.36 ms /   153 runs   (    0.57 ms per token,  1751.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18909.90 ms /   153 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 19381.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.60 ms /    20 runs   (    0.53 ms per token,  1886.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2442.04 ms /    20 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2500.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Classifique os astigmatismos abaixo de acordo com a ceratometria central. Considere o astigmatismo interno insignificante.\n",
      "\n",
      "I- 44,00 @ 90 x 42,00 @ 180.\n",
      "II- 44,00 @ 180 x 42,00 @ 90.\n",
      "III- 44,00 @ 45 x 42,00 @ 135.\n",
      "\n",
      "A- Astigmatismo a favor da regra.\n",
      "B- Astigmatismo contra a regra.\n",
      "C- Astigmatismo oblquo.\n",
      "\n",
      "a)I: A, II: B, III: C.\n",
      "b)I: A, II: C, III: B.\n",
      "c)I: B, II: A, III: C.\n",
      "d)I: B, II: C, III: A.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.35 ms /    97 runs   (    0.57 ms per token,  1752.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3683.07 ms /   228 tokens (   16.15 ms per token,    61.90 tokens per second)\n",
      "llama_print_timings:        eval time = 11787.56 ms /    96 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 15766.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.52 ms /     7 runs   (    0.50 ms per token,  1986.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   876.52 ms /     7 runs   (  125.22 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   897.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.48 ms /     7 runs   (    0.50 ms per token,  2013.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.85 ms /     7 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.62 ms /     9 runs   (    0.51 ms per token,  1948.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1114.18 ms /     9 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  1140.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.88 ms /    73 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9045.96 ms /    73 runs   (  123.92 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  9265.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.72 ms /    27 runs   (    0.55 ms per token,  1833.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.69 ms /    27 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3379.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.90 ms /    92 runs   (    0.56 ms per token,  1772.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11492.31 ms /    92 runs   (  124.92 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time = 11771.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.51 ms /     7 runs   (    0.50 ms per token,  1996.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   880.90 ms /     7 runs   (  125.84 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =   901.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.50 ms /     7 runs   (    0.50 ms per token,  1997.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.87 ms /     7 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.55 ms /     7 runs   (    0.51 ms per token,  1973.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.60 ms /     7 runs   (  124.51 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   891.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 73: \n",
      "Language: english\n",
      "Question: \n",
      "A patient moves away from the Greens so as not to fog up his lenses due to the use of a mask during the exam. Which of the following is correct if he stays away from the Greens and the ophthalmologist doesn't notice? a) If he is myopic, there will be undercorrection in his prescription. b) If he is myopic, there will be overcorrection in his prescription. c) If he is nearsighted, there will be no change in his prescription. d) If he is farsighted, he will need greater accommodative effort.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.31 ms /   110 runs   (    0.58 ms per token,  1710.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2744.23 ms /   140 tokens (   19.60 ms per token,    51.02 tokens per second)\n",
      "llama_print_timings:        eval time = 13343.75 ms /   109 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 16427.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.57 ms /    98 runs   (    0.58 ms per token,  1732.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11984.62 ms /    98 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 12283.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.00 ms /    31 runs   (    0.58 ms per token,  1722.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3781.17 ms /    31 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3873.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.02 ms /     7 runs   (  124.00 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.37 ms /   111 runs   (    0.58 ms per token,  1724.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13735.88 ms /   111 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 14077.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.88 ms /    24 runs   (    0.58 ms per token,  1729.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2900.55 ms /    24 runs   (  120.86 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2972.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.28 ms /    44 runs   (    0.57 ms per token,  1740.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5376.72 ms /    44 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5511.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.63 ms /   107 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13096.12 ms /   107 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 13425.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    87.74 ms /   152 runs   (    0.58 ms per token,  1732.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18649.18 ms /   152 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 19124.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.44 ms /    75 runs   (    0.58 ms per token,  1726.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9180.79 ms /    75 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  9408.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente se afasta do Greens para no embaar as lentes devido ao uso de mscara durante o exame. Qual das alternativas abaixo  correta caso ele permanea afastado do Greens e o oftalmologista no perceba? a) Se ele for mope, haver hipocorreo em sua prescrio. b) Se ele for mope, haver hipercorreo em sua prescrio. c) Se ele for mope, no haver mudana em sua prescrio. d) Se ele for hipermetrope, necessitar de maior esforo acomodativo.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.22 ms /     7 runs   (    0.60 ms per token,  1657.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2921.76 ms /   156 tokens (   18.73 ms per token,    53.39 tokens per second)\n",
      "llama_print_timings:        eval time =   739.29 ms /     6 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3682.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.21 ms /   110 runs   (    0.60 ms per token,  1661.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13485.26 ms /   110 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 13833.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1716.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.42 ms /     7 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.15 ms /    85 runs   (    0.58 ms per token,  1729.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10443.75 ms /    85 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10701.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.17 ms /     7 runs   (  124.45 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1762.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.68 ms /     7 runs   (  120.81 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.22 ms /     7 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.98 ms /    26 runs   (    0.58 ms per token,  1735.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3158.04 ms /    26 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3235.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.09 ms /     7 runs   (  120.73 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   865.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.15 ms /     7 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   871.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 74: \n",
      "Language: english\n",
      "Question: \n",
      "What is the function of the \"P\" setting on the Greens refractor? a) Increase positive spherical power to test near refraction. b) Increase the negative spherical power to discount the working distance in skiascopy. c) Insert a 6 DP prism and allow the evaluation of the refractometric balance. d) Separate the images and allow evaluation of refractometric balance and stereopsis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.76 ms /    27 runs   (    0.58 ms per token,  1713.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2820.43 ms /   100 tokens (   28.20 ms per token,    35.46 tokens per second)\n",
      "llama_print_timings:        eval time =  3187.01 ms /    26 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6089.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'd)'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.47 ms /    46 runs   (    0.58 ms per token,  1737.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5728.98 ms /    46 runs   (  124.54 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  5868.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.01 ms /    73 runs   (    0.58 ms per token,  1737.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8929.04 ms /    73 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9149.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.75 ms /    85 runs   (    0.57 ms per token,  1743.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10321.30 ms /    85 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time = 10579.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1724.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3435.11 ms /    28 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3518.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.00 ms /    64 runs   (    0.58 ms per token,  1729.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7823.95 ms /    64 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  8022.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.29 ms /    44 runs   (    0.57 ms per token,  1740.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5343.10 ms /    44 runs   (  121.43 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5478.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.01 ms /    27 runs   (    0.59 ms per token,  1686.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3296.81 ms /    27 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3380.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.48 ms /    27 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3386.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.08 ms /    28 runs   (    0.57 ms per token,  1740.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3393.46 ms /    28 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3481.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual a funo do ajuste \"P\" no refrator de Greens? a) Aumentar o poder esfrico positivo para testar a refrao para perto. b) Aumentar o poder esfrico negativo para descontar a distncia de trabalho na esquiascopia. c) Inserir um prisma de 6 DP e possibilitar a avaliao do balano refratomtrico. d) Separar as imagens e possibilitar avaliao do balano refratomtrico e da estereopsia.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.68 ms /    57 runs   (    0.59 ms per token,  1692.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2784.45 ms /   140 tokens (   19.89 ms per token,    50.28 tokens per second)\n",
      "llama_print_timings:        eval time =  6879.24 ms /    56 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  9838.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.82 ms /     7 runs   (  120.69 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1738.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.44 ms /    27 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3380.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   916.33 ms /     7 runs   (  130.90 ms per token,     7.64 tokens per second)\n",
      "llama_print_timings:       total time =   936.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.63 ms /    80 runs   (    0.58 ms per token,  1715.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9841.66 ms /    80 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 10085.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.24 ms /     7 runs   (  120.89 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.33 ms /    87 runs   (    0.59 ms per token,  1694.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10735.57 ms /    87 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 11014.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.14 ms /    92 runs   (    0.58 ms per token,  1731.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11337.62 ms /    92 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 11618.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.65 ms /    27 runs   (    0.58 ms per token,  1724.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3290.22 ms /    27 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3371.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.94 ms /    52 runs   (    0.58 ms per token,  1736.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6336.92 ms /    52 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6493.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 75: \n",
      "Language: english\n",
      "Question: \n",
      "An undercorrected myopic person often tilts his glasses to see better. What effect does this maneuver have on your corrective lenses? a) Increased optical divergence and positive cylinder induction on the tilt axis. b) Increased optical convergence and negative cylinder induction on the tilt axis. c) Increased optical divergence and negative cylinder induction on the tilt axis. d) Increased optical convergence and positive cylinder induction on the tilt axis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.83 ms /   128 runs   (    0.59 ms per token,  1687.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2478.21 ms /   113 tokens (   21.93 ms per token,    45.60 tokens per second)\n",
      "llama_print_timings:        eval time = 15498.57 ms /   127 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 18378.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.49 ms /    45 runs   (    0.57 ms per token,  1765.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5480.99 ms /    45 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5614.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.26 ms /    27 runs   (    0.57 ms per token,  1769.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3266.27 ms /    27 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3345.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.95 ms /   143 runs   (    0.59 ms per token,  1683.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17490.43 ms /   143 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 17942.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.16 ms /   112 runs   (    0.57 ms per token,  1745.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13727.72 ms /   112 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 14073.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.20 ms /    27 runs   (    0.56 ms per token,  1776.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3279.05 ms /    27 runs   (  121.45 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3358.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    28 runs   (    0.56 ms per token,  1785.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3446.01 ms /    28 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3529.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.18 ms /   102 runs   (    0.57 ms per token,  1753.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12494.38 ms /   102 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 12805.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.03 ms /   115 runs   (    0.57 ms per token,  1741.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14157.95 ms /   115 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 14516.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.49 ms /    79 runs   (    0.58 ms per token,  1736.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9828.67 ms /    79 runs   (  124.41 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 10071.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um mope hipocorrigido frequentemente inclina seus culos para enxergar melhor. Qual o efeito desta manobra em suas lentes corretoras? a) Aumento da divergncia ptica e induo de cilindro positivo no eixo da inclinao. b) Aumento da convergncia ptica e induo de cilindro negativo no eixo da inclinao. c) Aumento da divergncia ptica e induo de cilindro negativo no eixo da inclinao. d) Aumento da convergncia ptica e induo de cilindro positivo no eixo da inclinao.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.34 ms /    80 runs   (    0.58 ms per token,  1726.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4015.87 ms /   172 tokens (   23.35 ms per token,    42.83 tokens per second)\n",
      "llama_print_timings:        eval time =  9759.86 ms /    79 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 14019.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.70 ms /     7 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.80 ms /    72 runs   (    0.65 ms per token,  1538.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8936.38 ms /    72 runs   (  124.12 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  9436.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   101.75 ms /   159 runs   (    0.64 ms per token,  1562.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19661.06 ms /   159 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 20696.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   872.51 ms /     7 runs   (  124.64 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =   893.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.65 ms /     7 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1764.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.24 ms /     7 runs   (  120.32 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.90 ms /    76 runs   (    0.58 ms per token,  1731.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9418.75 ms /    76 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  9650.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.66 ms /     7 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.94 ms /     7 runs   (    0.56 ms per token,  1774.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.55 ms /     7 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   877.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 76: \n",
      "Language: english\n",
      "Question: \n",
      "During the refraction outpatient clinic, the first-year resident instilled a cycloplegic eye drop in the patients, but lost the bottle. His preceptor decided to measure the accommodation effect to find out which drops were used and noticed that the patients had good mydriasis and had a maximum reduction in accommodation 20 to 30 minutes after instillation, with a fleeting effect. What eye drops did the resident instill? a) Atropine. b) Cyclopentolate. c) Phenylephrine. d) Tropicamide.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.77 ms /    53 runs   (    0.58 ms per token,  1722.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3192.84 ms /   136 tokens (   23.48 ms per token,    42.60 tokens per second)\n",
      "llama_print_timings:        eval time =  6434.45 ms /    52 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  9790.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.01 ms /     7 runs   (  120.29 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.13 ms /    52 runs   (    0.58 ms per token,  1726.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6399.82 ms /    52 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6558.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.16 ms /     9 runs   (    0.57 ms per token,  1744.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1093.06 ms /     9 runs   (  121.45 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  1120.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.85 ms /    32 runs   (    0.59 ms per token,  1697.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3923.86 ms /    32 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4022.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1756.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   883.04 ms /     7 runs   (  126.15 ms per token,     7.93 tokens per second)\n",
      "llama_print_timings:       total time =   904.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.93 ms /     7 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.93 ms /     7 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   879.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.86 ms /    52 runs   (    0.57 ms per token,  1741.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6371.88 ms /    52 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6531.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Tropicamide'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.20 ms /    23 runs   (    0.57 ms per token,  1742.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2831.69 ms /    23 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2900.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Tropicamide.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1765.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.44 ms /     7 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Durante o ambulatrio de refrao o residente do primeiro ano instilou um colrio cicloplgico nos pacientes, mas perdeu o frasco. Seu preceptor resolveu medir o efeito de acomodao para descobrir qual colrio foi usado e notou que os pacientes estavam com boa midrase e tiveram reduo mxima na acomodao 20 a 30 minutos aps a instilao, com efeito fugaz. Qual colrio o residente instilou? a) Atropina. b) Ciclopentolato. c) Fenilefrina. d) Tropicamida.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1694.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3556.32 ms /   167 tokens (   21.30 ms per token,    46.96 tokens per second)\n",
      "llama_print_timings:        eval time =   732.07 ms /     6 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4310.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1697.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.91 ms /     7 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   877.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.49 ms /     7 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.07 ms /     7 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   885.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.63 ms /     7 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.81 ms /     7 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.33 ms /     7 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.21 ms /     7 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   887.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1710.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.76 ms /     7 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   868.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.34 ms /     7 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 77: \n",
      "Language: english\n",
      "Question: \n",
      "During a patient's skiascopy, which of the following characteristics indicates that the examiner is closest to the point of neutrality? a) Fast beam speed, high brightness, wide beam. b) Fast beam speed, low brightness, narrow beam. c) Slow beam speed, high brightness, wide beam. d) Slow beam speed, low brightness, narrow beam.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.62 ms /    34 runs   (    0.58 ms per token,  1733.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1655.95 ms /    88 tokens (   18.82 ms per token,    53.14 tokens per second)\n",
      "llama_print_timings:        eval time =  4029.29 ms /    33 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5789.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.82 ms /    42 runs   (    0.57 ms per token,  1763.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5153.27 ms /    42 runs   (  122.70 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5280.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.94 ms /    39 runs   (    0.56 ms per token,  1777.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4746.72 ms /    39 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4864.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.50 ms /    28 runs   (    0.55 ms per token,  1807.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3398.72 ms /    28 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3482.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.02 ms /    34 runs   (    0.56 ms per token,  1788.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4148.78 ms /    34 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4250.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.45 ms /    40 runs   (    0.56 ms per token,  1782.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4928.89 ms /    40 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5049.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.04 ms /    32 runs   (    0.56 ms per token,  1773.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3895.02 ms /    32 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3991.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.44 ms /    40 runs   (    0.56 ms per token,  1782.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4908.55 ms /    40 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5028.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.86 ms /     7 runs   (    0.55 ms per token,  1812.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.97 ms /     7 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.84 ms /    41 runs   (    0.56 ms per token,  1794.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5058.09 ms /    41 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5181.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Durante a esquiascopia de um paciente, qual das caractersticas abaixo indica que o examinador est mais prximo do ponto de neutralidade? a) Velocidade do feixe rpida, brilho alto, feixe largo. b) Velocidade do feixe rpida, brilho baixo, feixe estreito. c) Velocidade do feixe lenta, brilho alto, feixe largo. d) Velocidade do feixe lenta, brilho baixo, feixe estreito.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1703.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3228.10 ms /   140 tokens (   23.06 ms per token,    43.37 tokens per second)\n",
      "llama_print_timings:        eval time =   734.12 ms /     6 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3983.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1758.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.00 ms /     7 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   871.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.31 ms /    20 runs   (    0.57 ms per token,  1768.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2448.23 ms /    20 runs   (  122.41 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2509.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.93 ms /     7 runs   (    0.56 ms per token,  1782.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.96 ms /     7 runs   (  120.57 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.05 ms /    63 runs   (    0.57 ms per token,  1747.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7706.99 ms /    63 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7899.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.66 ms /    52 runs   (    0.57 ms per token,  1753.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6397.77 ms /    52 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6554.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1819.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   880.81 ms /     7 runs   (  125.83 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =   901.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1818.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.41 ms /     7 runs   (  124.06 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.76 ms /    21 runs   (    0.56 ms per token,  1785.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2631.41 ms /    21 runs   (  125.31 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  2693.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.08 ms /    23 runs   (    0.57 ms per token,  1758.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2785.65 ms /    23 runs   (  121.12 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2854.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 78: \n",
      "Language: english\n",
      "Question: \n",
      "On examination of a phakic patient, the closest point of accommodation was found in the right eye at 30 cm and in the left eye at 50 cm. In this case, it can be stated: a) The left eye must be more myopic than the right eye. b) More likely there is a need to adjust the patient's refraction. c) It is a common condition, as accommodation is rarely similar in both eyes. d) A disease that moves the retina forward, such as central serous chorioretinopathy, is the cause of this shorter distance in the right eye.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.89 ms /    25 runs   (    0.60 ms per token,  1679.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2952.49 ms /   141 tokens (   20.94 ms per token,    47.76 tokens per second)\n",
      "llama_print_timings:        eval time =  2950.35 ms /    24 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5978.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.34 ms /    28 runs   (    0.58 ms per token,  1713.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3401.18 ms /    28 runs   (  121.47 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3485.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.56 ms /    25 runs   (    0.58 ms per token,  1717.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3061.79 ms /    25 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3136.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.65 ms /    20 runs   (    0.58 ms per token,  1717.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2440.63 ms /    20 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2501.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.84 ms /    17 runs   (    0.58 ms per token,  1728.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2068.35 ms /    17 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2118.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.24 ms /     7 runs   (  120.75 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   865.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.01 ms /     7 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.88 ms /    74 runs   (    0.59 ms per token,  1686.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9259.07 ms /    74 runs   (  125.12 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  9486.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.12 ms /    87 runs   (    0.58 ms per token,  1735.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10604.68 ms /    87 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 10868.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1733.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3086.75 ms /    25 runs   (  123.47 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3161.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "No exame de um paciente fcico, foi encontrado o ponto prximo de acomodao no olho direito a 30 cm e no olho esquerdo a 50 cm. Neste caso, pode-se afirmar: a) O olho esquerdo deve ser mais mope que o olho direito. b) Mais provavelmente h necessidade de se ajustar a refrao do paciente. c)  uma condio comum, j que a acomodao  raramente semelhante nos dois olhos. d) Uma doena que desloque a retina para frente, como a coriorretinopatia central serosa,  causa dessa menor distncia no olho direito.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.92 ms /   115 runs   (    0.58 ms per token,  1718.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2765.37 ms /   177 tokens (   15.62 ms per token,    64.01 tokens per second)\n",
      "llama_print_timings:        eval time = 14130.72 ms /   114 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 17252.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.26 ms /    94 runs   (    0.58 ms per token,  1732.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11543.52 ms /    94 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11827.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.56 ms /    27 runs   (    0.58 ms per token,  1735.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3316.91 ms /    27 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3396.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.80 ms /   111 runs   (    0.58 ms per token,  1712.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13732.81 ms /   111 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 14072.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.70 ms /    27 runs   (    0.58 ms per token,  1720.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.12 ms /    27 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3384.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3433.22 ms /    28 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3516.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.32 ms /   113 runs   (    0.58 ms per token,  1729.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13888.60 ms /   113 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 14233.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1710.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.24 ms /     7 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.50 ms /    20 runs   (    0.58 ms per token,  1738.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2502.25 ms /    20 runs   (  125.11 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  2561.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1710.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.24 ms /     7 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   874.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 79: \n",
      "Language: english\n",
      "Question: \n",
      "If the patient's refraction is +1.50 spherical diopters and -0.50 cylindrical diopters x 180 and his keratometry is 42.00 diopters x 180 and 44.00 diopters x 90, we can say that the internal astigmatism is : a) +1.50 cylindrical diopters x 90. b) +2.50 cylindrical diopters x 180. c) -1.50 cylindrical diopters x 90. d) -2.50 cylindrical diopters x 180.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.77 ms /    46 runs   (    0.56 ms per token,  1784.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3167.71 ms /   169 tokens (   18.74 ms per token,    53.35 tokens per second)\n",
      "llama_print_timings:        eval time =  5535.88 ms /    45 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8841.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.41 ms /    44 runs   (    0.55 ms per token,  1802.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5372.01 ms /    44 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5502.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.10 ms /    45 runs   (    0.56 ms per token,  1793.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5522.88 ms /    45 runs   (  122.73 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5656.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.56 ms /    46 runs   (    0.56 ms per token,  1799.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5646.66 ms /    46 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5782.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.87 ms /    46 runs   (    0.56 ms per token,  1778.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5704.64 ms /    46 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  5841.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.17 ms /    46 runs   (    0.57 ms per token,  1757.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5599.77 ms /    46 runs   (  121.73 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5737.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.64 ms /    44 runs   (    0.56 ms per token,  1786.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5417.28 ms /    44 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5548.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.86 ms /    45 runs   (    0.57 ms per token,  1739.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5534.30 ms /    45 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5671.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.64 ms /    28 runs   (    0.56 ms per token,  1790.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3422.89 ms /    28 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3506.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Se a refrao do paciente  +1,50 dioptrias esfericas e -0,50 dioptrias cilindricas x 180 e sua ceratometria  42,00 Dioptrias x 180 e 44,00 Dioptrias x 90, podemos afirmar que o astigmatismo interno : a) +1,50 dioptrias cilindricas x 90. b) +2,50 dioptrias cilindricas x 180. c) -1,50 dioptrias cilindricas x 90. d) -2,50 dioptrias cilindricas x 180.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.00 ms /    46 runs   (    0.57 ms per token,  1769.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5630.20 ms /    46 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5769.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.18 ms /     9 runs   (    0.58 ms per token,  1737.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3068.61 ms /   187 tokens (   16.41 ms per token,    60.94 tokens per second)\n",
      "llama_print_timings:        eval time =  1006.87 ms /     8 runs   (  125.86 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =  4103.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.72 ms /    26 runs   (    0.57 ms per token,  1766.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3206.22 ms /    26 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3284.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.89 ms /    51 runs   (    0.61 ms per token,  1651.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6256.57 ms /    51 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6414.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.73 ms /     7 runs   (    0.53 ms per token,  1876.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.11 ms /     7 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    96.10 ms /   157 runs   (    0.61 ms per token,  1633.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19348.19 ms /   157 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 19853.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.59 ms /    47 runs   (    0.63 ms per token,  1588.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5804.39 ms /    47 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  5949.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.89 ms /    26 runs   (    0.61 ms per token,  1635.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3168.63 ms /    26 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3253.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'a'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.87 ms /     9 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1101.10 ms /     9 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1127.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3414.19 ms /    28 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3502.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.88 ms /    26 runs   (    0.76 ms per token,  1307.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3206.02 ms /    26 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3295.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 80: \n",
      "Language: english\n",
      "Question: \n",
      "A pseudophakic patient with a refraction of +1.00 spherical diopters and -3.00 cylindrical diopters x 180 is likely to notice less blurry vision at: a) 0.5 m. b) 1 m. c) 2 m. d) 4 m.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    89.08 ms /   150 runs   (    0.59 ms per token,  1683.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1864.02 ms /    82 tokens (   22.73 ms per token,    43.99 tokens per second)\n",
      "llama_print_timings:        eval time = 18222.07 ms /   149 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 20568.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.36 ms /    32 runs   (    0.57 ms per token,  1743.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3867.14 ms /    32 runs   (  120.85 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3962.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.07 ms /    28 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3422.12 ms /    28 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3505.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.11 ms /   162 runs   (    0.57 ms per token,  1739.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19761.38 ms /   162 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 20262.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.39 ms /    27 runs   (    0.57 ms per token,  1753.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3276.97 ms /    27 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3355.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   105.66 ms /   180 runs   (    0.59 ms per token,  1703.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22098.73 ms /   180 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 22664.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.43 ms /   126 runs   (    0.57 ms per token,  1739.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15451.41 ms /   126 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 15840.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    74.86 ms /   129 runs   (    0.58 ms per token,  1723.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15861.68 ms /   129 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 16262.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.31 ms /   159 runs   (    0.57 ms per token,  1741.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19454.09 ms /   159 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 19948.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.19 ms /   145 runs   (    0.59 ms per token,  1702.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17869.03 ms /   145 runs   (  123.23 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 18320.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente pseudofcico com refrao de +1,00 dioptrias esfericas e -3,00 dioptrias cilindricas x 180 provavelmente notar um viso menos borrada a: a) 0,5 m. b) 1 m. c) 2 m. d) 4 m.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   172.68 ms /   278 runs   (    0.62 ms per token,  1609.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2180.92 ms /    89 tokens (   24.50 ms per token,    40.81 tokens per second)\n",
      "llama_print_timings:        eval time = 34085.51 ms /   277 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 37190.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.12 ms /   132 runs   (    0.64 ms per token,  1550.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16163.91 ms /   132 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 16606.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    74.89 ms /   130 runs   (    0.58 ms per token,  1735.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15871.68 ms /   130 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 16268.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.75 ms /    33 runs   (    0.57 ms per token,  1759.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4028.94 ms /    33 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4126.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3259.56 ms /    27 runs   (  120.72 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3340.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.30 ms /   103 runs   (    0.58 ms per token,  1737.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12566.05 ms /   103 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 12882.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.44 ms /   100 runs   (    0.57 ms per token,  1741.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12193.37 ms /   100 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 12499.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.17 ms /   103 runs   (    0.57 ms per token,  1740.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12614.15 ms /   103 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12927.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.82 ms /   106 runs   (    0.57 ms per token,  1742.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12879.12 ms /   106 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time = 13201.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 81: \n",
      "Language: english\n",
      "Question: \n",
      "Patient returns complaining of diplopia after making eyeglasses. Has anisometropia, but previously wore glasses without problems. There was no change in the prescription. Optical centers are properly mounted. The most likely explanation is: a) Change in the base curve of one of the lenses. b) Change in frame format. c) Disappearance of the central suppression scotoma. d) Loss of cerebral compensation capacity for the difference in aniseikonia.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.56 ms /    39 runs   (    0.58 ms per token,  1728.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4831.83 ms /    39 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4948.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.03 ms /    31 runs   (    0.58 ms per token,  1719.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2036.32 ms /   118 tokens (   17.26 ms per token,    57.95 tokens per second)\n",
      "llama_print_timings:        eval time =  3703.91 ms /    30 runs   (  123.46 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  5834.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2927.31 ms /    24 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2998.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.67 ms /    45 runs   (    0.57 ms per token,  1752.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5484.03 ms /    45 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5618.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Test #3: \n",
      "{'response': 'd) Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.66 ms /    27 runs   (    0.58 ms per token,  1724.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.35 ms /    27 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3381.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.86 ms /    45 runs   (    0.57 ms per token,  1740.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5467.26 ms /    45 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5602.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.92 ms /    45 runs   (    0.58 ms per token,  1736.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5508.96 ms /    45 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5642.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.57 ms /   115 runs   (    0.58 ms per token,  1727.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14170.28 ms /   115 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 14525.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.83 ms /    45 runs   (    0.57 ms per token,  1742.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5488.75 ms /    45 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5624.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Test #8: \n",
      "{'response': 'd) Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.88 ms /    45 runs   (    0.57 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5525.05 ms /    45 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5662.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.39 ms /    44 runs   (    0.58 ms per token,  1732.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5449.56 ms /    44 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  5582.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Loss of cerebral compensation capacity for the difference in aniseikonia.'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente retorna com queixa de diplopia aps confeccionar culos. Tem anisometropia, mas usava culos anteriormente sem problemas. No houve modificao na prescrio. Os centros pticos esto montados adequadamente. A explicao mais provvel : a) Mudana na curva base de uma das lentes. b) Mudana no formato da armao. c) Desaparecimento do escotoma central de supresso. d) Perda da capacidade de compensao cerebral da diferena da aniseiconia.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.08 ms /    29 runs   (    0.59 ms per token,  1697.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2830.97 ms /   146 tokens (   19.39 ms per token,    51.57 tokens per second)\n",
      "llama_print_timings:        eval time =  3429.80 ms /    28 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6349.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Perda da capacidade de compensao cerebral da diferena da aniseiconia.'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.44 ms /     7 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   879.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.68 ms /    29 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3548.24 ms /    29 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3636.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Perda da capacidade de compensao cerebral da diferena da aniseiconia.'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.42 ms /     7 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.56 ms /     7 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.30 ms /     7 runs   (  120.61 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.73 ms /    43 runs   (    0.58 ms per token,  1738.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5295.28 ms /    43 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5424.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.94 ms /   154 runs   (    0.58 ms per token,  1731.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19029.60 ms /   154 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 19503.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.42 ms /    79 runs   (    0.57 ms per token,  1739.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9668.12 ms /    79 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  9906.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   896.25 ms /     7 runs   (  128.04 ms per token,     7.81 tokens per second)\n",
      "llama_print_timings:       total time =   916.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 82: \n",
      "Language: english\n",
      "Question: \n",
      "The best alternative to including time-based prisms in eyeglass lenses for a -4.00 spherical diopters myopic patient with 4 prism diopters binocular diplopia is: a) Prescription of a lens with a neutral filter in one eye. b) Prescription of lenses with polarized filters in both eyes. c) Reduction of the distance between the optical centers of the lenses. d) Do not prescribe refraction in one eye to promote suppression of that eye.\n",
      "\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.07 ms /    38 runs   (    0.58 ms per token,  1721.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3043.64 ms /   124 tokens (   24.55 ms per token,    40.74 tokens per second)\n",
      "llama_print_timings:        eval time =  4529.42 ms /    37 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7687.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.60 ms /   154 runs   (    0.58 ms per token,  1738.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18954.76 ms /   154 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 19427.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.90 ms /    93 runs   (    0.60 ms per token,  1663.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11533.59 ms /    93 runs   (  124.02 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 11822.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.09 ms /    42 runs   (    0.60 ms per token,  1674.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5139.31 ms /    42 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5266.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.27 ms /    25 runs   (    0.57 ms per token,  1752.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3062.02 ms /    25 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3136.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.08 ms /    42 runs   (    0.57 ms per token,  1744.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5178.10 ms /    42 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5303.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.77 ms /    24 runs   (    0.57 ms per token,  1743.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2921.46 ms /    24 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2992.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.81 ms /    38 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4666.89 ms /    38 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4780.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.88 ms /    38 runs   (    0.58 ms per token,  1736.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4637.77 ms /    38 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4750.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.93 ms /    25 runs   (    0.60 ms per token,  1674.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3055.42 ms /    25 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3130.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A melhor alternativa  incluso de prismas de base temporal nas lentes dos culos para paciente mope de -4,00 dioptrias esfericas com diplopia binocular de 4 dioptrias prismaticas : a) Prescrio de lente com filtro neutro em um dos olhos. b) Prescrio de lentes com filtros polarizados em ambos os olhos. c) Reduo da distncia entre os centros pticos das lentes. d) No prescrever a refrao em um dos olhos para promover a supresso deste olho.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.76 ms /     7 runs   (    0.68 ms per token,  1469.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3047.45 ms /   152 tokens (   20.05 ms per token,    49.88 tokens per second)\n",
      "llama_print_timings:        eval time =   734.59 ms /     6 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3805.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.56 ms /     7 runs   (    0.79 ms per token,  1258.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.37 ms /     7 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   872.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    69.56 ms /   115 runs   (    0.60 ms per token,  1653.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14128.60 ms /   115 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 14497.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.86 ms /    26 runs   (    0.57 ms per token,  1749.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3253.74 ms /    26 runs   (  125.14 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  3330.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1765.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.83 ms /     7 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.32 ms /     7 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.01 ms /    26 runs   (    0.58 ms per token,  1731.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3192.14 ms /    26 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3269.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.43 ms /    48 runs   (    0.61 ms per token,  1631.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5946.94 ms /    48 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6098.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.70 ms /     7 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   886.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 83: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the conditions below is most typically associated with finding a \"partially empty\" sella turcica on magnetic resonance imaging? a) Optic nerve glioma. b) Pituitary macroadenoma. c) Cerebral pseudotumor. d) Tolosa-Hunt syndrome.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.92 ms /    26 runs   (    0.57 ms per token,  1742.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3182.01 ms /    26 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3260.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.82 ms /    44 runs   (    0.59 ms per token,  1704.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1838.11 ms /    75 tokens (   24.51 ms per token,    40.80 tokens per second)\n",
      "llama_print_timings:        eval time =  5292.82 ms /    43 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7264.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.36 ms /    37 runs   (    0.58 ms per token,  1732.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4513.81 ms /    37 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4625.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.59 ms /    48 runs   (    0.57 ms per token,  1739.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5812.88 ms /    48 runs   (  121.10 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  5956.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.73 ms /    34 runs   (    0.58 ms per token,  1723.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4136.64 ms /    34 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4239.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    28 runs   (    0.58 ms per token,  1728.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3443.82 ms /    28 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3527.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.60 ms /    34 runs   (    0.58 ms per token,  1734.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4133.65 ms /    34 runs   (  121.58 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4235.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.05 ms /    36 runs   (    0.58 ms per token,  1710.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4457.13 ms /    36 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4566.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3280.72 ms /    27 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3361.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.14 ms /    33 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4143.44 ms /    33 runs   (  125.56 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  4243.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.33 ms /    28 runs   (    0.58 ms per token,  1714.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3455.31 ms /    28 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3538.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das condies abaixo est mais tipicamente associada ao achado de sela trcica \"parcialmente vazia\" em um exame de imagem por ressonncia nuclear magntica? a) Glioma de nervo ptico. b) Macroadenoma de hipfise. c) Pseudotumor cerebral. d) Sndrome de Tolosa-Hunt.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.25 ms /     7 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1939.63 ms /   101 tokens (   19.20 ms per token,    52.07 tokens per second)\n",
      "llama_print_timings:        eval time =   738.32 ms /     6 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2699.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.91 ms /    17 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2094.82 ms /    17 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2145.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.71 ms /    27 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3372.70 ms /    27 runs   (  124.91 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3454.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.80 ms /     7 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.79 ms /    17 runs   (    0.58 ms per token,  1736.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2072.87 ms /    17 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2123.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.40 ms /     7 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.72 ms /    17 runs   (    0.57 ms per token,  1749.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2053.43 ms /    17 runs   (  120.79 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2103.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.12 ms /     7 runs   (  121.73 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.31 ms /     7 runs   (    0.76 ms per token,  1318.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.09 ms /     7 runs   (  120.58 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   867.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    25 runs   (    0.62 ms per token,  1603.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3109.84 ms /    25 runs   (  124.39 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3187.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 84: \n",
      "Language: english\n",
      "Question: \n",
      "About fourth cranial nerve palsy, it is correct to state: a) Associated facial nerve palsy is often present. b) In the examination of ocular motricity, there is an increase in the excursion of the paralyzed eye when looking down. c) The patient evolves with vertical diplopia, vicious head position and hypotropia of the paralyzed eye. d) Nuclear or infranuclear involvement of the IV nerve may have the same clinical picture.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.07 ms /    17 runs   (    0.59 ms per token,  1688.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2481.22 ms /   124 tokens (   20.01 ms per token,    49.98 tokens per second)\n",
      "llama_print_timings:        eval time =  1994.65 ms /    16 runs   (  124.67 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  4527.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.54 ms /    25 runs   (    0.58 ms per token,  1719.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3054.04 ms /    25 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3130.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.12 ms /    61 runs   (    0.58 ms per token,  1736.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7555.36 ms /    61 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  7741.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1738.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2116.02 ms /    17 runs   (  124.47 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  2166.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3492.16 ms /    28 runs   (  124.72 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3577.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.39 ms /    49 runs   (    0.58 ms per token,  1726.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5985.66 ms /    49 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6134.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.83 ms /    17 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2080.35 ms /    17 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2131.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.41 ms /    49 runs   (    0.58 ms per token,  1724.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5979.71 ms /    49 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6129.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.78 ms /     7 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.45 ms /    44 runs   (    0.58 ms per token,  1728.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5468.65 ms /    44 runs   (  124.29 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  5603.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a paralisia do IV nervo craniano,  correto afirmar: a) Frequentemente, apresenta-se paralisia de nervo facial associada. b) No exame da motricidade ocular, existe um aumento da excurso do olho paralisado no olhar para baixo. c) O paciente evolui com diplopia vertical, posio viciosa de cabea e hipotropia do olho paralisado. d) O acometimento nuclear ou infranuclear do IV nervo pode ter o mesmo quadro clnico.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    24 runs   (    0.60 ms per token,  1653.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2826.11 ms /   141 tokens (   20.04 ms per token,    49.89 tokens per second)\n",
      "llama_print_timings:        eval time =  2827.70 ms /    23 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5729.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   910.47 ms /     7 runs   (  130.07 ms per token,     7.69 tokens per second)\n",
      "llama_print_timings:       total time =   931.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1713.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.66 ms /     7 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.32 ms /     7 runs   (  124.19 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   889.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.77 ms /     7 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.73 ms /     7 runs   (  125.10 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   896.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1708.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   912.65 ms /     7 runs   (  130.38 ms per token,     7.67 tokens per second)\n",
      "llama_print_timings:       total time =   933.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.92 ms /     7 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   887.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.79 ms /     7 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.51 ms /     7 runs   (  124.22 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   889.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 85: \n",
      "Language: english\n",
      "Question: \n",
      "Eight-year-old child with subacute bilateral vertical gaze palsy, papilledema and light-near dissociation. It is correct to state: a) Mesencephalic lesions, such as tumors, should be investigated. b) This is a classic case of vertically transmitted neurological syphilis. c) It is most likely a lesion of the optic chiasm. d) Frontal lobe lesion is the main diagnostic hypothesis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.11 ms /    24 runs   (    0.59 ms per token,  1701.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2402.98 ms /   116 tokens (   20.72 ms per token,    48.27 tokens per second)\n",
      "llama_print_timings:        eval time =  2844.65 ms /    23 runs   (  123.68 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5320.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.53 ms /    91 runs   (    0.58 ms per token,  1732.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11186.87 ms /    91 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 11462.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.94 ms /    27 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3384.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   144.92 ms /   251 runs   (    0.58 ms per token,  1732.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 30953.23 ms /   251 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 31749.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.02 ms /    40 runs   (    0.58 ms per token,  1737.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4985.33 ms /    40 runs   (  124.63 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  5105.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.94 ms /     7 runs   (  123.99 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.80 ms /    43 runs   (    0.58 ms per token,  1733.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5376.82 ms /    43 runs   (  125.04 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  5506.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1741.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.09 ms /     7 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.22 ms /    23 runs   (    0.57 ms per token,  1740.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2889.64 ms /    23 runs   (  125.64 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  2957.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.83 ms /    24 runs   (    0.58 ms per token,  1735.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2929.94 ms /    24 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3001.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Criana de oito anos de idade com quadro bilateral subagudo de paralisia do olhar vertical, papiledema e dissociao luz-perto.  correto afirmar: a) Leses mesenceflicas, como tumores, devem ser investigadas. b) Trata-se de um caso clssico de sfilis neurolgica de transmisso vertical. c) Trata-se, mais provavelmente, de uma leso de quiasma ptico. d) Leso do lobo frontal  a principal hiptese diagnstica.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.29 ms /     7 runs   (    0.61 ms per token,  1631.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3077.18 ms /   145 tokens (   21.22 ms per token,    47.12 tokens per second)\n",
      "llama_print_timings:        eval time =   728.24 ms /     6 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3826.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.35 ms /    29 runs   (    0.60 ms per token,  1671.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3557.07 ms /    29 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3645.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.86 ms /     7 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1663.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.76 ms /     7 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1693.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.83 ms /     7 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   874.53 ms /     7 runs   (  124.93 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =   895.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1715.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.47 ms /     7 runs   (  121.92 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1718.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   908.07 ms /     7 runs   (  129.72 ms per token,     7.71 tokens per second)\n",
      "llama_print_timings:       total time =   929.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.26 ms /     7 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.71 ms /    29 runs   (    0.58 ms per token,  1735.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3519.64 ms /    29 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3607.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 86: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "A 35-year-old female patient, after sensory loss in the right upper limb, evolved with diplopia. Among the diagnostic hypotheses, the most likely is: a) Pituitary adenoma. b) Multiple sclerosis. c) Idiopathic intracranial hypertension. d) Meningioma of the optic nerve.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1661.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1664.97 ms /    94 tokens (   17.71 ms per token,    56.46 tokens per second)\n",
      "llama_print_timings:        eval time =   727.99 ms /     6 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2413.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.25 ms /     9 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1081.34 ms /     9 runs   (  120.15 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  1108.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.88 ms /     7 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.18 ms /    20 runs   (    0.61 ms per token,  1641.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2442.52 ms /    20 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2503.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.37 ms /    11 runs   (    0.58 ms per token,  1725.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1341.00 ms /    11 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1373.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3417.51 ms /    28 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3500.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.33 ms /     7 runs   (  119.76 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =   859.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.43 ms /    20 runs   (    0.57 ms per token,  1749.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2460.78 ms /    20 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2520.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1740.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2051.56 ms /    17 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2100.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3400.93 ms /    28 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3484.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente de 35 anos, sexo feminino, aps quadro de perda sensitiva no membro superior direito, evoluiu com diplopia. Dentre as hipteses diagnsticas a mais provvel : a) Adenoma hipofisrio. b) Esclerose mltipla. c) Hipertenso intracraniana idioptica. d) Meningeoma do nervo ptico.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.12 ms /    24 runs   (    0.59 ms per token,  1700.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2729.97 ms /   107 tokens (   25.51 ms per token,    39.19 tokens per second)\n",
      "llama_print_timings:        eval time =  2863.54 ms /    23 runs   (  124.50 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  5666.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.00 ms /     7 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   877.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1739.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3049.48 ms /    25 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3123.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.30 ms /    18 runs   (    0.57 ms per token,  1747.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2188.93 ms /    18 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2242.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Meningeoma do nervo ptico.'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.87 ms /     7 runs   (  119.84 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'd) Meningeoma do nervo ptico.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.64 ms /    36 runs   (    0.57 ms per token,  1744.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4402.40 ms /    36 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4509.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.94 ms /     7 runs   (  119.85 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.62 ms /     7 runs   (  120.52 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.12 ms /     7 runs   (  120.59 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   835.67 ms /     7 runs   (  119.38 ms per token,     8.38 tokens per second)\n",
      "llama_print_timings:       total time =   856.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 87: \n",
      "Language: english\n",
      "Question: \n",
      "The patient has unilateral paralysis of the third, fourth and sixth cranial nerves. It is correct to state: a) When painless, it is called Tolosa-Hunt syndrome. b) Involvement of the olfactory nerve suggests involvement of the cavernous sinus. c) One way to find out if there is a lesion in the cavernous sinus is to test the trigeminal sensitivity. d) If the vision is normal, but the three branches of the trigeminal are affected, possibly the lesion is restricted to the apex of the orbit.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.59 ms /    56 runs   (    0.58 ms per token,  1718.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2350.08 ms /   139 tokens (   16.91 ms per token,    59.15 tokens per second)\n",
      "llama_print_timings:        eval time =  6764.86 ms /    55 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  9285.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.43 ms /     7 runs   (    0.63 ms per token,  1581.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.73 ms /     7 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.02 ms /    66 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8149.62 ms /    66 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8349.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.12 ms /   139 runs   (    0.58 ms per token,  1734.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17096.62 ms /   139 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 17528.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.71 ms /   135 runs   (    0.58 ms per token,  1737.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16537.58 ms /   135 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 16953.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'd) If the vision is normal, but the three branches of the trigeminal are affected, possibly the lesion is restricted to the apex of the orbit.'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   131.06 ms /   228 runs   (    0.57 ms per token,  1739.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28060.21 ms /   228 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 28781.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.17 ms /    56 runs   (    0.57 ms per token,  1740.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6851.73 ms /    56 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7017.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.37 ms /    32 runs   (    0.57 ms per token,  1742.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3903.40 ms /    32 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3998.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.02 ms /    61 runs   (    0.57 ms per token,  1741.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7491.35 ms /    61 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7676.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   131.94 ms /   228 runs   (    0.58 ms per token,  1728.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28333.74 ms /   228 runs   (  124.27 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 29057.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente apresenta paralisia unilateral do terceiro, quarto e sexto nervos cranianos.  correto afirmar: a) Quando indolor, denomina-se sndrome de Tolosa-Hunt. b) O envolvimento do nervo olfatrio sugere acometimento do seio cavernoso. c) Uma maneira de localizar se h leso no seio cavernoso  testar a sensibilidade trigeminal. d) Se a viso est normal, mas os trs ramos do trigmeo estiverem afetados, possivelmente a leso est restrita ao pice da rbita.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.23 ms /     7 runs   (    0.60 ms per token,  1654.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3539.78 ms /   165 tokens (   21.45 ms per token,    46.61 tokens per second)\n",
      "llama_print_timings:        eval time =   751.42 ms /     6 runs   (  125.24 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  4312.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1698.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.72 ms /     7 runs   (  125.10 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   897.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.16 ms /     9 runs   (    0.57 ms per token,  1742.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1088.20 ms /     9 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1115.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.64 ms /    27 runs   (    0.58 ms per token,  1726.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3293.07 ms /    27 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3373.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.67 ms /     7 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.24 ms /     7 runs   (    0.61 ms per token,  1652.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.66 ms /     7 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   877.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.66 ms /     7 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   875.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n",
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.70 ms /     7 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.71 ms /     7 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.00 ms /     7 runs   (  120.57 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   863.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 88: \n",
      "Language: english\n",
      "Question: \n",
      "After bariatric surgery, the patient evolved with low serum levels of vitamin B12. In this case, it is correct to state that: a) Dyschromatopsia is an atypical finding. b) Visual improvement is not possible even with vitamin replacement. c) Peripheral scotomas and preservation of the foveal area are typical in perimetry. d) Pernicious anemia is associated with bilateral, symmetrical, painless and progressive visual loss.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.53 ms /    48 runs   (    0.59 ms per token,  1682.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2270.57 ms /   118 tokens (   19.24 ms per token,    51.97 tokens per second)\n",
      "llama_print_timings:        eval time =  5779.16 ms /    47 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8195.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.83 ms /    24 runs   (    0.58 ms per token,  1735.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2948.16 ms /    24 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3018.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.54 ms /     7 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.21 ms /    28 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3447.31 ms /    28 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3530.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.32 ms /    28 runs   (    0.58 ms per token,  1716.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3445.71 ms /    28 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3531.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.57 ms /   131 runs   (    0.58 ms per token,  1733.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16135.91 ms /   131 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 16550.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.54 ms /    49 runs   (    0.62 ms per token,  1604.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6001.36 ms /    49 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6158.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.03 ms /   154 runs   (    0.59 ms per token,  1691.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18836.36 ms /   154 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 19318.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.90 ms /    24 runs   (    0.58 ms per token,  1726.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2931.83 ms /    24 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3002.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.15 ms /    49 runs   (    0.57 ms per token,  1740.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5948.69 ms /    49 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  6096.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Aps cirurgia baritrica, paciente evoluiu com nveis sricos baixos de vitamina B12. Nesse caso,  correto afirmar que: a) A discromatopsia  um achado atpico. b) No  possvel a melhora visual mesmo com a reposio da vitamina. c) Escotomas perifricos e preservao da rea foveal so tpicos nas campimetrias. d) A anemia perniciosa est associada a perda visual bilateral, simtrica, indolor e progressiva.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.16 ms /     7 runs   (    0.59 ms per token,  1684.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2673.23 ms /   147 tokens (   18.19 ms per token,    54.99 tokens per second)\n",
      "llama_print_timings:        eval time =   748.42 ms /     6 runs   (  124.74 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3443.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1716.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.24 ms /     7 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.50 ms /     7 runs   (  120.93 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1720.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.46 ms /     7 runs   (  120.49 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1725.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.70 ms /     7 runs   (  120.39 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   863.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   129.13 ms /   220 runs   (    0.59 ms per token,  1703.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27155.37 ms /   220 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 27861.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.35 ms /     7 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.48 ms /     7 runs   (  120.78 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1747.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.23 ms /     7 runs   (  120.75 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   867.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.53 ms /     7 runs   (  121.08 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   869.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 89: \n",
      "Language: english\n",
      "Question: \n",
      "After a vascular accident affecting the lateral portion of the cervical spinal cord (Wallenberg syndrome), the patient developed anisocoria. It is correct to state that: a) Anisocoria will worsen in the dark. b) There will be worsening of anisocoria in light. c) Will be unresponsive to the instillation of sympathomimetic eye drops. d) Involvement of the stellate ganglion is the most likely diagnosis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.77 ms /   101 runs   (    0.58 ms per token,  1718.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2643.56 ms /   118 tokens (   22.40 ms per token,    44.64 tokens per second)\n",
      "llama_print_timings:        eval time = 12280.84 ms /   100 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 15242.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.31 ms /     7 runs   (  120.19 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1722.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3034.56 ms /    25 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3110.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.46 ms /    25 runs   (    0.58 ms per token,  1729.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3045.76 ms /    25 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3121.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.63 ms /   147 runs   (    0.58 ms per token,  1736.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18027.79 ms /   147 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 18481.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   114.13 ms /   197 runs   (    0.58 ms per token,  1726.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24309.51 ms /   197 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 24925.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.90 ms /    24 runs   (    0.58 ms per token,  1726.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2931.49 ms /    24 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3002.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    95.60 ms /   166 runs   (    0.58 ms per token,  1736.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20406.95 ms /   166 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 20926.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.07 ms /   127 runs   (    0.58 ms per token,  1738.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15653.08 ms /   127 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16055.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.68 ms /   102 runs   (    0.58 ms per token,  1738.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12620.41 ms /   102 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 12935.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Aps acidente vascular acometendo a poro lateral da medula cervical (sndrome de Wallenberg), o paciente desenvolveu anisocoria.  correto afirmar que: a) Haver piora da anisocoria no escuro. b) Haver piora da anisocoria no claro. c) Ser no responsivo  instilao de colrios simpatomimticos. d) O acometimento do gnglio estrelado  o diagnstico mais provvel.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.28 ms /     7 runs   (    0.61 ms per token,  1637.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2906.14 ms /   137 tokens (   21.21 ms per token,    47.14 tokens per second)\n",
      "llama_print_timings:        eval time =   732.88 ms /     6 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3660.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1700.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.20 ms /     7 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1694.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.01 ms /     7 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   874.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1706.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.58 ms /     7 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.28 ms /   134 runs   (    0.58 ms per token,  1733.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16519.53 ms /   134 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16934.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   900.48 ms /     7 runs   (  128.64 ms per token,     7.77 tokens per second)\n",
      "llama_print_timings:       total time =   920.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1725.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.54 ms /     7 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.37 ms /     7 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   881.80 ms /     7 runs   (  125.97 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =   902.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   833.42 ms /     7 runs   (  119.06 ms per token,     8.40 tokens per second)\n",
      "llama_print_timings:       total time =   854.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 90: \n",
      "Language: english\n",
      "Question: \n",
      "A patient arrives at the emergency room complaining of pain, reduced vision and hyperemia in the right eye for two days. On examination, he has a visual acuity of 0.1, anterior chamber reaction two crosses out of four, granulomatous keratic precipitates and a white-yellowish lesion with poorly defined limits on the periphery of the retina in the right eye. The left eye has no changes. What is the most appropriate initial course of action? a) Eye ultrasound. b) Use of topical corticosteroids and cycloplegic. c) Use of oral corticosteroids. d) Serology for toxoplasmosis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.73 ms /   161 runs   (    0.58 ms per token,  1717.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3378.33 ms /   164 tokens (   20.60 ms per token,    48.54 tokens per second)\n",
      "llama_print_timings:        eval time = 19756.47 ms /   160 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 23637.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.12 ms /     7 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1750.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2951.24 ms /    24 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3022.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   108.14 ms /   188 runs   (    0.58 ms per token,  1738.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23117.15 ms /   188 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 23703.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   117.58 ms /   203 runs   (    0.58 ms per token,  1726.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25075.50 ms /   203 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 25715.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   104.79 ms /   181 runs   (    0.58 ms per token,  1727.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22362.71 ms /   181 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 22934.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   115.59 ms /   198 runs   (    0.58 ms per token,  1712.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24485.10 ms /   198 runs   (  123.66 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 25107.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.54 ms /   203 runs   (    0.58 ms per token,  1712.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25061.74 ms /   203 runs   (  123.46 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 25698.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.93 ms /   197 runs   (    0.58 ms per token,  1729.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24222.94 ms /   197 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 24842.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   117.30 ms /   203 runs   (    0.58 ms per token,  1730.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24932.49 ms /   203 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 25580.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente chega ao pronto-socorro com queixa de dor, reduo da viso e hiperemia do olho direito h dois dias. Ao exame, apresenta acuidade visual 0,1, reao de cmara anterior duas cruzes em quatro, precipitados certicos granulomatosos e leso branco-amarelada de limites pouco definidos na periferia da retina no olho direito. O olho esquerdo no tem alteraes. Qual a conduta inicial mais apropriada? a) Ultrassonografia ocular. b) Uso de corticoide e cicloplgico tpicos. c) Uso de corticoide oral. d) Sorologia para toxoplasmose.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.20 ms /     7 runs   (    0.60 ms per token,  1666.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3745.35 ms /   188 tokens (   19.92 ms per token,    50.20 tokens per second)\n",
      "llama_print_timings:        eval time =   733.03 ms /     6 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4499.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1707.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.53 ms /     7 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   884.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.17 ms /     7 runs   (    0.60 ms per token,  1679.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.16 ms /     7 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.53 ms /     7 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1708.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.09 ms /     7 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.96 ms /     7 runs   (  123.99 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   889.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    74.00 ms /   128 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15871.09 ms /   128 runs   (  123.99 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 16263.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.12 ms /     7 runs   (  120.59 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.05 ms /     7 runs   (  120.44 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.33 ms /    11 runs   (    0.58 ms per token,  1736.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1344.36 ms /    11 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  1376.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 91: \n",
      "Language: english\n",
      "Question: \n",
      "An 8-year-old patient with a diagnosis of juvenile idiopathic arthritis, without other comorbidities, still untreated, presents with recurrent anterior uveitis associated with posterior synechiae, band keratopathy and cataract. What is the most appropriate conduct at this time among the alternatives below? a) Facectomy with acrylic intraocular lens implantation. b) Use of systemic immunomodulator. c) Use of oral corticosteroids. d) Use of topical EDTA.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.22 ms /    36 runs   (    0.59 ms per token,  1696.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3114.22 ms /   136 tokens (   22.90 ms per token,    43.67 tokens per second)\n",
      "llama_print_timings:        eval time =  4290.04 ms /    35 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  7514.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   133.59 ms /   231 runs   (    0.58 ms per token,  1729.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28490.44 ms /   231 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 29222.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   133.44 ms /   231 runs   (    0.58 ms per token,  1731.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28476.44 ms /   231 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 29207.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.57 ms /   118 runs   (    0.57 ms per token,  1746.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14587.26 ms /   118 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 14947.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.75 ms /   185 runs   (    0.58 ms per token,  1733.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22731.50 ms /   185 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 23307.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.35 ms /   152 runs   (    0.58 ms per token,  1720.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18737.04 ms /   152 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 19208.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   129.82 ms /   224 runs   (    0.58 ms per token,  1725.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27605.30 ms /   224 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 28315.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.91 ms /   138 runs   (    0.58 ms per token,  1727.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17084.01 ms /   138 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 17507.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.16 ms /    35 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4260.39 ms /    35 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4365.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    94.78 ms /   163 runs   (    0.58 ms per token,  1719.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20106.43 ms /   163 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 20612.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente de 8 anos com diagnstico de artrite juvenil idioptica, sem outras comorbidades, ainda sem tratamento, apresenta quadro recidivante de uvete anterior associada a sinquias posteriores, ceratopatia em faixa e catarata. Qual conduta mais apropriada neste momento dentre as alternativas abaixo? a) Facectomia com implante de lente intraocular acrlica. b) Uso de imunomodulador sistmico. c) Uso de corticoide oral. d) Uso de EDTA tpico.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1660.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3179.95 ms /   152 tokens (   20.92 ms per token,    47.80 tokens per second)\n",
      "llama_print_timings:        eval time =   736.96 ms /     6 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3937.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.19 ms /     7 runs   (    0.60 ms per token,  1672.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.20 ms /     7 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   887.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.72 ms /     8 runs   (    0.59 ms per token,  1694.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1040.72 ms /     8 runs   (  130.09 ms per token,     7.69 tokens per second)\n",
      "llama_print_timings:       total time =  1064.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.17 ms /     7 runs   (    0.60 ms per token,  1677.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.37 ms /     7 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.58 ms /     7 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.75 ms /     7 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.66 ms /    27 runs   (    0.58 ms per token,  1724.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3339.52 ms /    27 runs   (  123.69 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3419.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.90 ms /     7 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   870.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.36 ms /     7 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   882.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 92: \n",
      "Language: english\n",
      "Question: \n",
      "What is the immunosuppressant of choice for children with anterior uveitis secondary to juvenile idiopathic arthritis? a) Azathioprine. b) Tacrolimus. c) Cyclophosphamide. d) Methotrexate.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    94.37 ms /   164 runs   (    0.58 ms per token,  1737.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20148.30 ms /   164 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 20658.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.06 ms /    24 runs   (    0.59 ms per token,  1706.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1714.74 ms /    71 tokens (   24.15 ms per token,    41.41 tokens per second)\n",
      "llama_print_timings:        eval time =  2807.93 ms /    23 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4595.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.08 ms /    24 runs   (    0.59 ms per token,  1704.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2906.09 ms /    24 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2978.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1727.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2925.94 ms /    24 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2996.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.54 ms /    32 runs   (    0.58 ms per token,  1725.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3891.91 ms /    32 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3987.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.87 ms /    31 runs   (    0.58 ms per token,  1735.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3749.88 ms /    31 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3841.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.91 ms /     7 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   863.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.17 ms /     9 runs   (    0.57 ms per token,  1739.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1105.20 ms /     9 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  1131.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.14 ms /    42 runs   (    0.57 ms per token,  1740.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5103.21 ms /    42 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5228.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.89 ms /    38 runs   (    0.58 ms per token,  1735.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4681.63 ms /    38 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4796.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.87 ms /    31 runs   (    0.58 ms per token,  1734.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3751.22 ms /    31 runs   (  121.01 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3843.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual  o imunossupressor de escolha para crianas com uvete anterior secundria  artrite juvenil idioptica? a) Azatioprina. b) Tacrolimus. c) Ciclofosfamida. d) Metotrexato.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.18 ms /     7 runs   (    0.60 ms per token,  1675.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1742.32 ms /    75 tokens (   23.23 ms per token,    43.05 tokens per second)\n",
      "llama_print_timings:        eval time =   737.56 ms /     6 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2501.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.21 ms /    39 runs   (    0.57 ms per token,  1756.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4750.17 ms /    39 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4866.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.72 ms /    36 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4396.12 ms /    36 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4501.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.36 ms /     7 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   884.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.93 ms /     7 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1702.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.34 ms /     7 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.17 ms /    42 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5101.65 ms /    42 runs   (  121.47 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5226.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.91 ms /     7 runs   (  120.70 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   865.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.17 ms /     9 runs   (    0.57 ms per token,  1740.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1083.15 ms /     9 runs   (  120.35 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  1109.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.66 ms /     7 runs   (    0.67 ms per token,  1501.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.86 ms /     7 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   882.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 93: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Among the alternatives below, which exam is the most appropriate for the follow-up of a patient with panuveitis secondary to Behet's disease, using cyclosporine? a) Creatinine. b) Ferritin. c) Fasting blood glucose. d) HLA-B51.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.26 ms /   163 runs   (    0.57 ms per token,  1747.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1823.25 ms /    78 tokens (   23.38 ms per token,    42.78 tokens per second)\n",
      "llama_print_timings:        eval time = 19764.05 ms /   162 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 22093.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} HLA-B51.'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.03 ms /    78 runs   (    0.58 ms per token,  1732.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9504.65 ms /    78 runs   (  121.85 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  9739.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.41 ms /    86 runs   (    0.57 ms per token,  1740.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10468.46 ms /    86 runs   (  121.73 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time = 10728.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.63 ms /    27 runs   (    0.58 ms per token,  1727.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3294.20 ms /    27 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3375.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) HLA-B51'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.02 ms /    24 runs   (    0.58 ms per token,  1712.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2929.84 ms /    24 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3002.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) HLA-B51'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.78 ms /    27 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3384.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) HLA-B51'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.16 ms /    84 runs   (    0.57 ms per token,  1744.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10308.83 ms /    84 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10563.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) HLA-B51'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.45 ms /    32 runs   (    0.58 ms per token,  1734.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3877.52 ms /    32 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3972.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} HLA-B51.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.29 ms /    70 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8525.15 ms /    70 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  8735.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.74 ms /    80 runs   (    0.57 ms per token,  1749.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9770.34 ms /    80 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 10012.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Dentre as alternativas abaixo, qual exame  o mais apropriado para o seguimento de um paciente com panuveite secundria  doena de Behet, em uso de ciclosporina? a) Creatinina. b) Ferritina. c) Glicemia de jejum. d) HLA-B51.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.80 ms /    85 runs   (    0.59 ms per token,  1706.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1917.59 ms /    89 tokens (   21.55 ms per token,    46.41 tokens per second)\n",
      "llama_print_timings:        eval time = 10311.97 ms /    84 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12491.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.65 ms /     7 runs   (  120.52 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.71 ms /    29 runs   (    0.58 ms per token,  1736.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3498.38 ms /    29 runs   (  120.63 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3584.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.51 ms /    32 runs   (    0.58 ms per token,  1729.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3888.09 ms /    32 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3983.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'd) HLA-B51'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.87 ms /    24 runs   (    0.58 ms per token,  1730.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2973.39 ms /    24 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3045.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.93 ms /    12 runs   (    0.58 ms per token,  1732.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1451.86 ms /    12 runs   (  120.99 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1487.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.57 ms /    20 runs   (    0.58 ms per token,  1728.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2418.28 ms /    20 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2479.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.97 ms /    75 runs   (    0.57 ms per token,  1745.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9265.58 ms /    75 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  9492.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.43 ms /    25 runs   (    0.58 ms per token,  1732.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3041.41 ms /    25 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3115.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 94: \n",
      "Language: english\n",
      "Question: \n",
      "A 25-year-old female patient reported reduced visual acuity for a few days, preceded by fever, headache and malaise. On examination, she has a two-cross anterior chamber reaction, vitreitis, a four-cross, and retinal detachment at the posterior pole, compromising the macula, without holes in both eyes. What is the most appropriate treatment for retinal detachment? a) Posterior vitrectomy with SF6 infusion and head position. b) oral corticosteroid. c) Pneumatic retinopexy. d) Scleral introflexion with macular explant.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.91 ms /    84 runs   (    0.58 ms per token,  1717.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10300.66 ms /    84 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10553.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1692.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4092.01 ms /   148 tokens (   27.65 ms per token,    36.17 tokens per second)\n",
      "llama_print_timings:        eval time =   735.46 ms /     6 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4848.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.71 ms /     7 runs   (  124.39 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.16 ms /     9 runs   (    0.57 ms per token,  1744.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1107.62 ms /     9 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  1134.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   122.39 ms /   213 runs   (    0.57 ms per token,  1740.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26332.90 ms /   213 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 26997.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.24 ms /    28 runs   (    0.58 ms per token,  1724.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3468.26 ms /    28 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3552.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1692.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.84 ms /     7 runs   (  124.55 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   893.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.12 ms /   144 runs   (    0.58 ms per token,  1732.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17694.56 ms /   144 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 18148.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   110.69 ms /   190 runs   (    0.58 ms per token,  1716.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23355.42 ms /   190 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 23962.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.01 ms /     7 runs   (  120.29 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente de 25 anos, sexo feminino, refere reduo da acuidade visual h poucos dias, precedida de febre, cefaleia e mal-estar. Ao exame, apresenta reao de cmara anterior duas cruzes, vitrete uma cruz em quatro e descolamento da retina no polo posterior comprometendo a mcula, sem roturas em ambos os olhos. Qual o tratamento mais apropriado para o descolamento de retina? a) Vitrectomia posterior com infuso de SF6 e posio de cabea. b) Corticoide oral. c) Retinopexia pneumtica. d) Introflexo escleral com explante macular.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1735.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3309.01 ms /    27 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3388.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1709.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3290.76 ms /   180 tokens (   18.28 ms per token,    54.70 tokens per second)\n",
      "llama_print_timings:        eval time =   727.16 ms /     6 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4039.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1710.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.88 ms /     7 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.74 ms /     7 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.16 ms /     7 runs   (    0.59 ms per token,  1681.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.36 ms /     7 runs   (  125.05 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =   896.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1714.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.33 ms /     7 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.28 ms /     7 runs   (    0.61 ms per token,  1637.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   882.07 ms /     7 runs   (  126.01 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =   903.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.45 ms /     7 runs   (  121.92 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.40 ms /     7 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.58 ms /     7 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.92 ms /     7 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   879.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 95: \n",
      "Language: english\n",
      "Question: \n",
      "Patient with a history of open ocular trauma in the right eye one year ago, presents anterior chamber reaction to a cross, iris color change, mild vitreous clouding and glued retina. The electroretinogram shows extinguished responses in the photopic and scotopic phases. The left eye shows no alterations. What is the most likely cause? a) Bacterial endophthalmitis. b) Fungal endophthalmitis. c) Sympathetic ophthalmia. d) Retention of metallic intraocular foreign body.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   109.32 ms /   189 runs   (    0.58 ms per token,  1728.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3100.64 ms /   140 tokens (   22.15 ms per token,    45.15 tokens per second)\n",
      "llama_print_timings:        eval time = 23147.84 ms /   188 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 26846.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   131.10 ms /   227 runs   (    0.58 ms per token,  1731.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27982.91 ms /   227 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 28704.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   103.06 ms /   178 runs   (    0.58 ms per token,  1727.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21929.45 ms /   178 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 22492.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.57 ms /    20 runs   (    0.58 ms per token,  1728.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2444.87 ms /    20 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2505.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.67 ms /    34 runs   (    0.58 ms per token,  1728.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4168.48 ms /    34 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4275.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.90 ms /   204 runs   (    0.58 ms per token,  1715.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25269.36 ms /   204 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 25912.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.16 ms /    40 runs   (    0.58 ms per token,  1727.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4906.40 ms /    40 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5026.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Retention of metallic intraocular foreign body'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   129.07 ms /   222 runs   (    0.58 ms per token,  1720.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27422.93 ms /   222 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 28126.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'd} Retention of metallic intraocular foreign body.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.10 ms /    21 runs   (    0.58 ms per token,  1735.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2595.50 ms /    21 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  2657.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    94.63 ms /   164 runs   (    0.58 ms per token,  1732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20046.28 ms /   164 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 20556.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paciente com histria de trauma ocular aberto no olho direito h um ano apresenta reao de cmara anterior uma cruz, alterao da cor da ris, turvao vtrea leve e retina colada. O eletrorretinograma apresenta respostas extintas nas fases fotpica e escotpica. O olho esquerdo no apresenta alteraes. Qual a causa mais provvel? a) Endoftalmite bacteriana. b) Endoftalmite fngica. c) Oftalmia simptica. d) Reteno de corpo estranho intraocular metlico.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.14 ms /    24 runs   (    0.59 ms per token,  1696.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3208.10 ms /   161 tokens (   19.93 ms per token,    50.19 tokens per second)\n",
      "llama_print_timings:        eval time =  2846.71 ms /    23 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6129.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Reteno de corpo estranho intraocular metlico'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.50 ms /    41 runs   (    0.60 ms per token,  1673.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5047.90 ms /    41 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5173.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Reteno de corpo estranho intraocular metlico'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1732.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2914.40 ms /    24 runs   (  121.43 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2986.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Reteno de corpo estranho intraocular metlico'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1736.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3112.02 ms /    25 runs   (  124.48 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3186.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Reteno de corpo estranho intraocular metlico.'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1741.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2999.16 ms /    24 runs   (  124.97 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  3071.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Reteno de corpo estranho intraocular metlico'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1738.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2967.97 ms /    24 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3039.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Reteno de corpo estranho intraocular metlico'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1737.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3073.58 ms /    25 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3148.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Reteno de corpo estranho intraocular metlico.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   104.07 ms /   178 runs   (    0.58 ms per token,  1710.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21969.33 ms /   178 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 22539.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Reteno de corpo estranho intraocular metlico.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.61 ms /    41 runs   (    0.58 ms per token,  1736.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5029.50 ms /    41 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5153.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Reteno de corpo estranho intraocular metlico'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.83 ms /    24 runs   (    0.58 ms per token,  1735.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.51 ms /    24 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3000.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Reteno de corpo estranho intraocular metlico'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 96: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Among the alternatives below, which microorganism is associated with Eales disease? a) Bartonella henselae. b) Mycobacterium tuberculosis. c) Toxoplasma gondii. d) Epstein-Barr virus.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.94 ms /    17 runs   (    0.58 ms per token,  1710.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1374.18 ms /    67 tokens (   20.51 ms per token,    48.76 tokens per second)\n",
      "llama_print_timings:        eval time =  1925.78 ms /    16 runs   (  120.36 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  3351.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.74 ms /    27 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3259.03 ms /    27 runs   (  120.70 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3341.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.39 ms /    29 runs   (    0.60 ms per token,  1667.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3510.16 ms /    29 runs   (  121.04 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3599.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.04 ms /    35 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4272.50 ms /    35 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4377.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.48 ms /    20 runs   (    0.57 ms per token,  1742.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2404.38 ms /    20 runs   (  120.22 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  2464.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1764.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   835.36 ms /     7 runs   (  119.34 ms per token,     8.38 tokens per second)\n",
      "llama_print_timings:       total time =   855.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.96 ms /    28 runs   (    0.57 ms per token,  1754.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3448.30 ms /    28 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3532.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.25 ms /    37 runs   (    0.57 ms per token,  1741.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4504.03 ms /    37 runs   (  121.73 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4614.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.47 ms /    41 runs   (    0.57 ms per token,  1746.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4975.02 ms /    41 runs   (  121.34 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5097.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.19 ms /    27 runs   (    0.56 ms per token,  1777.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3294.52 ms /    27 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3373.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Dentre as alternativas abaixo, qual microorganismo est associado  doena de Eales? a)Bartonella henselae. b)Mycobacterium tuberculosis. c)Toxoplasma gondii. d) Vrus Epstein-Barr.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.23 ms /     7 runs   (    0.60 ms per token,  1656.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1820.61 ms /    76 tokens (   23.96 ms per token,    41.74 tokens per second)\n",
      "llama_print_timings:        eval time =   723.08 ms /     6 runs   (  120.51 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2564.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.50 ms /    28 runs   (    0.59 ms per token,  1696.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3413.33 ms /    28 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3498.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.82 ms /    29 runs   (    0.58 ms per token,  1724.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3555.00 ms /    29 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3641.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.19 ms /    28 runs   (    0.58 ms per token,  1729.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3392.16 ms /    28 runs   (  121.15 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3475.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    27 runs   (    0.58 ms per token,  1720.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3299.61 ms /    27 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3380.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.76 ms /    24 runs   (    0.57 ms per token,  1744.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2945.03 ms /    24 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3016.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.50 ms /     7 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.77 ms /    24 runs   (    0.57 ms per token,  1742.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2901.87 ms /    24 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2972.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.52 ms /    35 runs   (    0.59 ms per token,  1705.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4272.87 ms /    35 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4378.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.17 ms /    35 runs   (    0.58 ms per token,  1734.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4249.70 ms /    35 runs   (  121.42 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4354.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 97: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding ocular involvement in ankylosing spondylitis, it is correct to state: a) It is bilateral, not simultaneous, in most cases. b) The most characteristic picture corresponds to episodes of intermediate uveitis. c) Posterior synechiae of the iris is a rare complication. d) It is a granulomatous inflammatory process.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.97 ms /    74 runs   (    0.58 ms per token,  1722.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1606.42 ms /    93 tokens (   17.27 ms per token,    57.89 tokens per second)\n",
      "llama_print_timings:        eval time =  8936.35 ms /    73 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10772.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.83 ms /    73 runs   (    0.57 ms per token,  1745.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8948.15 ms /    73 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  9169.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.16 ms /    66 runs   (    0.58 ms per token,  1729.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8042.92 ms /    66 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  8242.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3373.63 ms /    28 runs   (  120.49 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  3457.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.82 ms /    17 runs   (    0.58 ms per token,  1730.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2139.58 ms /    17 runs   (  125.86 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =  2189.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.70 ms /    22 runs   (    0.58 ms per token,  1732.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2741.10 ms /    22 runs   (  124.60 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  2806.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.99 ms /     7 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1740.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2076.57 ms /    17 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2127.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.93 ms /    17 runs   (    0.58 ms per token,  1711.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2059.87 ms /    17 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2111.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.00 ms /    17 runs   (    0.59 ms per token,  1699.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2052.89 ms /    17 runs   (  120.76 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2103.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre o acometimento ocular na espondilite ancilosante,  correto afirmar: a)  bilateral, no simultneo, na maioria dos casos. b) O quadro mais caracterstico corresponde a episdios de uvete intermediria. c) Sinquia posterior da ris  complicao rara. d) Trata-se de processo inflamatrio granulomatoso.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.20 ms /     7 runs   (    0.60 ms per token,  1667.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2772.35 ms /   111 tokens (   24.98 ms per token,    40.04 tokens per second)\n",
      "llama_print_timings:        eval time =   729.46 ms /     6 runs   (  121.58 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3522.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.01 ms /     7 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   873.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.79 ms /     7 runs   (    0.68 ms per token,  1460.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.53 ms /     7 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   878.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    75.01 ms /   129 runs   (    0.58 ms per token,  1719.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15885.78 ms /   129 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 16286.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.17 ms /     7 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.01 ms /     7 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.39 ms /     7 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   878.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.87 ms /     7 runs   (  121.12 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1717.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.75 ms /     7 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 98: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following findings, on optical coherence tomography, represents a greater risk of retinal pigment epithelium rupture in antiangiogenic treatment of neovascular membranes? a) Retinochoroidal anastomosis with retinal hemorrhage. b) Elevated detachment of the retinal pigment epithelium. c) Marked and diffuse increase in the thickness of the choroid and choriocapillaries. d) Large amount of subretinal fluid with few intraretinal cysts.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.88 ms /     7 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.70 ms /    25 runs   (    0.59 ms per token,  1700.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2253.48 ms /   137 tokens (   16.45 ms per token,    60.79 tokens per second)\n",
      "llama_print_timings:        eval time =  2971.59 ms /    24 runs   (  123.82 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  5300.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.92 ms /    24 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2946.97 ms /    24 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3018.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1724.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3107.83 ms /    25 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3181.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1740.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3042.58 ms /    25 runs   (  121.70 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3116.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1733.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2921.94 ms /    24 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2992.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.65 ms /    93 runs   (    0.58 ms per token,  1733.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11459.47 ms /    93 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11740.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.08 ms /    90 runs   (    0.58 ms per token,  1728.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11022.51 ms /    90 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 11295.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    25 runs   (    0.58 ms per token,  1727.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3043.51 ms /    25 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3117.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.22 ms /     7 runs   (    0.60 ms per token,  1657.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.31 ms /     7 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   871.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual dos achados abaixo, ao exame de tomografia de coerncia ptica, representa maior risco de ruptura do epitlio pigmentado da retina no tratamento com antiangiognico de membranas neovasculares? a) Anastomose retinocoroidal com hemorragia retiniana. b) Descolamento elevado do epitlio pigmentado da retina. c) Aumento acentuado e difuso da espessura da coroide e coriocapilares. d) Grande quantidade de lquido subretiniano com poucos cistos intraretinianos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.61 ms /    25 runs   (    0.58 ms per token,  1711.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3045.76 ms /    25 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3120.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.20 ms /     7 runs   (    0.60 ms per token,  1667.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3335.09 ms /   163 tokens (   20.46 ms per token,    48.87 tokens per second)\n",
      "llama_print_timings:        eval time =   730.49 ms /     6 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4086.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.84 ms /    27 runs   (    0.59 ms per token,  1704.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3345.09 ms /    27 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3426.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    27 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3317.00 ms /    27 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3398.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3440.01 ms /    28 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3523.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.81 ms /     7 runs   (  120.69 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.66 ms /     7 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.53 ms /     7 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.35 ms /   118 runs   (    0.58 ms per token,  1726.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14602.76 ms /   118 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 14965.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.64 ms /     7 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 99: \n",
      "Language: english\n",
      "Question: \n",
      "The acute phase of some retinal diseases typically presents only with reversible glare of the ellipsoid zone on optical coherence tomography of the macula. Mark the alternative that best exemplifies one of these conditions. a) Paracentral acute medium maculopathy. b) Occlusion of the central retinal artery. c) Acute macular neuroretinopathy. d) Retinal venous occlusion.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.72 ms /    27 runs   (    0.58 ms per token,  1717.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3338.33 ms /    27 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3419.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.03 ms /    36 runs   (    0.58 ms per token,  1711.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1944.06 ms /   104 tokens (   18.69 ms per token,    53.50 tokens per second)\n",
      "llama_print_timings:        eval time =  4271.05 ms /    35 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6324.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.08 ms /    40 runs   (    0.58 ms per token,  1733.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4870.48 ms /    40 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4991.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.60 ms /    74 runs   (    0.58 ms per token,  1736.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9131.02 ms /    74 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  9354.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.50 ms /    46 runs   (    0.58 ms per token,  1735.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5605.65 ms /    46 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5744.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.28 ms /    39 runs   (    0.57 ms per token,  1750.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4788.45 ms /    39 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4904.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.36 ms /    48 runs   (    0.57 ms per token,  1754.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5872.49 ms /    48 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6014.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.96 ms /    40 runs   (    0.57 ms per token,  1741.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4944.11 ms /    40 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  5062.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.14 ms /    47 runs   (    0.58 ms per token,  1731.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5859.34 ms /    47 runs   (  124.67 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  6000.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.56 ms /    41 runs   (    0.57 ms per token,  1740.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4977.46 ms /    41 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5100.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.39 ms /    48 runs   (    0.57 ms per token,  1752.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5888.53 ms /    48 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6032.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A fase aguda de algumas doenas da retina apresenta-se tipicamente, apenas, com apagamento reversvel da zona elipsoide ao exame de tomografia de coerncia ptica da mcula. Assinale a alternativa que melhor exemplifica uma destas condies. a) Maculopatia mdia aguda paracentral. b) Ocluso da artria central da retina. c) Neurorretinopatia macular aguda. d) Ocluso venosa retiniana.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2512.80 ms /   127 tokens (   19.79 ms per token,    50.54 tokens per second)\n",
      "llama_print_timings:        eval time =   742.43 ms /     6 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3276.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.56 ms /    91 runs   (    0.58 ms per token,  1731.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11161.43 ms /    91 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 11440.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1765.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   922.44 ms /     7 runs   (  131.78 ms per token,     7.59 tokens per second)\n",
      "llama_print_timings:       total time =   943.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.55 ms /    40 runs   (    0.59 ms per token,  1698.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4871.83 ms /    40 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4992.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.87 ms /    38 runs   (    0.58 ms per token,  1737.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4646.67 ms /    38 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4760.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.36 ms /     7 runs   (  124.48 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   891.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.62 ms /    94 runs   (    0.58 ms per token,  1721.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11601.31 ms /    94 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 11887.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.05 ms /     9 runs   (    0.56 ms per token,  1782.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1084.81 ms /     9 runs   (  120.53 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  1110.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.09 ms /     7 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   874.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 100: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following retinal dystrophies is most typically associated with central macular cystoid spaces in a radial pattern? a) Choroideremia. b) Cone dystrophy. c) Fundus flavimaculatus. d) Congenital X-linked retinoschisis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.51 ms /     7 runs   (  120.22 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   861.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.54 ms /    33 runs   (    0.59 ms per token,  1688.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1650.16 ms /    73 tokens (   22.60 ms per token,    44.24 tokens per second)\n",
      "llama_print_timings:        eval time =  3959.86 ms /    32 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  5710.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.83 ms /    36 runs   (    0.58 ms per token,  1728.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4378.11 ms /    36 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4487.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.06 ms /     7 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   875.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.76 ms /    43 runs   (    0.58 ms per token,  1736.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5228.62 ms /    43 runs   (  121.60 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5359.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.18 ms /    35 runs   (    0.58 ms per token,  1734.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4268.22 ms /    35 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4373.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2903.57 ms /    24 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2975.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   840.49 ms /     7 runs   (  120.07 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =   861.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.64 ms /    15 runs   (    0.58 ms per token,  1735.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1818.36 ms /    15 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  1863.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.88 ms /    36 runs   (    0.58 ms per token,  1724.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4370.84 ms /    36 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4480.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.00 ms /    24 runs   (    0.58 ms per token,  1714.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2969.43 ms /    24 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3041.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das distrofias retinianas abaixo est mais tipicamente associada a espaos cistoides maculares centrais em padro radial? a) Coroideremia. b) Distrofia de cones. c) Fundus flavimaculatus. d) Retinosquise congnita ligada ao X.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    27 runs   (    0.60 ms per token,  1678.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1475.93 ms /    85 tokens (   17.36 ms per token,    57.59 tokens per second)\n",
      "llama_print_timings:        eval time =  3147.97 ms /    26 runs   (  121.08 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4707.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.33 ms /    16 runs   (    0.58 ms per token,  1715.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1935.48 ms /    16 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1983.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.33 ms /    16 runs   (    0.58 ms per token,  1714.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1936.12 ms /    16 runs   (  121.01 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  1984.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1688.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.28 ms /     7 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.14 ms /     7 runs   (  120.59 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.22 ms /    16 runs   (    0.58 ms per token,  1735.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1931.61 ms /    16 runs   (  120.73 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  1978.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1723.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.86 ms /     7 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3278.27 ms /    27 runs   (  121.42 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3358.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.00 ms /    33 runs   (    0.58 ms per token,  1736.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3996.08 ms /    33 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4097.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 101: \n",
      "Language: english\n",
      "Question: \n",
      "Bilateral diffuse uveal melanocytic proliferation is best classified as: a) Paraneoplastic disorder. b) Severe presentation of choroidal melanoma. c) Variant of Vogt-Koyanagi-Harada syndrome. d) Disorder secondary to retinal detachment treatment.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.63 ms /    15 runs   (    0.58 ms per token,  1738.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1819.90 ms /    15 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  1864.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.40 ms /     7 runs   (    0.63 ms per token,  1589.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1894.28 ms /    83 tokens (   22.82 ms per token,    43.82 tokens per second)\n",
      "llama_print_timings:        eval time =   719.71 ms /     6 runs   (  119.95 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =  2635.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.62 ms /    42 runs   (    0.59 ms per token,  1705.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5141.90 ms /    42 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5271.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.38 ms /    25 runs   (    0.57 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3018.06 ms /    25 runs   (  120.72 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3093.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1724.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3419.49 ms /    28 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3504.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.16 ms /    63 runs   (    0.57 ms per token,  1742.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7649.43 ms /    63 runs   (  121.42 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  7838.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1733.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3031.62 ms /    25 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3105.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.30 ms /    37 runs   (    0.58 ms per token,  1737.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4583.99 ms /    37 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4692.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.55 ms /    41 runs   (    0.57 ms per token,  1740.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4938.17 ms /    41 runs   (  120.44 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  5058.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.52 ms /    25 runs   (    0.58 ms per token,  1721.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3076.62 ms /    25 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3150.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.58 ms /    69 runs   (    0.57 ms per token,  1743.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8501.83 ms /    69 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8709.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A proliferao melanoctica uveal difusa bilateral  melhor classificada como: a) Desordem paraneoplsica. b) Apresentao grave do melanoma de coroide. c) Variante da sndrome de Vogt-Koyanagi-Harada. d) Desordem secundria a tratamento de descolamento de retina.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.72 ms /    25 runs   (    0.59 ms per token,  1698.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1954.94 ms /    97 tokens (   20.15 ms per token,    49.62 tokens per second)\n",
      "llama_print_timings:        eval time =  2901.22 ms /    24 runs   (  120.88 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4932.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   884.10 ms /     7 runs   (  126.30 ms per token,     7.92 tokens per second)\n",
      "llama_print_timings:       total time =   904.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.72 ms /    48 runs   (    0.58 ms per token,  1731.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5960.73 ms /    48 runs   (  124.18 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  6104.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.79 ms /     7 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   871.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.89 ms /     7 runs   (  119.84 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.34 ms /    25 runs   (    0.57 ms per token,  1743.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3034.94 ms /    25 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3108.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.78 ms /    24 runs   (    0.57 ms per token,  1741.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2909.84 ms /    24 runs   (  121.24 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2980.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.76 ms /    24 runs   (    0.57 ms per token,  1744.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2956.09 ms /    24 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3027.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.79 ms /    26 runs   (    0.57 ms per token,  1757.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3170.80 ms /    26 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3247.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.69 ms /    50 runs   (    0.57 ms per token,  1742.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6157.10 ms /    50 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6307.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 102: \n",
      "Language: english\n",
      "Question: \n",
      "In the examination of the periphery of the retina, in order to evaluate a certain region: a) The patient must look to the opposite side of the region to be observed and the doctor should position himself on the same side. b) The patient should look to the side of the region to be observed and the doctor should position himself on the opposite side. c) The patient must look to the side of the region to be observed and the doctor also position himself on the same side. d) The patient should look at the opposite side of the region to be observed and the doctor should also position himself on the opposite side.\n",
      "Test #0: \n",
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1725.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3424.89 ms /   135 tokens (   25.37 ms per token,    39.42 tokens per second)\n",
      "llama_print_timings:        eval time =  3293.46 ms /    27 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  6803.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.31 ms /    28 runs   (    0.58 ms per token,  1716.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3467.31 ms /    28 runs   (  123.83 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3552.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.07 ms /    28 runs   (    0.57 ms per token,  1742.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3395.80 ms /    28 runs   (  121.28 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3479.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1734.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3414.86 ms /    28 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3500.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.59 ms /    28 runs   (    0.59 ms per token,  1687.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3487.87 ms /    28 runs   (  124.57 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3573.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.97 ms /    28 runs   (    0.57 ms per token,  1752.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3385.02 ms /    28 runs   (  120.89 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3468.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n",
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.97 ms /    28 runs   (    0.57 ms per token,  1753.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3437.35 ms /    28 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3521.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.47 ms /    27 runs   (    0.57 ms per token,  1744.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.64 ms /    27 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3382.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3438.22 ms /    28 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3524.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n",
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "No exame da periferia da retina, para avaliar uma determinada regio: a) O paciente deve olhar para o lado oposto da regio que se deseja observar e o mdico se posicionar no mesmo lado. b) O paciente deve olhar para o lado da regio que se deseja observar e o mdico se posicionar no lado oposto. c) O paciente deve olhar para o lado da regio que se deseja observar e o mdico se posicionar tambm no mesmo lado. d) O paciente deve olhar para o lado oposto da regio que se deseja observar e o mdico se posicionar tambm no lado oposto.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.05 ms /    28 runs   (    0.57 ms per token,  1745.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3443.59 ms /    28 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3529.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.49 ms /    59 runs   (    0.58 ms per token,  1710.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2605.21 ms /   162 tokens (   16.08 ms per token,    62.18 tokens per second)\n",
      "llama_print_timings:        eval time =  7109.82 ms /    58 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  9897.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.90 ms /    80 runs   (    0.57 ms per token,  1742.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9852.18 ms /    80 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 10094.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.94 ms /    28 runs   (    0.57 ms per token,  1757.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3419.85 ms /    28 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3503.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.56 ms /    60 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7391.67 ms /    60 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7573.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.38 ms /    60 runs   (    0.57 ms per token,  1745.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7290.58 ms /    60 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  7467.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.47 ms /    27 runs   (    0.57 ms per token,  1745.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3342.53 ms /    27 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3423.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.82 ms /     7 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.60 ms /    60 runs   (    0.58 ms per token,  1734.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7337.13 ms /    60 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7521.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1738.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3404.52 ms /    28 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3490.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 103: \n",
      "Language: english\n",
      "Question: \n",
      "Check the alternative that correctly correlates the change in the fluorescein angiography exam and its description. a) Accumulation (pooling): late appearance, area increases throughout the exam. b) Staining: early appearance, area increases throughout the exam. c) Window defect: early appearance, area maintained throughout the exam. d) Extravasation: late appearance, area maintained throughout the examination.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.59 ms /    60 runs   (    0.58 ms per token,  1734.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7365.73 ms /    60 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  7551.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   151.48 ms /   263 runs   (    0.58 ms per token,  1736.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1969.49 ms /    92 tokens (   21.41 ms per token,    46.71 tokens per second)\n",
      "llama_print_timings:        eval time = 32397.18 ms /   262 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 35219.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Extravasation: late appearance, area maintained throughout the examination.'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.31 ms /    95 runs   (    0.57 ms per token,  1749.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11734.75 ms /    95 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 12023.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.90 ms /    44 runs   (    0.57 ms per token,  1767.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5372.72 ms /    44 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5504.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Extravasation: late appearance, area maintained throughout the examination.'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.80 ms /    80 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9776.13 ms /    80 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 10017.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.13 ms /    32 runs   (    0.57 ms per token,  1765.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3892.97 ms /    32 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3988.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.49 ms /   114 runs   (    0.57 ms per token,  1740.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13995.57 ms /   114 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 14345.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.63 ms /   101 runs   (    0.57 ms per token,  1752.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12402.97 ms /   101 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 12712.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.90 ms /    23 runs   (    0.56 ms per token,  1782.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2784.51 ms /    23 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2853.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Extravasation: late appearance, area maintained throughout the examination.'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.76 ms /    33 runs   (    0.57 ms per token,  1759.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4086.78 ms /    33 runs   (  123.84 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4184.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.00 ms /    37 runs   (    0.57 ms per token,  1761.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4551.84 ms /    37 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4661.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que correlaciona corretamente a alterao no exame de angiofluoresceinografia e sua descrio. a) Acmulo (pooling): aparecimento tardio, rea aumenta ao longo do exame. b) Impregnao (staining): aparecimento precoce, rea aumenta ao longo do exame. c) Defeito em janela: aparecimento precoce, rea mantida ao longo do exame. d) Extravazamento: aparecimento tardio, rea mantida ao longo do exame.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.45 ms /    64 runs   (    0.59 ms per token,  1709.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2907.67 ms /   140 tokens (   20.77 ms per token,    48.15 tokens per second)\n",
      "llama_print_timings:        eval time =  7708.05 ms /    63 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10815.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.47 ms /    27 runs   (    0.57 ms per token,  1745.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3288.54 ms /    27 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3371.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.30 ms /    53 runs   (    0.57 ms per token,  1749.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6509.68 ms /    53 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6674.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.57 ms /    34 runs   (    0.58 ms per token,  1737.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4189.70 ms /    34 runs   (  123.23 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4294.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.35 ms /    27 runs   (    0.57 ms per token,  1758.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.39 ms /    27 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3384.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.91 ms /    35 runs   (    0.57 ms per token,  1757.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4266.80 ms /    35 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4371.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.92 ms /    87 runs   (    0.57 ms per token,  1742.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10653.59 ms /    87 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10915.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.46 ms /    53 runs   (    0.57 ms per token,  1739.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6568.78 ms /    53 runs   (  123.94 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6729.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.66 ms /    27 runs   (    0.58 ms per token,  1724.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3378.61 ms /    27 runs   (  125.13 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  3459.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.34 ms /    27 runs   (    0.57 ms per token,  1760.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3327.93 ms /    27 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3407.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 104: \n",
      "Language: english\n",
      "Question: \n",
      "Considering the classification of diabetic retinopathy based on funduscopic findings and its prognostic significance, we can state: a) If there are no new vessels in the fundus examination, the risk of developing proliferative diabetic retinopathy in one year is less than 20%. b) The presence of only microhemorrhages and microaneurysms in three quadrants allows us to state that this patient will not develop proliferative diabetic retinopathy in one year. c) The presence of engorged veins associated with microaneurysms and microhemorrhages in all quadrants is considered a normal finding in diabetic retinopathy and suggests a risk below 10% of developing proliferative diabetic retinopathy in one year. d) The presence of intraretinal microvascular alterations (IRMA), moderate, in two quadrants, indicates that more than half of the patients will develop proliferative diabetic retinopathy in five years.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.66 ms /    25 runs   (    0.59 ms per token,  1705.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  5217.58 ms /   247 tokens (   21.12 ms per token,    47.34 tokens per second)\n",
      "llama_print_timings:        eval time =  2931.58 ms /    24 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8224.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.92 ms /    24 runs   (    0.58 ms per token,  1724.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2979.89 ms /    24 runs   (  124.16 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3051.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.18 ms /    17 runs   (    0.60 ms per token,  1669.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2077.89 ms /    17 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2128.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3458.92 ms /    28 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3541.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.85 ms /    17 runs   (    0.58 ms per token,  1725.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2091.73 ms /    17 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2142.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.84 ms /    17 runs   (    0.58 ms per token,  1727.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2079.12 ms /    17 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2129.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.44 ms /    25 runs   (    0.58 ms per token,  1730.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3083.52 ms /    25 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3157.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3480.76 ms /    28 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3565.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1737.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3432.45 ms /    28 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3516.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Considerando a classificao da retinopatia diabtica a partir dos achados fundoscpicos e seu significado prognstico, podemos afirmar: a) Se no existem neovasos no exame de fundo de olho, o risco de desenvolver retinopatia diabtica proliferativa em um ano  menor que 20%. b) A presena apenas de microhemorragias e microaneurismas em trs quadrantes permite afirmar que este paciente no desenvolver retinopatia diabtica proliferativa em um ano. c) A presena de veias ingurgitadas associada a microaneurismas e microhemorragias em todos os quadrantes  considerada achado normal na retinopatia diabtica e sugere um risco abaixo de 10% de desenvolver retinopatia diabtica proliferativa em um ano. d) A presena de alteraes microvasculares intrarretinianas (IRMA), moderadas, em dois quadrantes, indica que mais da metade dos pacientes desenvolver retinopatia diabtica proliferativa em cinco anos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.85 ms /    17 runs   (    0.58 ms per token,  1725.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2188.23 ms /    17 runs   (  128.72 ms per token,     7.77 tokens per second)\n",
      "llama_print_timings:       total time =  2239.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.52 ms /    28 runs   (    0.59 ms per token,  1695.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4984.40 ms /   278 tokens (   17.93 ms per token,    55.77 tokens per second)\n",
      "llama_print_timings:        eval time =  3319.44 ms /    27 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8388.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.84 ms /    27 runs   (    0.59 ms per token,  1704.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3344.07 ms /    27 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3426.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1738.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3345.95 ms /    27 runs   (  123.92 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3425.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.24 ms /     7 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1724.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3456.02 ms /    28 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3539.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.76 ms /    28 runs   (    0.60 ms per token,  1670.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3473.48 ms /    28 runs   (  124.05 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3558.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3485.46 ms /    28 runs   (  124.48 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3568.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.34 ms /    11 runs   (    0.58 ms per token,  1734.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1349.68 ms /    11 runs   (  122.70 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  1382.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.00 ms /     7 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   884.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.14 ms /    28 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3476.65 ms /    28 runs   (  124.17 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3560.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 105: \n",
      "Language: english\n",
      "Question: \n",
      "In an optical coherence tomography exam, what is the correct correlation between the classification and the description of neovascular membranes? a) Membranes located below the retinal pigment epithelium are called type 1. b) Type 2 membranes are located below the retinal pigment epithelium, but extend into the region between the retinal pigment epithelium and the sensorineural retina. c) The membranes located below the retinal pigment epithelium are called type 3. d) The membranes that grow well delimited in the space between the sensorineural retina and the retinal pigment epithelium are called type 3.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.03 ms /   102 runs   (    0.58 ms per token,  1727.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3336.28 ms /   169 tokens (   19.74 ms per token,    50.66 tokens per second)\n",
      "llama_print_timings:        eval time = 12494.89 ms /   101 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 16142.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.81 ms /    76 runs   (    0.58 ms per token,  1734.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9418.46 ms /    76 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  9651.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n",
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    25 runs   (    0.58 ms per token,  1735.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3098.62 ms /    25 runs   (  123.94 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3174.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.72 ms /    81 runs   (    0.58 ms per token,  1733.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9880.78 ms /    81 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 10127.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.88 ms /    24 runs   (    0.58 ms per token,  1729.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2920.07 ms /    24 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2991.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.97 ms /    48 runs   (    0.58 ms per token,  1716.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5961.67 ms /    48 runs   (  124.20 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  6108.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.96 ms /   103 runs   (    0.66 ms per token,  1515.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12633.61 ms /   103 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12969.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.48 ms /    25 runs   (    0.62 ms per token,  1614.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3062.33 ms /    25 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3140.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.15 ms /    75 runs   (    0.58 ms per token,  1738.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9229.34 ms /    75 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  9457.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.70 ms /    47 runs   (    0.59 ms per token,  1696.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5833.90 ms /    47 runs   (  124.13 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  5977.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Num exame de tomografia de coerncia ptica, qual a correlao correta entre a classificao e a descrio das membranas neovasculares? a) As membranas localizadas abaixo do epitlio pigmentado da retina so denominadas tipo 1. b) As membranas do tipo 2 localizam-se abaixo do epitlio pigmentado da retina, mas se estendem para a regio entre o epitlio pigmentado da retina e a retina neurossensorial. c) As membranas localizadas abaixo do epitlio pigmentado da retina so denominadas tipo 3. d) As membranas que crescem bem delimitadas no espao entre a retina neurossensorial e o epitlio pigmentado da retina so denominadas tipo 3.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.19 ms /     7 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4066.00 ms /   210 tokens (   19.36 ms per token,    51.65 tokens per second)\n",
      "llama_print_timings:        eval time =   724.76 ms /     6 runs   (  120.79 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  4812.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.22 ms /     7 runs   (    0.60 ms per token,  1656.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.49 ms /     7 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   879.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1714.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.37 ms /     7 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   885.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    90.78 ms /   157 runs   (    0.58 ms per token,  1729.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19393.97 ms /   157 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 19883.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.41 ms /    92 runs   (    0.58 ms per token,  1722.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11385.17 ms /    92 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 11665.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.08 ms /    73 runs   (    0.58 ms per token,  1734.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9032.16 ms /    73 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  9252.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    28 runs   (    0.58 ms per token,  1732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3491.95 ms /    28 runs   (  124.71 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3575.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    69.95 ms /   121 runs   (    0.58 ms per token,  1729.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14929.93 ms /   121 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 15303.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.56 ms /    95 runs   (    0.57 ms per token,  1741.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11664.92 ms /    95 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11954.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1735.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3302.96 ms /    27 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3383.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 106: \n",
      "Language: english\n",
      "Question: \n",
      "When considering the treatment of a patient with age-related macular degeneration, the best approach based on the findings of the AREDS studies is: a) Vitamin and antioxidant supplementation is indicated in patients with a family history, even before retinal changes appear. b) The presence of intermediate and large drusen is an indication of vitamin and antioxidant supplementation. c) Supplementation in smokers should include beta-carotene. d) When there is an advanced lesion in one of the eyes, vitamin and antioxidant supplementation is not recommended.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.88 ms /    74 runs   (    0.59 ms per token,  1686.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2380.43 ms /   143 tokens (   16.65 ms per token,    60.07 tokens per second)\n",
      "llama_print_timings:        eval time =  8995.03 ms /    73 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11605.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.34 ms /    77 runs   (    0.58 ms per token,  1736.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9517.12 ms /    77 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  9749.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    25 runs   (    0.58 ms per token,  1728.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3043.44 ms /    25 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3118.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.27 ms /    70 runs   (    0.58 ms per token,  1738.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8581.30 ms /    70 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8795.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n",
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.85 ms /    71 runs   (    0.58 ms per token,  1738.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8670.80 ms /    71 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8887.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.99 ms /    81 runs   (    0.58 ms per token,  1723.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9911.03 ms /    81 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10158.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n",
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.39 ms /    25 runs   (    0.58 ms per token,  1737.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3086.94 ms /    25 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3161.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.83 ms /    81 runs   (    0.58 ms per token,  1729.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10011.95 ms /    81 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 10257.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    24 runs   (    0.60 ms per token,  1656.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2985.14 ms /    24 runs   (  124.38 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3058.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.67 ms /    27 runs   (    0.58 ms per token,  1723.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3303.68 ms /    27 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3383.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Quando consideramos o tratamento de um paciente com degenerao macular relacionada  idade, a melhor conduta baseada nos achados dos estudos AREDS : a) A suplementao de vitaminas e antioxidantes est indicada em pacientes com histrico familiar, mesmo antes de aparecerem alteraes retinianas. b) A presena de drusas intermedirias e grandes  indicao de suplementao de vitaminas e antioxidantes. c) A suplementao em pacientes fumantes deve incluir betacaroteno. d) Quando h leso avanada em um dos olhos, no se recomenda a suplementao de vitaminas e antioxidantes.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.28 ms /     7 runs   (    0.61 ms per token,  1637.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3411.64 ms /   178 tokens (   19.17 ms per token,    52.17 tokens per second)\n",
      "llama_print_timings:        eval time =   771.43 ms /     6 runs   (  128.57 ms per token,     7.78 tokens per second)\n",
      "llama_print_timings:       total time =  4204.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.71 ms /    75 runs   (    0.58 ms per token,  1715.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9207.73 ms /    75 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  9438.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.31 ms /    27 runs   (    0.60 ms per token,  1655.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3295.09 ms /    27 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3379.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.49 ms /    20 runs   (    0.57 ms per token,  1740.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2430.65 ms /    20 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2490.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   879.28 ms /     7 runs   (  125.61 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =   899.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.22 ms /     7 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   867.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.84 ms /     7 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.19 ms /     7 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.60 ms /    83 runs   (    0.57 ms per token,  1743.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10255.62 ms /    83 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 10507.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.48 ms /     7 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 107: \n",
      "Language: english\n",
      "Question: \n",
      "The electrical response of the Mller cell is best represented by: a) \"a\" wave of the electroretinogram. b) Wave \"b\" of the electroretinogram. c) Wave \"c\" of the electroretinogram. d) Arden ratio on the electro-oculogram.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1737.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1742.91 ms /    76 tokens (   22.93 ms per token,    43.61 tokens per second)\n",
      "llama_print_timings:        eval time =  3265.64 ms /    27 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  5092.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.19 ms /    24 runs   (    0.59 ms per token,  1691.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2897.80 ms /    24 runs   (  120.74 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2971.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1736.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3302.33 ms /    27 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3382.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.81 ms /    17 runs   (    0.58 ms per token,  1732.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2040.82 ms /    17 runs   (  120.05 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  2090.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.44 ms /    25 runs   (    0.58 ms per token,  1731.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3034.66 ms /    25 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3109.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1750.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2918.66 ms /    24 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2990.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.57 ms /    27 runs   (    0.58 ms per token,  1734.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3319.31 ms /    27 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3399.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.47 ms /    27 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3258.80 ms /    27 runs   (  120.70 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3339.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.08 ms /    28 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3396.40 ms /    28 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3479.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.03 ms /    28 runs   (    0.57 ms per token,  1746.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3398.73 ms /    28 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3483.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A resposta eltrica da clula de Mller est melhor representada pela: a) Onda \"a\" do eletrorretinograma. b) Onda \"b\" do eletrorretinograma. c) Onda \"c\" do eletrorretinograma. d) Relao de Arden no eletro-oculograma.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.25 ms /     7 runs   (    0.61 ms per token,  1648.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1769.89 ms /    91 tokens (   19.45 ms per token,    51.42 tokens per second)\n",
      "llama_print_timings:        eval time =   735.38 ms /     6 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2527.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.49 ms /    28 runs   (    0.59 ms per token,  1698.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3419.45 ms /    28 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3505.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1735.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3378.11 ms /    28 runs   (  120.65 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3463.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   839.21 ms /     7 runs   (  119.89 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   860.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.89 ms /     7 runs   (  120.84 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1731.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2933.91 ms /    24 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3005.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.57 ms /    27 runs   (    0.58 ms per token,  1733.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3262.49 ms /    27 runs   (  120.83 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3342.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1725.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3063.35 ms /    25 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3138.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   840.07 ms /     7 runs   (  120.01 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =   860.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3275.01 ms /    27 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3355.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 108: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following is the best course of action for a 65-year-old patient with total retinal detachment due to a superior 155-degree arcuate peripheral retinal tear with a rolled-up posterior edge? a) Laser photocoagulation followed by scleral introflexion, with explant positioned superiorly. b) Scleral introflexion, with explant positioned superiorly and use of SF6 gas at the end of surgery. c) Pneumatic retinopexy followed by cryotherapy or laser photocoagulation. d) Posterior vitrectomy using perfluorocarbon and laser photocoagulation.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.05 ms /   110 runs   (    0.58 ms per token,  1717.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3621.40 ms /   160 tokens (   22.63 ms per token,    44.18 tokens per second)\n",
      "llama_print_timings:        eval time = 13403.81 ms /   109 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 17374.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.27 ms /   110 runs   (    0.58 ms per token,  1738.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13705.65 ms /   110 runs   (  124.60 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time = 14055.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.32 ms /   153 runs   (    0.58 ms per token,  1732.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18842.06 ms /   153 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 19324.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3490.18 ms /    28 runs   (  124.65 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3574.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.29 ms /   115 runs   (    0.58 ms per token,  1734.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14060.53 ms /   115 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 14411.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.08 ms /   108 runs   (    0.57 ms per token,  1739.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13393.18 ms /   108 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 13721.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    89.36 ms /   155 runs   (    0.58 ms per token,  1734.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19028.06 ms /   155 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 19508.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.18 ms /   108 runs   (    0.58 ms per token,  1737.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13312.39 ms /   108 runs   (  123.26 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 13650.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    64.59 ms /   112 runs   (    0.58 ms per token,  1734.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13831.81 ms /   112 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 14183.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n",
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual a melhor conduta, entre as abaixo, para um paciente de 65 anos com descolamento de retina total decorrente de rasgadura retiniana perifrica arqueada em 155 graus superiores, com borda posterior enrolada? a) Fotocoagulao a laser seguido de introflexo escleral, com explante posicionado superiormente. b) Introflexo escleral, com explante posicionado superiormente e uso de gs SF6 ao final da cirurgia. c) Retinopexia pneumtica seguida de crioterapia ou fotocoagulao a laser. d) Vitrectomia posterior com uso de perfluorcarbono e fotocoagulao laser.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.19 ms /   110 runs   (    0.57 ms per token,  1740.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13595.53 ms /   110 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 13932.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.18 ms /     7 runs   (    0.60 ms per token,  1674.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3113.74 ms /   184 tokens (   16.92 ms per token,    59.09 tokens per second)\n",
      "llama_print_timings:        eval time =   735.61 ms /     6 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3870.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.46 ms /     7 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   882.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.06 ms /     7 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   878.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.85 ms /   102 runs   (    0.59 ms per token,  1704.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12716.18 ms /   102 runs   (  124.67 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time = 13031.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.30 ms /   183 runs   (    0.61 ms per token,  1629.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22498.37 ms /   183 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 23094.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'd be happy to help! Based on the information provided, the best course of action for a patient with a total retinal detachment due to a peripheral arcuate retinal tear would be:\n",
      "\n",
      "b) Introflexo escleral, com explante posicionado superiormente e uso de gs SF6 ao final da cirurgia.\n",
      "\n",
      "This is because the introduction of a gas bubble into the eye can help to push the retina back into place and relieve the detachment. The use of gs SF6 (sulfur hexafluoride) is particularly effective in this situation as it is less likely to cause cataracts or other complications compared to other gases.\n",
      "\n",
      "Here's the response in JSON format:\n",
      "\n",
      "{\"response\": \"b\") Introflexo escleral\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    82.44 ms /   142 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17551.06 ms /   142 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 17989.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.46 ms /     7 runs   (  121.92 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.49 ms /     7 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1756.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.45 ms /     7 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1765.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   868.42 ms /     7 runs   (  124.06 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   888.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 109: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Which of the systemic diseases below is most often associated with angioid striae? a) Sickle cell anemia. b) Megaloblastic anemia c) Rheumatoid arthritis. d) Polyarteritis nodosa.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.21 ms /     7 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.80 ms /    32 runs   (    0.59 ms per token,  1702.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1611.27 ms /    67 tokens (   24.05 ms per token,    41.58 tokens per second)\n",
      "llama_print_timings:        eval time =  3772.95 ms /    31 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5481.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.57 ms /    32 runs   (    0.58 ms per token,  1723.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3890.63 ms /    32 runs   (  121.58 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3986.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    24 runs   (    0.58 ms per token,  1725.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2919.93 ms /    24 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2991.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.55 ms /     7 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1731.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2874.77 ms /    24 runs   (  119.78 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =  2945.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.05 ms /    33 runs   (    0.58 ms per token,  1732.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4009.21 ms /    33 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4107.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1736.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3381.75 ms /    28 runs   (  120.78 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3464.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.50 ms /    32 runs   (    0.58 ms per token,  1729.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3955.99 ms /    32 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4050.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1732.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2888.28 ms /    24 runs   (  120.34 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2959.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2898.17 ms /    24 runs   (  120.76 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2969.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das doenas sistmicas abaixo est mais frequentemente associada a um quadro de estrias angioides? a) Anemia falciforme. b) Anemia megaloblstica c) Artrite reumatoide.d) Poliarterite nodosa.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.64 ms /    36 runs   (    0.60 ms per token,  1663.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1312.34 ms /    74 tokens (   17.73 ms per token,    56.39 tokens per second)\n",
      "llama_print_timings:        eval time =  4239.55 ms /    35 runs   (  121.13 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  5663.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.50 ms /     7 runs   (    0.64 ms per token,  1557.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.41 ms /     7 runs   (  120.77 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.32 ms /    56 runs   (    0.58 ms per token,  1732.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6818.91 ms /    56 runs   (  121.77 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6986.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.45 ms /    25 runs   (    0.58 ms per token,  1730.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3029.72 ms /    25 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3103.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.19 ms /    16 runs   (    0.57 ms per token,  1741.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1935.61 ms /    16 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1983.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.28 ms /    37 runs   (    0.58 ms per token,  1738.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4599.41 ms /    37 runs   (  124.31 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  4710.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.81 ms /    33 runs   (    0.57 ms per token,  1754.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4006.98 ms /    33 runs   (  121.42 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4106.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.95 ms /    33 runs   (    0.57 ms per token,  1741.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4051.54 ms /    33 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4148.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1723.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.47 ms /     7 runs   (  120.64 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {'response': 'A'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   839.90 ms /     7 runs   (  119.99 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =   860.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.22 ms /    37 runs   (    0.57 ms per token,  1743.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4459.51 ms /    37 runs   (  120.53 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  4569.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 110: \n",
      "Language: english\n",
      "Question: \n",
      "In addition to the classic triad of blepharoptosis, epicanthus inversus, and telecanthus, which of the findings below appears frequently in blepharophimosis syndrome? a) Trichiasis major. b) Lateral ectropion of the lower eyelid. c) Lacrimal obstruction due to imperforation of the Hasner valve. d) Shortening of the superior conjunctival cul-de-sac.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.35 ms /    40 runs   (    0.58 ms per token,  1713.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2273.04 ms /   112 tokens (   20.30 ms per token,    49.27 tokens per second)\n",
      "llama_print_timings:        eval time =  4770.32 ms /    39 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7164.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.70 ms /    43 runs   (    0.57 ms per token,  1740.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5245.99 ms /    43 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5376.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.33 ms /    63 runs   (    0.58 ms per token,  1734.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7816.78 ms /    63 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  8008.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.74 ms /    50 runs   (    0.57 ms per token,  1739.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6164.91 ms /    50 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  6317.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.51 ms /     7 runs   (  121.79 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   874.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    25 runs   (    0.58 ms per token,  1735.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3037.47 ms /    25 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3113.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.10 ms /    28 runs   (    0.58 ms per token,  1739.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3405.51 ms /    28 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3490.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1733.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3048.91 ms /    25 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3123.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    88.72 ms /   154 runs   (    0.58 ms per token,  1735.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19076.71 ms /   154 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 19556.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1739.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2067.12 ms /    17 runs   (  121.60 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2116.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Alm da trade clssica de blefaroptose, epicanto inverso e telecanto, qual dos achados abaixo aparece com frequncia na sndrome da blefarofimose? a) Triquase maior. b) Ectrpio lateral da plpebra inferior. c) Obstruo lacrimal por imperfurao da vlvula de Hasner. d) Encurtamento do fundo de saco conjuntival superior.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.47 ms /    49 runs   (    0.58 ms per token,  1721.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2674.55 ms /   116 tokens (   23.06 ms per token,    43.37 tokens per second)\n",
      "llama_print_timings:        eval time =  5892.82 ms /    48 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  8716.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.95 ms /     7 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.93 ms /     7 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.65 ms /    48 runs   (    0.58 ms per token,  1736.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5923.94 ms /    48 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6069.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.20 ms /     7 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1741.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.29 ms /     7 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.16 ms /    68 runs   (    0.58 ms per token,  1736.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8306.00 ms /    68 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8516.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   840.86 ms /     7 runs   (  120.12 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   861.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.45 ms /    27 runs   (    0.57 ms per token,  1747.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3321.91 ms /    27 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3403.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.84 ms /     7 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   885.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 111: \n",
      "Language: english\n",
      "Question: \n",
      "Check the correct alternative regarding lower blepharoplasty surgery for aesthetic purposes. a) Removal of the lateral fat pad mainly suffered postoperative diplopia due to an injury to the inferior oblique. b) When performed via the transconjunctival route, there is a greater risk of eyelid retraction. c) Greater horizontal flaccidity of the head in the pre-surgical evaluation indicates the need for a lateral canthoplasty. d) In young patients, who have a greater healing response, the preferred route is transcutaneous.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.50 ms /    54 runs   (    0.60 ms per token,  1661.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2250.10 ms /   137 tokens (   16.42 ms per token,    60.89 tokens per second)\n",
      "llama_print_timings:        eval time =  6522.28 ms /    53 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8944.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    98.35 ms /   170 runs   (    0.58 ms per token,  1728.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21006.85 ms /   170 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 21557.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.22 ms /    47 runs   (    0.58 ms per token,  1726.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5797.05 ms /    47 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5945.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1724.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3070.39 ms /    25 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3147.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.41 ms /    38 runs   (    0.59 ms per token,  1695.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4662.75 ms /    38 runs   (  122.70 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4783.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1735.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3429.26 ms /    28 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3517.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.27 ms /    28 runs   (    0.58 ms per token,  1720.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3431.28 ms /    28 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3518.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.19 ms /    28 runs   (    0.58 ms per token,  1729.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3426.62 ms /    28 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3514.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n",
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.36 ms /    49 runs   (    0.58 ms per token,  1727.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5989.55 ms /    49 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  6144.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.33 ms /    58 runs   (    0.57 ms per token,  1740.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7101.52 ms /    58 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7278.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa correta quanto a cirurgia de blefaroplastia inferior para fins estticos.  a) Remoo da bolsa de gordura lateral tem como principal complicao a diplopia ps-operatria por leso no obliquo inferior. b) Quando realizada por via transconjuntival h maior risco de retrao palpebral. c) Maior flacidez horizontal da plpebra na avaliao pr-operatria indica a necessidade de associao de cantoplastia lateral. d) Em pacientes jovens, que possuem maior resposta cicatricial, a via preferencial  a transcutnea.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.64 ms /    30 runs   (    0.59 ms per token,  1700.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2895.84 ms /   170 tokens (   17.03 ms per token,    58.70 tokens per second)\n",
      "llama_print_timings:        eval time =  3643.67 ms /    29 runs   (  125.64 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  6629.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.96 ms /    31 runs   (    0.58 ms per token,  1726.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3769.16 ms /    31 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3863.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    69.27 ms /   119 runs   (    0.58 ms per token,  1718.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14708.06 ms /   119 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15076.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.03 ms /     7 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.86 ms /     7 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.73 ms /    76 runs   (    0.58 ms per token,  1738.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9312.32 ms /    76 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  9543.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1729.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3290.18 ms /    27 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3371.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.07 ms /     7 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.22 ms /     7 runs   (  120.17 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   861.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.69 ms /     7 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 112: \n",
      "Language: english\n",
      "Question: \n",
      "Choose the correct alternative. a) The following side effects of the application of periocular botulinum toxin can be considered: aponeurotic blepharoptosis, spastic entropion and restrictive strabismus. b) Unlike essential blepharospasm, treatment with oral myorelaxant drugs shows a good response to hemifacial spasm. c) The application of botulinum toxin type B is the most common treatment for essential blepharospasm. d) The adjuvant application of botulinum toxin in case of peripheral facial paralysis is performed on the unaffected side.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.67 ms /    75 runs   (    0.61 ms per token,  1642.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2802.26 ms /   155 tokens (   18.08 ms per token,    55.31 tokens per second)\n",
      "llama_print_timings:        eval time =  9055.57 ms /    74 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12093.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.84 ms /    24 runs   (    0.58 ms per token,  1733.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2923.62 ms /    24 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2994.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.14 ms /    63 runs   (    0.59 ms per token,  1696.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7844.35 ms /    63 runs   (  124.51 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  8038.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    28 runs   (    0.58 ms per token,  1728.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3437.43 ms /    28 runs   (  122.77 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3520.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.64 ms /    34 runs   (    0.58 ms per token,  1730.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4142.00 ms /    34 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4243.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.95 ms /    24 runs   (    0.58 ms per token,  1720.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2921.05 ms /    24 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2992.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.14 ms /     7 runs   (    0.59 ms per token,  1689.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   892.43 ms /     7 runs   (  127.49 ms per token,     7.84 tokens per second)\n",
      "llama_print_timings:       total time =   912.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.95 ms /    24 runs   (    0.58 ms per token,  1720.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3063.71 ms /    24 runs   (  127.65 ms per token,     7.83 tokens per second)\n",
      "llama_print_timings:       total time =  3137.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    27 runs   (    0.58 ms per token,  1730.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3331.53 ms /    27 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3413.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Escolha a alternativa correta. a) Podem ser considerados efeitos colaterais da aplicao da toxina botulnica periocular: blefaroptose aponeurtica, entrpio espstico e estrabismo restritivo. b) Diferentemente do blefaroespasmo essencial, o tratamento com drogas miorrelaxantes orais apresenta boa resposta para o espasmo hemifacial. c) A aplicao de toxina botulnica tipo B  o tratamento mais realizado para blefaroespasmo essencial. d) A aplicao adjuvante de toxina botulnica em caso de paralisia facial perifrica  realizada no lado no acometido.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1734.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3041.82 ms /    25 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3118.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.63 ms /   160 runs   (    0.59 ms per token,  1708.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3540.79 ms /   183 tokens (   19.35 ms per token,    51.68 tokens per second)\n",
      "llama_print_timings:        eval time = 19557.80 ms /   159 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 23603.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.53 ms /     7 runs   (    0.65 ms per token,  1545.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.68 ms /     7 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   881.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   100.48 ms /   173 runs   (    0.58 ms per token,  1721.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21375.65 ms /   173 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 21913.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.45 ms /     7 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1729.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3337.28 ms /    27 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3417.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.92 ms /     7 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.92 ms /     7 runs   (  121.13 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.34 ms /   184 runs   (    0.58 ms per token,  1730.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22778.19 ms /   184 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 23353.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   880.29 ms /     7 runs   (  125.76 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =   901.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.75 ms /     7 runs   (  123.68 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   886.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 113: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Which suture thread used in eyelid surgeries has the greatest potential for tissue inflammatory reaction? a) Silk, as it is organic. b) Polyester (Mersilene), as it is absorbable. c) Polyamide (Nylon), as it is monofilament. d) Polypropylene (Prolene), as it is multifilament braided.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.72 ms /   100 runs   (    0.58 ms per token,  1732.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2591.84 ms /   106 tokens (   24.45 ms per token,    40.90 tokens per second)\n",
      "llama_print_timings:        eval time = 12203.97 ms /    99 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 15100.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.62 ms /    43 runs   (    0.57 ms per token,  1746.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5241.21 ms /    43 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  5368.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.33 ms /    25 runs   (    0.57 ms per token,  1744.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3130.22 ms /    25 runs   (  125.21 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  3205.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.60 ms /    48 runs   (    0.57 ms per token,  1739.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5878.66 ms /    48 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  6026.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3410.76 ms /    28 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3495.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.31 ms /    89 runs   (    0.58 ms per token,  1734.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10833.19 ms /    89 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time = 11108.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3063.73 ms /    25 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3139.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.74 ms /    45 runs   (    0.57 ms per token,  1748.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5598.56 ms /    45 runs   (  124.41 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  5734.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.82 ms /    17 runs   (    0.58 ms per token,  1731.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2048.19 ms /    17 runs   (  120.48 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2099.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.80 ms /    52 runs   (    0.57 ms per token,  1744.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6407.24 ms /    52 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6566.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual fio de sutura utilizado em cirurgias palpebrais tem maior potencial de reao inflamatria tecidual? a) Seda, por ser orgnico. b) Poliester (Mersilene), por ser absorvvel. c) Poliamida (Nylon), por ser monofilamentar. d) Polipropilene (Prolene), por ser multifilamentar tranado.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.42 ms /     7 runs   (    0.63 ms per token,  1582.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1796.25 ms /   112 tokens (   16.04 ms per token,    62.35 tokens per second)\n",
      "llama_print_timings:        eval time =   728.26 ms /     6 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2546.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.16 ms /     7 runs   (    0.59 ms per token,  1682.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.66 ms /     7 runs   (  120.67 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1700.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.10 ms /     7 runs   (  122.73 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.83 ms /     7 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1706.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.49 ms /     7 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.77 ms /     7 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   874.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'd) Polipropilene (Prolene)'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.97 ms /    19 runs   (    0.58 ms per token,  1731.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2300.41 ms /    19 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2357.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.86 ms /     7 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.53 ms /    27 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3287.99 ms /    27 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3368.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.10 ms /     7 runs   (  122.73 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   880.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 114: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding the chalazion. a) In elderly patients, malignant transformation to sebaceous carcinoma is common. b) Histologically, it is characterized by chronic lipogranulomatous inflammation. c) In most cases, it originates from the apocrine gland attached to the eyelashes. d) Use of topical ivermectin in ointment is the preferred clinical treatment due to the demonstrated association with the Demodex folliculorum mite.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.70 ms /    56 runs   (    0.58 ms per token,  1712.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2392.11 ms /   127 tokens (   18.84 ms per token,    53.09 tokens per second)\n",
      "llama_print_timings:        eval time =  6752.87 ms /    55 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  9317.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.40 ms /    56 runs   (    0.58 ms per token,  1728.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6863.86 ms /    56 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  7032.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.80 ms /    55 runs   (    0.58 ms per token,  1729.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6739.39 ms /    55 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6904.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.37 ms /    56 runs   (    0.58 ms per token,  1729.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6824.06 ms /    56 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6992.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.25 ms /    49 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6067.53 ms /    49 runs   (  123.83 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6214.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.77 ms /    56 runs   (    0.59 ms per token,  1708.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6857.49 ms /    56 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7027.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.16 ms /    59 runs   (    0.58 ms per token,  1727.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7237.95 ms /    59 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  7416.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.78 ms /    55 runs   (    0.58 ms per token,  1730.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6696.30 ms /    55 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6862.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.37 ms /    63 runs   (    0.58 ms per token,  1732.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7739.06 ms /    63 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7930.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.27 ms /    49 runs   (    0.58 ms per token,  1733.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5954.65 ms /    49 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  6101.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      " Assinale a alternativa correta quanto ao calzio. a) Em pacientes idosos  comum a transformao maligna para carcinoma sebceo. b) Histologicamente caracteriza-se por inflamao crnica lipogranulomatosa. c) Na maioria das vezes origina-se de glndula apcrina atrelada aos clios. d) Uso de ivermectina tpica em pomada  o tratamento clnico preferido devido a associao demonstrada com o caro Demodex foliculorum.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.02 ms /    98 runs   (    0.58 ms per token,  1718.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3287.59 ms /   144 tokens (   22.83 ms per token,    43.80 tokens per second)\n",
      "llama_print_timings:        eval time = 12048.40 ms /    97 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 15639.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.16 ms /    54 runs   (    0.58 ms per token,  1733.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6653.19 ms /    54 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6818.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.97 ms /    59 runs   (    0.58 ms per token,  1736.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7232.30 ms /    59 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  7411.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.17 ms /    61 runs   (    0.58 ms per token,  1734.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7509.74 ms /    61 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7697.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.30 ms /     7 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   868.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.14 ms /    66 runs   (    0.58 ms per token,  1730.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8082.72 ms /    66 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  8283.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.09 ms /    61 runs   (    0.58 ms per token,  1738.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7588.59 ms /    61 runs   (  124.40 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  7772.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1736.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3481.28 ms /    28 runs   (  124.33 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3564.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.23 ms /    61 runs   (    0.58 ms per token,  1731.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7473.19 ms /    61 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  7657.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 115: \n",
      "Language: english\n",
      "Question: \n",
      "A 60-year-old woman with tonic-clonic contractions that started in the periocular muscles on the right and in three months progressed to the entire hemiface. Although the contractions vary during the day, they usually don't let her sleep, as they \"don't stop at night\". Tick the correct alternative. a) This is a case of benign essential blepharospasm. b) Contractions tend to progressively affect the contralateral side and become bilateral and symmetrical. c) A possible cause is intracranial vascular compression of the ipsilateral facial nerve. d) Medications that modulate serotonin production in the basal nuclei, although not completely effective, help control contractions.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    69.87 ms /   121 runs   (    0.58 ms per token,  1731.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14804.14 ms /   121 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 15182.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.92 ms /    53 runs   (    0.58 ms per token,  1714.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3051.68 ms /   183 tokens (   16.68 ms per token,    59.97 tokens per second)\n",
      "llama_print_timings:        eval time =  6349.97 ms /    52 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  9562.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Medications that modulate serotonin production in the basal nuclei, although not completely effective, help control contractions.'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.34 ms /    56 runs   (    0.58 ms per token,  1731.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6942.93 ms /    56 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  7112.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.39 ms /    17 runs   (    0.61 ms per token,  1636.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2082.93 ms /    17 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2133.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   901.54 ms /     7 runs   (  128.79 ms per token,     7.76 tokens per second)\n",
      "llama_print_timings:       total time =   922.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1737.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3460.30 ms /    28 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3543.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.41 ms /    53 runs   (    0.57 ms per token,  1742.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6626.64 ms /    53 runs   (  125.03 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  6785.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.72 ms /    50 runs   (    0.57 ms per token,  1740.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6154.93 ms /    50 runs   (  123.10 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6305.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.50 ms /    53 runs   (    0.58 ms per token,  1737.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6546.82 ms /    53 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6706.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3457.81 ms /    28 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3541.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.31 ms /    28 runs   (    0.58 ms per token,  1716.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3440.69 ms /    28 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3525.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Mulher de 60 anos com contraes tnico-clnicas que se iniciaram na musculatura periocular  direita e em trs meses evoluiram para toda a hemiface. Embora as contraes variem durante o dia, geralmente no a deixam dormir, pois \"no param a noite\". Assinale a alternativa correta. a) Trata-se de um caso de blefaroespasmo essencial benigno. b) As contraes tendem a acometer progressivamente o lado contralateral e tornarem-se bilaterais e simtricas. c) Uma possvel causa  compresso intracraniana vascular do nervo facial ipsolateral. d) Medicaes que modulam produo de serotonina nos ncleos da base, embora no sejam completamente efetivas, auxiliam no controle das contraes.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.21 ms /     7 runs   (    0.60 ms per token,  1661.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3960.24 ms /   222 tokens (   17.84 ms per token,    56.06 tokens per second)\n",
      "llama_print_timings:        eval time =   751.65 ms /     6 runs   (  125.28 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  4733.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n",
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.72 ms /    20 runs   (    0.59 ms per token,  1705.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2462.99 ms /    20 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2524.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1694.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.22 ms /     7 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   880.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1727.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.66 ms /     7 runs   (  123.38 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.02 ms /    57 runs   (    0.58 ms per token,  1726.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7049.05 ms /    57 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  7221.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    83.57 ms /   145 runs   (    0.58 ms per token,  1735.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17965.68 ms /   145 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 18414.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.56 ms /     7 runs   (  124.51 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   892.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.79 ms /     7 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.01 ms /     7 runs   (  124.14 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =   889.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1685.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.08 ms /     7 runs   (  120.30 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 116: \n",
      "Language: english\n",
      "Question: \n",
      "The technique of tarsal fracture with marginal rotation is most indicated for the treatment of which type of eyelid entropion, among the following? a) Involutional (senile). b) Spastic. c) Congenital. d) Scarring.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.30 ms /     7 runs   (    0.61 ms per token,  1627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1527.86 ms /    66 tokens (   23.15 ms per token,    43.20 tokens per second)\n",
      "llama_print_timings:        eval time =   742.38 ms /     6 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  2291.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.96 ms /    17 runs   (    0.59 ms per token,  1706.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2056.25 ms /    17 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2107.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.85 ms /    17 runs   (    0.58 ms per token,  1725.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2054.46 ms /    17 runs   (  120.85 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2105.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.21 ms /    28 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3418.55 ms /    28 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3501.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.83 ms /    17 runs   (    0.58 ms per token,  1729.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2066.18 ms /    17 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2116.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.52 ms /    27 runs   (    0.57 ms per token,  1739.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3266.92 ms /    27 runs   (  121.00 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3346.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2916.09 ms /    24 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2987.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.12 ms /    21 runs   (    0.58 ms per token,  1733.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2534.65 ms /    21 runs   (  120.70 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2596.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2066.69 ms /    17 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2116.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.19 ms /     7 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   886.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A tcnica de fratura tarsal com rotao marginal  mais indicada para tratamento de qual tipo de entrpio palpebral, dentre os abaixo? a) Involucional (senil). b) Espstico. c) Congnito. d) Cicatricial.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.69 ms /     9 runs   (    0.63 ms per token,  1582.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1790.49 ms /    77 tokens (   23.25 ms per token,    43.01 tokens per second)\n",
      "llama_print_timings:        eval time =   960.28 ms /     8 runs   (  120.04 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  2778.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   864.05 ms /     7 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   885.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.07 ms /    21 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2550.98 ms /    21 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2614.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1738.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2935.94 ms /    24 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3007.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.08 ms /    59 runs   (    0.58 ms per token,  1731.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7179.03 ms /    59 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7356.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.94 ms /     7 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.66 ms /    29 runs   (    0.57 ms per token,  1740.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3529.39 ms /    29 runs   (  121.70 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3615.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b} Espstico.'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.81 ms /     7 runs   (  120.26 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1736.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3439.49 ms /    28 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3521.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.82 ms /     7 runs   (  120.55 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   863.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 117: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the alternatives best correlates with the measurements in the table below? Palpebral fissure09 mm Upper margin-reflex distance 01 mm Lower margin-reflex distance 08 mm Function of the eyelid levator muscle 14 mm Upper eyelid crease height 16 mm a) Possible case of senile blepharoptosis associated with senile ectropion. b) Possible case of congenital reverse eyelid ptosis. c) Probable case of eyelid retraction due to Graves' inflammatory orbitopathy d) If the patient is Caucasian, these measurements can be considered normal.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.89 ms /    77 runs   (    0.58 ms per token,  1715.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2912.09 ms /   160 tokens (   18.20 ms per token,    54.94 tokens per second)\n",
      "llama_print_timings:        eval time =  9333.56 ms /    76 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 12481.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.76 ms /     7 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.08 ms /   205 runs   (    0.58 ms per token,  1736.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25095.74 ms /   205 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 25733.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.03 ms /    95 runs   (    0.58 ms per token,  1726.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11650.85 ms /    95 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 11940.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   119.25 ms /   207 runs   (    0.58 ms per token,  1735.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25534.42 ms /   207 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 26186.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   928.09 ms /     7 runs   (  132.58 ms per token,     7.54 tokens per second)\n",
      "llama_print_timings:       total time =   948.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.53 ms /    32 runs   (    0.58 ms per token,  1727.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3980.01 ms /    32 runs   (  124.38 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  4075.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.19 ms /     7 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.04 ms /   167 runs   (    0.58 ms per token,  1720.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20604.92 ms /   167 runs   (  123.38 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 21125.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.33 ms /   168 runs   (    0.58 ms per token,  1726.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20596.97 ms /   168 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 21122.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das alternativas melhor se correlaciona com as medidas da tabela abaixo? Fenda palpebral 09 mm Distncia margem-reflexo superior 01 mm Distncia margem-reflexo inferior 08 mm Funo do msculo levantador da plpebra 14 mm Altura da prega palpebral superior 16 mm a) Possvel caso de blefaroptose senil associada a ectrpio senil. b) Possvel caso de ptose palpebral reversa congnita. c) Provvel caso de retrao palpebral por orbitopatia inflamatria de Graves d) Caso o paciente seja caucasiano, essas medidas podem ser consideradas normais.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1686.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3183.06 ms /   191 tokens (   16.67 ms per token,    60.01 tokens per second)\n",
      "llama_print_timings:        eval time =   734.85 ms /     6 runs   (  122.47 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3939.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   101.14 ms /   176 runs   (    0.57 ms per token,  1740.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21689.62 ms /   176 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 22237.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.42 ms /     7 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.27 ms /     7 runs   (  121.32 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1755.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.06 ms /     7 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   869.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.79 ms /     7 runs   (  121.11 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   839.22 ms /     7 runs   (  119.89 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =   859.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   100.92 ms /   176 runs   (    0.57 ms per token,  1743.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21629.76 ms /   176 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 22172.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.85 ms /     7 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.93 ms /     7 runs   (    0.56 ms per token,  1779.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   878.50 ms /     7 runs   (  125.50 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =   898.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 118: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding the lacrimal system. a) Approximately 50% of newborns maintain obstruction of the Hasner valve until the sixth month of life, and 90% of them require probing. b) In most newborns, tear secretion is less than in healthy adults. c) Complete canalization of the nasolacrimal duct usually occurs around the sixth week of extrauterine life. d) The newborn generally presents complete canalization of the nasolacrimal sac and duct; however, the canaliculi open around the sixth week of extrauterine life.\n",
      "\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.40 ms /    28 runs   (    0.59 ms per token,  1707.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3303.46 ms /   144 tokens (   22.94 ms per token,    43.59 tokens per second)\n",
      "llama_print_timings:        eval time =  3392.50 ms /    27 runs   (  125.65 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  6780.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.01 ms /    55 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6825.58 ms /    55 runs   (  124.10 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  6993.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.27 ms /    72 runs   (    0.57 ms per token,  1744.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8798.53 ms /    72 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9013.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.75 ms /    50 runs   (    0.58 ms per token,  1738.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6178.66 ms /    50 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  6328.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.30 ms /    93 runs   (    0.57 ms per token,  1744.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11455.96 ms /    93 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11738.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2916.56 ms /    24 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2987.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1738.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2073.35 ms /    17 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2123.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.02 ms /    24 runs   (    0.58 ms per token,  1711.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2939.33 ms /    24 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3012.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   129.02 ms /   223 runs   (    0.58 ms per token,  1728.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 27475.30 ms /   223 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 28183.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.26 ms /    49 runs   (    0.58 ms per token,  1733.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6004.07 ms /    49 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6150.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa correta quanto ao sistema lacrimal. a) Aproximadamente 50% dos recm-nascidos mantm obstruo da valva de Hasner at o sexto ms de vida, sendo que 90% deles necessitam de sondagem. b) Na maioria dos recm-nascidos a secreo lacrimal  menor que a do adulto saudvel. c) A canalizao completa do ducto nasolacrimal geralmente ocorre por volta da sexta semana de vida extrauterina. d) O recm-nascido geralmente apresenta canalizao completa do saco e ducto nasolacrimal; no entanto os canalculos abrem-se por volta da sexta semana de vida extrauterina.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.01 ms /    27 runs   (    0.59 ms per token,  1686.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2924.49 ms /   195 tokens (   15.00 ms per token,    66.68 tokens per second)\n",
      "llama_print_timings:        eval time =  3160.29 ms /    26 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  6166.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.22 ms /    75 runs   (    0.58 ms per token,  1735.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9240.66 ms /    75 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9468.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.32 ms /    70 runs   (    0.58 ms per token,  1735.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8657.44 ms /    70 runs   (  123.68 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  8868.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.69 ms /    75 runs   (    0.58 ms per token,  1716.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9223.34 ms /    75 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  9450.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1725.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.85 ms /     7 runs   (  124.55 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   892.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.20 ms /    89 runs   (    0.58 ms per token,  1738.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10870.88 ms /    89 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 11141.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.56 ms /    27 runs   (    0.58 ms per token,  1735.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3367.82 ms /    27 runs   (  124.73 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  3448.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.88 ms /    76 runs   (    0.58 ms per token,  1732.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9367.14 ms /    76 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9597.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.53 ms /     7 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.04 ms /     7 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   882.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 119: \n",
      "Language: english\n",
      "Question: \n",
      "Choose the alternative that best fills the gap: In adults, __________ is only performed for diagnosis, as for treatment it is potentially traumatic and rarely effective in permanently relieving lacrimal obstruction. a) Intubation with a silicone probe. b) Irrigation with mucolytic solution. c) Probing with metallic rod. d) Use of argon laser probe.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.69 ms /    37 runs   (    0.59 ms per token,  1705.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1922.79 ms /    99 tokens (   19.42 ms per token,    51.49 tokens per second)\n",
      "llama_print_timings:        eval time =  4466.76 ms /    36 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  6502.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.57 ms /    37 runs   (    0.58 ms per token,  1715.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4566.86 ms /    37 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  4679.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.30 ms /    35 runs   (    0.58 ms per token,  1723.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4277.81 ms /    35 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4382.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.03 ms /    33 runs   (    0.58 ms per token,  1734.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4046.73 ms /    33 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4147.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.82 ms /    29 runs   (    0.58 ms per token,  1723.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3513.21 ms /    29 runs   (  121.15 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3601.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.84 ms /    36 runs   (    0.58 ms per token,  1727.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4338.47 ms /    36 runs   (  120.51 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  4446.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.94 ms /    36 runs   (    0.58 ms per token,  1719.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4357.04 ms /    36 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4466.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.07 ms /    40 runs   (    0.58 ms per token,  1733.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4853.92 ms /    40 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4974.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.95 ms /    26 runs   (    0.57 ms per token,  1739.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3136.99 ms /    26 runs   (  120.65 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3215.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.95 ms /    74 runs   (    0.58 ms per token,  1723.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9080.72 ms /    74 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  9309.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Escolha a alternativa que melhor preencha a lacuna: Em adultos, a __________  apenas realizada para diagnstico, pois para tratamento  potencialmente traumtica e raramente efetiva para aliviar permanentemente a obstruo lacrimal. a) Intubao com sonda de silicone. b) Irrigao com soluo mucoltica. c) Sondagem com haste metlica. d) Utilizao de sonda de laser de argnio.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.85 ms /    98 runs   (    0.59 ms per token,  1694.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2170.08 ms /   129 tokens (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_print_timings:        eval time = 11954.63 ms /    97 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 14433.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.81 ms /    38 runs   (    0.57 ms per token,  1742.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4635.79 ms /    38 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4748.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.30 ms /    25 runs   (    0.57 ms per token,  1747.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3026.85 ms /    25 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3100.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.32 ms /    39 runs   (    0.57 ms per token,  1746.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4772.55 ms /    39 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4888.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.20 ms /     7 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.81 ms /    38 runs   (    0.57 ms per token,  1742.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4606.81 ms /    38 runs   (  121.23 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4719.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3392.05 ms /    28 runs   (  121.14 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3474.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.89 ms /    38 runs   (    0.58 ms per token,  1735.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4648.16 ms /    38 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4761.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.50 ms /    39 runs   (    0.58 ms per token,  1732.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4794.32 ms /    39 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4910.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.79 ms /     7 runs   (  121.68 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 120: \n",
      "Language: english\n",
      "Question: \n",
      "In the semiotics of obstructions of the lacrimal drainage pathways, the test that uses technetium-99m instillation in the lacrimal cul-de-sac is: a) Zapata-Milder. b) Jones II modified. c) Dacryocystography. d) Dacryocintigraphy.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    28 runs   (    0.58 ms per token,  1717.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2146.44 ms /    90 tokens (   23.85 ms per token,    41.93 tokens per second)\n",
      "llama_print_timings:        eval time =  3296.82 ms /    27 runs   (  122.10 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5527.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.79 ms /    36 runs   (    0.58 ms per token,  1731.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4372.48 ms /    36 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4480.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1726.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3466.00 ms /    28 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3549.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.20 ms /    28 runs   (    0.58 ms per token,  1728.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3438.50 ms /    28 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3521.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1739.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2077.24 ms /    17 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2128.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.81 ms /    15 runs   (    0.59 ms per token,  1702.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1814.26 ms /    15 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1858.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.44 ms /    45 runs   (    0.59 ms per token,  1701.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5576.01 ms /    45 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  5713.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1736.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3397.86 ms /    28 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3480.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3379.01 ms /    28 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3461.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1741.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3294.38 ms /    27 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3373.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Na semitica das obstrues das vias lacrimais de drenagem, o teste que usa a instilao de tecncio-99m no fundo de saco lacrimal  de: a) Zapata-Milder. b) Jones II modificado. c) Dacriocistografia. d) Dacriocintilografia.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.01 ms /    31 runs   (    0.58 ms per token,  1720.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1998.16 ms /    91 tokens (   21.96 ms per token,    45.54 tokens per second)\n",
      "llama_print_timings:        eval time =  3671.73 ms /    30 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5762.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.12 ms /    14 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1696.69 ms /    14 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  1738.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.72 ms /    27 runs   (    0.58 ms per token,  1717.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3260.95 ms /    27 runs   (  120.78 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3342.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1736.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3400.15 ms /    28 runs   (  121.43 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3483.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.41 ms /     7 runs   (  121.06 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   868.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3414.84 ms /    28 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3500.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.15 ms /     7 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    27 runs   (    0.60 ms per token,  1664.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3309.30 ms /    27 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3391.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.46 ms /    37 runs   (    0.58 ms per token,  1724.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4490.50 ms /    37 runs   (  121.36 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4602.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1694.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.25 ms /     7 runs   (  121.04 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   867.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 121: \n",
      "Language: english\n",
      "Question: \n",
      "Check the alternative that contains a treatment for acquired obstruction of the nasolacrimal duct. a) Transnasal dacrhinostomy. b) Pyrex tube implant. c) Enlargement of the lacrimal point. d) Crigler hydrostatic massage.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.34 ms /    28 runs   (    0.58 ms per token,  1713.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1701.93 ms /    71 tokens (   23.97 ms per token,    41.72 tokens per second)\n",
      "llama_print_timings:        eval time =  3346.70 ms /    27 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  5133.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.06 ms /     7 runs   (  120.29 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   863.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   125.96 ms /   217 runs   (    0.58 ms per token,  1722.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26573.45 ms /   217 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 27260.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.84 ms /    71 runs   (    0.58 ms per token,  1738.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8671.59 ms /    71 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8887.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1771.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   836.24 ms /     7 runs   (  119.46 ms per token,     8.37 tokens per second)\n",
      "llama_print_timings:       total time =   857.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.53 ms /    78 runs   (    0.58 ms per token,  1713.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9585.28 ms /    78 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  9828.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.74 ms /    64 runs   (    0.57 ms per token,  1741.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7806.39 ms /    64 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  8005.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.13 ms /    16 runs   (    0.57 ms per token,  1751.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1936.65 ms /    16 runs   (  121.04 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  1985.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    28 runs   (    0.57 ms per token,  1750.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3451.13 ms /    28 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3537.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1746.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3447.58 ms /    28 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3532.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que contenha um tratamento para obstruo adquirida do ducto lacrimonasal. a) Dacriorrinostomia transnasal. b) Implante de tubo de pirex. c) Ampliao do ponto lacrimal. d) Massagem hidrosttica de Crigler.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2054.08 ms /    85 tokens (   24.17 ms per token,    41.38 tokens per second)\n",
      "llama_print_timings:        eval time =   734.25 ms /     6 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2809.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.29 ms /    28 runs   (    0.58 ms per token,  1719.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3447.37 ms /    28 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3533.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.16 ms /     7 runs   (    0.59 ms per token,  1684.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.00 ms /     7 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.33 ms /     7 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   887.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    28 runs   (    0.58 ms per token,  1732.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3484.13 ms /    28 runs   (  124.43 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3569.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.58 ms /     7 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.01 ms /     7 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   885.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.64 ms /   114 runs   (    0.58 ms per token,  1710.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13983.28 ms /   114 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 14343.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.35 ms /    49 runs   (    0.58 ms per token,  1728.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5928.06 ms /    49 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  6076.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.21 ms /    28 runs   (    0.58 ms per token,  1727.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3416.00 ms /    28 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3499.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 122: \n",
      "Language: english\n",
      "Question: \n",
      "Preseptal orbital cellulitis in adults is usually: a) Caused by dissemination by continuity of ethmoidal sinusitis. b) Does not cause strabismus or optic disc edema. c) Should be treated with intravenous antibiotic therapy during hospitalization. d) Its etiology is Gram-negative and anaerobic germs.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.38 ms /     7 runs   (    0.63 ms per token,  1598.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2252.85 ms /    95 tokens (   23.71 ms per token,    42.17 tokens per second)\n",
      "llama_print_timings:        eval time =   734.84 ms /     6 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3009.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.72 ms /    31 runs   (    0.60 ms per token,  1655.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3775.14 ms /    31 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3872.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.75 ms /    27 runs   (    0.58 ms per token,  1714.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3281.97 ms /    27 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3363.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.63 ms /    60 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7340.06 ms /    60 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7521.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.35 ms /    58 runs   (    0.58 ms per token,  1738.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7089.67 ms /    58 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7264.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.22 ms /     9 runs   (    0.58 ms per token,  1723.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1100.95 ms /     9 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  1127.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3360.16 ms /    28 runs   (  120.01 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  3444.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.74 ms /    28 runs   (    0.60 ms per token,  1672.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3427.27 ms /    28 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3511.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.87 ms /    24 runs   (    0.58 ms per token,  1730.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2927.58 ms /    24 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2998.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.42 ms /    70 runs   (    0.58 ms per token,  1731.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8624.67 ms /    70 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8834.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "A celulite orbitaria pr-septal no adulto geralmente: a)  causada por disseminao por continuidade de sinusite etmoidal. b) No causa estrabismo ou edema de disco ptico. c) Deve ser tratada com antibioticoterapia endovenosa durante internao hospitalar. d) Tem como etiologia germes Gram-negativos e anaerbios.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.81 ms /    27 runs   (    0.59 ms per token,  1707.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2520.44 ms /   107 tokens (   23.56 ms per token,    42.45 tokens per second)\n",
      "llama_print_timings:        eval time =  3138.95 ms /    26 runs   (  120.73 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  5740.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.17 ms /     7 runs   (  120.31 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.41 ms /    72 runs   (    0.58 ms per token,  1738.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8754.75 ms /    72 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  8970.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.36 ms /    25 runs   (    0.57 ms per token,  1740.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3024.85 ms /    25 runs   (  120.99 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3098.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1752.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.62 ms /     7 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1749.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.70 ms /     7 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   877.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.24 ms /    73 runs   (    0.58 ms per token,  1728.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8926.02 ms /    73 runs   (  122.27 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9145.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.77 ms /    52 runs   (    0.57 ms per token,  1746.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6406.00 ms /    52 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6562.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   100.17 ms /   173 runs   (    0.58 ms per token,  1727.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21216.53 ms /   173 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 21761.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.31 ms /     7 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   875.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 123: \n",
      "Language: english\n",
      "Question: \n",
      "Topical or systemic application of beta-blockers presents positive therapeutic results in which orbital disease, among the following: a) Low-output carotid-cavernous fistula. b) Lymphoma associated with mucosal tissue (MALT). c) Capillary hemangioma of childhood. d) Graves orbitopathy in the acute phase.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.64 ms /    25 runs   (    0.59 ms per token,  1708.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2101.62 ms /    96 tokens (   21.89 ms per token,    45.68 tokens per second)\n",
      "llama_print_timings:        eval time =  2937.54 ms /    24 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5114.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n",
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.56 ms /    25 runs   (    0.58 ms per token,  1717.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3058.39 ms /    25 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3134.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.55 ms /    25 runs   (    0.58 ms per token,  1718.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3077.22 ms /    25 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3152.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    24 runs   (    0.58 ms per token,  1725.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2914.36 ms /    24 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2985.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.49 ms /    25 runs   (    0.58 ms per token,  1725.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3035.26 ms /    25 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3109.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.50 ms /    25 runs   (    0.58 ms per token,  1724.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3094.58 ms /    25 runs   (  123.78 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3169.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    25 runs   (    0.64 ms per token,  1562.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3044.34 ms /    25 runs   (  121.77 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3124.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.46 ms /    25 runs   (    0.58 ms per token,  1728.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3052.80 ms /    25 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3132.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1706.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.50 ms /     7 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.48 ms /    25 runs   (    0.58 ms per token,  1726.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3035.66 ms /    25 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3113.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Aplicao tpica ou sistmica de betabloqueadores apresenta resultados teraputicos positivos em qual doena orbitria, entre as abaixo: a) Fstula cartido-cavernosa de baixo dbito. b) Linfoma associado a tecido mucoso (MALT). c) Hemangioma capilar da infncia. d) Orbitopatia de Graves na fase aguda.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.10 ms /     7 runs   (    0.59 ms per token,  1706.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2009.79 ms /   110 tokens (   18.27 ms per token,    54.73 tokens per second)\n",
      "llama_print_timings:        eval time =   744.88 ms /     6 runs   (  124.15 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  2776.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1697.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.09 ms /     7 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   883.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.32 ms /     7 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   876.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   834.63 ms /     7 runs   (  119.23 ms per token,     8.39 tokens per second)\n",
      "llama_print_timings:       total time =   854.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.86 ms /     7 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1733.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3443.93 ms /    28 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3528.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1729.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.06 ms /     7 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1726.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.81 ms /     7 runs   (  120.97 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1741.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   847.04 ms /     7 runs   (  121.01 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =   867.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1723.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.94 ms /     7 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 124: \n",
      "Language: english\n",
      "Question: \n",
      "In inflammatory orbital disease associated with thyroid disorders, there is a typical ophthalmological sign, known as temporal flare, which corresponds to: a) Exotropia due to lateral rectus fibrosis. b) Chemosis and conjunctivochalasis in the lateral region of the inferior bulbar conjunctiva. c) Marked exophthalmos causing lateral dystopia of the eye. d) Pattern of eyelid retraction with the lateral region of the eyelid more retracted than the medial.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.75 ms /    28 runs   (    0.60 ms per token,  1671.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2217.51 ms /   133 tokens (   16.67 ms per token,    59.98 tokens per second)\n",
      "llama_print_timings:        eval time =  3370.08 ms /    27 runs   (  124.82 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  5674.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.69 ms /    28 runs   (    0.60 ms per token,  1677.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3473.19 ms /    28 runs   (  124.04 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3560.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.25 ms /    28 runs   (    0.58 ms per token,  1723.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3536.02 ms /    28 runs   (  126.29 ms per token,     7.92 tokens per second)\n",
      "llama_print_timings:       total time =  3621.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.61 ms /    27 runs   (    0.58 ms per token,  1729.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3271.28 ms /    27 runs   (  121.16 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3351.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.29 ms /    28 runs   (    0.58 ms per token,  1718.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3459.38 ms /    28 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3543.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.65 ms /    27 runs   (    0.58 ms per token,  1725.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3275.22 ms /    27 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3358.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.17 ms /    61 runs   (    0.58 ms per token,  1734.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7463.50 ms /    61 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7647.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1733.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3315.55 ms /    27 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3395.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.73 ms /    28 runs   (    0.63 ms per token,  1578.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3432.72 ms /    28 runs   (  122.60 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3524.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.24 ms /    28 runs   (    0.58 ms per token,  1724.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3440.21 ms /    28 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3524.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Na doena orbitria inflamatria associada a distrbios da tireoide existe um sinal oftalmolgico tpico, conhecido como flare temporal, que corresponde a: a) Exotropia por fibrose do reto lateral. b) Quemose e conjuntivocalase na regio lateral da conjuntiva bulbar inferior. c) Exoftalmia acentuada causando distopia lateral do olho. d) Padro de retrao palpebral com a regio lateral da plpebra mais retrada que a medial.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.50 ms /     9 runs   (    0.61 ms per token,  1636.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3259.48 ms /   142 tokens (   22.95 ms per token,    43.57 tokens per second)\n",
      "llama_print_timings:        eval time =   971.50 ms /     8 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4258.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1722.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3037.97 ms /    25 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3112.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   916.20 ms /     7 runs   (  130.89 ms per token,     7.64 tokens per second)\n",
      "llama_print_timings:       total time =   936.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    28 runs   (    0.58 ms per token,  1717.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3433.20 ms /    28 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3517.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.83 ms /    57 runs   (    0.58 ms per token,  1736.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6957.23 ms /    57 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7129.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1725.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3435.79 ms /    28 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3520.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.59 ms /    57 runs   (    0.59 ms per token,  1697.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7018.97 ms /    57 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7192.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1735.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.42 ms /     7 runs   (  121.20 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1736.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3290.83 ms /    27 runs   (  121.88 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3370.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2952.88 ms /    24 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3023.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 125: \n",
      "Language: english\n",
      "Question: \n",
      "Choose the alternative that best fills in the blank: In __________ , chronic maxillary sinusitis causes enophthalmos by collapsing the orbital floor. a) Silent sinus syndrome. b) Tolosa-Hunt syndrome. c) Mucocele. d) Fibrous dysplasia.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.97 ms /    25 runs   (    0.60 ms per token,  1670.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1918.62 ms /    81 tokens (   23.69 ms per token,    42.22 tokens per second)\n",
      "llama_print_timings:        eval time =  2896.45 ms /    24 runs   (  120.69 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  4891.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.06 ms /    33 runs   (    0.58 ms per token,  1731.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3978.34 ms /    33 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  4076.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.34 ms /    44 runs   (    0.58 ms per token,  1736.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5406.48 ms /    44 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5537.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.26 ms /    28 runs   (    0.58 ms per token,  1721.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3426.41 ms /    28 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3510.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.61 ms /    32 runs   (    0.58 ms per token,  1719.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3904.72 ms /    32 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4001.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.98 ms /    33 runs   (    0.58 ms per token,  1738.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3990.22 ms /    33 runs   (  120.92 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4089.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.03 ms /    33 runs   (    0.58 ms per token,  1734.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4022.33 ms /    33 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4120.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.00 ms /    25 runs   (    0.60 ms per token,  1667.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3059.59 ms /    25 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3135.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    24 runs   (    0.58 ms per token,  1724.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2918.60 ms /    24 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2990.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.80 ms /    24 runs   (    0.57 ms per token,  1739.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2890.32 ms /    24 runs   (  120.43 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2961.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Escolha a alternativa que melhor preencha a lacuna: Na __________ , uma sinusite maxilar crnica causa enoftalmo pelo colapso do assoalho da rbita. a) Sndrome do seio silencioso. b) Sndrome de Tolosa-Hunt. c) Mucocele. d) Displasia fibrosa.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.80 ms /    37 runs   (    0.59 ms per token,  1697.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1870.12 ms /    97 tokens (   19.28 ms per token,    51.87 tokens per second)\n",
      "llama_print_timings:        eval time =  4409.67 ms /    36 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6391.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.95 ms /    33 runs   (    0.57 ms per token,  1741.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4036.41 ms /    33 runs   (  122.32 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4134.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.84 ms /    29 runs   (    0.58 ms per token,  1722.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3542.62 ms /    29 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3628.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.05 ms /    47 runs   (    0.58 ms per token,  1737.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5750.96 ms /    47 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  5890.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1733.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3097.83 ms /    25 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3172.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.03 ms /    33 runs   (    0.58 ms per token,  1733.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4043.87 ms /    33 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4141.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.95 ms /     7 runs   (  120.85 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   866.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.11 ms /    47 runs   (    0.58 ms per token,  1733.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5701.65 ms /    47 runs   (  121.31 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5841.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.04 ms /     7 runs   (  123.01 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 126: \n",
      "Language: english\n",
      "Question: \n",
      "During the subjective refraction of the patient with low vision, the best visual acuity was obtained using a -5.00 spherical diopter -2.00 cylindrical diopter x 180 lens in the trial frame with the visual acuity table positioned at 1 m of the patient. Which of the alternatives below represents the most appropriate prescription for correction for distance? a) -3.00 spherical diopter -2.00 cylindrical diopter x 180. b) -4.00 spherical diopter -2.00 cylindrical diopter x 180. c) -2.00 cylindrical diopter x 180. d) -6.00 spherical diopter -2.00 cylindrical diopter x 180.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.23 ms /    28 runs   (    0.58 ms per token,  1725.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3450.65 ms /    28 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3534.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.83 ms /    27 runs   (    0.55 ms per token,  1820.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3940.77 ms /   196 tokens (   20.11 ms per token,    49.74 tokens per second)\n",
      "llama_print_timings:        eval time =  3219.72 ms /    26 runs   (  123.84 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  7241.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.85 ms /    31 runs   (    0.54 ms per token,  1839.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3781.26 ms /    31 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3873.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.85 ms /   171 runs   (    0.57 ms per token,  1747.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21234.68 ms /   171 runs   (  124.18 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 21769.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.88 ms /   163 runs   (    0.56 ms per token,  1774.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20129.21 ms /   163 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 20636.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.85 ms /    28 runs   (    0.53 ms per token,  1885.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3461.86 ms /    28 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3545.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.44 ms /    27 runs   (    0.53 ms per token,  1869.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3315.97 ms /    27 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3396.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.57 ms /    27 runs   (    0.54 ms per token,  1853.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3286.30 ms /    27 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3367.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.46 ms /    27 runs   (    0.54 ms per token,  1866.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3300.85 ms /    27 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3381.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.40 ms /    29 runs   (    0.53 ms per token,  1883.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3542.52 ms /    29 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3629.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.01 ms /    28 runs   (    0.54 ms per token,  1865.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3457.67 ms /    28 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3540.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Durante a refrao subjetiva do paciente com baixa viso, obteve-se a melhor acuidade visual utilizando-se lentes -5,00 dioptria esferica -2,00 dioptria cilindrica x 180 na armao de prova com a tabela de acuidade visual posicionada a 1 m do paciente. Qual dentre as alternativas abaixo representa a prescrio mais adequada da correo para longe? a) -3,00 dioptria esferica -2,00 dioptria cilindrica x 180. b) -4,00 dioptria esferica -2,00 dioptria cilindrica x 180. c) -2,00 dioptria cilindrica x 180. d) -6,00 dioptria esferica -2,00 dioptria cilindrica x 180.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.32 ms /    28 runs   (    0.58 ms per token,  1715.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4291.33 ms /   241 tokens (   17.81 ms per token,    56.16 tokens per second)\n",
      "llama_print_timings:        eval time =  3317.51 ms /    27 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7694.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.92 ms /     7 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   891.13 ms /     7 runs   (  127.30 ms per token,     7.86 tokens per second)\n",
      "llama_print_timings:       total time =   912.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.88 ms /     7 runs   (    0.55 ms per token,  1804.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   878.49 ms /     7 runs   (  125.50 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =   898.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1770.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.31 ms /     7 runs   (  121.47 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.19 ms /    20 runs   (    0.56 ms per token,  1787.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2447.50 ms /    20 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2506.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.89 ms /     7 runs   (    0.56 ms per token,  1800.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.93 ms /     7 runs   (  121.56 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.98 ms /    28 runs   (    0.57 ms per token,  1752.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3438.65 ms /    28 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3524.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.79 ms /    28 runs   (    0.56 ms per token,  1772.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3477.20 ms /    28 runs   (  124.19 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  3563.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.16 ms /    20 runs   (    0.56 ms per token,  1791.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2460.92 ms /    20 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2521.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.85 ms /     7 runs   (    0.55 ms per token,  1820.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.02 ms /     7 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 127: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Regarding non-optical aids, evaluate the following statements as true (T) or false (F) and mark the correct alternative: I. Also called functional adaptation aids, they are those that modify materials and environmental conditions. II. Enlarging letters is the most common aid and reduces the spatial frequency of the image. III. The typoscope is a guide for reading whose function is to reduce the light reflected on the white paper and thus reduce glare and increase the contrast of the line of text with the background. IV. A 65-year-old patient prefers approximately three times less lighting than a 20-year-old person to perform the same tasks. a) I: True; II: False; III: True; IV: False. b) I: True; II: True; III: False; IV: True. c) I: True; II: True; III: True; IV: False. d) I: False; II: False; III: False; IV: True.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.93 ms /   144 runs   (    0.56 ms per token,  1779.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3415.09 ms /   224 tokens (   15.25 ms per token,    65.59 tokens per second)\n",
      "llama_print_timings:        eval time = 17600.56 ms /   143 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 21464.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.38 ms /   144 runs   (    0.56 ms per token,  1791.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17780.08 ms /   144 runs   (  123.47 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 18224.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.77 ms /   144 runs   (    0.56 ms per token,  1782.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17750.40 ms /   144 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 18193.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.58 ms /   144 runs   (    0.56 ms per token,  1787.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17875.14 ms /   144 runs   (  124.13 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 18318.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.22 ms /   144 runs   (    0.56 ms per token,  1794.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17913.23 ms /   144 runs   (  124.40 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 18355.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.79 ms /   144 runs   (    0.56 ms per token,  1782.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17709.31 ms /   144 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18152.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    81.12 ms /   144 runs   (    0.56 ms per token,  1775.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17875.44 ms /   144 runs   (  124.14 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 18318.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.59 ms /   144 runs   (    0.56 ms per token,  1786.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17704.24 ms /   144 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18143.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.34 ms /   144 runs   (    0.56 ms per token,  1792.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17675.15 ms /   144 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 18113.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.73 ms /   144 runs   (    0.56 ms per token,  1783.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17907.26 ms /   144 runs   (  124.36 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 18353.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre os auxlios no-pticos, avalie as assertivas a seguir como verdadeiras (V) ou falsas (F) e assinale a alternativa correta: I. Tambm denominados auxlios de adaptao funcional, so aqueles que modificam materiais e condies do ambiente. II. A ampliao de letras  o auxlio mais comum e reduz a frequncia espacial da imagem. III. O tiposcpio  um guia para leitura cuja funo  diminuir a luz refletida sobre o papel branco e assim diminuir o ofuscamento e aumentar o contraste da linha de texto com o fundo. IV. Um paciente com 65 anos prefere aproximadamente trs vezes menos iluminao que uma pessoa com 20 anos para realizar as mesmas tarefas. a) I: Verdadeiro; II: Falso; III: Verdadeiro; IV: Falso. b) I: Verdadeiro; II: Verdadeiro; III: Falso; IV: Verdadeiro. c) I: Verdadeiro; II: Verdadeiro; III: Verdadeiro; IV: Falso. d) I: Falso; II: Falso; III: Falso; IV: Verdadeiro.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.50 ms /    56 runs   (    0.56 ms per token,  1777.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  5254.18 ms /   312 tokens (   16.84 ms per token,    59.38 tokens per second)\n",
      "llama_print_timings:        eval time =  6731.06 ms /    55 runs   (  122.38 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12152.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.43 ms /    56 runs   (    0.54 ms per token,  1840.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6899.60 ms /    56 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7064.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.94 ms /    56 runs   (    0.55 ms per token,  1810.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6919.40 ms /    56 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  7084.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.23 ms /    56 runs   (    0.58 ms per token,  1737.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6978.24 ms /    56 runs   (  124.61 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  7150.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.72 ms /    56 runs   (    0.55 ms per token,  1823.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6920.91 ms /    56 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  7087.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.52 ms /     7 runs   (    0.50 ms per token,  1985.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.71 ms /     7 runs   (  123.96 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.32 ms /    56 runs   (    0.56 ms per token,  1787.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7029.15 ms /    56 runs   (  125.52 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  7198.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.10 ms /    56 runs   (    0.56 ms per token,  1800.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6977.06 ms /    56 runs   (  124.59 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  7146.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.41 ms /    56 runs   (    0.56 ms per token,  1783.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6994.53 ms /    56 runs   (  124.90 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  7166.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.90 ms /    56 runs   (    0.55 ms per token,  1812.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6936.38 ms /    56 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  7106.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 128: \n",
      "Language: english\n",
      "Question: \n",
      "The subjective refraction of a patient with low vision achieves the best binocular acuity for distance without the interposition of corrective lenses. At close range, the best result is achieved with the addition of +8.00 spherical diopters in both eyes. To improve comfort while reading, it was decided to prescribe spheroprismatic lenses. What is the most appropriate value of the prisms in each eye? a) 4 prismatic diopters time base. b) 4 prismatic diopters at the nasal base. c) 10 prismatic diopters time basis. d) 10 prismatic diopters at the nasal base.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.33 ms /     7 runs   (    0.62 ms per token,  1614.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2672.33 ms /   160 tokens (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_print_timings:        eval time =   726.42 ms /     6 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3421.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.67 ms /   109 runs   (    0.58 ms per token,  1711.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13390.69 ms /   109 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 13730.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.40 ms /     7 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.69 ms /     7 runs   (  126.53 ms per token,     7.90 tokens per second)\n",
      "llama_print_timings:       total time =   907.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.33 ms /    95 runs   (    0.57 ms per token,  1748.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11674.74 ms /    95 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11964.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   119.21 ms /   207 runs   (    0.58 ms per token,  1736.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25542.05 ms /   207 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 26194.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1747.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.85 ms /     7 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   877.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.61 ms /   128 runs   (    0.58 ms per token,  1738.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15710.19 ms /   128 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 16103.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    86.54 ms /   150 runs   (    0.58 ms per token,  1733.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18505.29 ms /   150 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 18974.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1771.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.00 ms /     7 runs   (  121.14 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   868.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      " refrao subjetiva de um paciente com viso subnormal, atinge-se a melhor acuidade binocular para distncia sem a interposio de lentes corretivas. J para perto, o melhor resultado  atingido com adio de +8,00 Dioptrias esferiacs em ambos os olhos. Para melhorar o conforto durante a leitura, optou-se por prescrever lentes esferoprismticas. Qual o valor mais adequado dos prismas em cada olho? a) 4 Dioptrias prismaticas base temporal. b) 4 Dioptrias prismaticas base nasal. c) 10 Dioptrias prismaticas base temporal. d) 10 Dioptrias prismaticas base nasal.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.33 ms /    22 runs   (    0.56 ms per token,  1784.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3712.20 ms /   198 tokens (   18.75 ms per token,    53.34 tokens per second)\n",
      "llama_print_timings:        eval time =  2560.59 ms /    21 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  6338.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.20 ms /    22 runs   (    0.55 ms per token,  1802.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2718.99 ms /    22 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  2784.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    21 runs   (    0.55 ms per token,  1819.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2558.34 ms /    21 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2619.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.74 ms /     7 runs   (    0.53 ms per token,  1872.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.46 ms /     7 runs   (  121.92 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   873.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.63 ms /    33 runs   (    0.56 ms per token,  1771.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4081.93 ms /    33 runs   (  123.69 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4179.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.50 ms /    42 runs   (    0.58 ms per token,  1714.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5174.72 ms /    42 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5301.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.78 ms /     7 runs   (    0.54 ms per token,  1853.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.42 ms /     7 runs   (  121.20 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {:response: \"A\"}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.74 ms /     7 runs   (    0.53 ms per token,  1870.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.73 ms /     7 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.82 ms /     7 runs   (    0.55 ms per token,  1830.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   869.17 ms /     7 runs   (  124.17 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =   890.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.69 ms /     7 runs   (    0.53 ms per token,  1895.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.98 ms /     7 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.79 ms /     7 runs   (    0.54 ms per token,  1845.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.14 ms /     7 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   875.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 129: \n",
      "Language: english\n",
      "Question: \n",
      "The Cred method uses silver nitrate eye drops at what concentration? to 1%. b) 5%. c) 10%. d) 20%.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    28 runs   (    0.57 ms per token,  1750.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1003.41 ms /    42 tokens (   23.89 ms per token,    41.86 tokens per second)\n",
      "llama_print_timings:        eval time =  3272.72 ms /    27 runs   (  121.21 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4360.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.90 ms /    28 runs   (    0.57 ms per token,  1761.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3365.76 ms /    28 runs   (  120.21 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  3450.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.25 ms /    25 runs   (    0.57 ms per token,  1754.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3038.31 ms /    25 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3114.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.29 ms /    27 runs   (    0.57 ms per token,  1766.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3262.34 ms /    27 runs   (  120.83 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3344.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.87 ms /    28 runs   (    0.57 ms per token,  1764.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3384.16 ms /    28 runs   (  120.86 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3467.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.97 ms /    28 runs   (    0.57 ms per token,  1753.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3456.25 ms /    28 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3539.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.94 ms /    28 runs   (    0.57 ms per token,  1756.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3368.53 ms /    28 runs   (  120.30 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  3450.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.62 ms /    24 runs   (    0.57 ms per token,  1762.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2926.78 ms /    24 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2997.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1740.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3379.35 ms /    28 runs   (  120.69 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3462.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "O mtodo de Cred utiliza colrio de nitrato de prata em qual concentrao? a) 1%. b) 5%. c) 10%. d) 20%.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.09 ms /    30 runs   (    0.57 ms per token,  1755.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3632.92 ms /    30 runs   (  121.10 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3722.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.38 ms /    11 runs   (    0.58 ms per token,  1723.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1234.08 ms /    52 tokens (   23.73 ms per token,    42.14 tokens per second)\n",
      "llama_print_timings:        eval time =  1222.62 ms /    10 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2489.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) 5%'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.48 ms /    32 runs   (    0.58 ms per token,  1731.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3888.72 ms /    32 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3985.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) 5%'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.12 ms /    28 runs   (    0.58 ms per token,  1737.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3388.61 ms /    28 runs   (  121.02 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3472.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.00 ms /    28 runs   (    0.57 ms per token,  1749.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3423.17 ms /    28 runs   (  122.26 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3505.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.17 ms /    32 runs   (    0.60 ms per token,  1669.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3887.76 ms /    32 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3983.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.91 ms /    33 runs   (    0.57 ms per token,  1744.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4002.54 ms /    33 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  4098.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) 5%'}\n",
      "Test #6: \n",
      "{'response': 'b) 5%'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.84 ms /    31 runs   (    0.58 ms per token,  1738.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3844.16 ms /    31 runs   (  124.01 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3934.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.23 ms /    11 runs   (    0.57 ms per token,  1765.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1354.79 ms /    11 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  1386.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) 5%'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.25 ms /    11 runs   (    0.57 ms per token,  1758.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1317.37 ms /    11 runs   (  119.76 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =  1349.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) 5%'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 130: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Which of the topical drugs below is most indicated for the initial treatment of fungal keratitis caused by Fusarium? a) Terbinafine. b) Natamycin. c) Miconazole. d) Amphotericin B.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.01 ms /    28 runs   (    0.57 ms per token,  1749.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3417.15 ms /    28 runs   (  122.04 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3500.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.35 ms /    30 runs   (    0.58 ms per token,  1728.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1597.44 ms /    67 tokens (   23.84 ms per token,    41.94 tokens per second)\n",
      "llama_print_timings:        eval time =  3523.56 ms /    29 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5211.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.97 ms /    33 runs   (    0.57 ms per token,  1739.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3997.42 ms /    33 runs   (  121.13 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4095.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2976.97 ms /    24 runs   (  124.04 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3047.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.67 ms /     7 runs   (    0.67 ms per token,  1497.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.04 ms /     7 runs   (  120.15 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   863.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    28 runs   (    0.58 ms per token,  1732.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3414.55 ms /    28 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3497.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.65 ms /    34 runs   (    0.58 ms per token,  1730.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4156.02 ms /    34 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4256.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.42 ms /    30 runs   (    0.58 ms per token,  1721.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3648.33 ms /    30 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3739.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    17.86 ms /    31 runs   (    0.58 ms per token,  1735.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3744.66 ms /    31 runs   (  120.80 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3837.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1737.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3398.38 ms /    28 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3480.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3294.28 ms /    27 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3374.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das drogas de uso tpico, abaixo,  a mais indicada para o tratamento inicial de ceratite fngica causada por Fusarium? a) Terbinafina. b) Natamicina. c) Miconazol. d) Anfotericina B.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.50 ms /    23 runs   (    0.59 ms per token,  1703.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1948.04 ms /    76 tokens (   25.63 ms per token,    39.01 tokens per second)\n",
      "llama_print_timings:        eval time =  2642.84 ms /    22 runs   (  120.13 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  4660.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.93 ms /    32 runs   (    0.59 ms per token,  1690.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3961.53 ms /    32 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  4058.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.77 ms /    17 runs   (    0.57 ms per token,  1740.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2049.54 ms /    17 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2099.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.80 ms /    24 runs   (    0.58 ms per token,  1739.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2896.80 ms /    24 runs   (  120.70 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  2967.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c) Miconazol.'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.12 ms /    35 runs   (    0.57 ms per token,  1739.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4243.66 ms /    35 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4347.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.53 ms /    20 runs   (    0.58 ms per token,  1735.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2440.28 ms /    20 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2498.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1713.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.39 ms /     7 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1755.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.45 ms /     7 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.64 ms /     7 runs   (  121.52 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.55 ms /    20 runs   (    0.58 ms per token,  1731.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2409.78 ms /    20 runs   (  120.49 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  2470.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 131: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding penetrating corneal transplantation performed in children under two years of age. a) Typically, healing between the bed and the graft occurs more slowly than in adults. b) The incidence of rejection is significantly lower than that observed in adult transplants. c) In an uneventful postoperative period, suture removal should occur earlier than in adults. d) Generally, large grafts with more than 10 mm in diameter are used.\n",
      "\n",
      "Test #0: \n",
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.55 ms /    25 runs   (    0.58 ms per token,  1718.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1915.06 ms /   116 tokens (   16.51 ms per token,    60.57 tokens per second)\n",
      "llama_print_timings:        eval time =  2922.60 ms /    24 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4914.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.60 ms /    25 runs   (    0.58 ms per token,  1711.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3053.69 ms /    25 runs   (  122.15 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3129.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.66 ms /    55 runs   (    0.58 ms per token,  1737.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6768.66 ms /    55 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6936.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.59 ms /    81 runs   (    0.58 ms per token,  1738.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9885.95 ms /    81 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 10131.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    89.37 ms /   154 runs   (    0.58 ms per token,  1723.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18914.45 ms /   154 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 19393.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.71 ms /    97 runs   (    0.57 ms per token,  1741.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11885.37 ms /    97 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 12188.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.19 ms /    42 runs   (    0.58 ms per token,  1736.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5157.99 ms /    42 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5284.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.18 ms /    47 runs   (    0.58 ms per token,  1729.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5717.47 ms /    47 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5858.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.22 ms /    96 runs   (    0.58 ms per token,  1738.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11844.59 ms /    96 runs   (  123.38 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 12137.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.20 ms /    42 runs   (    0.58 ms per token,  1735.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5161.47 ms /    42 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5288.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa correta com relao ao transplante penetrante de crnea realizado em crianas abaixo de dois anos de idade. a) Tipicamente, a cicatrizao entre o leito e o enxerto ocorre mais lentamente do que no adulto. b) A incidncia de rejeio  significativamente menor que a observada nos transplantes de adultos. c) Em um ps-operatrio sem intercorrncias, a remoo das suturas deve ocorrer mais precocemente do que nos adultos. d) Geralmente so utilizados enxertos grandes, com mais de 10 mm de dimetro.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.72 ms /    67 runs   (    0.58 ms per token,  1730.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3373.37 ms /   169 tokens (   19.96 ms per token,    50.10 tokens per second)\n",
      "llama_print_timings:        eval time =  8150.26 ms /    66 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 11728.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.29 ms /   100 runs   (    0.57 ms per token,  1745.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12347.66 ms /   100 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 12652.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.71 ms /   106 runs   (    0.57 ms per token,  1746.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13089.99 ms /   106 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13413.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.35 ms /    53 runs   (    0.57 ms per token,  1746.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6536.07 ms /    53 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  6696.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.45 ms /    64 runs   (    0.57 ms per token,  1755.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7873.60 ms /    64 runs   (  123.03 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8069.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1771.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.80 ms /     7 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.14 ms /    25 runs   (    0.57 ms per token,  1767.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3068.59 ms /    25 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3143.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1763.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.31 ms /     7 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.30 ms /    60 runs   (    0.57 ms per token,  1749.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7425.12 ms /    60 runs   (  123.75 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  7604.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.29 ms /    20 runs   (    0.56 ms per token,  1771.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2484.88 ms /    20 runs   (  124.24 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  2544.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 132: \n",
      "Language: english\n",
      "Question: \n",
      "Mark the correct alternative regarding posterior lamellar corneal transplantation using the \"DSEK\" technique (Descemet Stripping Endothelial Keratoplasty): a) Immediately after the surgery, the patient must remain in the prone position for about twenty to thirty minutes. b) Only endothelium and Descemet's membrane are grafted into the recipient eye. c) Diffuse lamellar keratitis (also known as \"sands of the Sahara syndrome\"), is a complication of this procedure. d) The presence of a correctly positioned lamella will probably induce a positive spherical degree that will be added to the patient's previous refraction (\"hypermetropic shift\").\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.35 ms /   195 runs   (    0.58 ms per token,  1720.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3056.49 ms /   172 tokens (   17.77 ms per token,    56.27 tokens per second)\n",
      "llama_print_timings:        eval time = 24001.48 ms /   194 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 27685.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #1: \n",
      "{'response': 'D'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.56 ms /   195 runs   (    0.58 ms per token,  1732.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23982.14 ms /   195 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 24593.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.26 ms /   195 runs   (    0.58 ms per token,  1736.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24080.21 ms /   195 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 24691.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.97 ms /    74 runs   (    0.58 ms per token,  1722.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9145.75 ms /    74 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  9376.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.06 ms /   191 runs   (    0.59 ms per token,  1704.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23474.63 ms /   191 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 24083.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.66 ms /   195 runs   (    0.58 ms per token,  1715.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24195.68 ms /   195 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 24808.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    60.80 ms /   105 runs   (    0.58 ms per token,  1727.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12930.36 ms /   105 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 13249.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.13 ms /    35 runs   (    0.58 ms per token,  1738.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4283.97 ms /    35 runs   (  122.40 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4387.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.09 ms /   195 runs   (    0.58 ms per token,  1724.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24031.98 ms /   195 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 24641.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   112.27 ms /   195 runs   (    0.58 ms per token,  1736.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24149.35 ms /   195 runs   (  123.84 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 24766.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa correta com relao ao transplante de crnea lamelar posterior pela tcnica \"DSEK\" (Descemet Stripping Endothelial Keratoplasty): a) Imediatamente aps a cirurgia o paciente deve permanecer em decbito ventral por cerca de vinte a trinta minutos. b) Apenas endotlio e membrana de Descemet so enxertados no olho receptor. c) Ceratite lamelar difusa (tambm conhecida como \"sndrome das areias do Saara\"),  uma complicao desse procedimento. d) A presena da lamela corretamente posicionada provavelmente induzir grau esfrico positivo que se somar  refrao prvia do paciente (\"shift hipermetrpico\").\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.40 ms /     7 runs   (    0.63 ms per token,  1591.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4285.70 ms /   209 tokens (   20.51 ms per token,    48.77 tokens per second)\n",
      "llama_print_timings:        eval time =   736.95 ms /     6 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5043.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.24 ms /     7 runs   (    0.61 ms per token,  1649.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.60 ms /     7 runs   (  123.23 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   884.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.65 ms /    49 runs   (    0.58 ms per token,  1710.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6018.40 ms /    49 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6170.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.28 ms /   124 runs   (    0.58 ms per token,  1715.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15318.84 ms /   124 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15710.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.23 ms /     7 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1739.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.23 ms /     7 runs   (  120.75 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   865.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.07 ms /    47 runs   (    0.58 ms per token,  1736.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5799.74 ms /    47 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  5941.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.21 ms /     7 runs   (  124.46 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   891.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   873.29 ms /     7 runs   (  124.76 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =   894.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1693.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.32 ms /     7 runs   (  123.90 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   888.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 133: \n",
      "Language: english\n",
      "Question: \n",
      "Paralysis of the fifth cranial nerve can trigger in the cornea, most commonly: a) Neurotrophic ulcer. b) Disciform endothelitis. c) Exposure keratitis. d) Interstitial keratitis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.25 ms /    36 runs   (    0.59 ms per token,  1693.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1589.15 ms /    65 tokens (   24.45 ms per token,    40.90 tokens per second)\n",
      "llama_print_timings:        eval time =  4264.51 ms /    35 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5964.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.03 ms /    25 runs   (    0.60 ms per token,  1663.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3100.07 ms /    25 runs   (  124.00 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3176.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     8.66 ms /    15 runs   (    0.58 ms per token,  1731.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1830.01 ms /    15 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1875.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.73 ms /    36 runs   (    0.58 ms per token,  1736.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4363.96 ms /    36 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4471.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.30 ms /    35 runs   (    0.58 ms per token,  1723.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4257.12 ms /    35 runs   (  121.63 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4362.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.71 ms /    36 runs   (    0.58 ms per token,  1738.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4400.54 ms /    36 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4507.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.73 ms /    36 runs   (    0.58 ms per token,  1736.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4385.01 ms /    36 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4492.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1739.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3022.39 ms /    25 runs   (  120.90 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3096.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.75 ms /    36 runs   (    0.58 ms per token,  1735.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4390.29 ms /    36 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4498.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2464.22 ms /    20 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2523.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Paralisia do quinto nervo craniano pode desencadear na crnea, mais comumente: a) lcera neurotrfica. b) Endotelite disciforme. c) Ceratite de exposio. d) Ceratite intersticial.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.86 ms /    89 runs   (    0.58 ms per token,  1716.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1563.62 ms /    69 tokens (   22.66 ms per token,    44.13 tokens per second)\n",
      "llama_print_timings:        eval time = 10778.33 ms /    88 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 12613.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.39 ms /    32 runs   (    0.57 ms per token,  1740.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3908.10 ms /    32 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4002.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.89 ms /    45 runs   (    0.58 ms per token,  1738.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5427.65 ms /    45 runs   (  120.61 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  5562.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   843.81 ms /     7 runs   (  120.54 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.17 ms /    28 runs   (    0.58 ms per token,  1731.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3459.59 ms /    28 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3542.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.16 ms /    16 runs   (    0.57 ms per token,  1747.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1981.74 ms /    16 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  2028.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.98 ms /    26 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3151.72 ms /    26 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3228.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.79 ms /    36 runs   (    0.58 ms per token,  1731.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4360.99 ms /    36 runs   (  121.14 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4469.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.46 ms /    32 runs   (    0.58 ms per token,  1733.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3870.00 ms /    32 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3965.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.28 ms /    44 runs   (    0.57 ms per token,  1740.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5353.19 ms /    44 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5485.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 134: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding congenital and hereditary corneal endothelial dystrophy, it is correct to state: a) The most common pattern of transmission is the dominant autosomal one. b) Most patients have associated nystagmus and, rarely, glaucoma. c) Patients usually present with intense photophobia and epiphora immediately after birth. d) It is usually unilateral, with progressive increase in corneal opacity from birth onwards.\n",
      "\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.13 ms /    24 runs   (    0.59 ms per token,  1698.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2743.45 ms /   115 tokens (   23.86 ms per token,    41.92 tokens per second)\n",
      "llama_print_timings:        eval time =  2787.71 ms /    23 runs   (  121.20 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5603.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.13 ms /    21 runs   (    0.58 ms per token,  1730.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2562.95 ms /    21 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  2625.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.11 ms /    21 runs   (    0.58 ms per token,  1733.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2591.04 ms /    21 runs   (  123.38 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  2653.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.16 ms /    21 runs   (    0.58 ms per token,  1726.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2609.59 ms /    21 runs   (  124.27 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  2672.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.58 ms /    46 runs   (    0.58 ms per token,  1730.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5647.82 ms /    46 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5785.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.19 ms /    21 runs   (    0.58 ms per token,  1723.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2546.85 ms /    21 runs   (  121.28 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2610.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.09 ms /    21 runs   (    0.58 ms per token,  1737.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2537.66 ms /    21 runs   (  120.84 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  2600.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    25 runs   (    0.58 ms per token,  1728.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3049.73 ms /    25 runs   (  121.99 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3126.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.16 ms /    21 runs   (    0.58 ms per token,  1726.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2546.70 ms /    21 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2609.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.08 ms /    21 runs   (    0.58 ms per token,  1737.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2571.30 ms /    21 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2634.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao  distrofia endotelial congnita e hereditria da crnea,  correto afirmar: a) O padro de transmisso mais comum  o autossmico dominante. b) A maioria dos pacientes apresenta nistagmo associado e, raramente, glaucoma. c) Os pacientes costumam apresentar intensa fotofobia e epfora imediatamente aps o nascimento. d) Geralmente  unilateral, com aumento progressivo da opacidade da crnea a partir do nascimento.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    96.23 ms /   165 runs   (    0.58 ms per token,  1714.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2564.91 ms /   150 tokens (   17.10 ms per token,    58.48 tokens per second)\n",
      "llama_print_timings:        eval time = 20215.53 ms /   164 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 23297.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.34 ms /   205 runs   (    0.58 ms per token,  1732.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25336.58 ms /   205 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 25981.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.60 ms /     7 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    25 runs   (    0.58 ms per token,  1734.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3063.56 ms /    25 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3138.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    90.99 ms /   157 runs   (    0.58 ms per token,  1725.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19370.41 ms /   157 runs   (  123.38 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 19861.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   125.32 ms /   217 runs   (    0.58 ms per token,  1731.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26770.26 ms /   217 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 27455.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.53 ms /    20 runs   (    0.58 ms per token,  1735.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2455.21 ms /    20 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2514.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   131.95 ms /   217 runs   (    0.61 ms per token,  1644.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 26849.55 ms /   217 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 27927.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.61 ms /     7 runs   (    0.66 ms per token,  1520.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   867.83 ms /     7 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =   916.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.27 ms /    20 runs   (    0.66 ms per token,  1507.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2444.62 ms /    20 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2582.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 135: \n",
      "Language: english\n",
      "Question: \n",
      "In a patient with bullous keratopathy and corneal edema secondary to endothelial insufficiency, which of the following topical products should be avoided?\n",
      "a) Sodium hyaluronate.\n",
      "b) Sodium chloride.\n",
      "c) Inhibitors of carbonic anhydrase.\n",
      "d) Cyclopentolate.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    78.85 ms /   131 runs   (    0.60 ms per token,  1661.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2131.49 ms /    92 tokens (   23.17 ms per token,    43.16 tokens per second)\n",
      "llama_print_timings:        eval time = 15846.72 ms /   130 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 18589.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.17 ms /    93 runs   (    0.58 ms per token,  1716.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11319.35 ms /    93 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time = 11608.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.27 ms /   102 runs   (    0.58 ms per token,  1720.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12546.20 ms /   102 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 12862.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.38 ms /    92 runs   (    0.58 ms per token,  1723.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11189.16 ms /    92 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time = 11471.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.73 ms /    90 runs   (    0.57 ms per token,  1739.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11060.24 ms /    90 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11335.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.20 ms /    37 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4534.58 ms /    37 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4645.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.62 ms /    20 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2451.68 ms /    20 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2511.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.65 ms /    93 runs   (    0.58 ms per token,  1733.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11414.43 ms /    93 runs   (  122.74 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 11700.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.43 ms /    93 runs   (    0.57 ms per token,  1740.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11342.75 ms /    93 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 11626.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.73 ms /    93 runs   (    0.58 ms per token,  1731.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11432.07 ms /    93 runs   (  122.93 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 11718.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Em paciente com ceratopatia bolhosa e edema de crnea secundrio  insuficincia endotelial, qual dos produtos de uso tpico, dentre os abaixo, deve ser evitado?\n",
      "a)Hialuronato de sdio.\n",
      "b)Cloreto de sdio.\n",
      "c)Inibidores da anidrase carbnica.\n",
      "d)Ciclopentolato.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.53 ms /    62 runs   (    0.59 ms per token,  1697.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2198.89 ms /   111 tokens (   19.81 ms per token,    50.48 tokens per second)\n",
      "llama_print_timings:        eval time =  7454.63 ms /    61 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9844.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.42 ms /    86 runs   (    0.57 ms per token,  1740.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10499.55 ms /    86 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 10761.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.91 ms /     7 runs   (    0.56 ms per token,  1791.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   838.59 ms /     7 runs   (  119.80 ms per token,     8.35 tokens per second)\n",
      "llama_print_timings:       total time =   859.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.55 ms /   107 runs   (    0.58 ms per token,  1738.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13128.20 ms /   107 runs   (  122.69 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 13454.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.88 ms /    73 runs   (    0.57 ms per token,  1743.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8996.27 ms /    73 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9216.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.88 ms /     7 runs   (    0.55 ms per token,  1805.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   880.10 ms /     7 runs   (  125.73 ms per token,     7.95 tokens per second)\n",
      "llama_print_timings:       total time =   900.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.60 ms /     7 runs   (  125.09 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   897.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.96 ms /     7 runs   (    0.57 ms per token,  1766.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.22 ms /     7 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.93 ms /     7 runs   (    0.56 ms per token,  1780.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.60 ms /     7 runs   (  122.80 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.91 ms /     7 runs   (    0.56 ms per token,  1790.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.33 ms /     7 runs   (  125.05 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =   895.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 136: \n",
      "Language: english\n",
      "Question: \n",
      "Palpebral infestation by Phtirus pubis, can be preferably treated with which of the options below?\n",
      "\n",
      "a) Doxycycline orally.\n",
      "b) Tea tree oil-based shampoo.\n",
      "c) Multiple sessions of application of high-intensity regulated pulsed light (IRPL) in the periocular region.\n",
      "d) Ivermectin orally. \n",
      "d) Cyclopentolate.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.25 ms /    33 runs   (    0.58 ms per token,  1714.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2277.87 ms /   109 tokens (   20.90 ms per token,    47.85 tokens per second)\n",
      "llama_print_timings:        eval time =  3922.21 ms /    32 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  6299.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.76 ms /    24 runs   (    0.57 ms per token,  1744.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2926.61 ms /    24 runs   (  121.94 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2997.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.32 ms /    70 runs   (    0.58 ms per token,  1736.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8696.33 ms /    70 runs   (  124.23 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  8909.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.59 ms /    34 runs   (    0.58 ms per token,  1735.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4169.58 ms /    34 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4271.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.77 ms /     7 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   883.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1748.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.84 ms /     7 runs   (  120.41 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =   862.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.25 ms /    37 runs   (    0.57 ms per token,  1741.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4516.61 ms /    37 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4627.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.38 ms /    25 runs   (    0.58 ms per token,  1738.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3097.05 ms /    25 runs   (  123.88 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  3171.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.57 ms /    34 runs   (    0.58 ms per token,  1737.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4155.42 ms /    34 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  4256.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Ivermectin orally.'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.80 ms /    34 runs   (    0.58 ms per token,  1716.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4133.75 ms /    34 runs   (  121.58 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4234.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Infestao palpebral pelo Phtirus pubis, pode ser tratada, preferencialmente, com qual das opes abaixo?\n",
      "\n",
      "a)Doxiciclina via oral.\n",
      "b)Xampu a base de leo de melaleuca (tea tree oil).\n",
      "c)Mltiplas sesses de aplicao de luz pulsada regulada, de alta intensidade (IRPL), na regio periocular.\n",
      "d)Ivermectina via oral.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.18 ms /     7 runs   (    0.60 ms per token,  1673.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2421.01 ms /   124 tokens (   19.52 ms per token,    51.22 tokens per second)\n",
      "llama_print_timings:        eval time =   735.05 ms /     6 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3177.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1709.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.73 ms /     7 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.01 ms /    69 runs   (    0.58 ms per token,  1724.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8489.62 ms /    69 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  8702.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2918.18 ms /    24 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2990.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   840.46 ms /     7 runs   (  120.07 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =   861.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.84 ms /    69 runs   (    0.58 ms per token,  1731.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8438.59 ms /    69 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  8650.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.17 ms /    87 runs   (    0.58 ms per token,  1734.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10632.52 ms /    87 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 10898.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.08 ms /     7 runs   (  121.58 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.60 ms /    69 runs   (    0.57 ms per token,  1742.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8513.71 ms /    69 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8725.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.64 ms /    69 runs   (    0.57 ms per token,  1740.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8454.02 ms /    69 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8663.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 137: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the manifestations of conjunctivitis, it is correct to state:\n",
      "a) In vernal keratoconjunctivitis, papillary hypertrophy often occurs in both the upper and lower tarsal conjunctiva, with similar appearance and intensity.\n",
      "b) In giant papillary conjunctivitis secondary to the use of ocular prostheses, contact lenses and suture threads, the lower tarsal conjunctiva rarely presents papillary hypertrophy.\n",
      "c) In atopic dermatokeratoconjunctivitis, papillary hypertrophy characteristically occurs in the upper tarsal conjunctiva.\n",
      "d) Perennial allergic conjunctivitis often develops papillae, usually located in the upper tarsal conjunctiva, with a diameter greater than one millimeter.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.56 ms /    63 runs   (    0.58 ms per token,  1723.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3300.10 ms /   191 tokens (   17.28 ms per token,    57.88 tokens per second)\n",
      "llama_print_timings:        eval time =  7659.26 ms /    62 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 11151.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.60 ms /    60 runs   (    0.58 ms per token,  1734.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7423.01 ms /    60 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  7602.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.66 ms /    43 runs   (    0.57 ms per token,  1743.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5272.90 ms /    43 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5400.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.46 ms /    53 runs   (    0.57 ms per token,  1740.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6559.59 ms /    53 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6719.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.18 ms /     7 runs   (  121.17 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   868.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.49 ms /    28 runs   (    0.59 ms per token,  1698.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3467.42 ms /    28 runs   (  123.84 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3552.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.82 ms /    53 runs   (    0.58 ms per token,  1719.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6523.41 ms /    53 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6682.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.90 ms /    53 runs   (    0.58 ms per token,  1715.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6522.31 ms /    53 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6684.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.62 ms /    53 runs   (    0.58 ms per token,  1730.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6506.32 ms /    53 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6666.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao s manifestaes das conjuntivites,  correto afirmar:\n",
      "a)Na ceratoconjuntivite vernal, a hipertrofia papilar ocorre frequentemente tanto na conjuntiva tarsal superior quanto na inferior, com aspecto e intensidade semelhantes.\n",
      "b)Na conjuntivite papilar gigante secundria ao uso de prteses oculares, lentes de contato e fios de sutura, raramente a conjuntiva tarsal inferior apresenta hipertrofia papilar.\n",
      "c)Na dermatoceratoconjuntivite atpica a hipertrofia papilar ocorre caracteristicamente na conjuntiva tarsal superior.\n",
      "d)Conjuntivite alrgica perene frequentemente desenvolve papilas, localizadas geralmente na conjuntiva tarsal superior, com dimetro superior a um milmetro.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1728.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2954.59 ms /    24 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3026.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.14 ms /    63 runs   (    0.59 ms per token,  1696.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4380.33 ms /   225 tokens (   19.47 ms per token,    51.37 tokens per second)\n",
      "llama_print_timings:        eval time =  7649.17 ms /    62 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 12224.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.94 ms /    24 runs   (    0.58 ms per token,  1721.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2996.82 ms /    24 runs   (  124.87 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  3069.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.64 ms /    20 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2453.33 ms /    20 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  2513.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.06 ms /    45 runs   (    0.58 ms per token,  1726.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5527.02 ms /    45 runs   (  122.82 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5664.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.95 ms /    45 runs   (    0.58 ms per token,  1733.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5516.41 ms /    45 runs   (  122.59 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  5652.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "Error converting respose to json: {:response: \"c\"}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.97 ms /     7 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   878.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.92 ms /     7 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.53 ms /     7 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   877.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   875.91 ms /     7 runs   (  125.13 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =   896.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {'response': 'A'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.58 ms /     7 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   877.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1717.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.74 ms /     7 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   878.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 138: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding adenoviral conjunctivitis, it is correct to state:\n",
      "a) The removal of pseudomembranes is associated with a higher risk of symblepharon formation and therefore should be avoided.\n",
      "b) Use of low-concentration topical corticosteroids is indicated to prevent the appearance of pseudomembranes, and therefore, they are prescribed soon after the onset of symptoms.\n",
      "c) Topical corticosteroids, used in the acute phase, favor viral replication with increased viral load on the ocular surface.\n",
      "d) Controlled studies have shown the effectiveness of using ketorolac 0.5% in the acute phase of conjunctivitis to relieve symptoms, with a reduction in the duration of the contagion period, compared to the use of lubricating eye drops.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   854.38 ms /     7 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   875.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.42 ms /    77 runs   (    0.59 ms per token,  1695.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3548.77 ms /   196 tokens (   18.11 ms per token,    55.23 tokens per second)\n",
      "llama_print_timings:        eval time =  9358.80 ms /    76 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 13145.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.59 ms /    17 runs   (    0.74 ms per token,  1350.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2100.30 ms /    17 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  2158.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n",
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.67 ms /    24 runs   (    0.69 ms per token,  1439.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3014.93 ms /    24 runs   (  125.62 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  3096.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    25 runs   (    0.62 ms per token,  1602.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3047.20 ms /    25 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3129.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    46.91 ms /    70 runs   (    0.67 ms per token,  1492.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8637.71 ms /    70 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8869.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.64 ms /    20 runs   (    0.58 ms per token,  1718.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2457.66 ms /    20 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  2522.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n",
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.78 ms /    17 runs   (    0.58 ms per token,  1737.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2119.57 ms /    17 runs   (  124.68 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time =  2170.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    90.86 ms /   158 runs   (    0.58 ms per token,  1738.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19501.14 ms /   158 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 19994.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    98.88 ms /   171 runs   (    0.58 ms per token,  1729.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21196.51 ms /   171 runs   (  123.96 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 21730.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.26 ms /    25 runs   (    0.57 ms per token,  1752.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3129.88 ms /    25 runs   (  125.20 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  3204.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao s conjuntivites adenovirais,  correto afirmar:\n",
      "a)A remoo de pseudomembranas est associada a maior risco de formao de simblfaro e por isso deve ser evitada.\n",
      "b)Uso de corticosteroides tpicos de baixa concentrao est indicado para preveno do aparecimento de pseudomembranas, e por isso, eles so prescritos logo aps o incio dos sintomas.\n",
      "c)Corticosteroides tpicos, utilizados na fase aguda, favorecem replicao viral com aumento da carga viral na superfcie ocular.\n",
      "d)Estudos controlados demonstraram eficcia do uso do cetorolaco 0,5% na fase aguda da conjuntivite para alvio dos sintomas, com reduo da durao do perodo de contgio, em comparao ao uso de colrios lubrificantes.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1703.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4234.74 ms /   240 tokens (   17.64 ms per token,    56.67 tokens per second)\n",
      "llama_print_timings:        eval time =   741.14 ms /     6 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  4997.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.27 ms /    28 runs   (    0.58 ms per token,  1721.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3449.38 ms /    28 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3535.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1709.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   899.81 ms /     7 runs   (  128.54 ms per token,     7.78 tokens per second)\n",
      "llama_print_timings:       total time =   921.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.22 ms /   100 runs   (    0.58 ms per token,  1717.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12455.14 ms /   100 runs   (  124.55 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time = 12768.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1730.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   897.07 ms /     7 runs   (  128.15 ms per token,     7.80 tokens per second)\n",
      "llama_print_timings:       total time =   918.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n",
      "{'response': 'D'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.96 ms /   127 runs   (    0.57 ms per token,  1740.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15626.57 ms /   127 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 16021.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.93 ms /   127 runs   (    0.57 ms per token,  1741.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15721.23 ms /   127 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 16111.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.40 ms /    87 runs   (    0.58 ms per token,  1726.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10796.03 ms /    87 runs   (  124.09 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 11063.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1711.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.86 ms /     7 runs   (  126.55 ms per token,     7.90 tokens per second)\n",
      "llama_print_timings:       total time =   906.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.51 ms /     7 runs   (    0.64 ms per token,  1552.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.34 ms /     7 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   881.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 139: \n",
      "Language: english\n",
      "Question: \n",
      "Considering corneal transplants performed for optical purposes, what is the most appropriate association?\n",
      "\n",
      "I. Fuchs dystrophy.\n",
      "II. granular dystrophy.\n",
      "III. Opacity after hydrops.\n",
      "IV. bullous keratopathy.\n",
      "\n",
      "A- Indication for posterior lamellar transplantation.\n",
      "B- Contraindication for performing a deep anterior lamellar transplant.\n",
      "C- Contraindication for performing a superficial anterior lamellar transplant.\n",
      "D- Indication for deep anterior lamellar transplantation.\n",
      "\n",
      "a) I: A, II: B, III: D, IV: C.\n",
      "b) I: B, II: D, III: C, IV: A.\n",
      "c) I: C, II: A, III: D, IV: B.\n",
      "d) I: D, II: C, III: A, IV: B.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.01 ms /    51 runs   (    0.57 ms per token,  1758.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3503.31 ms /   221 tokens (   15.85 ms per token,    63.08 tokens per second)\n",
      "llama_print_timings:        eval time =  6176.84 ms /    50 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  9835.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #1: \n",
      "{'response': 'D'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.96 ms /    50 runs   (    0.56 ms per token,  1788.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6174.92 ms /    50 runs   (  123.50 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  6326.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.75 ms /    53 runs   (    0.56 ms per token,  1781.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6518.94 ms /    53 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6677.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.01 ms /    50 runs   (    0.58 ms per token,  1723.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6144.90 ms /    50 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6299.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.31 ms /    51 runs   (    0.56 ms per token,  1801.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6261.00 ms /    51 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6417.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.43 ms /    50 runs   (    0.63 ms per token,  1590.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6156.06 ms /    50 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6313.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.49 ms /    75 runs   (    0.57 ms per token,  1765.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9211.10 ms /    75 runs   (  122.81 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  9438.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.80 ms /    27 runs   (    0.55 ms per token,  1824.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3320.52 ms /    27 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3401.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.50 ms /    49 runs   (    0.56 ms per token,  1782.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6016.66 ms /    49 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6166.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.89 ms /    48 runs   (    0.56 ms per token,  1784.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5918.11 ms /    48 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  6061.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Considerando os transplantes de crnea realizados com finalidade ptica, qual a associao mais adequada?\n",
      "\n",
      "I. Distrofia de Fuchs.\n",
      "II. Distrofia granular.\n",
      "III. Opacidade aps hidrpsia.\n",
      "IV. Ceratopatia bolhosa.\n",
      "\n",
      "A- Indicao para realizao de transplante lamelar posterior.\n",
      "B- Contraindicao para a realizao de transplante lamelar anterior profundo.\n",
      "C- Contraindicao para realizao de transplante lamelar anterior superficial.\n",
      "D- Indicao para a realizao de transplante lamelar anterior profundo.\n",
      "\n",
      "a)I: A, II: B, III: D, IV: C.\n",
      "b)I: B, II: D, III: C, IV: A.\n",
      "c)I: C, II: A, III: D, IV: B.\n",
      "d)I: D, II: C, III: A, IV: B.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.86 ms /   120 runs   (    0.57 ms per token,  1742.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4739.18 ms /   246 tokens (   19.26 ms per token,    51.91 tokens per second)\n",
      "llama_print_timings:        eval time = 14669.78 ms /   119 runs   (  123.28 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 19780.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.53 ms /     7 runs   (    0.50 ms per token,  1984.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.12 ms /     7 runs   (  122.73 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #2: \n",
      "{'response': 'D'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.13 ms /    54 runs   (    0.56 ms per token,  1792.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6673.67 ms /    54 runs   (  123.59 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  6837.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.59 ms /    74 runs   (    0.58 ms per token,  1737.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9129.90 ms /    74 runs   (  123.38 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  9356.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.64 ms /   120 runs   (    0.56 ms per token,  1774.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14841.51 ms /   120 runs   (  123.68 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 15214.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "Test #5: \n",
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.98 ms /    52 runs   (    0.56 ms per token,  1794.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6378.41 ms /    52 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  6535.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.41 ms /    53 runs   (    0.55 ms per token,  1802.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6654.85 ms /    53 runs   (  125.56 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  6816.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.33 ms /    20 runs   (    0.52 ms per token,  1936.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2449.12 ms /    20 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  2508.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    27 runs   (    0.54 ms per token,  1861.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3342.39 ms /    27 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3423.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.05 ms /    54 runs   (    0.56 ms per token,  1796.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6721.60 ms /    54 runs   (  124.47 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  6885.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'D'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 140: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding ophthalmic herpes zoster, it is correct to state:\n",
      "a) In the treatment of immunocompetent adult patients when performed with valaciclovir, a total daily dose of 3 g is used.\n",
      "b) Disciform endothelitis, followed by neurotrophic ulcer, are the two most frequent clinical manifestations of corneal involvement, considering the first two months after the onset of infection.\n",
      "c) Hutchinson's sign indicates involvement of the maxillary and mandibular branches of the trigeminal nerve and indicates an increased probability of ocular involvement during infection.\n",
      "d) A single dermatome will be affected in the same occurrence of the infection.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.93 ms /    82 runs   (    0.58 ms per token,  1710.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3617.58 ms /   170 tokens (   21.28 ms per token,    46.99 tokens per second)\n",
      "llama_print_timings:        eval time = 10011.26 ms /    81 runs   (  123.60 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 13882.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.59 ms /    71 runs   (    0.57 ms per token,  1749.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8740.05 ms /    71 runs   (  123.10 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8957.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.25 ms /    67 runs   (    0.57 ms per token,  1751.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8363.36 ms /    67 runs   (  124.83 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  8566.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.19 ms /    67 runs   (    0.57 ms per token,  1754.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8275.78 ms /    67 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8478.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.86 ms /    66 runs   (    0.57 ms per token,  1743.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8251.51 ms /    66 runs   (  125.02 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  8454.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.50 ms /    67 runs   (    0.57 ms per token,  1740.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8268.34 ms /    67 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8470.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.43 ms /    67 runs   (    0.57 ms per token,  1743.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8273.41 ms /    67 runs   (  123.48 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8476.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'C'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    42.29 ms /    73 runs   (    0.58 ms per token,  1726.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8923.84 ms /    73 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9144.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2986.63 ms /    24 runs   (  124.44 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3057.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1724.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.75 ms /     7 runs   (  124.39 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao ao herpes zoster oftlmico,  correto afirmar:\n",
      "a)No tratamento de pacientes adultos imunocompetentes quando realizado com o valaciclovir,  utilizada a dose total diria de 3 g.\n",
      "b)A endotelite disciforme, seguida da lcera neurotrfica, so as duas manifestaes clnicas mais frequentes do comprometimento da crnea, considerando os dois primeiros meses aps o incio da infeco.\n",
      "c)O sinal de Hutchinson indica comprometimento dos ramos maxilar e mandibular do nervo trigmeo e sinaliza aumento de probabilidade do acometimento ocular durante a infeco.\n",
      "d)Um nico dermtomo ser acometido numa mesma ocorrncia da infeco.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.28 ms /     7 runs   (    0.61 ms per token,  1634.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4203.39 ms /   209 tokens (   20.11 ms per token,    49.72 tokens per second)\n",
      "llama_print_timings:        eval time =   739.83 ms /     6 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4964.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.14 ms /     7 runs   (    0.59 ms per token,  1692.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.82 ms /     7 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.12 ms /     7 runs   (    0.59 ms per token,  1700.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   876.96 ms /     7 runs   (  125.28 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =   898.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.00 ms /     7 runs   (  121.14 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   868.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1764.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   851.62 ms /     7 runs   (  121.66 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =   872.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1725.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.35 ms /     7 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1754.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.24 ms /     7 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   872.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json: {'response': 'b'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1743.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   885.63 ms /     7 runs   (  126.52 ms per token,     7.90 tokens per second)\n",
      "llama_print_timings:       total time =   906.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   857.30 ms /     7 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =   878.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   902.07 ms /     7 runs   (  128.87 ms per token,     7.76 tokens per second)\n",
      "llama_print_timings:       total time =   923.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 141: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding preoperative exams in refractive surgery, mark the correct alternative.\n",
      "a) Placido disc topography generates the pachymetric or corneal thickness map.\n",
      "b) Placido's disc topography and the Scheimpflug system are capable of generating both axial and tangential maps of the cornea.\n",
      "c) The maps generated by Plcido's disk topography are derived from the reflection of the anterior and posterior surface of the cornea.\n",
      "d) The Scheimpflug system evaluates the anterior curvature, the thickness map, but not the posterior face.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.40 ms /    11 runs   (    0.58 ms per token,  1718.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1340.95 ms /    11 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1373.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   133.06 ms /   229 runs   (    0.58 ms per token,  1720.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3242.48 ms /   138 tokens (   23.50 ms per token,    42.56 tokens per second)\n",
      "llama_print_timings:        eval time = 28020.37 ms /   228 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 31991.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.10 ms /    63 runs   (    0.59 ms per token,  1698.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7712.55 ms /    63 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7908.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.75 ms /    17 runs   (    0.57 ms per token,  1743.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2082.55 ms /    17 runs   (  122.50 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2132.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    87.78 ms /   153 runs   (    0.57 ms per token,  1742.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18835.90 ms /   153 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 19311.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   107.28 ms /   186 runs   (    0.58 ms per token,  1733.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23020.82 ms /   186 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 23600.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.74 ms /   206 runs   (    0.58 ms per token,  1734.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25407.18 ms /   206 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 26052.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.12 ms /    66 runs   (    0.58 ms per token,  1731.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8176.10 ms /    66 runs   (  123.88 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  8374.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   132.65 ms /   229 runs   (    0.58 ms per token,  1726.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28199.35 ms /   229 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 28924.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.28 ms /   146 runs   (    0.58 ms per token,  1732.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17905.42 ms /   146 runs   (  122.64 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 18353.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   132.31 ms /   229 runs   (    0.58 ms per token,  1730.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28180.94 ms /   229 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 28904.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Em relao aos exames pr-operatrios em cirurgia refrativa, assinale a alternativa correta.\n",
      "a)A topografia de disco de Plcido gera o mapa paquimtrico ou de espessura corneana.\n",
      "b)A topografia de disco de Plcido e o sistema de Scheimpflug so capazes de gerar tanto os mapas axiais como os tangenciais da crnea.\n",
      "c)Os mapas gerados pela topografia de disco de Plcido so derivados da reflexo da face anterior e posterior da crnea.\n",
      "d)O sistema de Scheimpflug avalia a curvatura anterior, o mapa de espessura, mas no a face posterior.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.14 ms /   136 runs   (    0.58 ms per token,  1718.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4208.74 ms /   172 tokens (   24.47 ms per token,    40.87 tokens per second)\n",
      "llama_print_timings:        eval time = 16746.79 ms /   135 runs   (  124.05 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 21377.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.49 ms /    27 runs   (    0.57 ms per token,  1743.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3340.86 ms /    27 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3421.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.60 ms /   147 runs   (    0.58 ms per token,  1737.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18142.86 ms /   147 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 18601.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    70.33 ms /   122 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15125.82 ms /   122 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 15499.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.06 ms /   115 runs   (    0.57 ms per token,  1740.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14208.60 ms /   115 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 14561.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    95.57 ms /   167 runs   (    0.57 ms per token,  1747.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20566.96 ms /   167 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 21085.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1759.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.68 ms /     7 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =   887.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.15 ms /    56 runs   (    0.57 ms per token,  1741.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6836.50 ms /    56 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7009.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3289.65 ms /    27 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3369.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.54 ms /    59 runs   (    0.57 ms per token,  1759.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7236.06 ms /    59 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  7411.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 142: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the conditions below is at increased risk after LASIK surgery?\n",
      "a) Cataract.\n",
      "b) Glaucoma.\n",
      "c) Dry eye.\n",
      "d) retinal detachment.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.16 ms /    28 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1213.61 ms /    52 tokens (   23.34 ms per token,    42.85 tokens per second)\n",
      "llama_print_timings:        eval time =  3322.62 ms /    27 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4619.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.61 ms /    22 runs   (    0.57 ms per token,  1744.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2667.94 ms /    22 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2733.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.89 ms /    28 runs   (    0.57 ms per token,  1761.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3390.17 ms /    28 runs   (  121.08 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3473.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #3: \n",
      "{'response': 'C'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   842.97 ms /     7 runs   (  120.42 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =   864.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.51 ms /    29 runs   (    0.57 ms per token,  1756.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3511.50 ms /    29 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3596.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'C'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1750.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.75 ms /     7 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   864.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1761.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.08 ms /     7 runs   (  120.15 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   861.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2920.16 ms /    24 runs   (  121.67 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2991.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.83 ms /    28 runs   (    0.57 ms per token,  1769.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3383.48 ms /    28 runs   (  120.84 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3466.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.42 ms /    27 runs   (    0.57 ms per token,  1750.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3269.36 ms /    27 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3349.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das condies abaixo tem seu risco aumentado aps cirurgia de LASIK?\n",
      "a)Catarata.\n",
      "b)Glaucoma.\n",
      "c)Olho seco.\n",
      "d)Descolamento de retina.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.73 ms /    13 runs   (    0.59 ms per token,  1681.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1465.94 ms /    63 tokens (   23.27 ms per token,    42.98 tokens per second)\n",
      "llama_print_timings:        eval time =  1467.02 ms /    12 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2972.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1744.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.16 ms /     7 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.46 ms /    13 runs   (    0.57 ms per token,  1741.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1588.04 ms /    13 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  1626.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.04 ms /    33 runs   (    0.58 ms per token,  1733.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4056.82 ms /    33 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4156.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.50 ms /    13 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1554.22 ms /    13 runs   (  119.56 ms per token,     8.36 tokens per second)\n",
      "llama_print_timings:       total time =  1593.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.50 ms /    13 runs   (    0.58 ms per token,  1733.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1572.20 ms /    13 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1610.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.44 ms /    13 runs   (    0.57 ms per token,  1747.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1563.65 ms /    13 runs   (  120.28 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  1601.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.46 ms /    13 runs   (    0.57 ms per token,  1743.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1568.85 ms /    13 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  1607.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.41 ms /    13 runs   (    0.57 ms per token,  1754.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1583.87 ms /    13 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  1622.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     7.46 ms /    13 runs   (    0.57 ms per token,  1742.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1576.90 ms /    13 runs   (  121.30 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  1616.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 143: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the use of therapeutic contact lenses, mark the correct alternative.\n",
      "a) Silicone-hydrogel lenses potentiate the action of medications.\n",
      "b) In the case of ocular perforation, the lens must not be used without association with tissue adhesive or suture.\n",
      "c) In cases of epithelial defects, the change is daily.\n",
      "d) Its adaptation is carried out with greater changes than usual.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.26 ms /   107 runs   (    0.58 ms per token,  1718.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2530.65 ms /   109 tokens (   23.22 ms per token,    43.07 tokens per second)\n",
      "llama_print_timings:        eval time = 12961.80 ms /   106 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 15825.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.34 ms /    96 runs   (    0.58 ms per token,  1734.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11809.83 ms /    96 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 12103.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.33 ms /    88 runs   (    0.58 ms per token,  1714.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10903.83 ms /    88 runs   (  123.91 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 11171.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n",
      "{'response': 'B'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   116.55 ms /   201 runs   (    0.58 ms per token,  1724.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24723.99 ms /   201 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 25357.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.73 ms /   102 runs   (    0.58 ms per token,  1736.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12488.12 ms /   102 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12797.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   148.30 ms /   258 runs   (    0.57 ms per token,  1739.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 31984.83 ms /   258 runs   (  123.97 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 32808.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.56 ms /    84 runs   (    0.58 ms per token,  1729.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10264.15 ms /    84 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 10519.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.05 ms /    99 runs   (    0.59 ms per token,  1705.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12123.78 ms /    99 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12441.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.83 ms /    78 runs   (    0.65 ms per token,  1534.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9643.02 ms /    78 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 10190.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.97 ms /    17 runs   (    0.65 ms per token,  1548.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2094.30 ms /    17 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2211.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Em relao ao uso de lente de contato teraputica, assinale a alternativa correta.\n",
      "a)As lentes de silicone-hidrogel potencializam a ao de medicamentos.\n",
      "b)No caso de perfurao ocular a lente no deve ser utilizada sem a associao com adesivo tecidual ou sutura.\n",
      "c)Nos casos de defeitos epiteliais a troca  diria.\n",
      "d)Sua adaptao  realizada com maiores trocas que a habitual.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.67 ms /     7 runs   (    0.67 ms per token,  1500.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3121.22 ms /   134 tokens (   23.29 ms per token,    42.93 tokens per second)\n",
      "llama_print_timings:        eval time =   741.20 ms /     6 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3910.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   137.19 ms /   233 runs   (    0.59 ms per token,  1698.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 28820.67 ms /   233 runs   (  123.69 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 29693.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.77 ms /   128 runs   (    0.58 ms per token,  1735.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15734.64 ms /   128 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 16131.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.76 ms /   109 runs   (    0.58 ms per token,  1736.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13483.10 ms /   109 runs   (  123.70 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 13817.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.37 ms /   114 runs   (    0.57 ms per token,  1743.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13934.91 ms /   114 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 14286.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.47 ms /   119 runs   (    0.58 ms per token,  1737.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14643.39 ms /   119 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 15012.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.43 ms /    65 runs   (    0.58 ms per token,  1736.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7937.63 ms /    65 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8136.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.20 ms /   107 runs   (    0.59 ms per token,  1693.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13152.56 ms /   107 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 13489.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.53 ms /    71 runs   (    0.58 ms per token,  1709.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8747.43 ms /    71 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8966.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 144: \n",
      "Language: english\n",
      "Question: \n",
      "One patient with a keratometry of 44.00/48.00 opted for contact lens fitting. One with a base curve of 45.00 was adapted. It is correct to say that:\n",
      "a) The lacrimal lens formed will be +3.00 diopters, since the difference between the most curved meridian of the lens and the base curve corresponds to this value.\n",
      "b) The concept of K applies to the flattest meridian, and its difference with the base curve results in a positive lens of +1.00 diopter.\n",
      "c) The patient with this keratometry value could not wear contact lenses, since there is very important corneal ectasia.\n",
      "d) The value of the most curved meridian of the corneal lens is called K, and adapted lenses with a base curve more curved than K form a lacrimal lens with a dioptric power of -1.00 Diopter.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   844.45 ms /     7 runs   (  120.64 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =   865.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.52 ms /   138 runs   (    0.58 ms per token,  1713.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3470.83 ms /   229 tokens (   15.16 ms per token,    65.98 tokens per second)\n",
      "llama_print_timings:        eval time = 16837.82 ms /   137 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 20747.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.72 ms /   138 runs   (    0.58 ms per token,  1731.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17081.44 ms /   138 runs   (  123.78 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 17519.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.99 ms /   138 runs   (    0.58 ms per token,  1725.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17086.37 ms /   138 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 17521.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.50 ms /    20 runs   (    0.57 ms per token,  1739.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2444.44 ms /    20 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2503.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.53 ms /   138 runs   (    0.58 ms per token,  1735.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17038.26 ms /   138 runs   (  123.47 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 17463.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.84 ms /    20 runs   (    0.59 ms per token,  1689.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2523.98 ms /    20 runs   (  126.20 ms per token,     7.92 tokens per second)\n",
      "llama_print_timings:       total time =  2585.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.67 ms /   138 runs   (    0.58 ms per token,  1732.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16954.67 ms /   138 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 17383.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n",
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.45 ms /   138 runs   (    0.58 ms per token,  1736.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17003.02 ms /   138 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 17432.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.50 ms /   138 runs   (    0.58 ms per token,  1714.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17025.17 ms /   138 runs   (  123.37 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 17456.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.11 ms /    28 runs   (    0.58 ms per token,  1737.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3413.14 ms /    28 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3496.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente com a ceratometria de 44,00/48,00 optou por adaptao de lente de contato. Foi adaptada uma de curva base 45,00.  correto afirmar que:\n",
      "a)A lente lacrimal formada ser de +3,00 dioptrias, uma vez que a diferena entre o meridiano mais curvo da lente e a curva base corresponde a esse valor.\n",
      "b)O conceito de K se aplica ao meridiano mais plano, e sua diferena com a curva base resulta em uma lente positiva de +1,00 dioptria.\n",
      "c)O paciente com esse valor de ceratometria no poderia usar lentes de contato, uma vez que h ectasia corneana muito importante.\n",
      "d)O valor do meridiano mais curvo da lente da crnea  chamado de K, e lentes adaptadas com curva base mais curva que K formam uma lente lacrimal com poder diptrico de -1,00 Dioptria.\n",
      "Test #0: \n",
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.45 ms /    28 runs   (    0.59 ms per token,  1701.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  5168.10 ms /   265 tokens (   19.50 ms per token,    51.28 tokens per second)\n",
      "llama_print_timings:        eval time =  3309.06 ms /    27 runs   (  122.56 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  8562.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.11 ms /     7 runs   (    0.59 ms per token,  1705.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.17 ms /     7 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   883.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.36 ms /    11 runs   (    0.58 ms per token,  1730.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1362.74 ms /    11 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  1396.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.14 ms /   102 runs   (    0.58 ms per token,  1724.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12672.78 ms /   102 runs   (  124.24 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 12984.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1719.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   865.89 ms /     7 runs   (  123.70 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   886.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.07 ms /     7 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   968.65 ms /     7 runs   (  138.38 ms per token,     7.23 tokens per second)\n",
      "llama_print_timings:       total time =   989.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.85 ms /     7 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   872.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.66 ms /   102 runs   (    0.58 ms per token,  1738.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12639.59 ms /   102 runs   (  123.92 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 12950.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.85 ms /   102 runs   (    0.58 ms per token,  1733.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12776.69 ms /   102 runs   (  125.26 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time = 13092.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.24 ms /    61 runs   (    0.58 ms per token,  1730.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7532.70 ms /    61 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  7719.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 145: \n",
      "Language: english\n",
      "Question: \n",
      "A patient has a static refraction of -8.00 spherical dioptry in both eyes and intends to wear contact lenses. With regard to glasses, your contact lens prescription will be:\n",
      "a)-7.50 Dioptres.\n",
      "b)-8.00 Dioptres.\n",
      "c)-8.50 Dioptres.\n",
      "d) It is not possible to determine lens graduation without performing corneal topography.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.86 ms /    37 runs   (    0.59 ms per token,  1692.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2062.43 ms /   108 tokens (   19.10 ms per token,    52.37 tokens per second)\n",
      "llama_print_timings:        eval time =  4394.65 ms /    36 runs   (  122.07 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  6571.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.69 ms /    34 runs   (    0.58 ms per token,  1726.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4131.94 ms /    34 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4234.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.73 ms /    17 runs   (    0.57 ms per token,  1747.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2064.40 ms /    17 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2116.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c)'}\n",
      "Test #3: \n",
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.37 ms /    37 runs   (    0.58 ms per token,  1731.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4546.65 ms /    37 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4660.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.48 ms /    34 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4191.31 ms /    34 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4294.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.93 ms /    38 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4637.12 ms /    38 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4754.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.06 ms /    40 runs   (    0.58 ms per token,  1734.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4911.07 ms /    40 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5032.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.41 ms /    37 runs   (    0.58 ms per token,  1728.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4587.98 ms /    37 runs   (  124.00 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  4698.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.27 ms /    37 runs   (    0.57 ms per token,  1739.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4538.23 ms /    37 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  4648.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.32 ms /    37 runs   (    0.58 ms per token,  1735.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4548.55 ms /    37 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4658.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8.00 Dioptres'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Um paciente apresenta na refrao esttica -8,00 dioptria esferica em ambos os olhos e pretende utilizar lentes de contato. Com relao aos culos, o grau da sua lente de contato ser:\n",
      "a)-7,50 Dioptrias.\n",
      "b)-8,00 Dioptrias.\n",
      "c)-8,50 Dioptrias.\n",
      "d)No  possvel determinar a graduao da lente sem a realizao da topografia de crnea.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.99 ms /    17 runs   (    0.59 ms per token,  1702.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2733.81 ms /   131 tokens (   20.87 ms per token,    47.92 tokens per second)\n",
      "llama_print_timings:        eval time =  1931.77 ms /    16 runs   (  120.74 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  4716.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.19 ms /    16 runs   (    0.57 ms per token,  1741.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1950.83 ms /    16 runs   (  121.93 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1998.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #2: \n",
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.66 ms /    41 runs   (    0.58 ms per token,  1732.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4994.99 ms /    41 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5117.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.76 ms /    36 runs   (    0.58 ms per token,  1734.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4359.97 ms /    36 runs   (  121.11 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  4467.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.70 ms /    36 runs   (    0.57 ms per token,  1739.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4439.67 ms /    36 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4546.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.38 ms /    37 runs   (    0.58 ms per token,  1730.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4558.52 ms /    37 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4671.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.82 ms /    36 runs   (    0.58 ms per token,  1729.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4386.80 ms /    36 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4494.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.20 ms /    16 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1967.40 ms /    16 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2015.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #8: \n",
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.69 ms /    36 runs   (    0.57 ms per token,  1740.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4391.12 ms /    36 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4499.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b)-8,00 Dioptrias'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 146: \n",
      "Language: english\n",
      "Question: \n",
      "\n",
      "Regarding intermittent exotropia, mark the correct alternative.\n",
      "a) Orthoptic exercises are contraindicated if there is insufficient convergence.\n",
      "b) It resolves spontaneously in the vast majority of cases.\n",
      "c) Treatment with occlusion is contraindicated if there is no amblyopia.\n",
      "d) The use of negative lenses (or farsightedness) provides better results if the accommodative convergence/accommodation ratio is high.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.32 ms /    16 runs   (    0.58 ms per token,  1716.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2005.30 ms /    16 runs   (  125.33 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  2053.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.90 ms /    61 runs   (    0.59 ms per token,  1699.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2453.34 ms /   119 tokens (   20.62 ms per token,    48.51 tokens per second)\n",
      "llama_print_timings:        eval time =  7372.82 ms /    60 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10013.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.97 ms /    59 runs   (    0.58 ms per token,  1736.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7212.40 ms /    59 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7390.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.89 ms /    61 runs   (    0.59 ms per token,  1699.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7588.71 ms /    61 runs   (  124.41 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  7774.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.08 ms /   105 runs   (    0.62 ms per token,  1613.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12911.26 ms /   105 runs   (  122.96 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 13250.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.72 ms /    56 runs   (    0.67 ms per token,  1484.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6895.52 ms /    56 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  7080.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.99 ms /    60 runs   (    0.58 ms per token,  1714.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7348.16 ms /    60 runs   (  122.47 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  7529.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.06 ms /    61 runs   (    0.57 ms per token,  1739.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7452.16 ms /    61 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7635.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n",
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.65 ms /   126 runs   (    0.58 ms per token,  1734.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15455.19 ms /   126 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 15843.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    34.65 ms /    60 runs   (    0.58 ms per token,  1731.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7394.58 ms /    60 runs   (  123.24 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  7575.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    78.31 ms /   135 runs   (    0.58 ms per token,  1723.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16619.46 ms /   135 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 17038.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao  exotropia intermitente, assinale a alternativa correta.\n",
      "a)Exerccios ortpticos so contraindicados se houver insuficincia de convergncia.\n",
      "b)Resolve-se espontaneamente na grande maioria dos casos.\n",
      "c)O tratamento com ocluso  contraindicado se no houver ambliopia.\n",
      "d)O uso de lentes negativas (ou hipermetropizao), proporciona melhor resultado se a relao convergncia acomodativa/acomodao for alta.\n",
      "Test #0: \n",
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.34 ms /     7 runs   (    0.62 ms per token,  1612.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2997.81 ms /   138 tokens (   21.72 ms per token,    46.03 tokens per second)\n",
      "llama_print_timings:        eval time =   724.89 ms /     6 runs   (  120.81 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3743.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.40 ms /   183 runs   (    0.58 ms per token,  1719.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22445.42 ms /   183 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 23024.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #2: \n",
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   100.16 ms /   174 runs   (    0.58 ms per token,  1737.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 21563.66 ms /   174 runs   (  123.93 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 22102.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.86 ms /    67 runs   (    0.58 ms per token,  1724.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8174.08 ms /    67 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  8376.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   118.42 ms /   206 runs   (    0.57 ms per token,  1739.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 25333.46 ms /   206 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 25976.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   115.70 ms /   193 runs   (    0.60 ms per token,  1668.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 23774.32 ms /   193 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 24393.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    95.31 ms /   166 runs   (    0.57 ms per token,  1741.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20336.58 ms /   166 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 20855.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.36 ms /    65 runs   (    0.57 ms per token,  1739.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8001.11 ms /    65 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8198.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    85.31 ms /   148 runs   (    0.58 ms per token,  1734.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18320.57 ms /   148 runs   (  123.79 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 18777.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #9: \n",
      "{'response': 'd'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 147: \n",
      "Language: english\n",
      "Question: \n",
      "Among the findings below, which one is associated with the sensory binocular function considered to be the most refined:\n",
      "a) Stereopsis.\n",
      "b) Binocular fusion.\n",
      "c) Diplopia.\n",
      "d) Simultaneous macular perception.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.09 ms /   196 runs   (    0.58 ms per token,  1733.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24219.85 ms /   196 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 24834.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.71 ms /    27 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1735.51 ms /    66 tokens (   26.30 ms per token,    38.03 tokens per second)\n",
      "llama_print_timings:        eval time =  3143.60 ms /    26 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4961.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.50 ms /    27 runs   (    0.57 ms per token,  1742.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3265.65 ms /    27 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3346.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.44 ms /    20 runs   (    0.57 ms per token,  1748.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2435.09 ms /    20 runs   (  121.75 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2494.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.13 ms /    28 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3389.80 ms /    28 runs   (  121.06 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3473.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n",
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.44 ms /    20 runs   (    0.57 ms per token,  1747.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2450.64 ms /    20 runs   (  122.53 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2509.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    27 runs   (    0.58 ms per token,  1732.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3281.57 ms /    27 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3362.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.44 ms /    20 runs   (    0.57 ms per token,  1747.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2435.11 ms /    20 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2494.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.45 ms /    20 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2499.99 ms /    20 runs   (  125.00 ms per token,     8.00 tokens per second)\n",
      "llama_print_timings:       total time =  2559.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.47 ms /    20 runs   (    0.57 ms per token,  1744.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2418.95 ms /    20 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2478.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.89 ms /    21 runs   (    0.57 ms per token,  1766.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2584.46 ms /    21 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2647.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Entre os achados abaixo, qual est associado a funo binocular sensorial considerada como a mais refinada:\n",
      "a)Estereopsia.\n",
      "b)Fuso binocular.\n",
      "c)Diplopia.\n",
      "d)Percepo macular simultnea.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1788.86 ms /    74 tokens (   24.17 ms per token,    41.37 tokens per second)\n",
      "llama_print_timings:        eval time =  3280.75 ms /    27 runs   (  121.51 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5154.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    27 runs   (    0.58 ms per token,  1730.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3255.04 ms /    27 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3336.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.54 ms /    36 runs   (    0.57 ms per token,  1752.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4407.28 ms /    36 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4515.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b) Fuso binocular'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.44 ms /    27 runs   (    0.57 ms per token,  1748.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3273.90 ms /    27 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3355.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.46 ms /    34 runs   (    0.57 ms per token,  1747.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4146.48 ms /    34 runs   (  121.96 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  4247.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.42 ms /    34 runs   (    0.57 ms per token,  1750.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4152.00 ms /    34 runs   (  122.12 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4253.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.69 ms /    27 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3275.94 ms /    27 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3358.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.98 ms /     7 runs   (    0.57 ms per token,  1757.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   853.25 ms /     7 runs   (  121.89 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =   874.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.30 ms /   100 runs   (    0.57 ms per token,  1745.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12200.35 ms /   100 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 12508.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 148: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the anomalous retinal correspondence, mark the correct alternative.\n",
      "a) It is a phenomenon of monocular sensory adaptation.\n",
      "b) It is more frequent in small angle deviations.\n",
      "c) It is considered a protective factor for diplopia in the postoperative period of strabismus surgery.\n",
      "d) It is considered a protective factor against recurrence in the postoperative period of strabismus surgery.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.98 ms /    28 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3473.55 ms /    28 runs   (  124.06 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =  3557.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.38 ms /    25 runs   (    0.58 ms per token,  1739.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2405.86 ms /   102 tokens (   23.59 ms per token,    42.40 tokens per second)\n",
      "llama_print_timings:        eval time =  2917.28 ms /    24 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  5398.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n",
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.82 ms /    24 runs   (    0.58 ms per token,  1736.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2912.12 ms /    24 runs   (  121.34 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2984.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.62 ms /    24 runs   (    0.57 ms per token,  1761.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2922.75 ms /    24 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2993.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1749.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2984.34 ms /    24 runs   (  124.35 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  3056.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.84 ms /    24 runs   (    0.58 ms per token,  1734.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2911.69 ms /    24 runs   (  121.32 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2984.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.22 ms /    25 runs   (    0.57 ms per token,  1757.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3082.23 ms /    25 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  3155.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.73 ms /    24 runs   (    0.57 ms per token,  1748.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2917.62 ms /    24 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2988.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.20 ms /    25 runs   (    0.57 ms per token,  1760.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3085.76 ms /    25 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3160.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.03 ms /    86 runs   (    0.58 ms per token,  1719.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10550.27 ms /    86 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10815.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.20 ms /    25 runs   (    0.57 ms per token,  1760.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3016.13 ms /    25 runs   (  120.65 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  3089.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao  correspondncia retiniana anmala, assinale a alternativa correta.\n",
      "a) um fenmeno de adaptao sensorial monocular.\n",
      "b) mais frequente nos desvios de pequeno ngulo.\n",
      "c) considerada fator protetor de diplopia no ps-operatrio de cirurgia de estrabismo.\n",
      "d) considerada fator protetor de recidiva no ps-operatrio de cirurgia de estrabismo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.03 ms /    81 runs   (    0.58 ms per token,  1722.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2126.33 ms /   126 tokens (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_print_timings:        eval time =  9812.57 ms /    80 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12190.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.88 ms /    24 runs   (    0.58 ms per token,  1729.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2953.51 ms /    24 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3025.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.70 ms /    24 runs   (    0.57 ms per token,  1751.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2969.30 ms /    24 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3041.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3456.82 ms /    28 runs   (  123.46 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3540.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    73.90 ms /   128 runs   (    0.58 ms per token,  1732.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15696.83 ms /   128 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 16091.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.09 ms /    28 runs   (    0.57 ms per token,  1739.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3461.50 ms /    28 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3545.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.45 ms /    27 runs   (    0.57 ms per token,  1747.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3314.63 ms /    27 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3395.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.07 ms /    28 runs   (    0.57 ms per token,  1742.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3433.03 ms /    28 runs   (  122.61 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3515.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3315.37 ms /    27 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3395.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 149: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following complications is most frequent after injection of botulinum toxin into the medial rectus muscle?\n",
      "a) Blepharoptosis.\n",
      "b) Retrobulbar hemorrhage.\n",
      "c) Mydriasis.\n",
      "d) Miosis.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.55 ms /    27 runs   (    0.58 ms per token,  1736.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3382.62 ms /    27 runs   (  125.28 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  3463.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.57 ms /    25 runs   (    0.58 ms per token,  1716.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1344.72 ms /    70 tokens (   19.21 ms per token,    52.06 tokens per second)\n",
      "llama_print_timings:        eval time =  2931.85 ms /    24 runs   (  122.16 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4351.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2947.07 ms /    24 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3019.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.75 ms /    17 runs   (    0.57 ms per token,  1744.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2040.42 ms /    17 runs   (  120.02 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  2090.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.69 ms /    24 runs   (    0.57 ms per token,  1753.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.88 ms /    24 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2986.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n",
      "{'response': 'C'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.04 ms /    28 runs   (    0.57 ms per token,  1745.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3391.81 ms /    28 runs   (  121.14 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3475.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.26 ms /    25 runs   (    0.57 ms per token,  1752.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3057.31 ms /    25 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3130.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.45 ms /    25 runs   (    0.58 ms per token,  1730.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3001.27 ms /    25 runs   (  120.05 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =  3075.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.16 ms /    44 runs   (    0.57 ms per token,  1748.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5331.04 ms /    44 runs   (  121.16 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5462.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1750.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2876.54 ms /    24 runs   (  119.86 ms per token,     8.34 tokens per second)\n",
      "llama_print_timings:       total time =  2947.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.80 ms /    45 runs   (    0.57 ms per token,  1744.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5418.20 ms /    45 runs   (  120.40 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  5552.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual das complicaes abaixo  mais frequente aps injeo de toxina botulnica no msculo reto medial?\n",
      "a)Blefaroptose.\n",
      "b)Hemorragia retrobulbar.\n",
      "c)Midrase.\n",
      "d)Miose.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.27 ms /    44 runs   (    0.57 ms per token,  1740.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1398.58 ms /    76 tokens (   18.40 ms per token,    54.34 tokens per second)\n",
      "llama_print_timings:        eval time =  5227.60 ms /    43 runs   (  121.57 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  6759.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.85 ms /     7 runs   (  121.26 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b} Hemorragia retrobulbar.'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    19.46 ms /    34 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4119.23 ms /    34 runs   (  121.15 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  4220.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.34 ms /     7 runs   (  121.19 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1753.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   873.69 ms /     7 runs   (  124.81 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =   893.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1743.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.65 ms /     7 runs   (  124.38 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.91 ms /    28 runs   (    0.57 ms per token,  1759.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3405.34 ms /    28 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3488.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.45 ms /    27 runs   (    0.57 ms per token,  1747.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3286.02 ms /    27 runs   (  121.70 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3365.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    24.65 ms /    43 runs   (    0.57 ms per token,  1744.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5221.48 ms /    43 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  5349.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   860.04 ms /     7 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   880.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 150: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding exotropia caused by low monocular (sensory) visual acuity, mark the correct alternative.\n",
      "a) It represents approximately 2% of all cases of adult exotropia.\n",
      "b) Prescription of prisms is the treatment of choice.\n",
      "c) It is usually associated with normal stereopsis.\n",
      "d) It is common for the deviation to increase over time.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.79 ms /    67 runs   (    0.58 ms per token,  1727.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2100.90 ms /    89 tokens (   23.61 ms per token,    42.36 tokens per second)\n",
      "llama_print_timings:        eval time =  8042.74 ms /    66 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time = 10345.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.34 ms /    25 runs   (    0.57 ms per token,  1743.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3026.45 ms /    25 runs   (  121.06 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  3100.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    30.91 ms /    54 runs   (    0.57 ms per token,  1747.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6573.81 ms /    54 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  6736.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.64 ms /   163 runs   (    0.57 ms per token,  1740.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19965.99 ms /   163 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 20469.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    82.01 ms /   143 runs   (    0.57 ms per token,  1743.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17474.16 ms /   143 runs   (  122.20 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time = 17912.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1750.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2922.66 ms /    24 runs   (  121.78 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2995.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.74 ms /    71 runs   (    0.57 ms per token,  1742.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8663.45 ms /    71 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  8878.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.12 ms /    95 runs   (    0.57 ms per token,  1755.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11638.41 ms /    95 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 11925.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.23 ms /    51 runs   (    0.57 ms per token,  1745.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6182.35 ms /    51 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  6333.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   160.11 ms /   278 runs   (    0.58 ms per token,  1736.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 34368.82 ms /   278 runs   (  123.63 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 35257.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao  exotropia causada por baixa acuidade visual monocular (sensorial), assinale a alternativa correta.\n",
      "a)Representa aproximadamente 2% de todos os casos de exotropia do adulto.\n",
      "b)Prescrio de prismas  o tratamento de escolha.\n",
      "c)Est associada, em geral, a estereopsia normal.\n",
      "d) comum o aumento do desvio com o passar do tempo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    84.36 ms /   145 runs   (    0.58 ms per token,  1718.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2336.95 ms /   118 tokens (   19.80 ms per token,    50.49 tokens per second)\n",
      "llama_print_timings:        eval time = 17738.99 ms /   144 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 20528.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.49 ms /    20 runs   (    0.57 ms per token,  1740.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2434.26 ms /    20 runs   (  121.71 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2494.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.77 ms /    88 runs   (    0.58 ms per token,  1733.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10822.29 ms /    88 runs   (  122.98 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 11090.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.08 ms /    71 runs   (    0.58 ms per token,  1728.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8652.63 ms /    71 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  8867.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1732.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2487.23 ms /    20 runs   (  124.36 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =  2546.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.87 ms /    83 runs   (    0.58 ms per token,  1733.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10153.67 ms /    83 runs   (  122.33 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10405.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.87 ms /    17 runs   (    0.58 ms per token,  1722.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2146.92 ms /    17 runs   (  126.29 ms per token,     7.92 tokens per second)\n",
      "llama_print_timings:       total time =  2197.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   116.20 ms /   200 runs   (    0.58 ms per token,  1721.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24616.41 ms /   200 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 25266.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.46 ms /    91 runs   (    0.58 ms per token,  1734.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11228.24 ms /    91 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 11513.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.76 ms /     7 runs   (  120.82 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   866.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 151: \n",
      "Language: english\n",
      "Question: \n",
      "Vicious head positions to compensate for strabismus occur most frequently in which of the following deviations?\n",
      "a) Partially accommodative.\n",
      "b) Incomitants.\n",
      "c) Intermittent exotropia.\n",
      "d) Commanders.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.07 ms /    24 runs   (    0.59 ms per token,  1705.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1163.60 ms /    60 tokens (   19.39 ms per token,    51.56 tokens per second)\n",
      "llama_print_timings:        eval time =  2775.69 ms /    23 runs   (  120.68 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =  4013.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.99 ms /    24 runs   (    0.58 ms per token,  1715.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2900.48 ms /    24 runs   (  120.85 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2975.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.48 ms /    24 runs   (    0.60 ms per token,  1657.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2964.36 ms /    24 runs   (  123.51 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3039.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.33 ms /    24 runs   (    0.60 ms per token,  1674.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2944.00 ms /    24 runs   (  122.67 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3019.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.69 ms /    24 runs   (    0.57 ms per token,  1752.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.21 ms /    24 runs   (  122.01 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  2999.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.86 ms /    24 runs   (    0.58 ms per token,  1731.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2883.70 ms /    24 runs   (  120.15 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  2955.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.80 ms /    17 runs   (    0.58 ms per token,  1734.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2077.93 ms /    17 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2128.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2945.93 ms /    24 runs   (  122.75 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3018.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n",
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.49 ms /    28 runs   (    0.59 ms per token,  1697.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3396.12 ms /    28 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3481.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "As posies viciosas da cabea para compensar os estrabismos ocorrem mais frequentemente em qual dos desvios abaixo?\n",
      "a)Parcialmente acomodativos.\n",
      "b)Incomitantes.\n",
      "c)Exotropia intermitente.\n",
      "d)Comitantes.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2910.47 ms /    24 runs   (  121.27 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  2981.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.89 ms /    27 runs   (    0.59 ms per token,  1699.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1447.67 ms /    76 tokens (   19.05 ms per token,    52.50 tokens per second)\n",
      "llama_print_timings:        eval time =  3161.71 ms /    26 runs   (  121.60 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4692.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.80 ms /    29 runs   (    0.58 ms per token,  1725.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3521.79 ms /    29 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3609.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Comitantes.'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.36 ms /    32 runs   (    0.57 ms per token,  1743.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3867.51 ms /    32 runs   (  120.86 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3963.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd}Comitantes'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.07 ms /    28 runs   (    0.57 ms per token,  1742.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3398.74 ms /    28 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3482.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.38 ms /    32 runs   (    0.57 ms per token,  1741.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3929.20 ms /    32 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  4024.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.95 ms /    33 runs   (    0.57 ms per token,  1741.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4078.99 ms /    33 runs   (  123.61 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4177.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.64 ms /    29 runs   (    0.57 ms per token,  1742.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3517.48 ms /    29 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3604.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) Comitantes'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.51 ms /    32 runs   (    0.58 ms per token,  1729.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3870.66 ms /    32 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  3965.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd}Comitantes'}\n",
      "Test #8: \n",
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.60 ms /    35 runs   (    0.59 ms per token,  1698.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4254.16 ms /    35 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4360.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.70 ms /    29 runs   (    0.58 ms per token,  1736.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3542.15 ms /    29 runs   (  122.14 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3628.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd} Comitantes.'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 152: \n",
      "Language: english\n",
      "Question: \n",
      "During the Maddox test, Maddox cylinders were placed in front of the patient's eyes, the red one in front of the right eye and the colorless one in front of the left eye, both vertically oriented. The patient, upon observing a point of light, reported seeing the red line tilted counterclockwise (patient's perspective). It most likely features:\n",
      "a) Inciclotorsion of the right eye.\n",
      "b) Excyclotorsion of the right eye.\n",
      "c) Inciclotorsion of the left eye.\n",
      "d) Hyperfunction of the left superior oblique muscle.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.49 ms /    39 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2801.65 ms /   145 tokens (   19.32 ms per token,    51.76 tokens per second)\n",
      "llama_print_timings:        eval time =  4661.93 ms /    38 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  7581.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.89 ms /    40 runs   (    0.57 ms per token,  1747.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4869.56 ms /    40 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4989.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.67 ms /    36 runs   (    0.57 ms per token,  1741.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4442.87 ms /    36 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  4551.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.81 ms /    36 runs   (    0.58 ms per token,  1729.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4378.02 ms /    36 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  4486.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.95 ms /    40 runs   (    0.57 ms per token,  1742.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4889.52 ms /    40 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5009.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.53 ms /    40 runs   (    0.59 ms per token,  1699.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4910.39 ms /    40 runs   (  122.76 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5032.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.30 ms /    37 runs   (    0.58 ms per token,  1736.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4515.94 ms /    37 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  4627.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.87 ms /    40 runs   (    0.57 ms per token,  1748.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4872.90 ms /    40 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4993.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.34 ms /    37 runs   (    0.58 ms per token,  1734.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4531.89 ms /    37 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  4643.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.98 ms /    40 runs   (    0.57 ms per token,  1740.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4889.70 ms /    40 runs   (  122.24 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  5009.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Durante o teste de Maddox, colocou-se cilindros de Maddox diante dos olhos do paciente, sendo o vermelho diante do olho direito e o incolor diante do olho esquerdo, ambos orientados verticalmente. O paciente, ao observar um foco de luz puntiforme, informou ver a linha vermelha inclinada no sentido anti-horrio (perspectiva do paciente). Ele apresenta mais provavelmente:\n",
      "a)Inciclotoro do olho direito.\n",
      "b)Exciclotoro do olho direito.\n",
      "c)Inciclotoro do olho esquerdo.\n",
      "d)Hiperfuno de msculo oblquo superior esquerdo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.08 ms /     7 runs   (    0.58 ms per token,  1713.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3532.18 ms /   187 tokens (   18.89 ms per token,    52.94 tokens per second)\n",
      "llama_print_timings:        eval time =   743.32 ms /     6 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4296.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.85 ms /    19 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2380.27 ms /    19 runs   (  125.28 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  2436.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.88 ms /    19 runs   (    0.57 ms per token,  1746.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2372.06 ms /    19 runs   (  124.85 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  2428.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #3: \n",
      "{'response': 'a'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.88 ms /    19 runs   (    0.57 ms per token,  1746.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2339.56 ms /    19 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  2396.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.90 ms /    19 runs   (    0.57 ms per token,  1742.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2344.71 ms /    19 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  2401.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.79 ms /    19 runs   (    0.57 ms per token,  1760.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2411.26 ms /    19 runs   (  126.91 ms per token,     7.88 tokens per second)\n",
      "llama_print_timings:       total time =  2467.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.41 ms /    19 runs   (    0.60 ms per token,  1664.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2350.54 ms /    19 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  2409.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1773.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   895.69 ms /     7 runs   (  127.96 ms per token,     7.82 tokens per second)\n",
      "llama_print_timings:       total time =   915.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #8: \n",
      "{'response': 'A'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.92 ms /    28 runs   (    0.57 ms per token,  1758.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3433.29 ms /    28 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3515.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.76 ms /    40 runs   (    0.57 ms per token,  1757.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4920.85 ms /    40 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  5038.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 153: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding pleomorphic adenoma of the lacrimal gland, mark the correct alternative.\n",
      "a) Computed tomography scan shows heterogeneous and poorly delimited lesion.\n",
      "b) The most common condition is a rapidly progressive growth mass.\n",
      "c) On palpation, the tumor is generally painless.\n",
      "d) It is more common in women.\n",
      "Test #0: \n",
      "{'response': 'C'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.97 ms /    17 runs   (    0.59 ms per token,  1705.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2065.30 ms /    86 tokens (   24.02 ms per token,    41.64 tokens per second)\n",
      "llama_print_timings:        eval time =  1934.97 ms /    16 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  4051.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.17 ms /    70 runs   (    0.57 ms per token,  1742.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8487.53 ms /    70 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  8696.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.71 ms /    17 runs   (    0.57 ms per token,  1749.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2082.91 ms /    17 runs   (  122.52 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  2132.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #3: \n",
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.60 ms /    50 runs   (    0.57 ms per token,  1748.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6072.95 ms /    50 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  6220.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.68 ms /    50 runs   (    0.57 ms per token,  1743.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6188.04 ms /    50 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  6341.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.89 ms /    24 runs   (    0.58 ms per token,  1728.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2904.45 ms /    24 runs   (  121.02 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2977.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    28.87 ms /    50 runs   (    0.58 ms per token,  1731.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6160.67 ms /    50 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6315.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.71 ms /    24 runs   (    0.57 ms per token,  1750.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2955.56 ms /    24 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  3027.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1740.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3044.05 ms /    25 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3119.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao ao adenoma pleomrfico de glndula lacrimal, assinale a alternativa correta.\n",
      "a)O exame de tomografia computadorizada mostra leso heterognea e mal delimitada.\n",
      "b)O quadro mais comum  de massa de crescimento rapidamente progressivo.\n",
      "c) palpao, a tumorao , em geral, indolor.\n",
      "d) mais frequente em mulheres.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.62 ms /    67 runs   (    0.58 ms per token,  1735.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8191.06 ms /    67 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  8393.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.65 ms /    20 runs   (    0.58 ms per token,  1716.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2080.83 ms /   114 tokens (   18.25 ms per token,    54.79 tokens per second)\n",
      "llama_print_timings:        eval time =  2394.25 ms /    19 runs   (  126.01 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  4536.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.94 ms /    17 runs   (    0.58 ms per token,  1709.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2071.81 ms /    17 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2123.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.89 ms /    28 runs   (    0.57 ms per token,  1762.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3406.10 ms /    28 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3489.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1749.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.13 ms /     7 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   882.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.46 ms /    27 runs   (    0.57 ms per token,  1746.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3338.65 ms /    27 runs   (  123.65 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  3418.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.62 ms /    24 runs   (    0.57 ms per token,  1761.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2901.56 ms /    24 runs   (  120.90 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  2972.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.46 ms /    51 runs   (    0.58 ms per token,  1730.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6280.26 ms /    51 runs   (  123.14 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  6434.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.91 ms /    57 runs   (    0.58 ms per token,  1731.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6957.70 ms /    57 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7131.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   140.92 ms /   244 runs   (    0.58 ms per token,  1731.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 30003.70 ms /   244 runs   (  122.97 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 30775.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.54 ms /    57 runs   (    0.57 ms per token,  1751.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7047.72 ms /    57 runs   (  123.64 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  7219.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 154: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding orbital involvement in leukemia, mark the correct alternative.\n",
      "a) The treatment is generally not sensitive to radiotherapy.\n",
      "b) The treatment is generally not sensitive to chemotherapy.\n",
      "c) Granulocytic sarcoma is the orbital infiltration most frequently associated with lymphoid leukemia.\n",
      "d) Imaging exams show an orbital mass that usually compromises the bone structure.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.18 ms /    64 runs   (    0.60 ms per token,  1676.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1850.97 ms /   101 tokens (   18.33 ms per token,    54.57 tokens per second)\n",
      "llama_print_timings:        eval time =  7699.35 ms /    63 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  9747.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.43 ms /    25 runs   (    0.58 ms per token,  1732.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3049.98 ms /    25 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3125.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.72 ms /    24 runs   (    0.57 ms per token,  1749.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2969.45 ms /    24 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3040.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.47 ms /    25 runs   (    0.58 ms per token,  1727.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3019.91 ms /    25 runs   (  120.80 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3096.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.80 ms /    24 runs   (    0.58 ms per token,  1738.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2915.94 ms /    24 runs   (  121.50 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  2988.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.35 ms /    25 runs   (    0.57 ms per token,  1742.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3171.45 ms /    25 runs   (  126.86 ms per token,     7.88 tokens per second)\n",
      "llama_print_timings:       total time =  3247.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.74 ms /    24 runs   (    0.57 ms per token,  1746.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2928.44 ms /    24 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3001.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.83 ms /    24 runs   (    0.58 ms per token,  1734.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2887.56 ms /    24 runs   (  120.31 ms per token,     8.31 tokens per second)\n",
      "llama_print_timings:       total time =  2961.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.81 ms /    24 runs   (    0.58 ms per token,  1737.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2914.37 ms /    24 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2986.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao ao comprometimento orbitrio na leucemia, assinale a alternativa correta.\n",
      "a)O tratamento geralmente no  sensvel  radioterapia.\n",
      "b)O tratamento geralmente no  sensvel  quimioterapia.\n",
      "c)O sarcoma granuloctico  a infiltrao orbitria mais frequentemente associada a leucemia linfoide.\n",
      "d)Exames de imagem mostram massa orbitria que geralmente compromete a estrutura ssea.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.62 ms /    55 runs   (    0.57 ms per token,  1739.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6765.00 ms /    55 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6933.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.25 ms /    27 runs   (    0.60 ms per token,  1661.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2317.21 ms /   129 tokens (   17.96 ms per token,    55.67 tokens per second)\n",
      "llama_print_timings:        eval time =  3173.30 ms /    26 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  5572.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.59 ms /    27 runs   (    0.58 ms per token,  1732.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3259.72 ms /    27 runs   (  120.73 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  3340.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.07 ms /    66 runs   (    0.58 ms per token,  1733.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8064.10 ms /    66 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  8262.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1734.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.83 ms /     7 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   871.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.74 ms /    62 runs   (    0.58 ms per token,  1734.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7605.08 ms /    62 runs   (  122.66 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  7792.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   881.86 ms /     7 runs   (  125.98 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =   902.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.10 ms /    65 runs   (    0.59 ms per token,  1706.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8160.97 ms /    65 runs   (  125.55 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  8359.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1749.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   886.69 ms /     7 runs   (  126.67 ms per token,     7.89 tokens per second)\n",
      "llama_print_timings:       total time =   906.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    38.61 ms /    66 runs   (    0.58 ms per token,  1709.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8153.04 ms /    66 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  8355.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.18 ms /    28 runs   (    0.58 ms per token,  1730.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3412.36 ms /    28 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3498.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 155: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding plexiform orbital neurofibroma, mark the correct alternative:\n",
      "a) Its malignant degeneration is rare.\n",
      "b) It is rarely seen in patients with neurofibromatosis.\n",
      "c) It has a good prognosis, with a low rate of recurrence after surgery.\n",
      "d) It is avascular, and bleeding from the tumor during surgery is rare.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.69 ms /    69 runs   (    0.59 ms per token,  1695.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2298.40 ms /    99 tokens (   23.22 ms per token,    43.07 tokens per second)\n",
      "llama_print_timings:        eval time =  8324.57 ms /    68 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 10838.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1764.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   841.18 ms /     7 runs   (  120.17 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =   862.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.38 ms /    44 runs   (    0.58 ms per token,  1733.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5399.82 ms /    44 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  5535.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.30 ms /    87 runs   (    0.58 ms per token,  1729.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10692.71 ms /    87 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 10962.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.10 ms /    24 runs   (    0.59 ms per token,  1702.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2930.12 ms /    24 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3004.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.67 ms /    48 runs   (    0.58 ms per token,  1734.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5896.11 ms /    48 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  6042.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n",
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.50 ms /    65 runs   (    0.58 ms per token,  1733.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8056.34 ms /    65 runs   (  123.94 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  8253.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    22.98 ms /    40 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4959.15 ms /    40 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  5079.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    25.17 ms /    44 runs   (    0.57 ms per token,  1748.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5418.65 ms /    44 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  5551.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.91 ms /    59 runs   (    0.57 ms per token,  1739.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7173.83 ms /    59 runs   (  121.59 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  7352.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Com relao ao neurofibroma da rbita tipo plexiforme, assinale a alternativa correta:\n",
      "a)Sua degeneraro maligna  rara.\n",
      "b) raramente observado em pacientes com neurofibromatose.\n",
      "c)Tem bom prognstico, com baixa taxa de recorrncia aps a cirurgia.\n",
      "d) avascular, sendo raro o sangramento do tumor durante a cirurgia.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.31 ms /     7 runs   (    0.62 ms per token,  1623.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2437.28 ms /   122 tokens (   19.98 ms per token,    50.06 tokens per second)\n",
      "llama_print_timings:        eval time =   762.14 ms /     6 runs   (  127.02 ms per token,     7.87 tokens per second)\n",
      "llama_print_timings:       total time =  3220.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.13 ms /     7 runs   (    0.59 ms per token,  1696.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.68 ms /     7 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   871.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "Error converting respose to json: {'response': 'A'}\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.09 ms /     7 runs   (    0.58 ms per token,  1712.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   848.71 ms /     7 runs   (  121.24 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   869.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   849.50 ms /     7 runs   (  121.36 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   870.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.72 ms /    27 runs   (    0.58 ms per token,  1717.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3385.66 ms /    27 runs   (  125.39 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time =  3467.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   945.05 ms /     7 runs   (  135.01 ms per token,     7.41 tokens per second)\n",
      "llama_print_timings:       total time =   965.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.95 ms /     7 runs   (    0.56 ms per token,  1772.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   856.17 ms /     7 runs   (  122.31 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1746.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.42 ms /     7 runs   (  120.77 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   865.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    93.11 ms /   152 runs   (    0.61 ms per token,  1632.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18683.51 ms /   152 runs   (  122.92 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 19169.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.62 ms /     7 runs   (    0.66 ms per token,  1514.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   859.49 ms /     7 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =   882.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.59 ms /     7 runs   (    0.66 ms per token,  1525.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.37 ms /     7 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   888.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 156: \n",
      "Language: english\n",
      "Question: \n",
      "Which of the following malignant epithelial tumors of the conjunctiva most commonly occurs in the limbal region?\n",
      "a) Melanoma.\n",
      "b) Kaposi's sarcoma.\n",
      "c) squamous cell carcinoma.\n",
      "d) Basal cell carcinoma.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.54 ms /    33 runs   (    0.65 ms per token,  1531.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1736.01 ms /    72 tokens (   24.11 ms per token,    41.47 tokens per second)\n",
      "llama_print_timings:        eval time =  3880.99 ms /    32 runs   (  121.28 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  5722.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.59 ms /    28 runs   (    0.66 ms per token,  1506.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3432.35 ms /    28 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3523.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.65 ms /    20 runs   (    0.58 ms per token,  1716.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2444.67 ms /    20 runs   (  122.23 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2504.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.53 ms /    36 runs   (    0.57 ms per token,  1753.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4373.44 ms /    36 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  4482.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n",
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.52 ms /    36 runs   (    0.57 ms per token,  1754.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4385.19 ms /    36 runs   (  121.81 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4493.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.70 ms /    24 runs   (    0.57 ms per token,  1752.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2906.79 ms /    24 runs   (  121.12 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  2979.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.32 ms /    37 runs   (    0.58 ms per token,  1735.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4466.20 ms /    37 runs   (  120.71 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  4577.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.54 ms /    27 runs   (    0.58 ms per token,  1737.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3301.81 ms /    27 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3383.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.90 ms /    24 runs   (    0.58 ms per token,  1726.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2934.85 ms /    24 runs   (  122.29 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3006.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.80 ms /    33 runs   (    0.57 ms per token,  1755.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4077.79 ms /    33 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4177.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Qual  o tumor epitelial maligno de conjuntiva, dentre os abaixo, que mais comumente ocorre na regio do limbo?\n",
      "a)Melanoma.\n",
      "b)Sarcoma de Kposi.\n",
      "c)Carcinoma espinocelular.\n",
      "d)Carcinoma de clulas basais.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.60 ms /    27 runs   (    0.58 ms per token,  1730.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2231.42 ms /    91 tokens (   24.52 ms per token,    40.78 tokens per second)\n",
      "llama_print_timings:        eval time =  3138.45 ms /    26 runs   (  120.71 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =  5450.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.21 ms /    11 runs   (    0.56 ms per token,  1770.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1343.16 ms /    11 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  1375.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a) Melanoma'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.70 ms /    17 runs   (    0.57 ms per token,  1752.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2068.77 ms /    17 runs   (  121.69 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  2120.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.24 ms /    11 runs   (    0.57 ms per token,  1763.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1331.37 ms /    11 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
      "llama_print_timings:       total time =  1364.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a) Melanoma'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.90 ms /    28 runs   (    0.57 ms per token,  1761.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3416.45 ms /    28 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  3501.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.94 ms /     7 runs   (    0.56 ms per token,  1777.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.48 ms /     7 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   881.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.21 ms /    11 runs   (    0.56 ms per token,  1772.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1334.98 ms /    11 runs   (  121.36 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  1368.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.20 ms /    11 runs   (    0.56 ms per token,  1773.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1341.78 ms /    11 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  1374.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.35 ms /    27 runs   (    0.57 ms per token,  1758.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3307.32 ms /    27 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =  3387.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #9: \n",
      "{'response': 'A'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 157: \n",
      "Language: english\n",
      "Question: \n",
      "Check the alternative that contains three factors associated with the development of cataracts.\n",
      "a) High myopia, prolonged use of vitamin C and alcohol consumption.\n",
      "b) Low-energy radiation, prolonged use of corticosteroids and exposure to blue light.\n",
      "c) Smoking, exposure to ultraviolet light and previous vitrectomy.\n",
      "d) Eye trauma, diabetes mellitus and high hyperopia.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.97 ms /     7 runs   (    0.57 ms per token,  1762.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   852.39 ms /     7 runs   (  121.77 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =   873.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    41.81 ms /    72 runs   (    0.58 ms per token,  1722.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1824.28 ms /   108 tokens (   16.89 ms per token,    59.20 tokens per second)\n",
      "llama_print_timings:        eval time =  8701.08 ms /    71 runs   (  122.55 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 10744.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.78 ms /    57 runs   (    0.58 ms per token,  1738.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6960.15 ms /    57 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  7132.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.40 ms /    56 runs   (    0.58 ms per token,  1728.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6843.82 ms /    56 runs   (  122.21 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  7012.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n",
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    32.71 ms /    57 runs   (    0.57 ms per token,  1742.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6940.15 ms /    57 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  7111.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.15 ms /    28 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3418.15 ms /    28 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3501.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    12.06 ms /    20 runs   (    0.60 ms per token,  1658.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2460.97 ms /    20 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2521.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.51 ms /    27 runs   (    0.57 ms per token,  1740.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3283.67 ms /    27 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3365.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.50 ms /    25 runs   (    0.58 ms per token,  1724.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3032.34 ms /    25 runs   (  121.29 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3109.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.85 ms /    17 runs   (    0.58 ms per token,  1726.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2092.04 ms /    17 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  2144.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que contm trs fatores associados ao desenvolvimento de catarata.\n",
      "a)Alta miopia, uso prolongado de vitamina C e consumo de lcool.\n",
      "b)Radiao de baixa energia, uso prolongado de corticoide e exposio  luz azul.\n",
      "c)Tabagismo, exposio  luz ultravioleta e vitrectomia prvia.\n",
      "d)Traumatismo ocular, diabetes melito e alta hipermetropia.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.15 ms /    46 runs   (    0.59 ms per token,  1694.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5695.46 ms /    46 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  5836.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.14 ms /    17 runs   (    0.60 ms per token,  1676.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2853.10 ms /   131 tokens (   21.78 ms per token,    45.91 tokens per second)\n",
      "llama_print_timings:        eval time =  1928.31 ms /    16 runs   (  120.52 ms per token,     8.30 tokens per second)\n",
      "llama_print_timings:       total time =  4832.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    86.27 ms /   150 runs   (    0.58 ms per token,  1738.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 18456.64 ms /   150 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 18916.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     9.73 ms /    17 runs   (    0.57 ms per token,  1747.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2155.68 ms /    17 runs   (  126.80 ms per token,     7.89 tokens per second)\n",
      "llama_print_timings:       total time =  2205.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.95 ms /    59 runs   (    0.58 ms per token,  1738.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7252.92 ms /    59 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  7430.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    35.37 ms /    61 runs   (    0.58 ms per token,  1724.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7493.98 ms /    61 runs   (  122.85 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  7676.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.40 ms /    51 runs   (    0.58 ms per token,  1734.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6275.15 ms /    51 runs   (  123.04 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6427.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.34 ms /    58 runs   (    0.57 ms per token,  1739.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7077.26 ms /    58 runs   (  122.02 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time =  7252.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    36.42 ms /    63 runs   (    0.58 ms per token,  1729.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7752.73 ms /    63 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  7943.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    33.35 ms /    58 runs   (    0.57 ms per token,  1739.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  7152.93 ms /    58 runs   (  123.33 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  7329.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    11.54 ms /    20 runs   (    0.58 ms per token,  1732.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2476.22 ms /    20 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  2537.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 158: \n",
      "Language: english\n",
      "Question: \n",
      "About congenital and infantile cataracts, judge the statements below as true (T) or false (F) and mark the correct alternative.\n",
      "\n",
      " I - When the opacity is bilateral and severe, the interval between surgery on the first and second eye should be minimal and generally does not exceed one week.\n",
      " II - In the case of total opacities, surgery should be performed as early as possible, preferably between three and four months of age.\n",
      " III - Congenital cataract is the most common cause of alteration of the red reflex test in maternity hospitals.\n",
      " IV - The normal red reflex at birth is sufficient for the early detection of congenital anomalies in the follow-up up to two years of age.\n",
      "a) I: True; II: False; III: True; IV: False.\n",
      "b) I: False; II: True; III: False; IV: True.\n",
      "c) I: False; II: False; III: True; IV: False.\n",
      "d) I: True; II: True; III: True; IV: True.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    68.04 ms /   119 runs   (    0.57 ms per token,  1749.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4074.65 ms /   248 tokens (   16.43 ms per token,    60.86 tokens per second)\n",
      "llama_print_timings:        eval time = 14551.36 ms /   118 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 18998.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n",
      "{'response': 'd'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.02 ms /   119 runs   (    0.56 ms per token,  1775.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14739.37 ms /   119 runs   (  123.86 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 15108.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.79 ms /   119 runs   (    0.57 ms per token,  1755.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14819.36 ms /   119 runs   (  124.53 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time = 15187.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.94 ms /   119 runs   (    0.56 ms per token,  1777.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14769.17 ms /   119 runs   (  124.11 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 15136.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.81 ms /   119 runs   (    0.56 ms per token,  1781.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14833.67 ms /   119 runs   (  124.65 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time = 15197.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    67.25 ms /   119 runs   (    0.57 ms per token,  1769.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14699.02 ms /   119 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 15062.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Test #6: \n",
      "{'response': 'd'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.79 ms /   119 runs   (    0.56 ms per token,  1781.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14635.88 ms /   119 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 14999.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.64 ms /   119 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14741.00 ms /   119 runs   (  123.87 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 15103.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd) I: True; II: True; III: True; IV: True.'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.37 ms /   119 runs   (    0.56 ms per token,  1793.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14755.04 ms /   119 runs   (  123.99 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 15117.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.95 ms /   119 runs   (    0.56 ms per token,  1777.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14798.66 ms /   119 runs   (  124.36 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 15162.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'd'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre as cataratas congnitas e infantis, julgue as assertivas abaixo como verdadeiras (V) ou falsas (F) e assinale a alternativa correta.\n",
      "\n",
      " I - Quando a opacidade  bilateral e grave, o intervalo entre a cirurgia do primeiro e do segundo olho deve ser apenas o mnimo e geralmente no ultrapassa uma semana.\n",
      " II - No caso de opacidades totais deve-se realizar a cirurgia o mais precocemente possvel, de preferncia entre os trs e os quatro meses de idade.\n",
      " III - A catarata congnita  a causa mais comum de alterao do teste do reflexo vermelho em maternidades.\n",
      " IV - O reflexo vermelho normal ao nascimento  suficiente para a deteco precoce das anomalias congnitas no acompanhamento at os dois anos de idade.\n",
      "a)I: Verdadeiro; II: Falso; III: Verdadeiro; IV: Falso.\n",
      "b)I: Falso; II: Verdadeiro; III: Falso; IV: Verdadeiro.\n",
      "c)I: Falso; II: Falso; III: Verdadeiro; IV: Falso.\n",
      "d)I: Verdadeiro; lI: Verdadeiro; III: Verdadeiro; IV: Verdadeiro.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.79 ms /    37 runs   (    0.56 ms per token,  1779.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4801.85 ms /   330 tokens (   14.55 ms per token,    68.72 tokens per second)\n",
      "llama_print_timings:        eval time =  4510.49 ms /    36 runs   (  125.29 ms per token,     7.98 tokens per second)\n",
      "llama_print_timings:       total time =  9424.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.46 ms /    37 runs   (    0.55 ms per token,  1808.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4560.11 ms /    37 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  4673.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.41 ms /    37 runs   (    0.55 ms per token,  1812.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4594.81 ms /    37 runs   (  124.18 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  4706.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'd be happy to help! Here's the answer in JSON format:\n",
      "\n",
      "{\"response\": \"c\")I: Falso; II: Falso;\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.54 ms /    37 runs   (    0.56 ms per token,  1801.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4586.33 ms /    37 runs   (  123.95 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  4700.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.15 ms /    37 runs   (    0.54 ms per token,  1836.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4657.68 ms /    37 runs   (  125.88 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  4769.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.33 ms /    37 runs   (    0.55 ms per token,  1820.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4593.64 ms /    37 runs   (  124.15 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  4706.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.13 ms /    37 runs   (    0.57 ms per token,  1750.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4682.90 ms /    37 runs   (  126.56 ms per token,     7.90 tokens per second)\n",
      "llama_print_timings:       total time =  4799.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to assist you! Here's my answer in JSON format:\n",
      "\n",
      "{\"response\": \"c\") I: Falso; II: Falso;\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.37 ms /    37 runs   (    0.55 ms per token,  1816.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4552.85 ms /    37 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  4665.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  Sure, I'm ready to help! Here's my answer in JSON format:\n",
      "\n",
      "{\"response\": \"c\")I: Falso; II: Falso; III\n",
      "Generating new response...\n",
      "Error converting respose to json:  Sure, I'm ready to help! Here's my answer in JSON format:\n",
      "\n",
      "{\"response\": \"c\") I: Falso; II: Falso; III\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.33 ms /    37 runs   (    0.55 ms per token,  1819.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4596.57 ms /    37 runs   (  124.23 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time =  4708.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.32 ms /    37 runs   (    0.55 ms per token,  1820.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4572.64 ms /    37 runs   (  123.58 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4682.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.50 ms /    37 runs   (    0.55 ms per token,  1805.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4571.40 ms /    37 runs   (  123.55 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4683.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.27 ms /    37 runs   (    0.55 ms per token,  1825.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4570.13 ms /    37 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  4681.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    20.28 ms /    37 runs   (    0.55 ms per token,  1824.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4556.67 ms /    37 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4671.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.73 ms /    27 runs   (    0.55 ms per token,  1833.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3390.38 ms /    27 runs   (  125.57 ms per token,     7.96 tokens per second)\n",
      "llama_print_timings:       total time =  3471.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 159: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding congenital anomalies and failures in the development of the lens, mark the correct alternative.\n",
      "a) The intermittent pupillary block observed in microspherophacy happens due to the touch of the iris in the medium periphery of the crystalline lens due to the increased side-to-side diameter.\n",
      "b) Lens subluxation in Marfan syndrome is most commonly superior and temporal and may induce amblyopia caused by refractive asymmetry.\n",
      "c) In galactosemia, a central shadow resembling an \"oil drop\" can be observed in the red reflex test, which does not occur in other diseases.\n",
      "d) In homocystinuria, lens displacement is usually bilateral, symmetrical and present at birth.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   105.99 ms /   182 runs   (    0.58 ms per token,  1717.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3743.77 ms /   185 tokens (   20.24 ms per token,    49.42 tokens per second)\n",
      "llama_print_timings:        eval time = 22302.50 ms /   181 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 26621.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.64 ms /   182 runs   (    0.59 ms per token,  1706.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22626.33 ms /   182 runs   (  124.32 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time = 23201.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   105.33 ms /   182 runs   (    0.58 ms per token,  1727.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22487.79 ms /   182 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 23060.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.44 ms /    98 runs   (    0.58 ms per token,  1736.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12025.77 ms /    98 runs   (  122.71 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 12323.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.55 ms /    24 runs   (    0.61 ms per token,  1649.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2970.45 ms /    24 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  3043.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n",
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.51 ms /   182 runs   (    0.59 ms per token,  1708.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22613.23 ms /   182 runs   (  124.25 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 23186.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   106.59 ms /   182 runs   (    0.59 ms per token,  1707.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22403.14 ms /   182 runs   (  123.09 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 22975.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   108.11 ms /   182 runs   (    0.59 ms per token,  1683.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 22541.47 ms /   182 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 23118.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    39.48 ms /    66 runs   (    0.60 ms per token,  1671.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8173.17 ms /    66 runs   (  123.84 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  8375.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    37.88 ms /    66 runs   (    0.57 ms per token,  1742.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8059.18 ms /    66 runs   (  122.11 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  8257.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre as anomalias congnitas e falhas do desenvolvimento do cristalino, assinale a alternativa correta.\n",
      "a)O bloqueio pupilar intermitente observado na microesferofacia acontece devido ao toque da ris na mdia periferia do cristalino em razo do dimetro ltero-lateral aumentado.\n",
      "b)A subluxao do cristalino na sndrome de Marfan  mais comumente superior e temporal e pode induzir ambliopia causada pela assimetria refracional.\n",
      "c)Na galactosemia pode-se observar no teste do reflexo vermelho uma sombra central  semelhana de \"gota de leo\", o que no ocorre em outras doenas.\n",
      "d)Na homocistinria, o deslocamento do cristalino  geralmente bilateral, simtrico e presente ao nascimento.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.38 ms /     7 runs   (    0.63 ms per token,  1597.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4011.51 ms /   227 tokens (   17.67 ms per token,    56.59 tokens per second)\n",
      "llama_print_timings:        eval time =   751.15 ms /     6 runs   (  125.19 ms per token,     7.99 tokens per second)\n",
      "llama_print_timings:       total time =  4783.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.20 ms /     7 runs   (    0.60 ms per token,  1665.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.09 ms /     7 runs   (  121.44 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =   870.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'C'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1686.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   850.01 ms /     7 runs   (  121.43 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =   871.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.42 ms /    87 runs   (    0.58 ms per token,  1725.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10716.56 ms /    87 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 10980.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.01 ms /     7 runs   (    0.57 ms per token,  1745.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.57 ms /     7 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1740.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.14 ms /     7 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   884.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.82 ms /    71 runs   (    0.57 ms per token,  1739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8747.01 ms /    71 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8960.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.75 ms /   140 runs   (    0.58 ms per token,  1733.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17277.25 ms /   140 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 17707.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.48 ms /   126 runs   (    0.63 ms per token,  1585.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15490.30 ms /   126 runs   (  122.94 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 15898.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   863.02 ms /     7 runs   (  123.29 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =   883.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 160: \n",
      "Language: english\n",
      "Question: \n",
      "After retrobulbar block for phacoemulsification surgery, the patient evolved with progressive loss of consciousness, seizures and respiratory arrest five minutes after anesthetic injection. Check the alternative that correctly describes the most likely complication in this case and a possible preventive measure.\n",
      "a) Intraocular injection - observe the joint movement of the eyeball and the needle before injecting.\n",
      "b) Intravascular injection - suspend anticoagulants or antiplatelet agents before surgery.\n",
      "c) Injection into the subarachnoid space - insert the needle less than 30 mm in depth.\n",
      "d) Retrobulbar hemorrhage - aspirate and check for the presence of hematic content before injecting.\n",
      "Test #0: \n",
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.27 ms /     7 runs   (    0.61 ms per token,  1638.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3466.36 ms /   177 tokens (   19.58 ms per token,    51.06 tokens per second)\n",
      "llama_print_timings:        eval time =   734.09 ms /     6 runs   (  122.35 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  4221.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    52.85 ms /    91 runs   (    0.58 ms per token,  1721.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11206.52 ms /    91 runs   (  123.15 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 11480.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    62.18 ms /   108 runs   (    0.58 ms per token,  1737.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13283.52 ms /   108 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 13614.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.00 ms /   124 runs   (    0.58 ms per token,  1722.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15378.13 ms /   124 runs   (  124.02 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 15766.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    72.45 ms /   126 runs   (    0.57 ms per token,  1739.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15614.50 ms /   126 runs   (  123.92 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 16004.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    78.54 ms /   136 runs   (    0.58 ms per token,  1731.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16799.17 ms /   136 runs   (  123.52 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 17219.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.65 ms /     8 runs   (    0.58 ms per token,  1722.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   999.26 ms /     8 runs   (  124.91 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =  1022.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    74.42 ms /   129 runs   (    0.58 ms per token,  1733.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15923.79 ms /   129 runs   (  123.44 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 16321.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.92 ms /    88 runs   (    0.58 ms per token,  1728.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10750.55 ms /    88 runs   (  122.17 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time = 11024.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    76.86 ms /   132 runs   (    0.58 ms per token,  1717.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16276.29 ms /   132 runs   (  123.31 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 16689.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Aps bloqueio retrobulbar para realizao de cirurgia de facoemulsificao, o paciente evolui com perda progressiva de conscincia, convulses e parada respiratria aps cinco minutos da injeo do anestsico. Assinale a alternativa que descreve corretamente a complicao mais provvel neste caso e uma possvel medida preventiva.\n",
      "a)Injeo intraocular - observar a movimentao conjunta do globo ocular e da agulha antes de injetar.\n",
      "b)Injeo intravascular - suspender anticoagulantes ou antiagregantes plaquetrios antes da cirurgia.\n",
      "c)Injeo no espao subaracnoide - inserir a agulha menos do que 30 mm em profundidade.\n",
      "d)Hemorragia retrobulbar - aspirar e verificar a presena de contedo hemtico antes de injetar.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    80.07 ms /   137 runs   (    0.58 ms per token,  1711.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3799.05 ms /   230 tokens (   16.52 ms per token,    60.54 tokens per second)\n",
      "llama_print_timings:        eval time = 16775.20 ms /   136 runs   (  123.35 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 20999.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.19 ms /   137 runs   (    0.58 ms per token,  1729.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16942.50 ms /   137 runs   (  123.67 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 17365.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.80 ms /   137 runs   (    0.58 ms per token,  1716.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16956.83 ms /   137 runs   (  123.77 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 17380.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.45 ms /   113 runs   (    0.58 ms per token,  1726.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 14091.29 ms /   113 runs   (  124.70 ms per token,     8.02 tokens per second)\n",
      "llama_print_timings:       total time = 14436.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error converting respose to json:  ####\n",
      "\n",
      "Response: A\n",
      "\n",
      "The correct answer is A, Injeo intraocular - observar a movimentao conjunta do globo ocular e da agulha antes de injetar.\n",
      "\n",
      "Explanation: The complication of inadvertent intravascular injection of local anesthetic is a possible consequence of retrobulbar block. To prevent this complication, it is essential to observe the movement of the globe and the needle before injecting the local anesthetic.\n",
      "Generating new response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.34 ms /   137 runs   (    0.58 ms per token,  1726.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17016.52 ms /   137 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 17441.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.81 ms /   137 runs   (    0.58 ms per token,  1716.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16828.07 ms /   137 runs   (  122.83 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 17256.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.16 ms /   137 runs   (    0.58 ms per token,  1730.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16892.36 ms /   137 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 17317.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n",
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.26 ms /   137 runs   (    0.58 ms per token,  1728.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16853.94 ms /   137 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 17276.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    78.97 ms /   137 runs   (    0.58 ms per token,  1734.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16880.95 ms /   137 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 17306.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n",
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.10 ms /   137 runs   (    0.58 ms per token,  1731.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16885.44 ms /   137 runs   (  123.25 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 17311.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    59.67 ms /   103 runs   (    0.58 ms per token,  1726.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12774.29 ms /   103 runs   (  124.02 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 13091.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 161: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding biometrics in eyes covered with silicone oil, it is correct to state:\n",
      "a) The axial length measured by ultrasound is falsely reduced in relation to the real value.\n",
      "b)Low coherence reflectometry cannot be used in this situation.\n",
      "c) The anterior chamber depth measurement must be performed in the supine position.\n",
      "d) Partial coherence interferometry is preferable to ultrasonography in these cases.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.90 ms /    25 runs   (    0.60 ms per token,  1678.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2014.88 ms /   106 tokens (   19.01 ms per token,    52.61 tokens per second)\n",
      "llama_print_timings:        eval time =  2964.78 ms /    24 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  5056.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    43.29 ms /    75 runs   (    0.58 ms per token,  1732.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9240.58 ms /    75 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9467.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n",
      "{'response': 'A'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.34 ms /    25 runs   (    0.57 ms per token,  1743.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3057.57 ms /    25 runs   (  122.30 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  3131.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.85 ms /    24 runs   (    0.58 ms per token,  1732.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2912.78 ms /    24 runs   (  121.37 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  2983.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.41 ms /    25 runs   (    0.58 ms per token,  1734.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3052.04 ms /    25 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3126.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.02 ms /    47 runs   (    0.57 ms per token,  1739.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5717.57 ms /    47 runs   (  121.65 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  5858.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #6: \n",
      "{'response': 'a'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.45 ms /    25 runs   (    0.58 ms per token,  1730.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3038.58 ms /    25 runs   (  121.54 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3112.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.51 ms /    25 runs   (    0.58 ms per token,  1723.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3072.32 ms /    25 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  3147.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.29 ms /    25 runs   (    0.57 ms per token,  1750.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3040.48 ms /    25 runs   (  121.62 ms per token,     8.22 tokens per second)\n",
      "llama_print_timings:       total time =  3116.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.42 ms /    25 runs   (    0.58 ms per token,  1734.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3029.43 ms /    25 runs   (  121.18 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =  3104.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a biometria em olhos tamponados por leo de silicone  correto afirmar:\n",
      "a)O comprimento axial medido pelo ultrassom  falsamente reduzido em relao ao valor real.\n",
      "b)A reflectometria de baixa coerncia no pode ser utilizada nessa situao.\n",
      "c)A medida da profundidade de cmara anterior deve ser realizada em posio supina.\n",
      "d)A interferometria de coerncia parcial  prefervel  ultrassonografia nesses casos.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    66.88 ms /   115 runs   (    0.58 ms per token,  1719.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2483.94 ms /   138 tokens (   18.00 ms per token,    55.56 tokens per second)\n",
      "llama_print_timings:        eval time = 14022.39 ms /   114 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 16866.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    29.34 ms /    51 runs   (    0.58 ms per token,  1738.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6275.84 ms /    51 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6430.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    65.85 ms /   114 runs   (    0.58 ms per token,  1731.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13988.00 ms /   114 runs   (  122.70 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 14341.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    79.84 ms /   137 runs   (    0.58 ms per token,  1716.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16840.77 ms /   137 runs   (  122.93 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 17273.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     5.18 ms /     9 runs   (    0.58 ms per token,  1736.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1088.67 ms /     9 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =  1115.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    63.56 ms /   110 runs   (    0.58 ms per token,  1730.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 13576.97 ms /   110 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 13915.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    27.59 ms /    48 runs   (    0.57 ms per token,  1739.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  5944.52 ms /    48 runs   (  123.84 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time =  6091.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'a'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     3.99 ms /     7 runs   (    0.57 ms per token,  1755.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   855.28 ms /     7 runs   (  122.18 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =   876.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1738.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   845.32 ms /     7 runs   (  120.76 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =   867.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    31.30 ms /    54 runs   (    0.58 ms per token,  1725.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  6645.76 ms /    54 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  6815.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'a'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 162: \n",
      "Language: english\n",
      "Question: \n",
      "Check the alternative that contains, respectively, a drug associated with the occurrence of flaccid iris syndrome in the perioperative period and an adequate intervention to restore mydriasis in these cases.\n",
      "a) Chlorpromazine - iris retractors.\n",
      "b) Doxasozine - Beehler dilator.\n",
      "c) Tamsulosin - sphincterectomies.\n",
      "d) Atropine - iris expander ring.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    24 runs   (    0.60 ms per token,  1669.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2504.60 ms /   109 tokens (   22.98 ms per token,    43.52 tokens per second)\n",
      "llama_print_timings:        eval time =  2803.10 ms /    23 runs   (  121.87 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  5380.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.47 ms /    28 runs   (    0.59 ms per token,  1699.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3396.99 ms /    28 runs   (  121.32 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3481.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    97.41 ms /   164 runs   (    0.59 ms per token,  1683.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 20258.28 ms /   164 runs   (  123.53 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 20775.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    15.58 ms /    27 runs   (    0.58 ms per token,  1732.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3296.28 ms /    27 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =  3376.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.30 ms /    28 runs   (    0.58 ms per token,  1717.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3436.14 ms /    28 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =  3519.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.22 ms /    28 runs   (    0.58 ms per token,  1725.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3402.95 ms /    28 runs   (  121.53 ms per token,     8.23 tokens per second)\n",
      "llama_print_timings:       total time =  3486.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.42 ms /    27 runs   (    0.61 ms per token,  1643.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3332.61 ms /    27 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =  3415.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    26.03 ms /    38 runs   (    0.69 ms per token,  1459.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4630.64 ms /    38 runs   (  121.86 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  4753.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.80 ms /    29 runs   (    0.58 ms per token,  1726.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3520.30 ms /    29 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_print_timings:       total time =  3607.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n",
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Assinale a alternativa que contm, respectivamente, um medicamento associado  ocorrncia da sndrome da ris flcida no peroperatrio e uma interveno adequada para restabelecimento da midrase nesses casos.\n",
      "a)Clorpromazina - retratores de ris.\n",
      "b)Doxasozina - dilatador de Beehler.\n",
      "c)Tamsulosina - esfincterectomias.\n",
      "d)Atropina - anel expansor de ris.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.57 ms /    93 runs   (    0.58 ms per token,  1736.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11338.03 ms /    93 runs   (  121.91 ms per token,     8.20 tokens per second)\n",
      "llama_print_timings:       total time = 11624.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.24 ms /     7 runs   (    0.61 ms per token,  1651.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2060.45 ms /   128 tokens (   16.10 ms per token,    62.12 tokens per second)\n",
      "llama_print_timings:        eval time =   730.90 ms /     6 runs   (  121.82 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  2812.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.87 ms /    81 runs   (    0.62 ms per token,  1624.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9995.27 ms /    81 runs   (  123.40 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 10343.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    18.46 ms /    27 runs   (    0.68 ms per token,  1462.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3287.52 ms /    27 runs   (  121.76 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3476.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.90 ms /    80 runs   (    0.67 ms per token,  1484.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9817.52 ms /    80 runs   (  122.72 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time = 10380.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    61.13 ms /    90 runs   (    0.68 ms per token,  1472.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11018.75 ms /    90 runs   (  122.43 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 11655.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.62 ms /     7 runs   (    0.66 ms per token,  1516.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   866.06 ms /     7 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =   915.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.77 ms /     7 runs   (    0.68 ms per token,  1466.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   861.02 ms /     7 runs   (  123.00 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   910.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    56.53 ms /    83 runs   (    0.68 ms per token,  1468.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10173.68 ms /    83 runs   (  122.57 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 10756.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    81.91 ms /   123 runs   (    0.67 ms per token,  1501.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 15122.52 ms /   123 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time = 15998.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    58.28 ms /    96 runs   (    0.61 ms per token,  1647.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11924.30 ms /    96 runs   (  124.21 ms per token,     8.05 tokens per second)\n",
      "llama_print_timings:       total time = 12322.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 163: \n",
      "Language: english\n",
      "Question: \n",
      "Regarding the prevention of endophthalmitis in cataract surgery, mark the correct alternative.\n",
      "a) In cases of contraindication to povidone-iodine, topical antibiotic eye drops should be used for five days before the procedure.\n",
      "b) The main risk factors include immunosuppression, diabetes, blepharitis, conjunctivitis, rupture of the posterior capsule and vitreous loss.\n",
      "c) The intracameral use of gentamicin should be adopted, especially in cases associated with previous vitrectomy.\n",
      "d) The most frequent etiological agents are bacteria from inadequate sterilization of surgical materials and intraocular lenses. \n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    10.15 ms /    17 runs   (    0.60 ms per token,  1674.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3413.91 ms /   169 tokens (   20.20 ms per token,    49.50 tokens per second)\n",
      "llama_print_timings:        eval time =  1973.12 ms /    16 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =  5437.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    16.26 ms /    28 runs   (    0.58 ms per token,  1722.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3411.60 ms /    28 runs   (  121.84 ms per token,     8.21 tokens per second)\n",
      "llama_print_timings:       total time =  3495.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.37 ms /    25 runs   (    0.57 ms per token,  1739.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3114.79 ms /    25 runs   (  124.59 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =  3190.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    40.34 ms /    70 runs   (    0.58 ms per token,  1735.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  8621.69 ms /    70 runs   (  123.17 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  8835.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.33 ms /    25 runs   (    0.57 ms per token,  1744.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3059.27 ms /    25 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3134.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    51.40 ms /    89 runs   (    0.58 ms per token,  1731.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11025.91 ms /    89 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 11298.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'A'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    14.20 ms /    25 runs   (    0.57 ms per token,  1761.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  3060.46 ms /    25 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3136.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    13.91 ms /    24 runs   (    0.58 ms per token,  1725.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2950.85 ms /    24 runs   (  122.95 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3023.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    53.07 ms /    92 runs   (    0.58 ms per token,  1733.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11355.77 ms /    92 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 11636.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    54.50 ms /    95 runs   (    0.57 ms per token,  1743.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11638.61 ms /    95 runs   (  122.51 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time = 11925.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Sobre a preveno de endoftalmite em cirurgia de catarata, assinale a alternativa correta.\n",
      "a)Em casos de contraindicao  iodopovidona, deve-se utilizar colrio de antibitico tpico por cinco dias antes do procedimento.\n",
      "b)Os principais fatores de risco incluem imunossupresso, diabetes, blefarite, conjuntivite, rotura da cpsula posterior e perda vtrea.\n",
      "c)O uso intracameral de gentamicina deve ser adotado, principalmente nos casos associados a vitrectomia anterior.\n",
      "d)Os agentes etiolgicos mais frequentes so bactrias provenientes da esterilizao inadequada dos materiais cirrgicos e lentes intraoculares.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    48.82 ms /    84 runs   (    0.58 ms per token,  1720.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3664.46 ms /   204 tokens (   17.96 ms per token,    55.67 tokens per second)\n",
      "llama_print_timings:        eval time = 10237.52 ms /    83 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 14158.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    49.13 ms /    85 runs   (    0.58 ms per token,  1730.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10543.71 ms /    85 runs   (  124.04 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time = 10805.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     6.33 ms /    11 runs   (    0.58 ms per token,  1737.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  1360.21 ms /    11 runs   (  123.66 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  1392.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    45.99 ms /    78 runs   (    0.59 ms per token,  1696.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9657.70 ms /    78 runs   (  123.82 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  9942.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.76 ms /    82 runs   (    0.62 ms per token,  1615.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10155.01 ms /    82 runs   (  123.84 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 10582.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   870.59 ms /     7 runs   (  124.37 ms per token,     8.04 tokens per second)\n",
      "llama_print_timings:       total time =   891.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.06 ms /     7 runs   (    0.58 ms per token,  1722.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.08 ms /     7 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =   879.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'B'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.40 ms /    77 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9487.11 ms /    77 runs   (  123.21 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  9720.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    47.86 ms /    83 runs   (    0.58 ms per token,  1734.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10412.88 ms /    83 runs   (  125.46 ms per token,     7.97 tokens per second)\n",
      "llama_print_timings:       total time = 10666.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    44.49 ms /    77 runs   (    0.58 ms per token,  1730.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9526.66 ms /    77 runs   (  123.72 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time =  9760.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "**************************************************\n",
      "**************************************************\n",
      "Question 164: \n",
      "Language: english\n",
      "Question: \n",
      "After performing the core fractures with the divide-and-conquer technique, a whitish portion and contraction of the tissue can be seen on the lateral portion of the corneal incision, with leakage of the irrigation solution through the gap formed. Among the alternatives below, which would be effective in preventing the occurrence of the described complication?\n",
      "a) Reduce the aspiration flow rate and make the incision narrower.\n",
      "b)Use larger diameter tips and smaller diameter coaxial irrigation sleeves.\n",
      "c) Keep the tip equidistant from the incision walls and use pulsed ultrasound.\n",
      "d) Fill the anterior chamber with cohesive viscoelastic and use continuous ultrasound.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.10 ms /   133 runs   (    0.58 ms per token,  1725.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2878.79 ms /   170 tokens (   16.93 ms per token,    59.05 tokens per second)\n",
      "llama_print_timings:        eval time = 16223.98 ms /   132 runs   (  122.91 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 19514.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    57.06 ms /    98 runs   (    0.58 ms per token,  1717.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 12150.53 ms /    98 runs   (  123.98 ms per token,     8.07 tokens per second)\n",
      "llama_print_timings:       total time = 12449.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n",
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    50.21 ms /    87 runs   (    0.58 ms per token,  1732.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 10762.34 ms /    87 runs   (  123.71 ms per token,     8.08 tokens per second)\n",
      "llama_print_timings:       total time = 11032.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   114.28 ms /   197 runs   (    0.58 ms per token,  1723.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24206.04 ms /   197 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time = 24828.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =   113.89 ms /   197 runs   (    0.58 ms per token,  1729.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 24351.63 ms /   197 runs   (  123.61 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 24967.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n",
      "{'response': 'b'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.04 ms /     7 runs   (    0.58 ms per token,  1731.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   873.37 ms /     7 runs   (  124.77 ms per token,     8.01 tokens per second)\n",
      "llama_print_timings:       total time =   894.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    55.76 ms /    97 runs   (    0.57 ms per token,  1739.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 11879.04 ms /    97 runs   (  122.46 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time = 12174.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    91.10 ms /   158 runs   (    0.58 ms per token,  1734.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19518.42 ms /   158 runs   (  123.53 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time = 20014.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    82.18 ms /   143 runs   (    0.57 ms per token,  1740.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 17606.51 ms /   143 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time = 18047.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'b'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    94.91 ms /   157 runs   (    0.60 ms per token,  1654.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 19374.69 ms /   157 runs   (  123.41 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time = 19866.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Language: portuguese\n",
      "Question: \n",
      "Aps realizar as fraturas do ncleo com a tcnica de dividir e conquistar, nota-se uma poro esbranquiada e contrao do tecido na poro lateral da inciso da crnea, com vazamento da soluo de irrigao pelo vo formado. Entre as alternativas abaixo, qual seria eficaz em prevenir a ocorrncia da complicao descrita?\n",
      "a)Reduzir a taxa de fluxo de aspirao e fazer inciso mais estreita.\n",
      "b)Usar ponteiras de maior dimetro e luvas de irrigao coaxial de menor dimetro.\n",
      "c)Manter a ponteira equidistante das paredes da inciso e utilizar ultrassom pulsado.\n",
      "d)Preencher a cmara anterior com viscoelstico coesivo e utilizar ultrassom contnuo.\n",
      "Test #0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.15 ms /     7 runs   (    0.59 ms per token,  1686.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4068.95 ms /   232 tokens (   17.54 ms per token,    57.02 tokens per second)\n",
      "llama_print_timings:        eval time =   721.26 ms /     6 runs   (  120.21 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =  4811.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     7 runs   (    0.57 ms per token,  1751.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   871.50 ms /     7 runs   (  124.50 ms per token,     8.03 tokens per second)\n",
      "llama_print_timings:       total time =   891.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.02 ms /     7 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   846.72 ms /     7 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =   867.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.05 ms /    40 runs   (    0.58 ms per token,  1735.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4913.71 ms /    40 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =  5032.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.24 ms /    37 runs   (    0.57 ms per token,  1741.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4557.60 ms /    37 runs   (  123.18 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =  4666.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.03 ms /     7 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   862.15 ms /     7 runs   (  123.16 ms per token,     8.12 tokens per second)\n",
      "llama_print_timings:       total time =   882.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    77.84 ms /   135 runs   (    0.58 ms per token,  1734.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time = 16648.36 ms /   135 runs   (  123.32 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time = 17062.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #7: \n",
      "{'response': 'c'}\n",
      "Test #8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    23.96 ms /    37 runs   (    0.65 ms per token,  1543.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4573.78 ms /    37 runs   (  123.62 ms per token,     8.09 tokens per second)\n",
      "llama_print_timings:       total time =  4694.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "Test #9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =     4.05 ms /     7 runs   (    0.58 ms per token,  1728.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   858.43 ms /     7 runs   (  122.63 ms per token,     8.15 tokens per second)\n",
      "llama_print_timings:       total time =   879.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'c'}\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3616.58 ms\n",
      "llama_print_timings:      sample time =    21.96 ms /    37 runs   (    0.59 ms per token,  1684.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  4658.40 ms /    37 runs   (  125.90 ms per token,     7.94 tokens per second)\n",
      "llama_print_timings:       total time =  4774.73 ms\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation:\n",
    "llm_language_evaluation(path=PATH, model=MODEL, temperature=TEMPERATURE, n_repetitions=N_REPETITIONS, reasoning=REASONING, languages=LANGUAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc602206",
   "metadata": {},
   "source": [
    "#### See the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c7d08b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>test</th>\n",
       "      <th>theme</th>\n",
       "      <th>subtheme</th>\n",
       "      <th>portuguese</th>\n",
       "      <th>english</th>\n",
       "      <th>answer</th>\n",
       "      <th>responses_english_0</th>\n",
       "      <th>responses_english_1</th>\n",
       "      <th>...</th>\n",
       "      <th>responses_portuguese_0</th>\n",
       "      <th>responses_portuguese_1</th>\n",
       "      <th>responses_portuguese_2</th>\n",
       "      <th>responses_portuguese_3</th>\n",
       "      <th>responses_portuguese_4</th>\n",
       "      <th>responses_portuguese_5</th>\n",
       "      <th>responses_portuguese_6</th>\n",
       "      <th>responses_portuguese_7</th>\n",
       "      <th>responses_portuguese_8</th>\n",
       "      <th>responses_portuguese_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>Terica I</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>cornea</td>\n",
       "      <td>Em qual regio ocular clulas caliciformes so...</td>\n",
       "      <td>In which ocular region are caliciform cells ph...</td>\n",
       "      <td>D</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>Terica I</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>retina</td>\n",
       "      <td>Assinale a alternativa que melhor correlaciona...</td>\n",
       "      <td>Mark the alternative that best correlates the ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>Terica I</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>cornea</td>\n",
       "      <td>Ordene as trs denominaes celulares encontra...</td>\n",
       "      <td>Order the three cell names found in the cornea...</td>\n",
       "      <td>A</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>Terica I</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>cornea</td>\n",
       "      <td>Sobre a membrana de Descemet da crnea,  corr...</td>\n",
       "      <td>Regarding Descemet's membrane of the cornea, i...</td>\n",
       "      <td>C</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>Terica I</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>cornea</td>\n",
       "      <td>Sobre a camada lipdica do filme lacrimal, ass...</td>\n",
       "      <td>About the lipidic layer of the lacrimal film, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>C</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>161</td>\n",
       "      <td>2022</td>\n",
       "      <td>Terica II</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aps bloqueio retrobulbar para realizao de c...</td>\n",
       "      <td>After retrobulbar block for phacoemulsificatio...</td>\n",
       "      <td>C</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>162</td>\n",
       "      <td>2022</td>\n",
       "      <td>Terica II</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sobre a biometria em olhos tamponados por leo...</td>\n",
       "      <td>Regarding biometrics in eyes covered with sili...</td>\n",
       "      <td>D</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>163</td>\n",
       "      <td>2022</td>\n",
       "      <td>Terica II</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assinale a alternativa que contm, respectivam...</td>\n",
       "      <td>Check the alternative that contains, respectiv...</td>\n",
       "      <td>A</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>164</td>\n",
       "      <td>2022</td>\n",
       "      <td>Terica II</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sobre a preveno de endoftalmite em cirurgia ...</td>\n",
       "      <td>Regarding the prevention of endophthalmitis in...</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>165</td>\n",
       "      <td>2022</td>\n",
       "      <td>Terica II</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aps realizar as fraturas do ncleo com a tcn...</td>\n",
       "      <td>After performing the core fractures with the d...</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  year        test                theme subtheme  \\\n",
       "0      1  2022   Terica I             Anatomia   cornea   \n",
       "1      2  2022   Terica I             Anatomia   retina   \n",
       "2      3  2022   Terica I             Anatomia   cornea   \n",
       "3      4  2022   Terica I             Anatomia   cornea   \n",
       "4      5  2022   Terica I             Anatomia   cornea   \n",
       "..   ...   ...         ...                  ...      ...   \n",
       "159  161  2022  Terica II  Cristalino/Catarata      NaN   \n",
       "160  162  2022  Terica II  Cristalino/Catarata      NaN   \n",
       "161  163  2022  Terica II  Cristalino/Catarata      NaN   \n",
       "162  164  2022  Terica II  Cristalino/Catarata      NaN   \n",
       "163  165  2022  Terica II  Cristalino/Catarata      NaN   \n",
       "\n",
       "                                            portuguese  \\\n",
       "0    Em qual regio ocular clulas caliciformes so...   \n",
       "1    Assinale a alternativa que melhor correlaciona...   \n",
       "2    Ordene as trs denominaes celulares encontra...   \n",
       "3    Sobre a membrana de Descemet da crnea,  corr...   \n",
       "4    Sobre a camada lipdica do filme lacrimal, ass...   \n",
       "..                                                 ...   \n",
       "159  Aps bloqueio retrobulbar para realizao de c...   \n",
       "160  Sobre a biometria em olhos tamponados por leo...   \n",
       "161  Assinale a alternativa que contm, respectivam...   \n",
       "162  Sobre a preveno de endoftalmite em cirurgia ...   \n",
       "163  Aps realizar as fraturas do ncleo com a tcn...   \n",
       "\n",
       "                                               english answer  \\\n",
       "0    In which ocular region are caliciform cells ph...      D   \n",
       "1    Mark the alternative that best correlates the ...      B   \n",
       "2    Order the three cell names found in the cornea...      A   \n",
       "3    Regarding Descemet's membrane of the cornea, i...      C   \n",
       "4    About the lipidic layer of the lacrimal film, ...      B   \n",
       "..                                                 ...    ...   \n",
       "159  After retrobulbar block for phacoemulsificatio...      C   \n",
       "160  Regarding biometrics in eyes covered with sili...      D   \n",
       "161  Check the alternative that contains, respectiv...      A   \n",
       "162  Regarding the prevention of endophthalmitis in...      B   \n",
       "163  After performing the core fractures with the d...      C   \n",
       "\n",
       "    responses_english_0 responses_english_1  ... responses_portuguese_0  \\\n",
       "0                     b                   b  ...                      a   \n",
       "1                     B                   B  ...                      B   \n",
       "2                     c                   c  ...                      b   \n",
       "3                     b                   b  ...                      b   \n",
       "4                     B                   B  ...                      c   \n",
       "..                  ...                 ...  ...                    ...   \n",
       "159                   b                   b  ...                      c   \n",
       "160                   b                   b  ...                      c   \n",
       "161                   b                   b  ...                      A   \n",
       "162                   b                   A  ...                      b   \n",
       "163                   c                   c  ...                      c   \n",
       "\n",
       "    responses_portuguese_1 responses_portuguese_2 responses_portuguese_3  \\\n",
       "0                        b                      a                      b   \n",
       "1                        B                      B                      A   \n",
       "2                        b                      a                      A   \n",
       "3                        b                      b                      b   \n",
       "4                        c                      c                      C   \n",
       "..                     ...                    ...                    ...   \n",
       "159                      c                      c                      c   \n",
       "160                      a                      c                      c   \n",
       "161                      b                      b                      b   \n",
       "162                      B                      b                      b   \n",
       "163                      c                      c                      c   \n",
       "\n",
       "    responses_portuguese_4 responses_portuguese_5 responses_portuguese_6  \\\n",
       "0                        b                      b                      b   \n",
       "1                        B                      B                      A   \n",
       "2                        a                      a                      b   \n",
       "3                        b                      b                      b   \n",
       "4                        b                      b                      c   \n",
       "..                     ...                    ...                    ...   \n",
       "159                      c                      c                      c   \n",
       "160                      a                      c                      c   \n",
       "161                      B                      B                      A   \n",
       "162                      b                      b                      B   \n",
       "163                      c                      c                      c   \n",
       "\n",
       "    responses_portuguese_7 responses_portuguese_8 responses_portuguese_9  \n",
       "0                        A                      a                      a  \n",
       "1                        A                      A                      B  \n",
       "2                        b                      a                      b  \n",
       "3                        b                      b                      b  \n",
       "4                        b                      B                      A  \n",
       "..                     ...                    ...                    ...  \n",
       "159                      c                      c                      c  \n",
       "160                      a                      a                      a  \n",
       "161                      b                      B                      b  \n",
       "162                      b                      b                      b  \n",
       "163                      c                      c                      c  \n",
       "\n",
       "[164 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if N_REPETITIONS > 1:\n",
    "    df = pd.read_csv(f\"responses/{MODEL}_Temperature{str(TEMPERATURE).replace('.', '_')}_{N_REPETITIONS}Repetitions.csv\")\n",
    "else:\n",
    "    df = pd.read_csv(f\"responses/{MODEL}_Temperature{str(TEMPERATURE).replace('.', '_')}.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81336b09",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a81fc827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Anatomia              4                 5     21                 19.047619   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    23.809524  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Crnea              4                 1     10                      40.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                         10.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         theme  match_english  match_portuguese  Total  \\\n",
      "0  Embriologia              1                 1      2   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                      50.0                         50.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          theme  match_english  match_portuguese  Total  \\\n",
      "0  Farmacologia              5                 4      9   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                 55.555556                    44.444444  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Gentica              0                 0      2                       0.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Glaucoma              3                 3      7                 42.857143   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    42.857143  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       theme  match_english  match_portuguese  Total  \\\n",
      "0  Oncologia              1                 0      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     100.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Refrao              9                 8     31                 29.032258   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    25.806452  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Retina              6                 2     12                      50.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    16.666667  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                theme  match_english  match_portuguese  Total  \\\n",
      "0  Cirurgia Refrativa              1                 1      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     100.0                        100.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 theme  match_english  match_portuguese  Total  \\\n",
      "0  Cirurgia Refrativva              0                 1      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                        100.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 theme  match_english  match_portuguese  Total  \\\n",
      "0  Cristalino/Catarata              3                 5      8   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                      37.5                         62.5  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAIjCAYAAABI0sIEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLmElEQVR4nO3df3zN9f//8fvZZjM/thkz8nsUmx+pSfk1ixgh9IOkDIXKr3gj3t5+TEqRHxWl9P6YhMqveic/8iP5lfxYJPkZSlLyYxtmYzvP7x8uO1/HhnM4L4d1u14u58J5vV7n+Xycs/N6nft5vn4cmzHGCAAAwEI+3i4AAADkfQQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AXtG5c2eVL1/+pvd76NAh2Ww2vfnmmze979tVYmKibDabDh065PV+Y2NjFRsbe1PrgGfcMoHjl19+UY8ePRQREaH8+fMrKChI9erV01tvvaVz5855uzy3/fzzzxo5cuR1raCDBg2SzWZT+/btPV9YHpD9gXHpLSgoSDVr1tTkyZOVlZXlsb46d+6sQoUKeaw9WKN8+fI53hO53RITE71dqlcsXLhQzZs3V7FixeTv76877rhD7dq106pVqyzrMy0tTSNHjtTq1ast68Nqp06dkp+fnz777DPHtKysLE2fPl2xsbEKDQ1VQECAypcvry5dumjLli1u93EjnxWeNHv2bE2aNMnSPvwsbd1FX331lZ544gkFBASoU6dOqlatms6fP69169Zp4MCB2rlzpz744ANvl+mWn3/+WQkJCYqNjXXrW5wxRnPmzFH58uX15Zdf6vTp0ypcuLB1hd7GOnTooIcffliSlJKSosWLF6t379769ddfNW7cOC9Xh2uZNm2a7Ha7R9qaNGmSzpw547i/ePFizZkzRxMnTlSxYsUc0+vWreuR/m4Xxhh17dpViYmJuueee9S/f3+VKFFCR48e1cKFC9W4cWOtX7/+mq/LM888oyeffFIBAQEu952WlqaEhARJ8uiIxNdff+2xtq5l2bJlstlsatq0qSTp3LlzevTRR7V06VLFxMTo3//+t0JDQ3Xo0CF99tlnmjFjhn777TeVLl3a5T6u97PC02bPnq2ffvpJL730kmV9eD1wHDx4UE8++aTKlSunVatWqWTJko55PXv21P79+/XVV1/dcD/GGKWnpyswMDDHvPT0dPn7+8vHx/sDPqtXr9bvv/+uVatWKS4uTgsWLFB8fLy3y/KozMxM2e12+fv731A79957r55++mnH/RdffFH333+/Zs+eTeC4DeTLl89jbbVp08bp/p9//qk5c+aoTZs2OTbi3v4meTONHz9eiYmJeumllzRhwgTZbDbHvKFDh2rmzJny87vyx8DZs2dVsGBB+fr6ytfX92aUfE03ut1wx+LFi1WvXj2FhIRIkgYOHKilS5dq4sSJOT6YR4wYoYkTJ9602q4lLS1NBQoU8HYZzoyXPf/880aSWb9+vUvLX7hwwYwaNcpEREQYf39/U65cOTNkyBCTnp7utFy5cuVMixYtzNKlS010dLQJCAgwEydONN98842RZObMmWOGDh1q7rjjDmOz2cypU6eMMcZs3LjRxMXFmaCgIBMYGGhiYmLMunXrctTx+++/m65du5qSJUsaf39/U758efP888+bjIwMM336dCMpx+2bb7655vN79tlnTVRUlDHGmObNm5smTZrkWCb7OXz66adm9OjRplSpUiYgIMA0atTI7Nu3z2nZvXv3mkcffdSEh4ebgIAAU6pUKdO+fXuTnJxsjDGmbdu25p577nF6TMuWLY0k88UXXzimbdy40Ugyixcvdkw7deqU6du3ryldurTx9/c3FStWNK+//rrJyspyLHPw4EEjyYwbN85MnDjRREREGB8fH/PDDz8YY4x5++23TVRUlAkMDDQhISEmOjrazJo166qv0aVtXq5ly5ambNmyjvudOnUyRYsWNefPn8+xbJMmTcxdd9111b7i4+NNwYIFr7rMoUOHzAsvvGDuuusukz9/fhMaGmoef/xxc/DgQaflst8X69atM/369TPFihUzBQoUMG3atDHHjh1zWjYrK8uMGDHClCxZ0gQGBprY2Fizc+dOU65cORMfH+9YbsSIESa31Ti7r0tr+Pzzz83DDz/seM9GRESYUaNGmczMzByPnzx5sqlQoYLJnz+/ue+++8yaNWtMw4YNTcOGDZ2WS09PN8OHDzcVK1Y0/v7+pnTp0mbgwIE51sfcxMfHm3LlyjnuX/p3ff/99x3reK1atcymTZuu2d6lxo0bl+P5X28/u3btMo899pgpUqSICQgIMNHR0U7rhjH///Veu3at6d27tylWrJgJDg423bt3NxkZGebUqVPmmWeeMSEhISYkJMQMHDjQ2O12pzaysrLMxIkTTVRUlAkICDDFixc33bt3NydPnnRaLjk52ezatcuxDl9JWlqaCQ0NNVWqVMn1b3y57OewevVq88ILL5iwsDATEhLiNO/S13Pz5s2madOmpmjRoiZ//vymfPnypkuXLk6v8eW3ESNGGGOM2b59u4mPjzcVKlQwAQEBJjw83HTp0sUcP34815ou7ffy96E720NjjPnss8/Mvffea/Lnz2+KFi1qOnbsaH7//fccy2VlZZmwsDAzduxYY4wxhw8fNn5+frluk3PjynbhWp8Vrq6zDRs2NFWrVjVbtmwxDRo0MIGBgaZv374ut9GwYcMcNWSvmxkZGWbYsGHm3nvvNUFBQaZAgQKmfv36ZtWqVS69Dpfy+gjHl19+qYiICJeHOp977jnNmDFDjz/+uP71r3/p+++/15gxY7Rr1y4tXLjQadk9e/aoQ4cO6tGjh7p166bKlSs75r3yyivy9/fXgAEDlJGRIX9/f61atUrNmzdXdHS0RowYIR8fH02fPl2NGjXS2rVrVbt2bUnSH3/8odq1ays5OVndu3dXlSpVdOTIEc2bN09paWmKiYlRnz599Pbbb+vf//63IiMjJcnx75VkZGRo/vz5+te//iXp4i6DLl266M8//1SJEiVyLP/666/Lx8dHAwYMUEpKisaOHauOHTvq+++/lySdP39ecXFxysjIUO/evVWiRAkdOXJEixYtUnJysoKDg9WgQQN98cUXSk1NVVBQkIwxWr9+vXx8fLR27Vo98sgjkqS1a9fKx8dH9erVk3QxPTds2FBHjhxRjx49VLZsWW3YsEFDhgzR0aNHc+wLnD59utLT09W9e3cFBAQoNDRU06ZNU58+ffT444+rb9++Sk9P148//qjvv/9eTz311DXfC2lpaTp+/LgkKTU1VUuWLNHSpUs1ZMgQxzLPPPOMPvroIy1btkwtW7Z0TP/zzz+1atUqjRgx4pr9XMvmzZu1YcMGPfnkkypdurQOHTqk9957T7Gxsfr5559zfMvo3bu3ihQpohEjRujQoUOaNGmSevXqpU8//dSxzJAhQzR27Fi1atVKcXFx2r59u+Li4pSenn7ddSYmJqpQoULq37+/ChUqpFWrVmn48OFKTU11GhF677331KtXLzVo0ED9+vXToUOH1KZNGxUpUsRpqNhut+uRRx7RunXr1L17d0VGRmrHjh2aOHGi9u7dq88///y66pw9e7ZOnz6tHj16yGazaezYsXr00Ud14MABj46KuNLPzp07Va9ePZUqVUqDBw9WwYIF9dlnn6lNmzaaP3++2rZt69Rm9nqWkJCgjRs36oMPPlBISIg2bNigsmXL6rXXXtPixYs1btw4VatWTZ06dXI8tkePHkpMTFSXLl3Up08fHTx4UJMnT9YPP/yg9evXO2pauHChunTpounTp6tz585XfH7r1q3TyZMn9dJLL7k1OvHiiy8qLCxMw4cP19mzZ3Nd5tixY2ratKnCwsI0ePBghYSE6NChQ1qwYIEkKSwsTO+9955eeOEFtW3bVo8++qgkqUaNGpKk5cuX68CBA+rSpYtKlCjh2G2+c+dObdy40WkkxlXX2h5Kcry+9913n8aMGaO//vpLb731ltavX68ffvjBMZIhXVyv//77b8du2yVLligzM1PPPPOMS/W4sl241meFq+usJJ04cULNmzfXk08+qaefflrh4eEutzF06FClpKTo999/d4zSZB+7lpqaqg8//FAdOnRQt27ddPr0af33v/9VXFycNm3apJo1a7r+R3I7onhQSkqKkWRat27t0vLbtm0zksxzzz3nNH3AgAFGklPiKleunJFkli5d6rRsdhqOiIgwaWlpjul2u93ceeedJi4uzumbR1pamqlQoYJTqu3UqZPx8fExmzdvzlFj9mPnzp3r8qhGtnnz5hlJjlSemppq8ufPbyZOnJjrc4iMjDQZGRmO6W+99ZaRZHbs2GGMMeaHH34wkszcuXOv2OfmzZudRi5+/PFHI8k88cQT5v7773cs98gjjziNhLzyyiumYMGCZu/evU7tDR482Pj6+prffvvNGPP/v+kEBQXl+BbfunVrU7VqVVdfHocrfXuSZF544QWnv19WVpYpXbq0ad++vVMbEyZMMDabzRw4cOCqfbkywnHp+yjbd999ZySZjz76yDEt+9vMQw895FRjv379jK+vr+Mb659//mn8/PxMmzZtnNocOXKkkXTdIxy51dmjRw9ToEABx4hERkaGKVq0qLnvvvvMhQsXHMslJiYaSU7fLGfOnGl8fHzM2rVrndqcOnWqS6OWVxrhKFq0qNO3+i+++MJIMl9++eVV27uUKyMcrvTTuHFjU716dacRG7vdburWrWvuvPNOx7Ts1/vy7UedOnWMzWYzzz//vGNaZmamKV26tNNruXbtWiMpx+je0qVLc0zP7mv69OlXfQ2ytwcLFy686nKXt1u/fv0c36Avfz8tXLjQSMp1G5jt77//dhrVuFRu78U5c+YYSWbNmjVX7NeYK49wXGt7eP78eVO8eHFTrVo1c+7cOcdyixYtMpLM8OHDneoZNmyY0/uzX79+RpJjdPZaXN0uXO2zwpV11pj/P0IxderU626jRYsWTs83W2ZmptPraszF0e3w8HDTtWvXHMtfjVcPWkhNTZUklw+KXLx4sSSpf//+TtOzRwQuP9ajQoUKiouLy7Wt+Ph4p+M5tm3bpn379umpp57SiRMndPz4cR0/flxnz55V48aNtWbNGtntdtntdn3++edq1aqVatWqlaPd60nm2WbNmqVatWqpUqVKki6+Li1atNCsWbNyXb5Lly5O+zMbNGggSTpw4IAkKTg4WNLFA5/S0tJybeOee+5RoUKFtGbNGkkXRzJKly6tTp06KSkpSWlpaTLGaN26dY72JWnu3Llq0KCBihQp4nitjh8/roceekhZWVmO9rI99thjCgsLc5oWEhKi33//XZs3b3b5NbpU9+7dtXz5ci1fvlzz589Xz5499f777zu9P3x8fNSxY0f973//0+nTpx3TZ82apbp166pChQrX1felLn0fXbhwQSdOnFClSpUUEhKipKSkXOu+9H3SoEEDZWVl6ddff5UkrVy5UpmZmXrxxRedHte7d2+P1Xn69GkdP35cDRo0UFpamnbv3i1J2rJli06cOKFu3bo57dvv2LGjihQp4tTe3LlzFRkZqSpVqji9Bxo1aiRJ+uabb66rzvbt2zv1dfn72lOu1c/Jkye1atUqtWvXzvF6HT9+XCdOnFBcXJz27dunI0eOOLX57LPPOv1t77//fhlj9Oyzzzqm+fr6qlatWk7PZ+7cuQoODlaTJk2cXsvo6GgVKlTI6bXs3LmzjDFXHd2Q3N++ZuvWrds1R0SyRwIWLVqkCxcuuNW+5PxeTE9P1/Hjx/XAAw9IUq7rjCuutT3csmWLjh07phdffFH58+d3LNeiRQtVqVIlx+fH4sWL1aJFC8d9d19Pd7cL12rjSutstoCAAHXp0uWG2siNr6+v43W12+06efKkMjMzVatWLbf/Vl7dpRIUFCRJTh8EV/Prr7/Kx8fH8YGcrUSJEgoJCXFssLNd7cPk8nn79u2TpKseoJmSkqLz588rNTVV1apVc6lmVyUnJ2vx4sXq1auX9u/f75her149zZ8/X3v37tVdd93l9JiyZcs63c/eeJ46dUrSxefYv39/TZgwQbNmzVKDBg30yCOP6Omnn3aEEV9fX9WpU0dr166VdDFwNGjQQPXr11dWVpY2btyo8PBwnTx50ilw7Nu3Tz/++GOOEJHt2LFjTvdz+1u8/PLLWrFihWrXrq1KlSqpadOmeuqppxy7ba7lzjvv1EMPPeS4/+ijj8pms2nSpEnq2rWrqlevLknq1KmT3njjDS1cuFCdOnXSnj17tHXrVk2dOtWlfq7l3LlzGjNmjKZPn64jR47IGOOYl5KSkmP5a/3dst/Hl7/PQ0NDc3zou2Pnzp36z3/+o1WrVjk2npfXeaW+/fz8chx8uW/fPu3atcvl94CrrvX6eMq1+tm/f7+MMRo2bJiGDRuWaxvHjh1TqVKlrthm9npWpkyZHNMvfT779u1TSkqKihcvfsV+3OXu9jWbKyG8YcOGeuyxx5SQkKCJEycqNjZWbdq00VNPPeXSmSwnT55UQkKCPvnkkxzPLbd1xhWurleX7lrPVqVKFa1bt85x/88//1RSUpJGjRrlmObu6+nudiE3rqyz2UqVKpXrAbXutHElM2bM0Pjx47V7926ngOnuFzavB4477rhDP/30k1uPc3UUIbczUq40L/v0vHHjxl1xn1ShQoV08uRJ14p009y5c5WRkaHx48dr/PjxOebPmjXLcYpZtit9C7n0jT1+/Hh17txZX3zxhb7++mv16dNHY8aM0caNGx374+vXr69XX31V6enpWrt2rYYOHaqQkBBVq1ZNa9eudewLvDRw2O12NWnSRIMGDcq1hsvDUW5/i8jISO3Zs0eLFi3S0qVLNX/+fL377rsaPnx4jufqqsaNG2vy5Mlas2aNI3BERUUpOjpaH3/8sTp16qSPP/5Y/v7+ateu3XX1cbnevXtr+vTpeumll1SnTh0FBwfLZrPpySefzPW0T1f+bq660rpw+bVIkpOT1bBhQwUFBWnUqFGqWLGi8ufPr6SkJL388svXdXqq3W5X9erVNWHChFznX/4h6ypPvj430k/2azJgwIArjpReHsyu1GZu0y99Pna7XcWLF7/iaOaVQt3VVKlSRZK0Y8eOHGfxXM3VtpvZbDab5s2bp40bN+rLL7/UsmXL1LVrV40fP14bN2685rVr2rVrpw0bNmjgwIGqWbOmChUqJLvdrmbNml33qdKefN8sWbJE+fPn14MPPuiYdunr6cpxC+5uFy7n7jqb29/NE+v9xx9/rM6dO6tNmzYaOHCgihcvLl9fX40ZM0a//PLLNR9/Ka8fNNqyZUt98MEH+u6771SnTp2rLluuXDnZ7Xbt27fP6QDMv/76S8nJySpXrtx111GxYkVJF0PQpd+aLxcWFqagoKBrhiR3d63MmjVL1apVy/Ugxvfff1+zZ8++7g/h6tWrq3r16vrPf/6jDRs2qF69epo6dapGjx4t6WKQOH/+vObMmaMjR444gkVMTIwjcNx1112O4CFdfL3OnDlz1dfKFQULFlT79u3Vvn17nT9/Xo8++qheffVVDRkyxGnY01WZmZmS5HRNBuniKEf//v119OhRzZ49Wy1atLih0YJLzZs3T/Hx8U5BMT09XcnJydfVXvb7eP/+/U7fIE6cOJHjW372c0hOTnY64O3y0b7Vq1frxIkTWrBggWJiYhzTDx48eMW+L93YZmZm6tChQ46D/qSL74Ht27ercePGN7Qr8VYVEREh6eLpuzf6Pr+WihUrasWKFapXr55LH/iuqF+/vooUKaI5c+bo3//+tyWntT7wwAN64IEH9Oqrr2r27Nnq2LGjPvnkEz333HNXfE+cOnVKK1euVEJCgoYPH+6Ynj3KbJXs9/aePXscu/2y7dmzx+nz46uvvtKDDz7o9Ldo3ry5fH199fHHH7t04Kir24UrvU6urrNX404bV6pj3rx5ioiI0IIFC5yWuZ4D7r1+4YlBgwapYMGCeu655/TXX3/lmP/LL7/orbfekiTH0cKXnwGR/Q3r0v1t7oqOjlbFihX15ptv5viwkqS///5b0sVjAtq0aaMvv/wy16vKZafpggULSpJLHzqHDx/WmjVr1K5dOz3++OM5bl26dNH+/fudjrZ2RWpqquMDOFv16tXl4+OjjIwMx7T7779f+fLl0xtvvKHQ0FBVrVpV0sUgsnHjRn377bdOoxvSxW8o3333nZYtW5aj3+Tk5Bz95ubEiRNO9/39/RUVFSVjzHXtF5YunvUkSXfffbfT9A4dOshms6lv3746cOCA0/U7bpSvr2+Ob1HvvPPOdV/xtHHjxvLz89N7773nNH3y5Mk5ls0OypceM3P27FnNmDEjR42S87e98+fP691333VarlatWipatKimTZvm9DecNWtWjrDTrl07HTlyRNOmTctR17lz5654hsPtonjx4oqNjdX777+vo0eP5pifvU3whHbt2ikrK0uvvPJKjnmZmZlO25GUlBTt3r37msPhBQoU0Msvv6xdu3bp5ZdfzvWb/scff6xNmza5Xe+pU6dytJf9rT9725J9dtbl28Dc3otSzu26p9WqVUvFixfX1KlTnbZ/S5Ys0a5duxyfHxcuXNDy5ctzfJ6UKVNG3bp109dff6133nknR/t2u13jx4/X77//Lsn17cKVPitcXWevxp02ChYsmOt7Krc2vv/+e3333Xcu15HN6yMcFStW1OzZs9W+fXtFRkY6XWl0w4YNmjt3ruPgqLvvvlvx8fH64IMPHENFmzZt0owZM9SmTRunb2Tu8vHx0YcffqjmzZuratWq6tKli0qVKqUjR47om2++UVBQkOPD7LXXXtPXX3+thg0bOk4HPHr0qObOnat169YpJCRENWvWlK+vr9544w2lpKQoICBAjRo1ynUf7ezZs2WMcZyCermHH35Yfn5+mjVrlu6//36Xn9OqVavUq1cvPfHEE7rrrruUmZmpmTNnytfXV4899phjuQIFCig6OlobN25Uq1atHCk2JiZGZ8+e1dmzZ3MEjoEDB+p///ufWrZsqc6dOys6Olpnz57Vjh07NG/ePB06dMjpCo+5adq0qUqUKKF69eopPDxcu3bt0uTJk9WiRQuXDsxKSkrSxx9/LOniftWVK1dq/vz5qlu3ruPKgNnCwsLUrFkzzZ07VyEhIW6F0wsXLjhGgy4VGhqqF198US1bttTMmTMVHBysqKgofffdd1qxYoWKFi3qch+XCg8PV9++fTV+/Hg98sgjatasmbZv364lS5aoWLFiTt8ymjZtqrJly+rZZ5/VwIED5evrq//7v/9TWFiYfvvtN8dydevWVZEiRRQfH68+ffrIZrNp5syZOTaI/v7+GjlypHr37q1GjRqpXbt2OnTokBITE1WxYkWnvp955hl99tlnev755/XNN9+oXr16ysrK0u7du/XZZ59p2bJluR5YfTuZMmWK6tevr+rVq6tbt26KiIjQX3/9pe+++06///67tm/f7pF+GjZsqB49emjMmDHatm2bmjZtqnz58mnfvn2aO3eu3nrrLT3++OOSXD8tVpLjSs3jx4/XN998o8cff1wlSpTQn3/+qc8//1ybNm3Shg0b3K53xowZevfdd9W2bVtVrFhRp0+f1rRp0xQUFOT4YhgYGKioqCh9+umnuuuuuxQaGqpq1aqpWrVqiomJ0dixY3XhwgWVKlVKX3/9tVvf3K9H9peqLl26qGHDhurQoYPjtNjy5curX79+ki6eTpyamprrNmL8+PH65Zdf1KdPHy1YsEAtW7ZUkSJF9Ntvv2nu3LnavXu3nnzySUlyebtwpc8KV9fZq3GnjejoaH366afq37+/7rvvPhUqVEitWrVSy5YttWDBArVt21YtWrTQwYMHNXXqVEVFReX65fyq3DqnxUJ79+413bp1M+XLlzf+/v6mcOHCpl69euadd95xOnXnwoULJiEhwVSoUMHky5fPlClT5qoX/rpc9ilUVzpV9IcffjCPPvqoKVq0qAkICDDlypUz7dq1MytXrnRa7tdffzWdOnUyYWFhJiAgwERERJiePXs6nT40bdo0ExERYXx9fa96imz16tWdLlaVm9jYWFO8eHFz4cKFKz6H7NP9sk+XO3DggOnataupWLGi48IzDz74oFmxYkWO9gcOHGgkmTfeeMNpeqVKlYwk88svv+R4zOnTp82QIUNMpUqVjL+/vylWrJipW7euefPNNx0X2rraRbref/99ExMT43itK1asaAYOHGhSUlKu+lrkdlqsn5+fiYiIMAMHDjSnT5/O9XGfffaZkWS6d+9+1fYvFR8ff8VTcCtWrGiMuXiKWJcuXUyxYsVMoUKFTFxcnNm9e3eOi3Rln+J3+amE2X/PS98fmZmZZtiwYaZEiRImMDDQNGrUyOzatcsULVrU6RRLY4zZunWruf/++42/v78pW7asmTBhQq6nE65fv9488MADJjAw0Nxxxx1m0KBBZtmyZbm+N99++21Trlw5ExAQYGrXrm3Wr19voqOjTbNmzZyWO3/+vHnjjTdM1apVTUBAgClSpIiJjo42CQkJ1/w7Xu3CX5fTFU6vvBJXL/zlSj+//PKL6dSpkylRooTJly+fKVWqlGnZsqWZN2+eY5kr/W2zT1v++++/naZf6XTrDz74wERHR5vAwEBTuHBhU716dTNo0CDzxx9/5OjrWqfFXmrevHmmadOmJjQ01Pj5+ZmSJUua9u3bm9WrV1/zOVw6L/v1TEpKMh06dDBly5Z1XKSsZcuWZsuWLU6P27Bhg4mOjjb+/v5Or+3vv/9u2rZta0JCQkxwcLB54oknzB9//JHj9XfntNhrbQ+zffrpp+aee+4xAQEBJjQ0NMeFvwYMGOC4+GJuMjMzzYcffmgaNGhggoODTb58+Uy5cuVMly5dnE6ZdXW7YMyVPytcXWezL/yVG1fbOHPmjHnqqadMSEiI0SUX/rLb7ea1115zbA/uueces2jRohzrrytsxnj4SCzgFvXFF1+oTZs2WrNmTY4Rm9tBcnKyihQpotGjR2vo0KE3tW+73a6wsDA9+uijue5CAfKKqKgotWzZUmPHjvV2KXmO14/hAG6WadOmKSIiQvXr1/d2KdeU2y8kZ+/jtvqnudPT03MMuX700Uc6efIkPwuOPO38+fNq3759rtezwI3z+jEcgNU++eQT/fjjj/rqq6/01ltv3RZnVHz66adKTEzUww8/rEKFCmndunWaM2eOmjZt6vJ1Sq7Xxo0b1a9fPz3xxBMqWrSokpKS9N///lfVqlXTE088YWnfgDf5+/t75OcOkDt2qSDPs9lsKlSokNq3b6+pU6de9dcxbxVJSUkaNGiQtm3bptTUVIWHh+uxxx7T6NGjr3mNgxt16NAh9enTR5s2bdLJkycVGhqqhx9+WK+//voVL0wFANdC4AAAAJbjGA4AAGA5AgcAALDcrb8z+yrsdrv++OMPFS5c+LY4EBAAgFuFMUanT5/WHXfcIR8f68cfbuvA8ccff1z3D0QBAICLP6+R/WOeVrqtA0f25a8PHz7s+OlgAABwbampqSpTpoxLPyXhCbd14MjejRIUFETgAADgOtysQxI4aBQAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOa8GjpEjR8pmszndqlSp4s2SAACABfy8XUDVqlW1YsUKx30/P6+XBAAAPMzrn+5+fn4qUaKEt8sAAAAW8voxHPv27dMdd9yhiIgIdezYUb/99tsVl83IyFBqaqrTDQAA3Ppsxhjjrc6XLFmiM2fOqHLlyjp69KgSEhJ05MgR/fTTTypcuHCO5UeOHKmEhIQc01NSUhQUFHQzSgZwCyk/+CtvlwDcNIdeb+HR9lJTUxUcHHzTPkO9Gjgul5ycrHLlymnChAl69tlnc8zPyMhQRkaG435qaqrKlClD4AD+oQgc+Ce53QOH14/huFRISIjuuusu7d+/P9f5AQEBCggIuMlVAQCAG+X1YzgudebMGf3yyy8qWbKkt0sBAAAe5NXAMWDAAH377bc6dOiQNmzYoLZt28rX11cdOnTwZlkAAMDDvLpL5ffff1eHDh104sQJhYWFqX79+tq4caPCwsK8WRYAAPAwrwaOTz75xJvdAwCAm+SWOoYDAADkTQQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAsd8sEjtdff102m00vvfSSt0sBAAAedksEjs2bN+v9999XjRo1vF0KAACwgNcDx5kzZ9SxY0dNmzZNRYoU8XY5AADAAl4PHD179lSLFi300EMPXXPZjIwMpaamOt0AAMCtz8+bnX/yySdKSkrS5s2bXVp+zJgxSkhIsLgqAADgaV4b4Th8+LD69u2rWbNmKX/+/C49ZsiQIUpJSXHcDh8+bHGVAADAE7w2wrF161YdO3ZM9957r2NaVlaW1qxZo8mTJysjI0O+vr5OjwkICFBAQMDNLhUAANwgrwWOxo0ba8eOHU7TunTpoipVqujll1/OETYAAMDty2uBo3DhwqpWrZrTtIIFC6po0aI5pgMAgNub189SAQAAeZ9Xz1K53OrVq71dAgAAsAAjHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwnNuBIykpSTt27HDc/+KLL9SmTRv9+9//1vnz5z1aHAAAyBvcDhw9evTQ3r17JUkHDhzQk08+qQIFCmju3LkaNGiQxwsEAAC3P7cDx969e1WzZk1J0ty5cxUTE6PZs2crMTFR8+fP93R9AAAgD3A7cBhjZLfbJUkrVqzQww8/LEkqU6aMjh8/7tnqAABAnuB24KhVq5ZGjx6tmTNn6ttvv1WLFi0kSQcPHlR4eLjHCwQAALc/twPHpEmTlJSUpF69emno0KGqVKmSJGnevHmqW7euxwsEAAC3Pz93Fs7KylJycrLWrFmjIkWKOM0bN26cfH19PVocAADIG9wa4fD19VXTpk2VnJycY17+/PmVL18+T9UFAADyELd3qVSrVk0HDhywohYAAJBHuR04Ro8erQEDBmjRokU6evSoUlNTnW4AAACXc+sYDkmO02AfeeQR2Ww2x3RjjGw2m7KysjxXHQAAyBPcDhzffPONFXUAAIA8zO3A0bBhQyvqAAAAedh1/Vrs2rVr9fTTT6tu3bo6cuSIJGnmzJlat26dR4sDAAB5g9uBY/78+YqLi1NgYKCSkpKUkZEhSUpJSdFrr73m8QIBAMDt77rOUpk6daqmTZvmdN2NevXqKSkpyaPFAQCAvMHtwLFnzx7FxMTkmB4cHJzrBcEAAADcDhwlSpTQ/v37c0xft26dIiIiPFIUAADIW9wOHN26dVPfvn31/fffy2az6Y8//tCsWbM0YMAAvfDCC2619d5776lGjRoKCgpSUFCQ6tSpoyVLlrhbEgAAuMW5fVrs4MGDZbfb1bhxY6WlpSkmJkYBAQEaMGCAevfu7VZbpUuX1uuvv64777xTxhjNmDFDrVu31g8//KCqVau6WxoAALhF2Ywx5noeeP78ee3fv19nzpxRVFSUChUq5JGCQkNDNW7cOD377LPXXDY1NVXBwcFKSUlRUFCQR/oHcPsoP/grb5cA3DSHXm/h0fZu9meo2yMcq1atUt26dZU/f35FRUV5rJCsrCzNnTtXZ8+eVZ06dXJdJiMjw3EariR+uwUAgNuE24HjkUceUWZmpu677z7FxsaqYcOGqlevngIDA6+rgB07dqhOnTpKT09XoUKFtHDhwisGmTFjxighIeG6+nEH35rwT+Lpb00AkBu3Dxo9deqUVq5cqebNm2vTpk1q27atQkJCVK9ePf3nP/9xu4DKlStr27Zt+v777/XCCy8oPj5eP//8c67LDhkyRCkpKY7b4cOH3e4PAADcfNd9DEe2nTt3aty4cZo1a5bsdvsN/1rsQw89pIoVK+r999+/5rJW7X9ihAP/JLfzCAfrKv5J/nHHcOzdu1erV6/W6tWr9e233yojI0MNGjTQm2++qdjY2BsuyG63Ox2nAQAAbn9uB44qVaooLCxMffv21eDBg1W9enXZbLbr6nzIkCFq3ry5ypYtq9OnT2v27NlavXq1li1bdl3tAQCAW5PbgaNPnz5as2aNRo0apUWLFik2NlaxsbGqX7++ChQo4FZbx44dU6dOnXT06FEFBwerRo0aWrZsmZo0aeJuWQAA4BbmduCYNGmSJCk5OVlr167Vt99+q6FDh2rnzp265557tH79epfb+u9//+tu9wAA4Dbk9lkq2bKysnThwgVlZGQoPT1dGRkZ2rNnjydrAwAAeYTbgaNPnz6qUaOGwsPD1aNHD/3xxx/q1q2bfvjhB/39999W1AgAAG5zbu9SOXr0qLp3767Y2FhVq1bNipoAAEAe43bgmDt3rhV1AACAPMztXSozZszQV1/9/4vtDBo0SCEhIapbt65+/fVXjxYHAADyBrcDx2uvveb43ZTvvvtOU6ZM0dixY1WsWDH169fP4wUCAIDbn9u7VA4fPqxKlSpJkj7//HM99thj6t69u+rVq+eRK40CAIC8x+0RjkKFCunEiROSpK+//tpxka78+fPr3Llznq0OAADkCW6PcDRp0kTPPfec7rnnHu3du1cPP/ywpIs/4la+fHlP1wcAAPIAt0c4pkyZojp16ujvv//W/PnzVbRoUUnS1q1b1aFDB48XCAAAbn9uj3CEhIRo8uTJOaYnJCR4pCAAAJD3uB04pIu/o7Jp0yYdO3ZMdrvdMd1ms+mZZ57xWHEAACBvcDtwfPnll+rYsaPOnDmjoKAgp5+mJ3AAAIDcuH0Mx7/+9S917dpVZ86cUXJysk6dOuW4nTx50ooaAQDAbc7twHHkyBH16dNHBQoUsKIeAACQB7kdOOLi4rRlyxYragEAAHmU28dwtGjRQgMHDtTPP/+s6tWrK1++fE7zH3nkEY8VBwAA8ga3A0e3bt0kSaNGjcoxz2azKSsr68arAgAAeYrbgePS02ABAABc4fYxHFeSnJyc6wXBAAAAbjhwrFy5Uk899ZRKliypESNGeKImAACQx1xX4Dh8+LBGjRqlChUqqGnTprLZbFq4cKH+/PNPT9cHAADyAJcDx4ULFzR37lzFxcWpcuXK2rZtm8aNGycfHx8NHTpUzZo1y3HGCgAAgOTGQaOlSpVSlSpV9PTTT+uTTz5RkSJFJIlfiAUAANfk8ghHZmambDabbDabfH19rawJAADkMS4Hjj/++EPdu3fXnDlzVKJECT322GNauHCh04+3AQAA5MblwJE/f3517NhRq1at0o4dOxQZGak+ffooMzNTr776qpYvX85FvwAAQK6u6yyVihUravTo0fr111/11VdfKSMjQy1btlR4eLin6wMAAHmA21cavZSPj4+aN2+u5s2b6++//9bMmTM9VRcAAMhDPHal0bCwMPXv399TzQEAgDzEY4EDAADgSggcAADAcgQOAABgObcDx6hRo5SWlpZj+rlz5zRq1CiPFAUAAPIWtwNHQkKCzpw5k2N6WlqaEhISPFIUAADIW9wOHMaYXK8uun37doWGhnqkKAAAkLe4fB2OIkWKOH5L5a677nIKHVlZWTpz5oyef/55S4oEAAC3N5cDx6RJk2SMUdeuXZWQkKDg4GDHPH9/f5UvX1516tSxpEgAAHB7czlwxMfHS5IqVKigevXqyc/vhi5SCgAA/kHcPobj7NmzWrlyZY7py5Yt05IlSzxSFAAAyFvcDhyDBw/O9VdhjTEaPHiwR4oCAAB5i9uBY9++fYqKisoxvUqVKtq/f79HigIAAHmL24EjODhYBw4cyDF9//79KliwoEeKAgAAeYvbgaN169Z66aWX9Msvvzim7d+/X//617/0yCOPeLQ4AACQN7gdOMaOHauCBQuqSpUqqlChgipUqKDIyEgVLVpUb775phU1AgCA25zb57YGBwdrw4YNWr58ubZv367AwEDVqFFDMTExVtQHAADygOu6mIbNZlPTpk0VExOjgICAXC91DgAAkM3tXSp2u12vvPKKSpUqpUKFCungwYOSpGHDhum///2vxwsEAAC3P7cDx+jRo5WYmKixY8fK39/fMb1atWr68MMPPVocAADIG9wOHB999JE++OADdezYUb6+vo7pd999t3bv3u3R4gAAQN7gduA4cuSIKlWqlGO63W7XhQsXPFIUAADIW9wOHFFRUVq7dm2O6fPmzdM999zjkaIAAEDe4vZZKsOHD1d8fLyOHDkiu92uBQsWaM+ePfroo4+0aNEiK2oEAAC3ueu60uiXX36pFStWqGDBgho+fLh27dqlL7/8Uk2aNLGiRgAAcJtza4QjMzNTr732mrp27arly5dbVRMAAMhj3Brh8PPz09ixY5WZmWlVPQAAIA9ye5dK48aN9e2331pRCwAAyKPcPmi0efPmGjx4sHbs2KHo6OgcP0nPL8YCAIDLuR04XnzxRUnShAkTcsyz2WzKysq68aoAAECe4nbgsNvtVtQBAADyMLeO4bhw4YL8/Pz0008/WVUPAADIg9wKHPny5VPZsmXZbQIAANzi9lkqQ4cO1b///W+dPHnSinoAAEAe5PYxHJMnT9b+/ft1xx13qFy5cjnOUklKSvJYcQAAIG9wO3C0adPGgjIAAEBe5nbgGDFihBV1AACAPMztwJFt69at2rVrlySpatWq/DQ9AAC4IrcDx7Fjx/Tkk09q9erVCgkJkSQlJyfrwQcf1CeffKKwsDBP1wgAAG5zbp+l0rt3b50+fVo7d+7UyZMndfLkSf30009KTU1Vnz59rKgRAADc5twe4Vi6dKlWrFihyMhIx7SoqChNmTJFTZs29WhxAAAgb3B7hMNutytfvnw5pufLl4/LngMAgFy5HTgaNWqkvn376o8//nBMO3LkiPr166fGjRt7tDgAAJA3uB04Jk+erNTUVJUvX14VK1ZUxYoVVaFCBaWmpuqdd96xokYAAHCbc/sYjjJlyigpKUkrVqzQ7t27JUmRkZF66KGHPF4cAADIG67rOhw2m01NmjRRkyZNPF0PAADIg1zepbJq1SpFRUUpNTU1x7yUlBRVrVpVa9eu9WhxAAAgb3A5cEyaNEndunVTUFBQjnnBwcHq0aOHJkyY4NHiAABA3uBy4Ni+fbuaNWt2xflNmzbV1q1b3ep8zJgxuu+++1S4cGEVL15cbdq00Z49e9xqAwAA3PpcDhx//fVXrtffyObn56e///7brc6//fZb9ezZUxs3btTy5ct14cIFNW3aVGfPnnWrHQAAcGtz+aDRUqVK6aefflKlSpVynf/jjz+qZMmSbnW+dOlSp/uJiYkqXry4tm7dqpiYGLfaAgAAty6XRzgefvhhDRs2TOnp6TnmnTt3TiNGjFDLli1vqJiUlBRJUmhoaK7zMzIylJqa6nQDAAC3PpdHOP7zn/9owYIFuuuuu9SrVy9VrlxZkrR7925NmTJFWVlZGjp06HUXYrfb9dJLL6levXqqVq1arsuMGTNGCQkJ190HAADwDpcDR3h4uDZs2KAXXnhBQ4YMkTFG0sVrcsTFxWnKlCkKDw+/7kJ69uypn376SevWrbviMkOGDFH//v0d91NTU1WmTJnr7hMAANwcbl34q1y5clq8eLFOnTql/fv3yxijO++8U0WKFLmhInr16qVFixZpzZo1Kl269BWXCwgIUEBAwA31BQAAbr7rutJokSJFdN99991w58YY9e7dWwsXLtTq1atVoUKFG24TAADceq4rcHhKz549NXv2bH3xxRcqXLiw/vzzT0kXLyQWGBjozdIAAIAHuf1rsZ703nvvKSUlRbGxsSpZsqTj9umnn3qzLAAA4GFeHeHIPvAUAADkbV4d4QAAAP8MBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACzn1cCxZs0atWrVSnfccYdsNps+//xzb5YDAAAs4tXAcfbsWd19992aMmWKN8sAAAAW8/Nm582bN1fz5s29WQIAALgJvBo43JWRkaGMjAzH/dTUVC9WAwAAXHVbHTQ6ZswYBQcHO25lypTxdkkAAMAFt1XgGDJkiFJSUhy3w4cPe7skAADggttql0pAQIACAgK8XQYAAHDTbTXCAQAAbk9eHeE4c+aM9u/f77h/8OBBbdu2TaGhoSpbtqwXKwMAAJ7k1cCxZcsWPfjgg477/fv3lyTFx8crMTHRS1UBAABP82rgiI2NlTHGmyUAAICbgGM4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAsR+AAAACWI3AAAADLETgAAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4AAAAJYjcAAAAMsROAAAgOUIHAAAwHIEDgAAYDkCBwAAsByBAwAAWI7AAQAALEfgAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABY7pYIHFOmTFH58uWVP39+3X///dq0aZO3SwIAAB7k9cDx6aefqn///hoxYoSSkpJ09913Ky4uTseOHfN2aQAAwEO8HjgmTJigbt26qUuXLoqKitLUqVNVoEAB/d///Z+3SwMAAB7i583Oz58/r61bt2rIkCGOaT4+PnrooYf03Xff5Vg+IyNDGRkZjvspKSmSpNTUVI/WZc9I82h7wK3M0+vPzcS6in8ST6+r2e0ZYzza7pV4NXAcP35cWVlZCg8Pd5oeHh6u3bt351h+zJgxSkhIyDG9TJkyltUI5HXBk7xdAQBXWLWunj59WsHBwdY0fgmvBg53DRkyRP3793fct9vtOnnypIoWLSqbzebFynCjUlNTVaZMGR0+fFhBQUHeLgfAFbCu5h3GGJ0+fVp33HHHTenPq4GjWLFi8vX11V9//eU0/a+//lKJEiVyLB8QEKCAgACnaSEhIVaWiJssKCiIjRhwG2BdzRtuxshGNq8eNOrv76/o6GitXLnSMc1ut2vlypWqU6eOFysDAACe5PVdKv3791d8fLxq1aql2rVra9KkSTp79qy6dOni7dIAAICHeD1wtG/fXn///beGDx+uP//8UzVr1tTSpUtzHEiKvC0gIEAjRozIscsMwK2FdRXXy2Zu1vkwAADgH8vrF/4CAAB5H4EDAABYjsABAAAsR+DALadz585q06aN435sbKxeeukllx7rzrIAgJvH62epANeyYMEC5cuXz9tlAHlG586dlZycrM8//9zbpeAfhMCBW15oaKi3SwDyhKysLH4GAl7DLhW4xW63a8yYMapQoYICAwN19913a968eZKk1atXy2azaeXKlapVq5YKFCigunXras+ePU5tjB49WsWLF1fhwoX13HPPafDgwapZs+YV+7x8N8m7776rO++8U/nz51d4eLgef/zxHDUOGjRIoaGhKlGihEaOHOmppw/cVLGxserVq5d69eql4OBgFStWTMOGDXP8uuepU6fUqVMnFSlSRAUKFFDz5s21b98+x+MTExMVEhKi//3vf4qKilJAQIC6du2qGTNm6IsvvpDNZpPNZtPq1asd629ycrLj8du2bZPNZtOhQ4cc06ZNm6YyZcqoQIECatu2rSZMmOD0ExOX7xKVpJdeekmxsbGO+1fbjmQ/r44dOyosLEyBgYG68847NX36dMf8w4cPq127dgoJCVFoaKhat27tVCNuTQQOuGXMmDH66KOPNHXqVO3cuVP9+vXT008/rW+//daxzNChQzV+/Hht2bJFfn5+6tq1q2PerFmz9Oqrr+qNN97Q1q1bVbZsWb333nsu979lyxb16dNHo0aN0p49e7R06VLFxMQ4LTNjxgwVLFhQ33//vcaOHatRo0Zp+fLlN/7kAS+YMWOG/Pz8tGnTJr311luaMGGCPvzwQ0kXP9y3bNmi//3vf/ruu+9kjNHDDz+sCxcuOB6flpamN954Qx9++KF27typt99+W+3atVOzZs109OhRHT16VHXr1nWplvXr1+v5559X3759tW3bNjVp0kSvvvqq28/pWtuRYcOG6eeff9aSJUu0a9cuvffeeypWrJgk6cKFC4qLi1PhwoW1du1arV+/XoUKFVKzZs10/vx5t2vBTWQAF6Wnp5sCBQqYDRs2OE1/9tlnTYcOHcw333xjJJkVK1Y45n311VdGkjl37pwxxpj777/f9OzZ0+nx9erVM3fffbfjfnx8vGndurXjfsOGDU3fvn2NMcbMnz/fBAUFmdTU1FxrbNiwoalfv77TtPvuu8+8/PLL7j5dwOsaNmxoIiMjjd1ud0x7+eWXTWRkpNm7d6+RZNavX++Yd/z4cRMYGGg+++wzY4wx06dPN5LMtm3bnNq9fB0zxjjW31OnTjmm/fDDD0aSOXjwoDHGmPbt25sWLVo4Pa5jx44mODj4qm337dvXNGzY0Bhz7e2IMca0atXKdOnSJdfXZObMmaZy5cpOr0lGRoYJDAw0y5Yty/UxuDUwwgGX7d+/X2lpaWrSpIkKFSrkuH300Uf65ZdfHMvVqFHD8f+SJUtKko4dOyZJ2rNnj2rXru3U7uX3r6ZJkyYqV66cIiIi9Mwzz2jWrFlKS0tzWubS/rNryO4fuN088MADTsdd1KlTR/v27dPPP/8sPz8/3X///Y55RYsWVeXKlbVr1y7HNH9//xzrxPW60fVXcm078sILL+iTTz5RzZo1NWjQIG3YsMHx+O3bt2v//v0qXLiw47GhoaFKT0932g7h1sNBo3DZmTNnJElfffWVSpUq5TQvICDAsbJfekZJ9obSbrd7pIbChQsrKSlJq1ev1tdff63hw4dr5MiR2rx5s2M/8uVntNhsNo/1D9xuAgMDXTpQ1Mfn4vdPc8mvXVy6a8ZVPj4+Tm1c3s61tiOS1Lx5c/36669avHixli9frsaNG6tnz5568803debMGUVHR2vWrFk5+g4LC3O7Xtw8jHDAZdkHnf3222+qVKmS061MmTIutVG5cmVt3rzZadrl96/Fz89PDz30kMaOHasff/xRhw4d0qpVq9xqA7hdfP/99073N27cqDvvvFNRUVHKzMx0mn/ixAnt2bNHUVFRV23T399fWVlZTtOyP6yPHj3qmLZt2zanZVxZf8PCwpzauLwdV7cjYWFhio+P18cff6xJkybpgw8+kCTde++92rdvn4oXL57j8cHBwVd93vAuRjjgssKFC2vAgAHq16+f7Ha76tevr5SUFK1fv15BQUEqV67cNdvo3bu3unXrplq1aqlu3br69NNP9eOPPyoiIsKlGhYtWqQDBw4oJiZGRYoU0eLFi2W321W5cuUbfXrALem3335T//791aNHDyUlJemdd97R+PHjdeedd6p169bq1q2b3n//fRUuXFiDBw9WqVKl1Lp166u2Wb58eS1btkx79uxR0aJFFRwc7PjAHzlypF599VXt3btX48ePd3pc7969FRMTowkTJqhVq1ZatWqVlixZ4jSC0qhRI40bN04fffSR6tSpo48//lg//fST7rnnHknX3o7Ex8dr+PDhio6OVtWqVZWRkaFFixYpMjJSktSxY0eNGzdOrVu31qhRo1S6dGn9+uuvWrBggQYNGqTSpUt7+C8AT2GEA2555ZVXNGzYMI0ZM0aRkZFq1qyZvvrqK1WoUMGlx3fs2FFDhgzRgAEDdO+99+rgwYPq3Lmz8ufP79LjQ0JCtGDBAjVq1EiRkZGaOnWq5syZo6pVq97I0wJuWZ06ddK5c+dUu3Zt9ezZU3379lX37t0lSdOnT1d0dLRatmypOnXqyBijxYsXX/NCed26dVPlypVVq1YthYWFaf369cqXL5/mzJmj3bt3q0aNGnrjjTc0evRop8fVq1dPU6dO1YQJE3T33Xdr6dKl6tevn9P6GxcXp2HDhmnQoEG67777dPr0aXXq1MmpnWttR/z9/TVkyBDVqFFDMTEx8vX11SeffCJJKlCggNasWaOyZcvq0UcfVWRkpJ599lmlp6crKCjohl9vWIefp4fXNWnSRCVKlNDMmTO9XQpwS4mNjVXNmjU1adIkb5dyRd26ddPu3bu1du1ab5eCWxy7VHBTpaWlaerUqYqLi5Ovr6/mzJmjFStWcJ0M4Dbx5ptvqkmTJipYsKCWLFmiGTNm6N133/V2WbgNEDhwU9lsNi1evFivvvqq0tPTVblyZc2fP18PPfSQt0sD4IJNmzZp7NixOn36tCIiIvT222/rueee83ZZuA2wSwUAAFiOg0YBAIDlCBwAAMByBA4AAGA5AgcAALAcgQMAAFiOwAEAACxH4ADysM6dO6tNmzbeLgMACBwAAMB6BA7gH2rChAmqXr26ChYsqDJlyujFF1/UmTNnHPMTExMVEhKiZcuWKTIyUoUKFVKzZs2cfno8MzNTffr0UUhIiIoWLaqXX35Z8fHxTqMq5cuXz/FbIDVr1tTIkSNdrkWSpk2bpjJlyqhAgQJq27atJkyYoJCQEKdlvvjiC917773Knz+/IiIilJCQoMzMzBt+rQDcOAIH8A/l4+Ojt99+Wzt37tSMGTO0atUqDRo0yGmZtLQ0vfnmm5o5c6bWrFmj3377TQMGDHDMf+ONNzRr1ixNnz5d69evV2pqqj7//HOP17J+/Xo9//zz6tu3r7Zt26YmTZro1VdfdWpj7dq16tSpk/r27auff/5Z77//vhITE3MsB8BLDIA8Kz4+3rRu3dqlZefOnWuKFi3quD99+nQjyezfv98xbcqUKSY8PNxxPzw83IwbN85xPzMz05QtW9apz3LlypmJEyc69XX33XebESNGuFxL+/btTYsWLZyW6dixowkODnbcb9y4sXnttdeclpk5c6YpWbLkFfsBcPPw423AP9SKFSs0ZswY7d69W6mpqcrMzFR6errS0tJUoEABSVKBAgVUsWJFx2NKliypY8eOSZJSUlL0119/qXbt2o75vr6+io6Olt1u92gte/bsUdu2bZ0eU7t2bS1atMhxf/v27Vq/fr3TiEZWVlaO5wTAO9ilAvwDHTp0SC1btlSNGjU0f/58bd26VVOmTJEknT9/3rFcvnz5nB5ns9lk3Py9Rx8fnxyPuXDhgtu1XMuZM2eUkJCgbdu2OW47duzQvn37lD9/frdqBuB5jHAA/0Bbt26V3W7X+PHj5eNz8XvHZ5995lYbwcHBCg8P1+bNmxUTEyPp4ohCUlKSatas6VguLCzM6UDT1NRUHTx40K1aKleurM2bNztNu/z+vffeqz179qhSpUpuPQ8ANweBA8jjUlJStG3bNqdpxYoV04ULF/TOO++oVatWWr9+vaZOnep2271799aYMWNUqVIlValSRe+8845OnTolm83mWKZRo0ZKTExUq1atFBISouHDh8vX19cxv1KlStespXfv3oqJidGECRPUqlUrrVq1SkuWLHHqZ/jw4WrZsqXKli2rxx9/XD4+Ptq+fbt++uknjR492u3nBsDDvH0QCQDrxMfHG0k5bs8++6yZMGGCKVmypAkMDDRxcXHmo48+MpLMqVOnjDEXDxq99KBMY4xZuHChuXSzceHCBdOrVy8TFBRkihQpYl5++WXzxBNPmCeffNKxTEpKimnfvr0JCgoyZcqUMYmJiTkOGr1WLcYY88EHH5hSpUqZwMBA06ZNGzN69GhTokQJp/qWLl1q6tatawIDA01QUJCpXbu2+eCDDzz2egK4fjZj3NwhCwBXYLfbFRkZqXbt2umVV16xtK9u3bpp9+7dWrt2raX9APAMdqkAuG6//vqrvv76azVs2FAZGRmaPHmyDh48qKeeesrjfb355ptq0qSJChYsqCVLlmjGjBl69913Pd4PAGsQOABcNx8fHyUmJmrAgAEyxqhatWpasWKFIiMjPd7Xpk2bNHbsWJ0+fVoRERF6++239dxzz3m8HwDWYJcKAACwHNfhAAAAliNwAAAAyxE4AACA5QgcAADAcgQOAABgOQIHAACwHIEDAABYjsABAAAs9/8AYKMB+nYDpiYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Crnea              4                 1     10                      40.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                         10.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               theme  match_english  match_portuguese  Total  \\\n",
      "0  Crnea/Cristalino              1                 0      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     100.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        theme  match_english  match_portuguese  Total  \\\n",
      "0  Estrabismo              3                 3     11   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                 27.272727                    27.272727  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          theme  match_english  match_portuguese  Total  \\\n",
      "0  Farmacologia              5                 4      9   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                 55.555556                    44.444444  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   theme  match_english  match_portuguese  Total  \\\n",
      "0  Farmacologia/Glaucoma              0                 0      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Glaucoma              3                 3      7                 42.857143   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    42.857143  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       theme  match_english  match_portuguese  Total  \\\n",
      "0  Glaucoma               1                 0      2   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                      50.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             theme  match_english  match_portuguese  Total  \\\n",
      "0  Glaucoma/Uvete              0                 0      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               theme  match_english  match_portuguese  Total  \\\n",
      "0  Lentes de Contato              0                 0      3   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              theme  match_english  match_portuguese  Total  \\\n",
      "0  Neuroftalmologia              0                 1      7   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                    14.285714  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       theme  match_english  match_portuguese  Total  \\\n",
      "0  Oncologia/Plstica Ocular              1                 0      3   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                 33.333333                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             theme  match_english  match_portuguese  Total  \\\n",
      "0  Plstica Ocular              3                 4     16   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     18.75                         25.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Refrao              9                 8     31                 29.032258   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    25.806452  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      theme  match_english  match_portuguese  Total  \\\n",
      "0  Refrao/Viso subnormal              0                 0      2   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Retina              6                 2     12                      50.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                    16.666667  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              theme  match_english  match_portuguese  Total  \\\n",
      "0  Retina/Oncologia              0                 0      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                       0.0                          0.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  Uvete              4                 2      8                      50.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                         25.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             theme  match_english  match_portuguese  Total  \\\n",
      "0  Viso subnormal              1                 1      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     100.0                        100.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    theme  match_english  match_portuguese  Total  english_ratio_percentage  \\\n",
      "0  ptica              0                 1      1                       0.0   \n",
      "\n",
      "   portuguese_ratio_percentage  \n",
      "0                        100.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             theme  match_english  match_portuguese  Total  \\\n",
      "0  ptica/Refrao              1                 1      1   \n",
      "\n",
      "   english_ratio_percentage  portuguese_ratio_percentage  \n",
      "0                     100.0                        100.0  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEMPERATURE = str(TEMPERATURE).replace('.', '_')\n",
    "\n",
    "run_analysis(model=MODEL, temperature=TEMPERATURE, n_repetitions=N_REPETITIONS, languages=LANGUAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1743df60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>year</th>\n",
       "      <th>theme</th>\n",
       "      <th>match_english</th>\n",
       "      <th>match_portuguese</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Terica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Anatomia</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Crnea</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Terica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Embriologia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Farmacologia</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Gentica</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Terica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Terica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Oncologia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Terica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Refrao</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Terica I</td>\n",
       "      <td>2022</td>\n",
       "      <td>Retina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Cirurgia Refrativa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Cirurgia Refrativva</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Cristalino/Catarata</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Crnea</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Crnea/Cristalino</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Estrabismo</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Farmacologia</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Farmacologia/Glaucoma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Glaucoma/Uvete</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Lentes de Contato</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Neuroftalmologia</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Oncologia/Plstica Ocular</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Plstica Ocular</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Refrao</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Refrao/Viso subnormal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Retina</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Retina/Oncologia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Uvete</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>Viso subnormal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>ptica</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Terica II</td>\n",
       "      <td>2022</td>\n",
       "      <td>ptica/Refrao</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          test  year                      theme  match_english  \\\n",
       "0    Terica I  2022                   Anatomia              4   \n",
       "1    Terica I  2022                     Crnea              1   \n",
       "2    Terica I  2022                Embriologia              1   \n",
       "3    Terica I  2022               Farmacologia              2   \n",
       "4    Terica I  2022                   Gentica              0   \n",
       "5    Terica I  2022                   Glaucoma              1   \n",
       "6    Terica I  2022                  Oncologia              1   \n",
       "7    Terica I  2022                   Refrao              3   \n",
       "8    Terica I  2022                     Retina              0   \n",
       "9   Terica II  2022         Cirurgia Refrativa              1   \n",
       "10  Terica II  2022        Cirurgia Refrativva              0   \n",
       "11  Terica II  2022        Cristalino/Catarata              3   \n",
       "12  Terica II  2022                     Crnea              3   \n",
       "13  Terica II  2022          Crnea/Cristalino              1   \n",
       "14  Terica II  2022                 Estrabismo              3   \n",
       "15  Terica II  2022               Farmacologia              3   \n",
       "16  Terica II  2022      Farmacologia/Glaucoma              0   \n",
       "17  Terica II  2022                   Glaucoma              2   \n",
       "18  Terica II  2022                  Glaucoma               1   \n",
       "19  Terica II  2022            Glaucoma/Uvete              0   \n",
       "20  Terica II  2022          Lentes de Contato              0   \n",
       "21  Terica II  2022           Neuroftalmologia              0   \n",
       "22  Terica II  2022  Oncologia/Plstica Ocular              1   \n",
       "23  Terica II  2022            Plstica Ocular              3   \n",
       "24  Terica II  2022                   Refrao              6   \n",
       "25  Terica II  2022   Refrao/Viso subnormal              0   \n",
       "26  Terica II  2022                     Retina              6   \n",
       "27  Terica II  2022           Retina/Oncologia              0   \n",
       "28  Terica II  2022                     Uvete              4   \n",
       "29  Terica II  2022            Viso subnormal              1   \n",
       "30  Terica II  2022                     ptica              0   \n",
       "31  Terica II  2022            ptica/Refrao              1   \n",
       "\n",
       "    match_portuguese  Total  \n",
       "0                  5     21  \n",
       "1                  1      1  \n",
       "2                  1      2  \n",
       "3                  2      3  \n",
       "4                  0      2  \n",
       "5                  0      1  \n",
       "6                  0      1  \n",
       "7                  0     12  \n",
       "8                  0      1  \n",
       "9                  1      1  \n",
       "10                 1      1  \n",
       "11                 5      8  \n",
       "12                 0      9  \n",
       "13                 0      1  \n",
       "14                 3     11  \n",
       "15                 2      6  \n",
       "16                 0      1  \n",
       "17                 3      6  \n",
       "18                 0      2  \n",
       "19                 0      1  \n",
       "20                 0      3  \n",
       "21                 1      7  \n",
       "22                 0      3  \n",
       "23                 4     16  \n",
       "24                 8     19  \n",
       "25                 0      2  \n",
       "26                 2     11  \n",
       "27                 0      1  \n",
       "28                 2      8  \n",
       "29                 1      1  \n",
       "30                 1      1  \n",
       "31                 1      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_REPETITIONS = 1 if N_REPETITIONS < 1 else N_REPETITIONS\n",
    "pd.read_csv(f'results/results_{MODEL}_Temperature{TEMPERATURE}_Repetitions{N_REPETITIONS}/matches_results_{MODEL}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025a628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_bias_vpython=3_8_15]",
   "language": "python",
   "name": "conda-env-nlp_bias_vpython_3_8_15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
